<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jonchan1013.github.io</id>
    <title>CY的学习博客</title>
    <updated>2020-08-19T18:14:54.922Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jonchan1013.github.io"/>
    <link rel="self" href="https://jonchan1013.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://jonchan1013.github.io/images/avatar.png</logo>
    <icon>https://jonchan1013.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, CY的学习博客</rights>
    <entry>
        <title type="html"><![CDATA[Docker]]></title>
        <id>https://jonchan1013.github.io/post/docker/</id>
        <link href="https://jonchan1013.github.io/post/docker/">
        </link>
        <updated>2020-08-15T06:53:42.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200815145424.png" alt="" loading="lazy"></figure>
<h2 id="1-容器介绍">1、容器介绍</h2>
<p>容器其实是⼀种沙盒技术。顾名思义，沙盒就是能够像⼀个集装箱⼀样，把你的应⽤&quot;装&quot;起来的技术。这样，应⽤与应⽤之间，就因为有了边界⽽不⾄于相互⼲扰；⽽被装进集装箱的应⽤，也可以被⽅便地搬来搬去，这其实是 PaaS 最理想的状态。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200815145424.png" alt="" loading="lazy"></figure>
<h2 id="1-容器介绍">1、容器介绍</h2>
<p>容器其实是⼀种沙盒技术。顾名思义，沙盒就是能够像⼀个集装箱⼀样，把你的应⽤&quot;装&quot;起来的技术。这样，应⽤与应⽤之间，就因为有了边界⽽不⾄于相互⼲扰；⽽被装进集装箱的应⽤，也可以被⽅便地搬来搬去，这其实是 PaaS 最理想的状态。</p>
<!-- more -->
<p><strong>问题：容器的本质到底是什么？</strong><br>
容器的本质是进程。容器就是未来云计算系统中的进程；容器镜像就是这个系统⾥的&quot;.exe&quot;安装包。Kubernetes 就是操作系统！</p>
<h3 id="11-docker介绍">1.1 Docker介绍</h3>
<h4 id="111-docker公司认知">1.1.1 Docker公司认知</h4>
<p>官⽹地址：docker.io docker.com</p>
<p>公司名称：原名dotCloud  14年改名为docker</p>
<p>容器产品：docker 16年已经被更名为Moby</p>
<h4 id="112-容器简史">1.1.2 容器简史</h4>
<p>和虚拟机⼀样，容器技术也是⼀种资源隔离的虚拟化技术。我们追溯它的历史，会发现它的技术雏形早已有之。</p>
<p>容器概念始于 1979 年提出的 UNIX chroot，它是⼀个 UNIX 操作系统的系统调⽤，将⼀个进程及其⼦进程的根⽬录改变到⽂件系统中的⼀个新位置，让这些进程只能访问到这个新的位置，从⽽达到了进程隔离的⽬的。</p>
<p>2000 年的时候 FreeBSD 开发了⼀个类似于 chroot 的容器技术 Jails，这是最早期，也是功能最多的容器技术。Jails 英译过来是监狱的意思，这个“监狱”（⽤沙盒更为准确）包含了⽂件系统、⽤户、⽹络、进程等的隔离。</p>
<p>2001 Linux 也发布⾃⼰的容器技术 Linux VServer，2004 Solaris 也发布了 Solaris Containers，两者都将资源进⾏划分，形成⼀个个 zones，⼜叫做虚拟服务器。</p>
<p>2005 年推出 OpenVZ，它通过对 Linux 内核进⾏补丁来提供虚拟化的⽀持，每个 OpenVZ 容器完整⽀持了⽂件系统、⽤户及⽤户、进程、⽹络、设备和 IPC 对象的隔离。</p>
<p>2007 年 Google 实现了 Control Groups( cgroups )，并加⼊到 Linux 内核中，这是划时代的，为后期容器的资源配额提供了技术保障。</p>
<p>2008 年基于 cgroups 和 linux namespace 推出了第⼀个最为完善的 Linux 容器 LXC。</p>
<p>2013 年推出到现在为⽌最为流⾏和使⽤最⼴泛的容器 Docker，相⽐其他早期的容器技术，Docker 引⼊了⼀整套容器管理的⽣态系统，包括分层的镜像模型，容器注册库，友好的 Rest API。</p>
<p>2014 年 CoreOS 也推出了⼀个类似于 Docker 的容器 Rocket，CoreOS ⼀个更加轻量级的 Linux 操作系统，在安全性上⽐ Docker 更严格。</p>
<p>2016 年微软也在 Windows 上提供了容器的⽀持，Docker 可以以原⽣⽅式运⾏在 Windows 上，⽽不是需要使⽤ Linux 虚拟机。</p>
<p>基本上到这个时间节点，容器技术就已经很成熟了，再往后就是容器云的发展，由此也衍⽣出多种容器云的平台管理技术，其中以 kubernetes 最为出众，有了这样⼀些细粒度的容器集群管理技术，也为微服务的发展奠定了基⽯。因此，对于未来来说，应⽤的微服务化是⼀个较⼤的趋势。</p>
<h4 id="113-容器需求成因">1.1.3 容器需求成因</h4>
<p>其⼀，这是技术演进的⼀种创新结果，其⼆，这是⼈们追求⾼效⽣产活动的⼀种⼯具。</p>
<p>随着软件开发的发展，相⽐于早期的集中式应⽤部署⽅式，现在的应⽤基本都是采⽤分布式的部署⽅式，⼀个应⽤可能包含多种服务或多个模块，因此多种服务可能部署在多种环境中，如虚拟服务器、公有云、私有云等，由于多种服务之间存在⼀些依赖关系，所以可能存在应⽤在运⾏过程中的动态迁移问题，那这时如何保证不同服务在不同环境中都能平滑的适配，不需要根据环境的不同⽽去进⾏相应的定制，就显得尤为重要。</p>
<p>就像货物的运输问题⼀样，如何将不同的货物放在不同的运输机器上，减少因货物的不同⽽频繁进⾏货物的装载和卸载，浪费⼤量的⼈⼒物⼒。</p>
<p>为此⼈们发明了集装箱，将货物根据尺⼨形状等的不同，⽤不同规格的集装箱装载，然后再放到运输机上运输，由于集装箱密封，只有货物到达⽬的地才需拆封，在运输过程能够再不同运输机上平滑过渡，所以避免了资源的浪费。</p>
<p>因此集装箱被誉为是运输业与世界贸易最重要的发明。</p>
<p>Docker 容器的思想就是采⽤集装箱思想，为应⽤提供了⼀个基于容器的标准化运输系统。Docker 可以将任何应⽤及其依赖打包成⼀个轻量级、可移植、⾃包含的容器。容器可以运⾏在⼏乎所有的操作系统上。这样容器就可以跑在任何环境中，因此才有了那句话：Build Once, Run Anywhere</p>
<p>这种集装箱的思想我们也能从 Docker 的 Logo 中看出来，这不就是⼀堆集装箱吗？</p>
<h4 id="114-docker-vs-传统">1.1.4、Docker VS 传统</h4>
<p><strong>部署模式区别</strong></p>
<p>传统的部署模式：  安装(包管理⼯具或者源码包编译)-&gt;配置-&gt;运⾏</p>
<p>Docker部署模式：复制-&gt;运⾏</p>
<p><strong>容器和虚拟机区别</strong></p>
<ol>
<li>容器提供了基于进程的隔离，⽽虚拟机提供了资源的完全隔离。</li>
<li>虚拟机可能需要⼀分钟来启动，⽽容器只需要⼀秒钟或更短。</li>
<li>容器使⽤宿主操作系统的内核，⽽虚拟机使⽤独⽴的内核</li>
<li>容器只是⼀个进程，⽽虚拟机不是</li>
</ol>
<p><strong>Docker对服务器端开发/部署带来的变化：</strong></p>
<p>实现更轻量级的虚拟化，⽅便快速部署</p>
<p>对于部署来说可以极⼤的减少部署的时间成本和⼈⼒成本</p>
<p>Docker⽀持将应⽤打包进⼀个可以移植的容器中，重新定义了应⽤开发，测试，部署上线的过程，核⼼<br>
理念就</p>
<p>是 Build once, Run anywhere</p>
<p>1）标准化应⽤发布，docker容器包含了运⾏环境和可执⾏程序，可以跨平台和主机使⽤；</p>
<p>2）节约时间，快速部署和启动，VM启动⼀般是分钟级，docker容器启动是秒级；</p>
<p>3）⽅便构建基于SOA架构或微服务架构的系统，通过服务编排，更好的松耦合；</p>
<p>4）节约成本，以前⼀个虚拟机⾄少需要⼏个G的磁盘空间，docker容器可以减少到MB级；</p>
<p>5）⽅便持续集成，通过与代码进⾏关联使持续集成⾮常⽅便；</p>
<p>6）可以作为集群系统的轻量主机或节点，在IaaS平台上，已经出现了CaaS，通过容器替代原来的主机。</p>
<p><strong>Docker 优势</strong></p>
<p>1、交付物标准化</p>
<p>Docker是软件⼯程领域的&quot;标准化&quot;交付组件，最恰到好处的类⽐是&quot;集装箱&quot;。</p>
<p>集装箱将零散、不易搬运的⼤量物品封装成⼀个整体，集装箱更重要的意义在于它提供了⼀种通⽤的封装货物的</p>
<p>标准，卡⻋、⽕⻋、货轮、桥吊等运输或搬运⼯具采⽤此标准，隧道、桥梁等也采⽤此标准。以集装箱为中⼼的</p>
<p>标准化设计⼤⼤提⾼了物流体系的运⾏效率。</p>
<p>传统的软件交付物包括：应⽤程序、依赖软件安装包、配置说明⽂档、安装⽂档、上线⽂档等⾮标准化组件。</p>
<p>Docker的标准化交付物称为&quot;镜像&quot;，它包含了应⽤程序及其所依赖的运⾏环境，⼤⼤简化了应⽤交付的模式。</p>
<p>2、⼀次构建，多次交付</p>
<p>类似于集装箱的&quot;⼀次装箱，多次运输&quot;，Docker镜像可以做到&quot;⼀次构建，多次交付&quot;。当涉及到应⽤程序多副本</p>
<p>部署或者应⽤程序迁移时，更能体现Docker的价值。</p>
<p>3、应⽤隔离</p>
<p>集装箱可以有效做到货物之间的隔离，使化学物品和⻝品可以堆砌在⼀起运输。Docker可以隔离不同应<br>
⽤程序之间的相互影响，但是⽐虚拟机开销更⼩。</p>
<p>总之，容器技术部署速度快，开发、测试更敏捷；提⾼系统利⽤率，降低资源成本。</p>
<p><strong>Docker的度量</strong></p>
<p>Docker是利⽤容器来实现的⼀种轻量级的虚拟技术，从⽽在保证隔离性的同时达到节省资源的⽬的。<br>
Docker的可移植性可以让它⼀次建⽴，到处运⾏。Docker的度量可以从以下四个⽅⾯进⾏：</p>
<p>1）隔离性</p>
<p>Docker采⽤libcontainer作为默认容器，代替了以前的LXC。libcontainer的隔离性主要是通过内核的命名空 间来实现 的，有pid、net、ipc、mnt、uts命令空间，将容器的进程、⽹络、消息、⽂件系统和主机名进⾏隔 离。</p>
<p>2）可度量性</p>
<p>Docker主要通过cgroups控制组来控制资源的度量和分配。</p>
<p>3）移植性</p>
<p>Docker利⽤AUFS来实现对容器的快速更新。</p>
<p>AUFS是⼀种⽀持将不同⽬录挂载到同⼀个虚拟⽂件系统下的⽂件系统，⽀持对每个⽬录的读写权限管理。AUFS具有层 的概念，每⼀次修改都是在已有的只写层进⾏增量修改，修改的内容将形成新的⽂件层，不影响原有的层。</p>
<p>4）安全性</p>
<p>安全性可以分为容器内部之间的安全性；容器与托管主机之间的安全性。</p>
<p>容器内部之间的安全性主要是通过命名空间和cgroups来保证的。</p>
<p>容器与托管主机之间的安全性主要是通过内核能⼒机制的控制，可以防⽌Docker⾮法⼊侵托管主机。</p>
<p><strong>Docker容器使⽤AUFS作为⽂件系统，有如下优势</strong></p>
<p>1）节省存储空间</p>
<p>多个容器可以共享同⼀个基础镜像存储。</p>
<p>2）快速部署</p>
<p>如果部署多个来⾃同⼀个基础镜像的容器时，可以避免多次复制操作。</p>
<p>3）升级⽅便</p>
<p>升级⼀个基础镜像即可影响到所有基于它的容器。</p>
<p>4）增量修改</p>
<p>可以在不改变基础镜像的同时修改其⽬录的⽂件，所有的更⾼都发⽣在最上层的写操作层，增加了基础镜像的可共享内容。</p>
<h4 id="115-容器的应用场景">1.1.5、 容器的应⽤场景</h4>
<ol>
<li><strong>简化配置</strong></li>
</ol>
<p>这是Docker公司宣传的Docker的主要使⽤场景。虚拟机的最⼤好处是能在你的硬件设施上运⾏各种配置不⼀样的平台（软件、系统），Docker在降低额外开销的情况下提供了同样的功能。它能让你将运⾏环境和配置放在代码中然后部署，同⼀个Docker的配置可以在不同的环境中使⽤，这样就降低了硬件要求和应⽤环境之间耦合度。</p>
<ol start="2">
<li><strong>代码流⽔线管理</strong></li>
</ol>
<p>前⼀个场景对于管理代码的流⽔线起到了很⼤的帮助。代码从开发者的机器到最终在⽣产环境上的部署，需要经过很多的中间环境。⽽每⼀个中间环境都有⾃⼰微⼩的差别，Docker给应⽤提供了⼀个从开发到上线均⼀致的环境，让代码的流⽔线变得简单不少。</p>
<ol start="3">
<li><strong>提⾼开发效率</strong></li>
</ol>
<p>这就带来了⼀些额外的好处：Docker能提升开发者的开发效率。如果你想看⼀个详细⼀点的例⼦，可以参考Aater在DevOpsDays Austin 2014 ⼤会或者是DockerCon上的演讲。</p>
<p>不同的开发环境中，我们都想把两件事做好。⼀是我们想让开发环境尽量贴近⽣产环境，⼆是我们想快速搭建开发环境。</p>
<p>理想状态中，要达到第⼀个⽬标，我们需要将每⼀个服务都跑在独⽴的虚拟机中以便监控⽣产环境中服务的运⾏状态。然⽽，我们却不想每次都需要⽹络连接，每次重新编译的时候远程连接上去特别麻烦。这就是Docker做的特别好的地⽅，开发环境的机器通常内存⽐较⼩，之前使⽤虚拟的时候，我们经常需要为开发环境的机器加内存，⽽现在Docker可以轻易的让⼏⼗个服务在Docker中跑起来。</p>
<ol start="4">
<li><strong>隔离应⽤</strong></li>
</ol>
<p>有很多种原因会让你选择在⼀个机器上运⾏不同的应⽤，⽐如之前提到的提⾼开发效率的场景等。</p>
<p>我们经常需要考虑两点，⼀是因为要降低成本⽽进⾏服务器整合，⼆是将⼀个整体式的应⽤拆分成松耦合的单个服务（译者注：微服务架构）。如果你想了解为什么松耦合的应⽤这么重要，请参考Steve Yege的这篇论⽂，⽂中将Google和亚⻢逊做了⽐较。</p>
<ol start="5">
<li><strong>整合服务器</strong></li>
</ol>
<p>正如通过虚拟机来整合多个应⽤，Docker隔离应⽤的能⼒使得Docker可以整合多个服务器以降低成本。由于没有多个操作系统的内存占⽤，以及能在多个实例之间共享没有使⽤的内存，Docker可以⽐虚拟机提供更好的服务器整合解决⽅案。</p>
<ol start="6">
<li><strong>调试能⼒</strong></li>
</ol>
<p>Docker提供了很多的⼯具，这些⼯具不⼀定只是针对容器，但是却适⽤于容器。它们提供了很多的功能，包括可以为容器设置检查点、设置版本和查看两个容器之间的差别，这些特性可以帮助调试Bug。你可以在《Docker拯救世界》的⽂章中找到这⼀点的例证。</p>
<ol start="7">
<li><strong>多租户环境</strong></li>
</ol>
<p>另外⼀个Docker有意思的使⽤场景是在多租户的应⽤中，它可以避免关键应⽤的重写。我们⼀个特别的关于这个场景的例⼦是为物联⽹的应⽤开发⼀个快速、易⽤的多租户环境。这种多租户的基本代码⾮常复杂，很难处理，重新规划这样⼀个应⽤不但消耗时间，也浪费⾦钱。</p>
<p>使⽤Docker，可以为每⼀个租户的应⽤层的多个实例创建隔离的环境，这不仅简单⽽且成本低廉，当然这⼀切得益于Docker环境的启动速度和其⾼效的命令。</p>
<ol start="8">
<li><strong>快速部署</strong></li>
</ol>
<p>在虚拟机之前，引⼊新的硬件资源需要消耗⼏天的时间。虚拟化技术将这个时间缩短到了分钟级别。⽽Docker通过为进程仅仅创建⼀个容器⽽⽆需启动⼀个操作系统，再次将这个过程缩短到了秒级。这正是Google和Facebook都看重的特性。</p>
<h3 id="12-docker容器历史解读扩展阅读">1.2 Docker容器历史解读【扩展阅读】</h3>
<p><strong>PaaS</strong></p>
<p>从过去以物理机和虚拟机为主体的开发运维环境，向以容器为核⼼的基础设施的转变过程，并不是⼀次温和的改⾰，⽽是涵盖了对⽹络、存储、调度、操作系统、分布式原理等各个⽅⾯的容器化理解和改造。</p>
<p>2013 年的后端技术领域，已经太久没有出现过令⼈兴奋的东⻄了。曾经被⼈们寄予厚望的云计算技术，也已经从当初虚⽆缥缈的概念蜕变成了实实在在的虚拟机和账单。⽽相⽐于如⽇中天 AWS 和盛极⼀时的 OpenStack，以 Cloud Foundry 为代表的开源 PaaS 项⽬，却成为了当时云计算技术中的⼀股清流。</p>
<p>当时，Cloud Foundry 项⽬已经基本度过了最艰难的概念普及和⽤户教育阶段，吸引了包括百度、京东、华为、IBM 等⼀⼤批国内外技术⼚商，开启了以开源 PaaS 为核⼼构建平台层服务能⼒的变⾰。如果你有机会问问当时的云计算从业者们，他们⼗有⼋九都会告诉你：PaaS 的时代就要来了！</p>
<p>这个说法其实⼀点⼉没错，如果不是后来⼀个叫 Docker 的开源项⽬突然冒出来的话。</p>
<p>事实上，当时还名叫 dotCloud 的 Docker 公司，也是这股 PaaS 热潮中的⼀份⼦。只不过相⽐于 Heroku、Pivotal、Red Hat 等 PaaS 弄潮⼉们，dotCloud 公司实在是太微不⾜道了，⽽它的主打产品由于跟主流的 Cloud Foundry 社区脱节，⻓期以来也⽆⼈问津。眼看就要被如⽕如荼的 PaaS ⻛潮抛弃，dotCloud 公司却做出了这样⼀个决定：开源⾃⼰的容器项⽬ Docker。</p>
<p>显然，这个决定在当时根本没⼈在乎。</p>
<p>&quot;容器&quot;这个概念从来就不是什么新鲜的东⻄，也不是 Docker 公司发明的。即使在当时最热⻔的 PaaS 项⽬ Cloud Foundry 中，容器也只是其最底层、最没⼈关注的那⼀部分。说到这⾥，正好以当时的事实标准 Cloud Foundry 为例，来解说⼀下 PaaS 技术。</p>
<p>PaaS 项⽬被⼤家接纳的⼀个主要原因，就是它提供了⼀种名叫&quot;应⽤托管&quot;的能⼒。 在当时，虚拟机和云计算已经是⽐较普遍的技术和服务了，那时主流⽤户的普遍⽤法，就是租⼀批 AWS 或者 OpenStack 的虚拟机，然后像以前管理物理服务器那样，⽤脚本或者⼿⼯的⽅式在这些机器上部署应⽤。</p>
<p>当然，这个部署过程难免会碰到云端虚拟机和本地环境不⼀致的问题，所以当时的云计算服务，⽐的就是谁能更好地模拟本地服务器环境，能带来更好的&quot;上云&quot;体验。⽽ PaaS 开源项⽬的出现，就是当时解决这个问题的⼀个最佳⽅案。</p>
<p>举个例⼦，虚拟机创建好之后，运维⼈员只需要在这些机器上部署⼀个 Cloud Foundry 项⽬，然后开发者只要执⾏⼀条命令就能把本地的应⽤部署到云上，这条命令就是：</p>
<pre><code class="language-shell">$ cf push &quot; 我的应⽤ &quot;
</code></pre>
<p>是不是很神奇？</p>
<p>事实上，像 Cloud Foundry 这样的 PaaS 项⽬，最核⼼的组件就是⼀套应⽤的打包和分发机制。 Cloud Foundry 为每种主流编程语⾔都定义了⼀种打包格式，⽽&quot;cf push&quot;的作⽤，基本上等同于⽤户把应⽤的可执⾏⽂件和启动脚本打进⼀个压缩包内，上传到云上 Cloud Foundry 的存储中。接着，Cloud<br>
Foundry 会通过调度器选择⼀个可以运⾏这个应⽤的虚拟机，然后通知这个机器上的 Agent 把应⽤压缩包下载下来启动。</p>
<p>这时候关键来了，由于需要在⼀个虚拟机上启动很多个来⾃不同⽤户的应⽤，Cloud Foundry 会调⽤操作系统的 Cgroups 和 Namespace 机制为每⼀个应⽤单独创建⼀个称作&quot;沙盒&quot;的隔离环境，然后在&quot;沙盒&quot;中启动这些应⽤进程。这样，就实现了把多个⽤户的应⽤互不⼲涉地在虚拟机⾥批量地、⾃动地运⾏起来的⽬的。</p>
<p>这，正是 PaaS 项⽬最核⼼的能⼒。 ⽽这些 Cloud Foundry ⽤来运⾏应⽤的隔离环境，或者说&quot;沙盒&quot;，就是所谓的&quot;容器&quot;。</p>
<p>⽽ Docker 项⽬，实际上跟 Cloud Foundry 的容器并没有太⼤不同，所以在它发布后不久，Cloud Foundry 的⾸席产品经理 James Bayer 就在社区⾥做了⼀次详细对⽐，告诉⽤户 Docker 实际上只是⼀个同样使⽤ Cgroups 和 Namespace 实现的&quot;沙盒&quot;⽽已，没有什么特别的⿊科技，也不需要特别关注。</p>
<pre><code class="language-shell">$ cf push &quot; 我的应⽤ &quot;
</code></pre>
<p>然⽽，短短⼏个⽉，Docker 项⽬就迅速崛起了。它的崛起速度如此之快，以⾄于 Cloud Foundry 以及所有的 PaaS 社区还没来得及成为它的竞争对⼿，就直接被宣告出局了。那时候，⼀位多年的 PaaS 从业者曾经如此感慨道：这简直就是⼀场&quot;降维打击&quot;啊。</p>
<p>事实上，Docker 项⽬确实与 Cloud Foundry 的容器在⼤部分功能和实现原理上都是⼀样的，可偏偏就是这剩下的⼀⼩部分不⼀样的功能，成了 Docker 项⽬接下来&quot;呼⻛唤⾬&quot;的不⼆法宝。</p>
<p>这个功能，就是 Docker 镜像。</p>
<p>恐怕连 Docker 项⽬的作者 Solomon Hykes ⾃⼰当时都没想到，这个⼩⼩的创新，在短短⼏年内就如此迅速地改变了整个云计算领域的发展历程。</p>
<p>前⾯已经介绍过，PaaS 之所以能够帮助⽤户⼤规模部署应⽤到集群⾥，是因为它提供了⼀套应⽤打包的功能。可就是这个打包功能，却成了 PaaS ⽇后不断遭到⽤户诟病的⼀个&quot;软肋&quot;。</p>
<p>出现这个问题的根本原因是，⼀旦⽤上了 PaaS，⽤户就必须为每种语⾔、每种框架，甚⾄每个版本的应⽤维护⼀个打好的包。这个打包过程，没有任何章法可循，更麻烦的是，明明在本地运⾏得好好的应⽤，却需要做很多修改和配置⼯作才能在 PaaS ⾥运⾏起来。⽽这些修改和配置，并没有什么经验可以借鉴，基本上得靠不断试错，直到你摸清楚了本地应⽤和远端 PaaS 匹配的&quot;脾⽓&quot;才能够搞定。</p>
<p>最后结局就是，&quot;cf push&quot;确实是能⼀键部署了，但是为了实现这个⼀键部署，⽤户为每个应⽤打包的⼯作可谓⼀波三折，费尽⼼机。</p>
<p>⽽Docker 镜像解决的，恰恰就是打包这个根本性的问题。 所谓 Docker 镜像，其实就是⼀个压缩包。但是这个压缩包⾥的内容，⽐ PaaS 的应⽤可执⾏⽂件 + 启停脚本的组合就要丰富多了。实际上，⼤多数 Docker 镜像是直接由⼀个完整操作系统的所有⽂件和⽬录构成的，所以这个压缩包⾥的内容跟你本地开发和测试环境⽤的操作系统是完全⼀样的。</p>
<p>这就有意思了：假设你的应⽤在本地运⾏时，能看⻅的环境是 CentOS 7.2 操作系统的所有⽂件和⽬录，那么只要⽤ CentOS 7.2 的 ISO 做⼀个压缩包，再把你的应⽤可执⾏⽂件也压缩进去，那么⽆论在哪⾥解压这个压缩包，都可以得到与你本地测试时⼀样的环境。当然，你的应⽤也在⾥⾯！</p>
<p>这就是 Docker 镜像最厉害的地⽅：只要有这个压缩包在⼿，你就可以使⽤某种技术创建⼀个&quot;沙盒&quot;，在&quot;沙盒&quot;中解压这个压缩包，然后就可以运⾏你的程序了。</p>
<p>更重要的是，这个压缩包包含了完整的操作系统⽂件和⽬录，也就是包含了这个应⽤运⾏所需要的所有依赖，所以你可以先⽤这个压缩包在本地进⾏开发和测试，完成之后，再把这个压缩包上传到云端运⾏。</p>
<p>在这个过程中，你完全不需要进⾏任何配置或者修改，因为这个压缩包赋予了你⼀种极其宝贵的能⼒：本地环境和云端环境的⾼度⼀致！</p>
<p>这，正是 Docker 镜像的精髓。</p>
<p>那么，有了 Docker 镜像这个利器，PaaS ⾥最核⼼的打包系统⼀下⼦就没了⽤武之地，最让⽤户抓狂的打包过程也随之消失了。相⽐之下，在当今的互联⽹⾥，Docker 镜像需要的操作系统⽂件和⽬录，可谓唾⼿可得。</p>
<p>所以，你只需要提供⼀个下载好的操作系统⽂件与⽬录，然后使⽤它制作⼀个压缩包即可，这个命令就：</p>
<pre><code class="language-shell">$ docker build 我的镜像
</code></pre>
<p>⼀旦镜像制作完成，⽤户就可以让 Docker 创建⼀个&quot;沙盒&quot;来解压这个镜像，然后在&quot;沙盒&quot;中运⾏⾃⼰的应⽤，这个命令就是：</p>
<pre><code class="language-shell">$ docker run &quot; 我的镜像 &quot;
</code></pre>
<p>当然，docker run 创建的&quot;沙盒&quot;，也是使⽤ Cgroups 和 Namespace 机制创建出来的隔离环境。</p>
<p>所以，Docker 项⽬给 PaaS 世界带来的&quot;降维打击&quot;，其实是提供了⼀种⾮常便利的打包机制。这种机制直接打包了应⽤运⾏所需要的整个操作系统，从⽽保证了本地环境和云端环境的⾼度⼀致，避免了⽤户通过&quot;试错&quot;来匹配两种不同运⾏环境之间差异的痛苦过程。</p>
<p>⽽对于开发者们来说，在终于体验到了⽣产⼒解放所带来的痛快之后，他们⾃然选择了⽤脚投票，直接宣告了 PaaS 时代的结束。</p>
<p>不过，Docker 项⽬固然解决了应⽤打包的难题，但正如前⾯所介绍的那样，它并不能代替 PaaS 完成⼤规模部署应⽤的职责。</p>
<p>遗憾的是，考虑到 Docker 公司是⼀个与⾃⼰有潜在竞争关系的商业实体，再加上对 Docker 项⽬普及程度的错误判断，Cloud Foundry 项⽬并没有第⼀时间使⽤ Docker 作为⾃⼰的核⼼依赖，去替换⾃⼰那套饱受诟病的打包流程。</p>
<p>反倒是⼀些机敏的创业公司，纷纷在第⼀时间推出了 Docker 容器集群管理的开源项⽬（⽐如 Deis 和 Flynn），它们⼀般称⾃⼰为 CaaS，即 ontainer-as-a-Service，⽤来跟&quot;过时&quot;的 PaaS 们划清界限。</p>
<p>⽽在 2014 年底的 DockerCon 上，Docker 公司雄⼼勃勃地对外发布了⾃家研发的&quot;Docker 原⽣&quot;容器集群管理项⽬ Swarm，不仅将这波&quot;CaaS&quot;热推向了⼀个前所未有的⾼潮，更是寄托了整个 Docker 公司重新定义 PaaS 的宏伟愿望。</p>
<p>在 2014 年的这段巅峰岁⽉⾥，Docker 公司离⾃⼰的理想真的只有⼀步之遥。</p>
<p>2013~2014 年，以 Cloud Foundry 为代表的 PaaS 项⽬，逐渐完成了教育⽤户和开拓市场的艰巨任务，也正是在这个将概念逐渐落地的过程中，应⽤&quot;打包&quot;困难这个问题，成了整个后端技术圈⼦的⼀块⼼病。</p>
<pre><code class="language-shell">$ docker build 我的镜像
</code></pre>
<pre><code class="language-shell">$ docker run &quot; 我的镜像 &quot;
</code></pre>
<p>Docker 项⽬的出现，则为这个根本性的问题提供了⼀个近乎完美的解决⽅案。这正是 Docker 项⽬刚刚开源不久，就能够带领⼀家原本默默⽆闻的 PaaS 创业公司脱颖⽽出，然后迅速占领了所有云计算领域头条的技术原因。</p>
<p>⽽在成为了基础设施领域近⼗年难得⼀⻅的技术明星之后，dotCloud 公司则在 2013 年底⼤胆改名为 Docker 公司。不过，这个在当时就颇具争议的改名举动，也成为了⽇后容器技术圈⻛云变幻的⼀个关键伏笔。</p>
<p>之前说到，伴随着 PaaS 概念的逐步普及，以 Cloud Foundry 为代表的经典 PaaS 项⽬，开始进⼊基础设施领域的视野，平台化和 PaaS 化成了这个⽣态中的⼀个最为重要的进化趋势。</p>
<p>就在对开源 PaaS 项⽬落地的不断尝试中，这个领域的从业者们发现了 PaaS 中最为棘⼿也最亟待解决的⼀个问题：究竟如何给应⽤打包？</p>
<p>遗憾的是，⽆论是 Cloud Foundry、OpenShift，还是 Clodify，⾯对这个问题都没能给出⼀个完美的答案，反⽽在竞争中⾛向了碎⽚化的歧途。</p>
<p>⽽就在这时，⼀个并不引⼈瞩⽬的 PaaS 创业公司 dotCloud，却选择了开源⾃家的⼀个容器项⽬ Docker。更出⼈意料的是，就是这样⼀个普通到不能再普通的技术，却开启了⼀个名为&quot;Docker&quot;的全新时代。</p>
<p>Docker 项⽬的崛起，是不是偶然呢？这个以&quot;鲸⻥&quot;为注册商标的技术创业公司，最重要的战略之⼀就是：坚持把&quot;开发者&quot;群体放在⾄⾼⽆上的位置。</p>
<p>相⽐于其他正在企业级市场⾥厮杀得头破⾎流的经典 PaaS 项⽬们，Docker 项⽬的推⼴策略从⼀开始就呈现出⼀副&quot;憨态可掬&quot;的亲⼈姿态，把每⼀位后端技术⼈员（⽽不是他们的⽼板）作为主要的传播对象。</p>
<p>简洁的 UI，有趣的 demo，&quot;1 分钟部署⼀个 WordPress ⽹站&quot;&quot;3 分钟部署⼀个 Nginx 集群&quot;，这种同开发者之间与⽣俱来的亲近关系，使 Docker 项⽬迅速成为了全世界 Meetup 上最受欢迎的⼀颗新星。</p>
<p>在过去的很⻓⼀段时间⾥，相较于前端和互联⽹技术社区，服务器端技术社区⼀直是⼀个相对沉闷⽽⼩众的圈⼦。在这⾥，从事 Linux 内核开发的极客们⾃带&quot;不合群&quot;的&quot;光环&quot;，后端开发者们啃着多年不变的 TCP/IP 发着牢骚，运维更是天⽣注定的幕后英雄。</p>
<p>⽽ Docker 项⽬，却给后端开发者提供了⾛向聚光灯的机会。就⽐如 Cgroups 和 Namespace 这种已经存在多年却很少被⼈们关⼼的特性，在 2014 年和 2015 年竟然频繁⼊选各⼤技术会议的分享议题，就因为听众们想要知道 Docker 这个东⻄到底是怎么⼀回事⼉。</p>
<p>⽽ Docker 项⽬之所以能取得如此⾼的关注，⼀⽅⾯正如前⾯所说的那样，它解决了应⽤打包和发布这⼀困扰运维⼈员多年的技术难题；⽽另⼀⽅⾯，就是因为它第⼀次把⼀个纯后端的技术概念，通过⾮常友好的设计和封装，交到了最⼴⼤的开发者群体⼿⾥。</p>
<p>在这种独特的氛围烘托下，你不需要精通 TCP/IP，也⽆需深谙 Linux 内核原理，哪怕只是⼀个前端或者⽹站的 PHP ⼯程师，都会对如何把⾃⼰的代码打包成⼀个随处可以运⾏的 Docker 镜像充满好奇和兴趣。</p>
<p>这种受众群体的变⾰，正是 Docker 这样⼀个后端开源项⽬取得巨⼤成功的关键。这也是经典 PaaS 项⽬想做却没有做好的⼀件事情：PaaS 的最终⽤户和受益者，⼀定是为这个 PaaS 编写应⽤的开发者们，⽽在 Docker 项⽬开源之前，PaaS 与开发者之间的关系却从未如此紧密过。</p>
<p>解决了应⽤打包这个根本性的问题，同开发者与⽣俱来的的亲密关系，再加上 PaaS 概念已经深⼊⼈⼼的完美契机，成为 Docker 这个技术上看似平淡⽆奇的项⽬⼀举⾛红的重要原因。</p>
<p>⼀时之间，&quot;容器化&quot;取代&quot;PaaS 化&quot;成为了基础设施领域最炙⼿可热的关键词，⼀个以&quot;容器&quot;为中⼼的、全新的云计算市场，正呼之欲出。⽽作为这个⽣态的⼀⼿缔造者，此时的 dotCloud 公司突然宣布将公司名称改为&quot;Docker&quot;。</p>
<p>这个举动，在当时颇受质疑。在⼤家印象中，Docker 只是⼀个开源项⽬的名字。可是现在，这个单词却成了 Docker 公司的注册商标，任何⼈在商业活动中使⽤这个单词，以及鲸⻥的 Logo，都会⽴刻受到法律警告。</p>
<p>Docker 项⽬在短时间内迅速崛起的三个重要原因：</p>
<ol>
<li>Docker 镜像通过技术⼿段解决了 PaaS 的根本性问题；</li>
<li>Docker 容器同开发者之间有着与⽣俱来的密切关系；</li>
<li>PaaS 概念已经深⼊⼈⼼的完美契机。</li>
</ol>
<h4 id="121-何为paas">1.2.1 何为Paas</h4>
<p><strong>PaaS 项⽬成功的主要原因</strong></p>
<p>是它提供了⼀种名叫&quot;应⽤托管&quot;的能⼒。</p>
<p>paas之前主流⽤户的普遍⽤法是租⼀批 AWS 或者 OpenStack 的虚拟机，然后像以前管理物理服务器那样，⽤脚本或者⼿⼯的⽅式在这些机器上部署应⽤。</p>
<p>这个部署过程会碰到云端虚拟机和本地环境不⼀致的问题，所以当时的云计算服务，⽐的就是谁能更好地模拟本地服务器环境，能带来更好的&quot;上云&quot;体验。⽽ PaaS 开源项⽬的出现，就是当时解决这个问题的⼀个最佳⽅案。</p>
<p><strong>PaaS 如何部署应⽤</strong></p>
<p>虚拟机创建好之后，运维⼈员只需要在这些机器上部署⼀个 Cloud Foundry 项⽬，然后开发者只要执⾏⼀条命令就能把本地的应⽤部署到云上，这条命令就是：</p>
<pre><code class="language-shell"> [root@Linux ~]# cf push &quot; 应⽤ &quot;
</code></pre>
<p><strong>PaaS 项⽬的核⼼组件</strong></p>
<p>像 Cloud Foundry 这样的 PaaS 项⽬，最核⼼的组件就是⼀套应⽤的打包和分发机制。 Cloud Foundry 为每种主流编程语⾔都定义了⼀种打包格式，⽽&quot;cf push&quot;的作⽤，基本上等同于⽤户把应⽤的可执⾏⽂件和启动脚本打进⼀个压缩包内，上传到云上 Cloud Foundry 的存储中。接着，Cloud Foundry 会通过调度器选择⼀个可以运⾏这个应⽤的虚拟机，然后通知这个机器上的 Agent 把应⽤压缩包下载下来启动。</p>
<p>由于需要在⼀个虚拟机上启动很多个来⾃不同⽤户的应⽤，Cloud Foundry 会调⽤操作系统的 Cgroups 和 Namespace 机制为每⼀个应⽤单独创建⼀个称作&quot;沙盒&quot;的隔离环境，然后在&quot;沙盒&quot;中启动这些应⽤进程。这就实现了把多个⽤户的应⽤互不⼲涉地在虚拟机⾥批量⾃动地运⾏起来的⽬的。</p>
<p>这正是 PaaS 项⽬最核⼼的能⼒。 ⽽这些 Cloud Foundry ⽤来运⾏应⽤的隔离环境，或者说&quot;沙盒&quot;，就是所谓的&quot;容器&quot;。</p>
<p>注：Cloud Foundry是当时⾮常主流⾮常⽕的⼀个PaaS项⽬</p>
<h4 id="122-docker对paas的降维打击">1.2.2 Docker对Paas的降维打击</h4>
<p><strong>Docker 镜像</strong></p>
<p>Docker 项⽬确实与 Cloud Foundry 的容器在⼤部分功能和实现原理上都是⼀样的，可偏偏就是这剩下的⼀⼩部分不⼀样的功能，成了 Docker 项⽬接下来&quot;呼⻛唤⾬&quot;的不⼆法宝。这个功能，就是 Docker 镜像。</p>
<p>恐怕连 Docker 项⽬的作者 Solomon Hykes ⾃⼰当时都没想到，这个⼩⼩的创新，在短短⼏年内就如此迅速地改变了整个云计算领域的发展历程。</p>
<p><strong>PaaS的问题：</strong></p>
<p>PaaS 之所以能够帮助⽤户⼤规模部署应⽤到集群⾥，是因为它提供了⼀套应⽤打包的功能。可就是这个打包功能，却成了 PaaS ⽇后不断遭到⽤户诟病的⼀个&quot;软肋&quot;</p>
<p><strong>根本原因：</strong></p>
<p>⼀旦⽤上了 PaaS，⽤户就必须为每种语⾔、每种框架，甚⾄每个版本的应⽤维护⼀个打好的包。这个打包过程，没有任何章法可循，更麻烦的是，明明在本地运⾏得好好的应⽤，却需要做很多修改和配置⼯作才能在 PaaS ⾥运⾏起来。⽽这些修改和配置，并没有什么经验可以借鉴，基本上得靠不断试错，直到你摸清楚了本地应⽤和远端 PaaS 匹配的&quot;脾⽓&quot;才能够搞定。</p>
<p>最后结局是，&quot;cf push&quot;确实是能⼀键部署了，但是为了实现这个⼀键部署，⽤户为每个应⽤打包的⼯作可谓⼀波三折，费尽⼼机。</p>
<p>⽽Docker 镜像解决的，恰恰就是打包这个根本性的问题。</p>
<p><strong>Docker 镜像的精髓</strong></p>
<p>所谓 Docker 镜像，其实就是⼀个压缩包。但是这个压缩包⾥的内容，⽐ PaaS 的应⽤可执⾏⽂件 + 启停脚本的组合就要丰富多了。实际上，⼤多数 Docker 镜像是直接由⼀个完整操作系统的所有⽂件和⽬录构成的，所以这个压缩包⾥的内容跟你本地开发和测试环境⽤的操作系统是完全⼀样的。</p>
<p>这就有意思了：假设你的应⽤在本地运⾏时，能看⻅的环境是 CentOS 7.2 操作系统的所有⽂件和⽬录，那么只要⽤ CentOS 7.2 的 ISO 做⼀个压缩包，再把你的应⽤可执⾏⽂件也压缩进去，那么⽆论在哪⾥解压这个压缩包，都可以得到与你本地测试时⼀样的环境。当然，你的应⽤也在⾥⾯！</p>
<p>这就是 Docker 镜像最厉害的地⽅：只要有这个压缩包在⼿，你就可以使⽤某种技术创建⼀个&quot;沙盒&quot;，在&quot;沙盒&quot;中解压这个压缩包，然后就可以运⾏你的程序了。</p>
<p>更重要的是，这个压缩包包含了完整的操作系统⽂件和⽬录，也就是包含了这个应⽤运⾏所需要的所有依赖，所以你可以先⽤这个压缩包在本地进⾏开发和测试，完成之后，再把这个压缩包上传到云端运⾏。</p>
<p>在这个过程中，你完全不需要进⾏任何配置或者修改，因为这个压缩包赋予了你⼀种极其宝贵的能⼒：本地环境和云端环境的⾼度⼀致！</p>
<p>这，正是 Docker 镜像的精髓。</p>
<p>那么，有了 Docker 镜像这个利器，PaaS ⾥最核⼼的打包系统⼀下⼦就没了⽤武之地，最让⽤户抓狂的打包过程也随之消失了。相⽐之下，在当今的互联⽹⾥，Docker 镜像需要的操作系统⽂件和⽬录，可谓唾⼿可得。</p>
<p>所以，你只需要提供⼀个下载好的操作系统⽂件与⽬录，然后使⽤它制作⼀个压缩包即可，这个命令就是：</p>
<pre><code class="language-shell">[root@Linux ~]# docker build &quot; 镜像 &quot;
</code></pre>
<p>镜像制作完成，⽤户就可以让 Docker 创建⼀个&quot;沙盒&quot;来解压这个镜像，然后在&quot;沙盒&quot;中运⾏⾃⼰的应⽤，这个命令就是：</p>
<pre><code class="language-shell">[root@Linux ~]# docker run &quot; 镜像 &quot;
</code></pre>
<p>Docker 项⽬给 PaaS 世界带来的&quot;降维打击&quot;</p>
<p>其实是提供了⼀种⾮常便利的打包机制。这种机制直接打包了应⽤运⾏所需要的整个操作系统，从⽽保证了本地环境和云端环境的⾼度⼀致，避免了⽤户通过&quot;试错&quot;来匹配两种不同运⾏环境之间差异的痛苦过程。</p>
<h2 id="2-docker安装">2、Docker安装</h2>
<h3 id="21-docker版本解读">2.1 Docker版本解读</h3>
<p>moby、docker-ce与docker-ee</p>
<p>最早时docker是⼀个开源项⽬，主要由docker公司维护。</p>
<p>2017年3⽉1⽇起，docker公司将原先的docker项⽬改名为moby，并创建了docker-ce和docker-ee。</p>
<p><strong>三者关系</strong></p>
<p>moby是继承了原先的docker的项⽬，是社区维护的的开源项⽬，谁都可以在moby的基础打造⾃⼰的容器产品</p>
<p>docker-ce是docker公司维护的开源项⽬，是⼀个基于moby项⽬的免费的容器产品</p>
<p>docker-ee是docker公司维护的闭源产品，是docker公司的商业产品。</p>
<p><strong>版本维护</strong></p>
<p>moby project由社区维护，docker-ce project是docker公司维护，docker-ee是闭源的。</p>
<p><strong>Docker-ce发布计划</strong></p>
<p>v1.13.1之后，发布计划更改为:</p>
<p>Edge:  ⽉版本，每⽉发布⼀次，命名格式为YY.MM，维护到下个⽉的版本发布</p>
<p>Stable: 季度版本，每季度发布⼀次，命名格式为YY.MM，维护4个⽉</p>
<p><strong>版本获取</strong></p>
<p>要使⽤免费的docker，从https://github.com/docker/docker-ce上获取。</p>
<p>要使⽤收费的docker，从https://www.docker.com/products/docker-enterprise上获取。</p>
<h3 id="22-官方安装方案">2.2 官⽅安装⽅案</h3>
<p>docker-ce的release计划跟随moby的release计划，可以使⽤下⾯的命令直接安装最新的docker-ce</p>
<pre><code class="language-shell">[root@Linux ~]# curl -fsSL https://get.docker.com/ | sh
</code></pre>
<p>如果是centos，上⾯的安装命令会在系统上添加yum源:/etc/yum.repos.d/docker-ce.repo</p>
<pre><code class="language-yaml"> [root@Linux ~]# wget https://download.docker.com/linux/centos/docker-ce.repo
  [root@Linux ~]# mv docker-ce.repo /etc/yum.repos.d
  [root@Linux ~]# yum install -y docker-ce
</code></pre>
<p>或者直接下载rpm安装</p>
<pre><code class="language-shell">[root@Linux ~]# wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-17.09.0.ce-1.el7.centos.x86_64.rpm
  [root@Linux ~]# yum localinstall docker-ce-17.09.0.ce-1.el7.centos.x86_64.rpm
</code></pre>
<h3 id="23-docker加速器">2.3 Docker加速器</h3>
<p>使⽤Aliyun Docker Yum源安装Docker</p>
<p><strong>删除已安装的Docker</strong></p>
<pre><code class="language-shell">[root@Linux ~]# yum remove docker \
        docker-client \
        docker-client-latest \
        docker-common \
        docker-latest \
        docker-latest-logrotate \
        docker-logrotate \
        docker-selinux \
        docker-engine-selinux \
        docker-engine
</code></pre>
<p><strong>配置阿⾥云Docker Yum源</strong></p>
<pre><code class="language-shell">[root@Linux ~]# yum install -y yum-utils device-mapper-persistent-data lvm2 git
  [root@Linux ~]# yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</code></pre>
<p><strong>如何安装指定版本</strong></p>
<p>查看Docker版本：</p>
<pre><code class="language-shell">[root@Linux ~]# yum list docker-ce --showduplicates
</code></pre>
<p>安装较旧版本（⽐如Docker 17.03.2) ：</p>
<p>需要指定完整的rpm包的包名，并且加上--setopt=obsoletes=0 参数：</p>
<pre><code class="language-shell"> [root@Linux ~]# yum install -y --setopt=obsoletes=0 \
   docker-ce-17.03.2.ce-1.el7.centos.x86_64 \
   docker-ce-selinux-17.03.2.ce-1.el7.centos.noarch
</code></pre>
<p>安装Docker最新版</p>
<pre><code class="language-shell">  [root@Linux ~]# yum install docker-ce -y
</code></pre>
<p><strong>Centos8安装Docker报错解决⽅案</strong></p>
<p>官⽅docker rpm包地址</p>
<pre><code class="language-shell">https://download.docker.com/linux/centos/7/x86_64/stable/Packages/
</code></pre>
<ol>
<li>
<p>有关runc</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200819171538.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>有关containerd.io</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200819171555.png" alt="" loading="lazy"></figure>
</li>
</ol>
<p><strong>启动Docker服务</strong></p>
<pre><code class="language-shell">[root@Linux ~]#systemctl enable docker
 [root@Linux ~]#systemctl start docker 
</code></pre>
<p>查看Docker版本及启动状态</p>
<pre><code class="language-shell">[root@Linux ~]# docker -v
  Docker version 1.13.1, build 8633870/1.13.1  

  [root@Linux ~]# docker version
  Client:
   Version:        18.09.0
   API version:    1.39
   Go version:     go1.10.4
   Git commit:     4d60db4
   Built:          Wed Nov  7 00:48:22 2018
   OS/Arch:        linux/amd64
   Experimental:   false

  Server: Docker Engine - Community
   Engine:
   Version:        18.09.0
   API version:    1.39 (minimum version 1.12)
   Go version:     go1.10.4
   Git commit:     4d60db4
   Built:          Wed Nov  7 00:19:08 2018
   OS/Arch:        linux/amd64
   Experimental:   false
</code></pre>
<p>查看Docker运⾏状态</p>
<pre><code class="language-shell">[root@Linux ~]# docker info
  Containers: 0
   Running: 0
   Paused: 0
   Stopped: 0
  Images: 0
  Server Version: 18.09.0
  Storage Driver: overlay2
   Backing Filesystem: xfs
   Supports d_type: true
   Native Overlay Diff: true
  Logging Driver: json-file
  Cgroup Driver: cgroupfs
  Plugins:
   Volume: local
   Network: bridge host macvlan null overlay
   Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
  Swarm: inactive
  Runtimes: runc
  Default Runtime: runc
  Init Binary: docker-init
  containerd version: c4446665cb9c30056f4998ed953e6d4ff22c7c39
  runc version: 4fc53a81fb7c994640722ac585fa9ca548971871
  init version: fec3683
  Security Options:
   seccomp
   Profile: default
  Kernel Version: 3.10.0-957.el7.x86_64
  Operating System: CentOS Linux 7 (Core)
  OSType: linux
  Architecture: x86_64
  CPUs: 4
  Total Memory: 1.934GiB
  Name: docker
  ID: MF5S:ZX25:SWJ3:XEIG:FFHP:5VXF:F5AL:KQFF:KKXP:XZGY:YGTE:EBQF
  Docker Root Dir: /var/lib/docker
  Debug Mode (client): false
  Debug Mode (server): false
  Registry: https://index.docker.io/v1/
  Labels:
  Experimental: false
  Insecure Registries:
   127.0.0.0/8
  Live Restore Enabled: false
  Product License: Community Engine
</code></pre>
<p><strong>问题1</strong></p>
<p>docker info的时候报如下错误</p>
<pre><code class="language-shell">bridge-nf-call-iptables is disabled
</code></pre>
<p><strong>解决</strong></p>
<p>追加如下配置,然后重启系统</p>
<pre><code class="language-shell">[root@Linux ~]# vim /etc/sysctl.conf  
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-arptables = 1
</code></pre>
<p><strong>问题2</strong></p>
<p>虚拟机ping百度也能ping通，但是需要等好⼏秒才出结果，关键是下载镜像⼀直报错如下</p>
<pre><code class="language-shell">[root@Linux ~]# docker pull daocloud.io/library/nginx
Using default tag: latest
Error response from daemon: Get https://daocloud.io/v2/: dial tcp: lookup daocloud.io on 192.168.1.2:53: read udp  192.168.1.189:41335-&gt;192.168.1.2:53: i/o timeout
</code></pre>
<p><strong>解决</strong></p>
<p>我的虚拟机⽤的⽹关和dns都是虚拟机⾃⼰的.1或者.2，把DNS改成8.8.8.8问题就解决了，ping百度也秒出结果</p>
<pre><code class="language-shell"> [root@Linux ~]# vim /etc/resolv.conf
  nameserver 8.8.8.8
</code></pre>
<h3 id="24-国内源镜像源">2.4 国内源镜像源</h3>
<ol>
<li>
<p>Daocloud</p>
</li>
<li>
<p>Aliyun</p>
</li>
<li>
<p>⽹易蜂巢</p>
</li>
</ol>
<h2 id="3-docker核心概念">3、Docker核⼼概念</h2>
<h3 id="31-docker系统">3.1 Docker系统</h3>
<p>Docker系统有两个程序：Docker服务端和Docker客户端</p>
<pre><code class="language-shell">Docker服务端：
	是⼀个服务进程，管理着所有的容器。
    docker engine  
Docker客户端：
    扮演着docker服务端的远程控制器，可以⽤来控制docker的服务端进程。
</code></pre>
<h3 id="32-docker核心组件">3.2 Docker核⼼组件</h3>
<blockquote>
<p>Docker 镜像 - Docker  images</p>
<p>Docker 仓库 - Docker  registeries</p>
<p>Docker 容器 - Docker  containers</p>
</blockquote>
<p><strong>容器组成要素</strong></p>
<p>名称空间 namespace</p>
<p>资源限制 cgroups</p>
<p>⽂件系统 overlay2(UnionFS)</p>
<h4 id="321-docker-仓库">3.2.1 Docker 仓库</h4>
<p>⽤来保存镜像，可以理解为代码控制中的代码仓库。同样的，Docker 仓库也有公有和私有的概念。</p>
<p>公有的 Docker  仓库名字是 Docker Hub。Docker Hub  提供了庞⼤的镜像集合供使⽤。这些镜像可以是⾃⼰创建，或者在别⼈的镜像基础上创建。Docker 仓库是 Docker 的分发部分。</p>
<h4 id="322-docker-镜像">3.2.2 Docker 镜像</h4>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200819172539.png" alt="" loading="lazy"></figure>
<p>Docker 镜像是 Docker 容器运⾏时的只读模板，每⼀个镜像由⼀系列的层 (layers) 组成。Docker 使⽤  UnionFS 来将这些层联合到单独的镜像中。UnionFS  允许独⽴⽂件系统中的⽂件和⽂件夹(称之为分⽀)被透明覆盖，形成⼀个单独连贯的⽂件系统。正因为有了这些层的存在，Docker  是如此的轻量。当你改变了⼀个 Docker  镜像，⽐如升级到某个程序到新的版本，⼀个新的层会被创建。因此，不⽤替换整个原先的镜像或者重新建⽴(在使⽤虚拟机的时候你可能会这么做)，只是⼀个新的层被添加或升级了。现在你不⽤重新发布整个镜像，只需要升级，层使得分发 Docker 镜像变得简单和快。</p>
<p>在 Docker 的术语⾥，⼀个只读层被称为镜像，⼀个镜像是永久不会变的。</p>
<p>由于 Docker 使⽤⼀个统⼀⽂件系统，Docker 进程认为整个⽂件系统是以读写⽅式挂载的。 但是所有的变更都发⽣顶层的可写层，⽽下层的原始的只读镜像⽂件并未变化。由于镜像不可写，所以镜像是⽆状态的。</p>
<p>每⼀个镜像都可能依赖于由⼀个或多个下层的组成的另⼀个镜像。下层那个镜像是上层镜像的⽗镜像。</p>
<p><strong>镜像名称组成</strong></p>
<p>registry/repo:tag</p>
<p><strong>基础镜像</strong></p>
<p>⼀个没有任何⽗镜像的镜像，谓之基础镜像</p>
<p><strong>镜像ID</strong></p>
<p>所有镜像都是通过⼀个 64 位⼗六进制字符串 （内部是⼀个 256 bit 的值）来标识的。 为简化使⽤，前 12 个字符可以组成⼀个短ID，可以在命令⾏中使⽤。短ID还是有⼀定的碰撞机率，所以服务器总是返回⻓ID。</p>
<h4 id="323-docker-容器">3.2.3 Docker 容器</h4>
<p>Docker 容器和⽂件夹很类似，⼀个Docker容器包含了所有的某个应⽤运⾏所需要的环境。每⼀个 Docker 容器都是从 Docker  镜像创建的。Docker 容器可以运⾏、开始、停⽌、移动和删除。每⼀个 Docker 容器都是独⽴和安全的应⽤平台，Docker 容器是  Docker 的运⾏部分。</p>
<h4 id="324-docker镜像和容器区别">3.2.4 Docker镜像和容器区别</h4>
<p><strong>Docker镜像</strong></p>
<p>要理解Docker镜像和docker容器之间的区别，确实不容易。</p>
<p>假设Linux内核是第0层，那么⽆论怎么运⾏Docker，它都是运⾏于内核层之上的。这个Docker镜像，是⼀个只读的镜像，位于第1层，它不能被修改或不能保存状态。</p>
<p>⼀个Docker镜像可以构建于另⼀个Docker镜像之上，这种层叠关系可以是多层的。第1层的镜像层我们称之为基础镜像（Base  Image），其他层的镜像（除了最顶层）我们称之为⽗层镜像（Parent  Image）。这些镜像继承了他们的⽗层镜像的所有属性和设置，并在Dockerﬁle中添加了⾃⼰的配置。</p>
<p>Docker镜像通过镜像ID进⾏识别。镜像ID是⼀个64字符的⼗六进制的字符串。但是当我们运⾏镜像时，通常我们不会使⽤镜像ID来引⽤镜像，⽽是使⽤镜像名来引⽤。</p>
<p>要列出本地所有有效的镜像，可以使⽤命令</p>
<pre><code class="language-shell">[root@Linux ~]# docker images
</code></pre>
<p>镜像可以发布为不同的版本，这种机制我们称之为标签（Tag）。</p>
<p>如上图所示，neo4j镜像有两个版本：lastest版本和2.1.5版本。</p>
<p>可以使⽤pull命令加上指定的标签：</p>
<pre><code class="language-shell">[root@Linux ~]# docker pull ubuntu:14.04
[root@Linux ~]# docker pull ubuntu:12.04
</code></pre>
<p><strong>Docker容器</strong></p>
<p>Docker容器可以使⽤命令创建</p>
<pre><code class="language-shell">[root@Linux ~]# docker run imagename
</code></pre>
<p>它会在所有的镜像层之上增加⼀个可写层。这个可写层有运⾏在CPU上的进程，⽽且有两个不同的状态：运⾏态（Running）和退出态 （Exited）。这就是Docker容器。当我们使⽤docker  run启动容器，Docker容器就进⼊运⾏态，当我们停⽌Docker容器时，它就进⼊退出态。</p>
<p>当我们有⼀个正在运⾏的Docker容器时，从运⾏态到停⽌态，我们对它所做的⼀切变更都会永久地写到容器的⽂件系统中。要切记，对容器的变更是写⼊到容器的⽂件系统的，⽽不是写⼊到Docker镜像中的。</p>
<p>我们可以⽤同⼀个镜像启动多个Docker容器，这些容器启动后都是活动的，彼此还是相互隔离的。我们对其中⼀个容器所做的变更只会局限于那个容器本身。</p>
<p>如果对容器的底层镜像进⾏修改，那么当前正在运⾏的容器是不受影响的，不会发⽣⾃动更新现象。</p>
<p>如果想更新容器到其镜像的新版本，那么必须当⼼，确保我们是以正确的⽅式构建了数据结构，否则我们可能会导致损失容器中所有数据的后果。</p>
<p>64字符的⼗六进制的字符串来定义容器ID，它是容器的唯⼀标识符。容器之间的交互是依靠容器ID识别的，由于容器ID的字符太⻓，我们通常只需键⼊容器ID的前4个字符即可。当然，我们还可以使⽤容器名，但显然⽤4字符的容器ID更为简便。</p>
<h3 id="33-名字空间">3.3 名字空间</h3>
<p>名字空间是 Linux 内核⼀个强⼤的特性。每个容器都有⾃⼰单独的名字空间，运⾏在其中的应⽤都像是在独⽴的操作系统中运⾏⼀样。名字空间保证了容器之间彼此互不影响。</p>
<ol>
<li>pid 名字空间</li>
</ol>
<p>不同⽤户的进程就是通过 pid 名字空间隔离开的，且不同名字空间中可以有相同 pid。所有的 LXC 进程在 Docker中的⽗进程为Docker进程，每个 LXC 进程具有不同的名字空间。同时由于允许嵌套，因此可以很⽅便的实现嵌套的 Docker 容器。</p>
<ol start="2">
<li>net 名字空间</li>
</ol>
<p>有 了 pid 名字空间, 每个名字空间中的 pid 能够相互隔离，但是⽹络端⼝还是共享 host 的端⼝。⽹络隔离是通过 net 名字空间实现的，每个 net 名字空间有独⽴的 ⽹络设备, IP 地址, 路由表, /proc/net ⽬录。这样每个容器的⽹络就能隔离开来。Docker  默认采⽤ veth 的⽅式，将容器中的虚拟⽹卡同 host 上的⼀ 个Docker ⽹桥 docker0 连接在⼀起。</p>
<ol start="3">
<li>ipc 名字空间</li>
</ol>
<p>容器中进程交互还是采⽤了 Linux 常⻅的进程间交互⽅法(interprocess communication - IPC),  包括信号量、消息队列和共享内存、socket、管道等。然⽽同 VM 不同的是，容器的进程间交互实际上还是 host 上具有相同 pid  名字空间中的进程间交互，因此需要在 IPC 资源申请时加⼊名字空间信息，每个 IPC 资源有⼀个唯⼀的 32 位 id。</p>
<ol start="4">
<li>mnt名字空间</li>
</ol>
<p>类似 change root，将⼀个进程放到⼀个特定的⽬录执⾏。mnt 名字空间允许不同名字空间的进程看到的⽂件结构不同，这样每个名字空间  中的进程所看到的⽂件⽬录就被隔离开了。同 chroot 不同，每个名字空间中的容器在 /proc/mounts 的信息只包含所在名字空间的  mount point。</p>
<ol start="5">
<li>uts 名字空间</li>
</ol>
<p>UTS(&quot;UNIX Time-sharing System&quot;) 名字空间允许每个容器拥有独⽴的 hostname 和 domain name, 使其在⽹络上可以被视作⼀个独⽴的节点⽽⾮主机上的⼀个进程。</p>
<ol start="6">
<li>user 名字空间</li>
</ol>
<p>每个容器可以有不同的⽤户和组 id, 也就是说可以在容器内⽤容器内部的⽤户执⾏程序⽽⾮主机上的⽤户。</p>
<h2 id="4-镜像管理">4、镜像管理</h2>
<pre><code class="language-shell">搜索镜像：  这种⽅法只能⽤于官⽅镜像库
例如搜索基于 Centos 操作系统的镜像
[root@Linux ~]# docker search centos

按星级搜索镜像
查找 star 数⾄少为 100 的镜像，默认不加 s 选项找出所有相关 ubuntu 镜像
[root@Linux ~]# docker search ubuntu -f stars=100  
</code></pre>
<pre><code class="language-shell">拉取镜像
[root@Linux ~]# docker pull centos

查看本地镜像
[root@Linux ~]# docker image list

查看镜像详情
[root@Linux ~]# docker image inspect 镜像id

删除镜像
删除⼀个或多个，多个之间⽤空格隔开，可以使⽤镜像名称或id
[root@Linux ~]# docker rmi daocloud.io/library/mysql
</code></pre>
<h2 id="5-docker容器管理">5、Docker容器管理</h2>
<pre><code class="language-shell">创建新容器但不启动
[root@Linux ~]# docker create -it 
daocloud.io/library/centos:5 /bin/bash

创建并运⾏⼀个新Docker 容器
同⼀个镜像可以启动多个容器,每次执⾏run⼦命令都会运⾏⼀个全新的容器
[root@Linux ~]# docker run -it --restart=always 
centos /bin/bash
   如果执⾏成功，说明CentOS 容器已经被启动，并且应该已经得到了 bash 提示符。
  -i  
   捕获标准输⼊输出
  -t  
   分配⼀个终端或控制台
  --restart=always  
   容器随docker engine⾃启动，因为在重启docker的时候默认容器都会被关闭  
   也适⽤于create选项    
  --rm
   默认情况下，每个容器在退出时，它的⽂件系统也会保存下来，这样⼀⽅⾯调试会⽅便些，因为你可以通过查看⽇志等⽅式来确定最终状态。另⼀⽅⾯，也可以保存容器所产⽣的数据。
    但是当你仅仅需要短暂的运⾏⼀个容器，并且这些数据不需要保存，你可能就希望Docker能在容器结束时⾃动清理其所产⽣的数据。这个时候就需要--rm参数了。注意：--rm 和 -d不能共⽤

  容器名称
  --name= Assign a name to the container   
          --为容器分配⼀个名字，如果没有指定，docker会⾃动分配⼀个随机名称
          是docker run⼦命令的参数

  可以通过三种⽅式调⽤容器命名：
  1）使⽤UUID⻓命名
（&quot;f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778&quot;）
  2）使⽤UUID短Id（&quot;f78375b1c487&quot;）
  3）使⽤Name(&quot;evil_ptolemy&quot;) 

  这个UUID标识是由Docker deamon⽣成的。
  如果你在执⾏docker run时没有指定--name，那么deamon会⾃动⽣成⼀个随机字符串UUID。
  但是对于⼀个容器来说有个name会⾮常⽅便，当你需要连接其它容器时或者类似需要区分其它容器时，使⽤容器名称可以简化操作。⽆论容器运⾏在前台或者后台，这个名字都是有效的。

保存容器PID equivalent：
如果在使⽤Docker时有⾃动化的需求，你可以将containerID输出到指定的⽂件中（PIDfile），类似于某些应⽤程序将⾃身ID输出到⽂件中，⽅便后续脚本操作。
--cidfile=&quot;&quot;: Write the container ID to the file

断开与容器的连接，并且关闭容器：
root@d33c4e8c51f8 /#exit

如果只想断开和容器的连接⽽不关闭容器：
快捷键：ctrl+p+q

查看容器：
  只查看运⾏状态的容器：
    [root@Linux ~]#docker ps
    [root@Linux ~]#docker ps -a
    -a  查看所有容器
    
  只查看所有容器id:
        [root@Linux ~]# docker ps -a -q

  列出最近⼀次启动的容器(了解)
        [root@Linux ~]# docker ps -l  

    查看容器详细信息
    inspect  Return low-level information on a container or image
    ⽤于查看容器的配置信息，包含容器名、环境变量、运⾏命令、主机配置、⽹络配置和数据卷配置等。
    ⽬标：
    查找某⼀个运⾏中容器的id，然后使⽤docker inspect命令查看容器的信息。

    提示：可以使⽤镜像id的前⾯部分，不需要完整的id。
    [root@Linux ~]# docker inspect d95   //d95是我机器上运⾏的⼀个容器ID的前3个字符
    [
    {
       &quot;Id&quot;: 
&quot;d95a220a498e352cbfbc098c949fc528dbf5a5c911710b108ea3a9b4aa3a4761&quot;,
        &quot;Created&quot;: &quot;2017-07-08T03:59:16.18225183Z&quot;,
        &quot;Path&quot;: &quot;bash&quot;,
        &quot;Args&quot;: [],
        &quot;State&quot;: {
         &quot;Status&quot;: &quot;exited&quot;,
          &quot;Running&quot;: false,
          &quot;Paused&quot;: false,
          &quot;Restarting&quot;: false,
          &quot;OOMKilled&quot;: false,
          &quot;Dead&quot;: false,
          &quot;Pid&quot;: 0,
</code></pre>
<p>容器信息很多，这⾥只粘贴了⼀部分<br>
⽐如：容器⾥在安装ip或ifconﬁg命令之前，查看⽹卡IP显示容器IP地址和端⼝号，如果输出是空的说明没有配置IP地址（不同的Docker容器可以通过此IP地址互相访问）</p>
<pre><code class="language-shell">[root@Linux ~]# docker inspect --format='{{.NetworkSettings.IPAddress}}'  容器id
</code></pre>
<p>列出所有绑定的端⼝</p>
<pre><code class="language-shell">[root@Linux ~]# docker inspect --format='{{range $p, $conf := .NetworkSettings.Ports}} {{$p}} {{(index $conf ).HostPort}} {{end}}' $INSTANCE_ID
</code></pre>
<pre><code class="language-shell">[root@Linux ~]# docker inspect --format='{{range 
$p, $conf := .NetworkSettings.Ports}} {{$p}} -&gt; {{(index $conf 0).HostPort}} {{end}}' b220fabf815a 22/tcp -&gt; 20020
</code></pre>
<p>找出特殊的端⼝映射<br>
⽐如找出容器⾥22端⼝所映射的docker本机的端⼝</p>
<pre><code class="language-shell">[root@Linux ~]# docker inspect --format='{{(index (index .NetworkSettings.Ports &quot;22/tcp&quot;) 0).HostPort}}' $INSTANCE_ID
[root@Linux ~]# docker inspect --format='{{(index (index .NetworkSettings.Ports &quot;22/tcp&quot;) 0).HostPort}}' b220fabf815a 20020
</code></pre>
<p><strong>stop和kill的区别</strong><br>
docker stop命令给容器中的进程发送SIGTERM信号，默认⾏为是会导致容器退出，当然，容器内程序可以捕获该信号并⾃⾏处理，例如可以选择忽略。⽽docker kill则是给容器的进程发送SIGKILL信号，该信号将会使容器必然退出。</p>
<pre><code class="language-shell">删除容器
[root@Linux ~]# docker rm 容器id或名称
要删除⼀个运⾏中的容器，添加 -f 参数

根据格式删除所有容器：
[root@Linux ~]# docker rm $(docker ps -qf status=exited)

重启容器：
[root@Linux ~]#docker restart name

暂停容器：
pause  --暂停容器内的所有进程，
  通过docker stats可以观察到此时的资源使⽤情况是固定不变的，通过docker logs -f也观察不到⽇志的进⼀步输出。

恢复容器：
unpause  --恢复容器内暂停的进程，与pause参数相对应
[root@Linux ~]# docker start infallible_ramanujan  
这⾥的名字是状态⾥⾯NAMES列列出的名字，这种⽅式同样会让容器运⾏在后台

让容器运⾏在后台：
如果在docker run后⾯追加-d=true或者-d，那么容器将会运⾏在后台模式。此时所有I/O数据只能通过⽹络资源或者共享卷组来进⾏交互。因为容器不再监听你执⾏docker run的这个终端命令⾏窗⼝。但你可以通过执⾏
docker attach来重新附着到该容器的回话中。
注：
容器运⾏在后台模式下，是不能使⽤--rm选项的(⽼版本是这样，新版本已经可以同时⽣效) 
[root@Linux ~]#docker run -d IMAGE[:TAG] 命令
[root@Linux ~]#docker logs container_id  
[root@Linux ~]#打印该容器的输出
[root@Linux ~]# docker run -it -d --name mytest docker.io/centos /bin/sh -c &quot;while true; do echo hello world; sleep 2; done&quot;
37738fe3d6f9ef26152cb25018df9528a89e7a07355493020e72f147a291cd17

[root@Linux ~]# docker logs mytest
hello world
hello world

docker attach container_id #附加该容器的标准输出到当前
命令⾏
[root@Linux ~]# docker attach mytest
hello world
hello world
.......
此时，ctrl+d等同于exit命令，按ctrl+p+q可以退出到宿主机，⽽保持container仍然在运⾏

rename 
  Rename a container

stats   
  Display a live stream of container(s) resource usage statistics   
  --动态显示容器的资源消耗情况，包括：CPU、内存、⽹络I/O   
 

port   
  List port mappings or a specific mapping for the CONTAINER
   --输出容器端⼝与宿主机端⼝的映射情况
[root@Linux ~]# docker port blog
   80/tcp -&gt; 0.0.0.0:80
   容器blog的内部端⼝80映射到宿主机的80端⼝，这样可通过宿主机的80端⼝查看容器blog提供的服务

连接容器：   
⽅法1.attach
[root@Linux ~]# docker attach 容器id  //前提是容器创建时必须指定了交互shell

⽅法2.exec    
  通过exec命令可以创建两种任务：后台型任务和交互型任务
  交互型任务：
   [root@Linux ~]# docker exec -it  容器id  /bin/bash
   root@68656158eb8e:/[root@Linux ~]# ls    

  后台型任务：
     [root@Linux ~]# docker exec 容器id touch /testfile

监控容器的运⾏：
可以使⽤logs、top、events、wait这些⼦命令
  logs:
    使⽤logs命令查看守护式容器
    可以通过使⽤docker logs命令来查看容器的运⾏⽇志，其中--tail选项可以指定查看最后⼏条⽇志，⽽-t选项则可以对⽇志条⽬附加时间戳。使⽤-f选项可以跟踪⽇志的输出，直到⼿动停⽌。
    [root@Linux ~]# docker logs  App_Container  //不同终端操作
    [root@Linux ~]# docker logs -f App_Container

  top:
  显示⼀个运⾏的容器⾥⾯的进程信息
        [root@Linux ~]# docker top birdben/ubuntu:v1

  events   
    Get real time events from the server
    实时输出Docker服务器端的事件，包括容器的创建，启动，关
闭等。
    [root@Linux ~]# docker start loving_meninsky         
    loving_meninsky
    [root@Linux ~]# docker events  //不同终端操作
      2017-07-08T16:39:23.177664994+08:00 network connect df15746d60ffaad2d15db0854a696d6e49fdfcedc7cfd8504a8aac51a43de6d4 
     
 (container=50a0449d7729f94046baf0fe5a1ce2119742261bb3ce8c3c98f35c80458e3e7a, 
      name=bridge, type=bridge)
      2017-07-08T16:39:23.356162529+08:00 
container start 
      
50a0449d7729f94046baf0fe5a1ce2119742261bb3ce8c3c98f35c80458e3e7a (image=ubuntu,  name=loving_meninsky)

  wait（X）   
   Block until a container stops, then print its 
exit code  
    --捕捉容器停⽌时的退出码
   执⾏此命令后，该命令会&quot;hang&quot;在当前终端，直到容器停⽌，此时，会打印出容器的退出码
        [root@Linux ~]# docker wait 01d8aa  //不同终端操作
        137

  diff
    查看容器内发⽣改变的⽂件，以elated_lovelace容器为例
            root@68656158eb8e:/# touch c.txt

    ⽤diff查看：
    包括⽂件的创建、删除和⽂件内容的改变都能看到
    [root@Linux ~]# docker diff  容器名称 
        A /c.txt

    C对应的⽂件内容的改变，A对应的均是⽂件或者⽬录的创建删
除
    [root@Linux ~]# docker diff 7287
        A /a.txt
        C /etc
        C /etc/passwd
        A /run
        A /run/secrets   

宿主机和容器之间相互Copy⽂件
cp的⽤法如下：
  docker cp [OPTIONS] CONTAINER:PATH LOCALPATH
  docker cp [OPTIONS] LOCALPATH CONTAINER:PATH
如：容器mysql中/usr/local/bin/存在docker-
entrypoint.sh⽂件，可如下⽅式copy到宿主机
    [root@Linux ~]# docker cp mysql:/usr/local/bin/docker-entrypoint.sh  /root

修改完毕后，将该⽂件重新copy回容器
    [root@Linux ~]# docker cp /root/docker-entrypoint.sh mysql:/usr/local/bin/ 
</code></pre>
<h2 id="6-docker容器镜像制作">6、Docker容器镜像制作</h2>
<h3 id="61-容器文件系统打包">6.1 容器⽂件系统打包</h3>
<p>将容器的⽂件系统打包成tar⽂件,也就是把正在运⾏的容器直接导出为tar包的镜像⽂件<br>
export Export a container's ﬁlesystem as a tar archive</p>
<p>有两种⽅式（elated_lovelace为容器名）</p>
<pre><code class="language-shell">第⼀种：
  [root@master ~][root@Linux ~]# docker export -o elated_lovelace.tar elated_lovelace
第⼆种：
  [root@master ~][root@Linux ~]# docker export 容器名称 &gt; 镜像.tar
</code></pre>
<p>导⼊镜像归档⽂件到其他宿主机<br>
import Import the contents from a tarball to create a ﬁlesystem image</p>
<pre><code class="language-shell"> [root@qfedu.com ~]# docker import elated_lovelace.tar  elated_lovelace:v1
</code></pre>
<p>注意：</p>
<blockquote>
<p>如果导⼊镜像时没有起名字，随后可以单独起名字(没有名字和tag)，可以⼿动加tag</p>
</blockquote>
<pre><code class="language-shell">[root@qfedu.com ~]# docker tag 镜像ID mycentos:7
</code></pre>
<h3 id="62-通过容器创建本地镜像">6.2 通过容器创建本地镜像</h3>
<p>背景：<br>
容器运⾏起来后，⼜在⾥⾯做了⼀些操作，并且要把操作结果保存到镜像⾥<br>
⽅案：<br>
使⽤ docker commit 指令，把⼀个正在运⾏的容器，直接提交为⼀个镜像。commit 是提交的意思,类似告诉svn服务器我要⽣成⼀个新的版本。</p>
<p>例：在容器内部新建了⼀个⽂件</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker exec -it 4ddf4638572d 
/bin/sh  
root@4ddf4638572d# touch test.txt
root@4ddf4638572d# exit
将这个新建的⽂件提交到镜像中保存
[root@qfedu.com ~]# docker commit 4ddf4638572d wing/helloworld:v2
</code></pre>
<p>例：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker commit -m &quot;my images 
version1&quot; -a &quot;wing&quot; 108a85b1ed99 
daocloud.io/ubuntu:v2
  
sha256:ffa8a185ee526a9b0d8772740231448a25855031f25c61c1b63077220469b057
  -m                   添加注释
  -a                   作者
  108a85b1ed99         容器环境id
  daocloud.io/ubuntu:v2    镜像名称：hub的名称/镜像名称：
tag 
  -p，–pause=true        提交时暂停容器运⾏
</code></pre>
<p>Init 层的存在，是为了避免执⾏ docker commit 时，把 Docker⾃⼰对 /etc/hosts 等⽂件做的修改，也⼀起提交掉。</p>
<h3 id="63-镜像迁移">6.3 镜像迁移</h3>
<p>保存⼀台宿主机上的镜像为tar⽂件，然后可以导⼊到其他的宿主机上：<br>
save Save an image(s) to a tar archive</p>
<p>将镜像打包，与下⾯的load命令相对应</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker save -o nginx.tar nginx
[root@qfedu.com ~]# docker save &gt; nginx.tar nginx
</code></pre>
<p>load Load an image from a tar archive or STDIN<br>
与上⾯的save命令相对应，将上⾯sava命令打包的镜像通过load命令导⼊</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker load &lt; nginx.tar
</code></pre>
<p>注：<br>
1.tar⽂件的名称和保存的镜像名称没有关系<br>
2.导⼊的镜像如果没有名称，⾃⼰打tag起名字</p>
<h3 id="64-通过dockerfile创建镜像">6.4 通过Dockerﬁle创建镜像</h3>
<p>虽然可以⾃⼰制作 rootfs(⻅'容器⽂件系统那些事⼉')，但Docker提供了⼀种更便捷的⽅式，叫作 Dockerﬁle<br>
docker build命令⽤于根据给定的Dockerﬁle和上下⽂以构建Docker镜像。</p>
<p><strong>docker build语法</strong></p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker build [OPTIONS] &lt;PATH | URL | -&gt;
</code></pre>
<p><strong>选项说明</strong></p>
<blockquote>
<p>--build-arg，设置构建时的变量<br>
--no-cache，默认false。设置该选项，将不使⽤Build Cache构建镜像</p>
<p>--pull，默认false。设置该选项，总是尝试pull镜像的最新版本</p>
<p>--compress，默认false。设置该选项，将使⽤gzip压缩构建的上下⽂<br>
--disable-content-trust，默认true。设置该选项，将对镜像进⾏验证<br>
--ﬁle, -f，Dockerﬁle的完整路径，默认值为‘PATH/Dockerﬁle’<br>
--isolation，默认--isolation=&quot;default&quot;，即Linux命名空间；其他还有process或hyperv<br>
--label，为⽣成的镜像设置metadata<br>
--squash，默认false。设置该选项，将新构建出的多个层压缩为⼀个新层，但是将⽆法在多个镜像之间共享新层；设置该选项，实际上是创建了新image，同时保留原有image。<br>
--tag, -t，镜像的名字及tag，通常name:tag或者name格式；可以在⼀次构建中为⼀个镜像设置多个tag<br>
--network，默认default。设置该选项，Set the networking mode for the RUN instructions during build<br>
--quiet, -q ，默认false。设置该选项，Suppress the build output and print image ID on success<br>
--force-rm，默认false。设置该选项，总是删除掉中间环节的容器<br>
--rm，默认--rm=true，即整个构建过程成功后删除中间环节的容器</p>
</blockquote>
<p><strong>PATH | URL | -说明</strong></p>
<p>给出命令执⾏的上下⽂。<br>
上下⽂可以是构建执⾏所在的本地路径，也可以是远程URL，如Git库、tarball或⽂本⽂件等。<br>
如果是Git库，如https://github.com/docker/rootfs.git#container:docker，则隐含先执⾏git clone --depth 1 --recursive，到本地临时⽬录；然后再将该临时⽬录发送给构建进程。<br>
构建镜像的进程中，可以通过ADD命令将上下⽂中的任何⽂件（注意⽂件必须在上下⽂中）加⼊到镜像中。<br>
-表示通过STDIN给出Dockerﬁle或上下⽂。<br>
示例：</p>
<pre><code class="language-shell">docker build - &lt; Dockerfile 
</code></pre>
<p>说明：该构建过程只有Dockerﬁle，没有上下⽂</p>
<pre><code class="language-shell">docker build - &lt; context.tar.gz
</code></pre>
<p>说明：其中Dockerﬁle位于context.tar.gz的根路径<br>
可以同时设置多个tag</p>
<pre><code class="language-shell"> [root@qfedu.com ~]# docker build -t champagne/bbauto:latest -t champagne/bbauto:v2.1 . 
</code></pre>
<p>创建镜像所在的⽂件夹和Dockerﬁle⽂件</p>
<pre><code class="language-shell">mkdir dockerfile-test 
cd dockerfile-test 
touch Dockerfile 
</code></pre>
<p>在Dockerﬁle⽂件中写⼊指令，每⼀条指令都会更新镜像的信息例如：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# vim Dockerfile 
[root@qfedu.com ~]# This is a comment 
FROM  daocloud.io/library/centos:7 
MAINTAINER wing wing@qfedu.com
RUN  命令1;命令2；命令3
RUN  命令
</code></pre>
<p><strong>格式说明</strong></p>
<blockquote>
<p>每⾏命令都是以 INSTRUCTION statement 形式，就是命令+清单的模式。命令要⼤写，&quot;#&quot;是注解。<br>
FROM 命令是告诉docker 我们的镜像什么。<br>
MAINTAINER 是描述 镜像的创建⼈。<br>
RUN 命令是在镜像内部执⾏。就是说他后⾯的命令应该是针对镜像可以运⾏的命令。</p>
</blockquote>
<p><strong>创建镜像</strong></p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker build  -t  centos:v2 . 
     docker build  是docker创建镜像的命令 
     -t  镜像名称  
     &quot;.&quot; 是⽤来指明我们使⽤的Dockerfile⽂件所在的当前⽬录
</code></pre>
<p>2.4、创建完成后，⽤这个镜像运⾏容器</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run -it centos:v2 /bin/bash
</code></pre>
<h3 id="65-dockerfile实例01容器化python的flask应用">6.5 Dockerﬁle实例01：容器化Python的Flask应⽤</h3>
<p><strong>⽬标</strong><br>
⽤ Docker 部署⼀个⽤ Python 编写的 Web 应⽤。<br>
<strong>应⽤代码部分</strong><br>
代码功能：如果当前环境中有&quot;NAME&quot;这个环境变量，就把它打印&quot;Hello&quot;后，否则就打印&quot;Hello world&quot;，最后再打印出当前环境的hostname。</p>
<pre><code class="language-shell">[root@qfedu.com ~]# mkdir python_app
[root@qfedu.com ~]# cd python_app
[root@qfedu.com ~]# vim app.py
from flask import Flask
import socket
import os
app = Flask(__name__)
@app.route('/')
def hello():
  html = &quot;&lt;h3&gt;Hello {name}!&lt;/h3&gt;&quot; \
      &quot;&lt;b&gt;Hostname:&lt;/b&gt; {hostname}&lt;br/&gt;&quot;      
  return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname())
if __name__ == &quot;__main__&quot;:
  app.run(host='0.0.0.0', port=80)
</code></pre>
<p>应⽤依赖<br>
定义在同⽬录下的 requirements.txt ⽂件⾥，内容如下：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# vim requirements.txt
Flask
</code></pre>
<p>编写Dockerﬁle</p>
<pre><code class="language-shell">[root@qfedu.com ~]# vim Dockerfile
FROM python:2.7-slim
WORKDIR /app
ADD  .  /app
RUN pip install --trusted-host pypi.python.org -r 
requirements.txt
EXPOSE 80
ENV NAME World
CMD [&quot;python&quot;, &quot;app.py&quot;]
</code></pre>
<p><strong>Dockerﬁle⽂件说明</strong></p>
<p>FROM python:2.7-slim<br>
使⽤官⽅提供的 Python 开发镜像作为基础镜像<br>
指定&quot;python:2.7-slim&quot;这个官⽅维护的基础镜像，从⽽免去安装Python 等语⾔环境的操作。否则，这⼀段就得这么写了：<br>
FROM ubuntu:latest<br>
RUN apt-get update -y<br>
RUN apt-get install -y python-pip python-dev build-essential<br>
WORKDIR /app<br>
将⼯作⽬录切换为 /app，意思是在这⼀句之后，Dockerﬁle 后⾯的操作都以这⼀句指定的 /app ⽬录作为当前⽬录。<br>
ADD . /app<br>
将当前⽬录下的所有内容复制到 /app 下，Dockerﬁle ⾥的原语并不都是指对容器内部的操作。⽐如 ADD，指的是把当前⽬录（即Dockerﬁle 所在的⽬录）⾥的⽂件，复制到指定容器内的⽬录当中。</p>
<p>RUN pip install --trusted-host pypi.python.org -r requirements.txt<br>
使⽤ pip 命令安装这个应⽤所需要的依赖<br>
EXPOSE 80 //允许外界访问容器的 80 端⼝<br>
ENV NAME World //设置环境变量<br>
CMD [&quot;python&quot;, &quot;app.py&quot;]<br>
设置容器进程为：python app.py，即：这个 Python 应⽤的启动<br>
命令<br>
这⾥app.py 的实际路径是 /app/app.py。CMD [&quot;python&quot;,&quot;app.py&quot;] 等价于 &quot;docker run python app.py&quot;。<br>
在使⽤ Dockerﬁle 时，可能还会看到⼀个叫作 ENTRYPOINT 的原语。它和 CMD 都是 Docker 容器进程启动所必需的参数，完整执⾏格式是：&quot;ENTRYPOINT CMD&quot;。<br>
但是，默认，Docker 会提供⼀个隐含的 ENTRYPOINT，即：/bin/sh -c。所以，在不指定 ENTRYPOINT 时，⽐如在这个例⼦⾥，实际上运⾏在容器⾥的完整进程是：/bin/sh -c &quot;python app.py&quot;，即 CMD 的内容就是 ENTRYPOINT 的参数。<br>
基于以上原因，后⾯会统⼀称 Docker 容器的启动进程为ENTRYPOINT，⽽不是 CMD。<br>
现在⽬录结构：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# ls
Dockerfile  app.py  requirements.txt
</code></pre>
<p><strong>构建镜像</strong></p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker build -t helloworld .
-t  给这个镜像加⼀个 Tag
</code></pre>
<p>Dockerﬁle 中的每个原语执⾏后，都会⽣成⼀个对应的镜像层。即使原语本身并没有明显地修改⽂件的操作（⽐如，ENV 原语），它对应的层也会存在。只不过在外界看来，这个层是空的。</p>
<p>查看结果</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker image ls
REPOSITORY       TAG             IMAGE ID
helloworld       latest        653287cdf998
</code></pre>
<p>启动容器</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run -p 4000:80 helloworld
镜像名 helloworld 后⾯，什么都不⽤写，因为在 Dockerfile 中已经指定了 CMD。
否则，就得把进程的启动命令加在后⾯：
[root@qfedu.com ~]# docker run -p 4000:80 helloworld python app.py
</code></pre>
<p>查看容器</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker ps
CONTAINER ID     IMAGE         COMMAND          
CREATED
4ddf4638572d     helloworld    &quot;python app.py&quot;   10 
seconds ago
</code></pre>
<p>进⼊容器</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker exec -it b69 /bin/bash
</code></pre>
<p>访问容器内应⽤</p>
<pre><code class="language-shell">[root@qfedu.com ~]# curl http://localhost:4000
</code></pre>
<p><strong>Hello World!</strong></p>
<p><strong>Hostname: 4ddf4638572d</strong></p>
<p>⾄此，已经使⽤容器完成了⼀个应⽤的开发与测试，如果现在想要把这个容器的镜像上传到 DockerHub 上分享给更多的⼈，⾸先要注册⼀个 Docker Hub 账号，然后使⽤ docker login 命令登录。</p>
<p>给容器镜像打tag起⼀个完整的名字：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker tag helloworld chenyoong/helloworld:v1
chenyong为我在docker hub的⽤户名
</code></pre>
<p>推送镜像到Docker Hub</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker push chenyong/helloworld:v1
</code></pre>
<h3 id="66-dockerfile实例02制作kubectl的镜像">6.6 Dockerﬁle实例02：制作Kubectl的镜像</h3>
<p>注：本实例学完k8s之后才能做<br>
制作镜像：wing/kubectl</p>
<pre><code class="language-shell">[root@qfedu.com ~]#cat Dockerfile/kubectl/Dockerfile
FROM alpine
MAINTAINER wing &lt;276267003@qq.com&gt;
LABEL org.label-schema.vcs-ref=$VCS_REF \
   org.label-schema.vcs-
url=&quot;https://github.com/vfarcic/kubectl&quot; \
   org.label-schema.docker.dockerfile=&quot;/Dockerfile&quot;
ENV KUBE_LATEST_VERSION=&quot;v1.13.0&quot;
RUN apk add --update ca-certificates &amp;&amp; \
  apk add --update -t deps curl &amp;&amp; \
  curl -L https://storage.googleapis.com/kubernetes-release/release/${KUBE_LATEST_VERSION}/bin/linux/amd64/kubectl -o /usr/local/bin/kubectl &amp;&amp; \
  chmod +x /usr/local/bin/kubectl &amp;&amp; \
  apk del --purge deps &amp;&amp; \
  rm /var/cache/apk/* 
CMD [&quot;kubectl&quot;, &quot;help&quot;]
</code></pre>
<h3 id="67-dockerfile优化">6.7 Dockerﬁle优化</h3>
<p>编译⼀个简单的nginx成功以后发现好⼏百M。<br>
1、RUN 命令要尽量写在⼀条⾥，每次 RUN 命令都是在之前的镜像上封装，只会增⼤不会减⼩<br>
2、每次进⾏依赖安装后使⽤yum clean all清除缓存中的rpm头⽂件和包⽂件<br>
3、选择⽐较⼩的基础镜像，⽐如：alpine</p>
<h2 id="7-docker私有仓库">7、Docker私有仓库</h2>
<h3 id="71-仓库镜像">7.1 仓库镜像</h3>
<p>Docker hub官⽅已提供容器镜像registry,⽤于搭建私有仓库</p>
<p><strong>拉取镜像</strong></p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker pull daocloud.io/library/registry:latest
</code></pre>
<h3 id="72-运行容器">7.2 运⾏容器</h3>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run --name &quot;pri_registry&quot; --restart=always -d -p 5000:5000 daocloud.io/library/registry 
</code></pre>
<p>注：如果创建容器不成功，报错防⽕墙，解决⽅案如下</p>
<pre><code class="language-shell">[root@qfedu.com ~]#systemctl stop firewalld
[root@qfedu.com ~]#yum install iptables*
[root@qfedu.com ~]#systemctl start iptables
[root@qfedu.com ~]#iptables -F
[root@qfedu.com ~]#systemctl restart docker
</code></pre>
<h3 id="73-查看容器">7.3 查看容器</h3>
<pre><code class="language-shell">[root@qfedu.com ~]# docker ps
CONTAINER ID  IMAGE  COMMAND  CREATED  STATUS   PORTS 
  NAMES
1f444285bed8     daocloud.io/library/registry 
 &quot;/entrypoint.sh /etc/&quot;  23 seconds ago    Up 21 
seconds    0.0.0.0:5000-&gt;5000/tcp  elegant_rosalind
</code></pre>
<h3 id="74-连接容器查看端口状态">7.4 连接容器查看端⼝状态</h3>
<pre><code class="language-shell">[root@qfedu.com ~]# docker exec -it  1f444285bed8  /bin/sh    //这⾥是sh 不是bash
  /# netstat -lnp                        //查看5000端
⼝是否开启
  Active Internet connections (only servers)
  Proto Recv-Q Send-Q Local Address      Foreign 
Address     State    PID/Program name   
  tcp     0    0 :::5000         :::*           
LISTEN    1/registry
  Active UNIX domain sockets (only servers)
  Proto RefCnt Flags    Type    State     I-Node 
PID/Program name   Path
</code></pre>
<p>在本机查看能否访问该私有仓库,看看状态码是不是200</p>
<pre><code class="language-shell">[root@qfedu.com ~]# curl  -I  127.0.0.1:5000   //参数是⼤写的i
HTTP/1.1 200 OK    
</code></pre>
<h3 id="75-仓库功能测试">7.5 仓库功能测试</h3>
<pre><code class="language-shell">为了⽅便，下载1个⽐较⼩的镜像,buysbox
 [root@qfedu.com ~]# docker pull busybox

上传前必须给镜像打tag  注明ip和端⼝：
 [root@qfedu.com ~]# docker tag  busybox  私有仓库IP:端⼝/busybox

这是直接从官⽅拉的镜像，很慢：
  [root@qfedu.com ~]# docker tag busybox 192.168.245.136:5000/busybox
</code></pre>
<p>下⾯这个Mysql是我测试的第⼆个镜像，从daocloud拉取的：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker tag daocloud.io/library/mysql 192.168.245.136:5000/daocloud.io/library/mysql
  注：tag后⾯可以使⽤镜像名称也可以使⽤id,我这⾥使⽤的镜像名称，如果使⽤官⽅的镜像，不需要加前缀，但是daocloud.io的得加前缀
</code></pre>
<p>修改请求⽅式为http</p>
<pre><code class="language-shell">默认为https，不改会报以下错误:
    Get https://master.up.com:5000/v1/_ping: http: 
server gave HTTP response to HTTPS client
  [root@qfedu.com ~]# vim /etc/docker/daemon.json
  { &quot;insecure-registries&quot;:[&quot;192.168.245.136:5000&quot;] }
  
重启docker:
  [root@qfedu.com ~]# systemctl restart docker
</code></pre>
<p>上传镜像到私有仓库</p>
<pre><code class="language-shell"> [root@qfedu.com ~] # docker push 192.168.245.136:5000/busybox 
 [root@qfedu.com ~] # docker push 192.168.245.136:5000/daocloud.io/library/mysql
</code></pre>
<p>查看私有仓库⾥的所有镜像<br>
注：我这⾥是⽤的是ubuntu的例⼦</p>
<pre><code class="language-shell">[root@qfedu.com ~] # curl 192.168.245.130:5000/v2/_catalog
 { &quot;repositories&quot; :[ &quot;daocloud.io/ubuntu&quot; ]}
或者
[root@qfedu.com ~] # curl http://192.168.245.130:5000/v2/daocloud.io/ubuntu/tags/list
 { &quot;name&quot; : &quot;daocloud.io/ubuntu&quot; , &quot;tags&quot; :[ &quot;v2&quot; ]}
[root@qfedu.com ~] # curl http://192.168.245.130:5000/v2/repo 名字/tags/list
</code></pre>
<p>拉取镜像测试</p>
<pre><code class="language-shell">[root@qfedu.com ~] # docker pull 192.168.245.136:5000/busybox
</code></pre>
<h2 id="8-部署docker-webui">8、部署Docker-WebUI</h2>
<h3 id="81-下载并运行容器">8.1 下载并运⾏容器</h3>
<pre><code class="language-shell">[root@qfedu.com ~]#docker pull uifd/ui-for-docker 
[root@qfedu.com ~]#docker run -it -d --name docker-web -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock docker.io/uifd/ui-for-docker 
</code></pre>
<h3 id="82-浏览器访问测试">8.2 浏览器访问测试</h3>
<p>http://ip:9000</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200820012943.png" alt="" loading="lazy"></figure>
<h2 id="9-docker资源限制">9、Docker资源限制</h2>
<p>在使⽤ Docker 运⾏容器时，⼀台主机上可能会运⾏⼏百个容器，这些容器虽然互相隔离，但是底层却使⽤着相同的 CPU、内存和磁盘资源。如果不对容器使⽤的资源进⾏限制，那么容器之间会互相影响，⼩的来说会导致容器资源使⽤不公平；⼤的来说，可能会导致主机和集群资源耗尽，服务完全不可⽤。<br>
CPU 和内存的资源限制已经是⽐较成熟和易⽤，能够满⾜⼤部分⽤户的需求。磁盘限制也是不错的，虽然现在⽆法动态地限制容量，但是限制磁盘读写速度也能应对很多场景。</p>
<p>⾄于⽹络，Docker 现在并没有给出⽹络限制的⽅案，也不会在可⻅的未来做这件事情，因为⽬前⽹络是通过插件来实现的，和容器本身的功能相对独⽴，不是很容易实现，扩展性也很差。<br>
资源限制⼀⽅⾯可以让我们为容器（应⽤）设置合理的 CPU、内存等资源，⽅便管理；另外⼀⽅⾯也能有效地预防恶意的攻击和异常，<br>
对容器来说是⾮常重要的功能。如果你需要在⽣产环境使⽤容器，请务<br>
必要花时间去做这件事情。</p>
<h3 id="91-系统压力测试">9.1 系统压⼒测试</h3>
<p>Stress是⼀个linux下的压⼒测试⼯具，专⻔为那些想要测试⾃⼰的系统，完全⾼负荷和监督这些设备运⾏的⽤户。</p>
<pre><code class="language-shell">安装
[root@qfedu.com ~]# yum install stress -y
 
测试场景举例 
测试CPU负荷 
[root@qfedu.com ~]# stress -c 4  //增加4个cpu进程，处理sqrt()函数函数，以提⾼系统CPU负荷
 
内存测试
[root@qfedu.com ~]# stress –i 4 –vm 10 –vm-bytes 1G –vm-hang 100 –timeout 100s
新增4个io进程，10个内存分配进程，每次分配⼤⼩1G，分配后不释放，测试100S

磁盘I/O测试
[root@qfedu.com ~]# stress –d 1 --hdd-bytes 3G  //新增1个写进程，每次写3G⽂件块

硬盘测试（不删除）
[root@qfedu.com ~]# stress –i 1 –d 10 --hdd-bytes 3G –hdd-noclean
新增1个IO进程，10个写进程，每次写⼊3G⽂件块，且不清除，会逐步将硬盘耗尽。
</code></pre>
<p><strong>Stress各主⽤参数说明</strong><br>
-表示后接⼀个中划线，--表示后接2个中划线，均可⽤于stress后接参数，不同表达⽅式</p>
<blockquote>
<p>-？<br>
--help 显示帮助信息<br>
--version 显示软件版本信息<br>
-t secs:<br>
--timeout secs指定运⾏多少秒<br>
--backoﬀ usecs 等待usecs微秒后才开始运⾏<br>
-c forks:<br>
--cpu forks 产⽣多个处理sqrt()函数的CPU进程<br>
-m forks<br>
--vm forks:产⽣多个处理malloc()内存分配函数的进程，后接进程数量<br>
-i forks<br>
--io forks:产⽣多个处理sync()函数的磁盘I/O进程<br>
--vm-bytes bytes：指定内存的byte数，默认值是1<br>
--vm-hang:表示malloc分配的内存多少时间后在free()释放掉<br>
-d :</p>
<p>--hdd:写进程，写⼊固定⼤⼩，通过mkstemp()函数写⼊当前⽬录</p>
<p>--hdd-bytes bytes:指定写的byte数，默认1G<br>
--hdd-noclean:不要将写⼊随机ascii数据的⽂件unlink，则写⼊的⽂件不删除，会保留在硬盘空间。</p>
</blockquote>
<h3 id="92-cpu资源限制">9.2 Cpu资源限制</h3>
<p>Cpu 资源<br>
主机上的进程会通过时间分⽚机制使⽤ CPU，CPU 的量化单位是频率，也就是每秒钟能执⾏的运算次数。为容器限制 CPU 资源并不能改变 CPU 的运⾏频率，⽽是改变每个容器能使⽤的 CPU 时间⽚。理想状态下，CPU 应该⼀直处于运算状态（并且进程需要的计算量不会超过 CPU 的处理能⼒）。</p>
<h4 id="921-限制cpu-share">9.2.1 限制Cpu Share</h4>
<p>什么是cpu share？<br>
docker 允许⽤户为每个容器设置⼀个数字，代表容器的 CPUshare，默认情况下每个容器的 share 是 1024。这个 share 是相对的，本身并不能代表任何确定的意义。当主机上有多个容器运⾏时，每个容器占⽤的 CPU 时间⽐例为它的 share 在总额中的⽐例。docker 会根据主机上运⾏的容器和进程动态调整每个容器使⽤ CPU 的时间⽐例。<br>
例：<br>
如果主机上有两个⼀直使⽤ CPU 的容器（为了简化理解，不考虑主机上其他进程），其 CPU share 都是 1024，那么两个容器 CPU 使⽤率都是 50%；如果把其中⼀个容器的 share 设置为 512，那么两者CPU 的使⽤率分别为 67% 和 33%；如果删除 share 为 1024 的容器，剩下来容器的 CPU 使⽤率将会是 100%。<br>
好处：<br>
能保证 CPU 尽可能处于运⾏状态，充分利⽤ CPU 资源，⽽且保证所有容器的相对公平；<br>
缺点：<br>
⽆法指定容器使⽤ CPU 的确定值。<br>
设置 CPU share 的参数：<br>
-c --cpu-shares，它的值是⼀个整数。<br>
我的机器是 4 核 CPU，因此运⾏⼀个stress容器,使⽤ stress 启动4 个进程来产⽣计算压⼒：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker pull progrium/stress
[root@qfedu.com ~]# yum install htop -y
[root@qfedu.com ~]# docker run --rm -it 
progrium/stress --cpu 4 
stress: info: [1] dispatching hogs: 4 cpu, 0 io, 0 vm, 0 hdd
stress: dbug: [1] using backoff sleep of 12000us
stress: dbug: [1] --&gt; hogcpu worker 4 [7] forked
stress: dbug: [1] using backoff sleep of 9000us
stress: dbug: [1] --&gt; hogcpu worker 3 [8] forked
stress: dbug: [1] using backoff sleep of 6000us
stress: dbug: [1] --&gt; hogcpu worker 2 [9] forked
stress: dbug: [1] using backoff sleep of 3000us
stress: dbug: [1] --&gt; hogcpu worker 1 [10] forked
</code></pre>
<p>在另外⼀个 Terminal 使⽤ htop 查看资源的使⽤情况：</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200820013659.png" alt="" loading="lazy"></figure>
<p>上图中看到，CPU 四个核资源都达到了 100%。四个 stress 进程CPU 使⽤率没有达到 100% 是因为系统中还有其他机器在运⾏。为了⽐较，另外启动⼀个 share 为 512 的容器：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run --rm -it -c 512 
progrium/stress --cpu 4 
stress: info: [1] dispatching hogs: 4 cpu, 0 io, 0 vm, 0 hdd
stress: dbug: [1] using backoff sleep of 12000us
stress: dbug: [1] --&gt; hogcpu worker 4 [6] forked
stress: dbug: [1] using backoff sleep of 9000us
stress: dbug: [1] --&gt; hogcpu worker 3 [7] forked
stress: dbug: [1] using backoff sleep of 6000us
stress: dbug: [1] --&gt; hogcpu worker 2 [8] forked
stress: dbug: [1] using backoff sleep of 3000us
stress: dbug: [1] --&gt; hogcpu worker 1 [9] forked
</code></pre>
<p>因为默认情况下，容器的 CPU share 为 1024，所以这两个容器的CPU 使⽤率应该⼤致为 2：1，下⾯是启动第⼆个容器之后的监控截图：</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200820013735.png" alt="" loading="lazy"></figure>
<p>两个容器分别启动了四个 stress 进程，第⼀个容器 stress 进程CPU 使⽤率都在 54% 左右，第⼆个容器 stress 进程 CPU 使⽤率在25% 左右，⽐例关系⼤致为 2：1，符合之前的预期。</p>
<h4 id="922-限制cpu-核数">9.2.2 限制Cpu 核数</h4>
<p>限制容器能使⽤的 CPU 核数<br>
-c --cpu-shares 参数只能限制容器使⽤ CPU 的⽐例，或者说优先级，⽆法确定地限制容器使⽤ CPU 的具体核数；从 1.13 版本之后，docker 提供了 --cpus 参数可以限定容器能使⽤的 CPU 核数。这个功能可以让我们更精确地设置容器 CPU 使⽤量，是⼀种更容易理解也因此更常⽤的⼿段。<br>
--cpus 后⾯跟着⼀个浮点数，代表容器最多使⽤的核数，可以精确到⼩数点⼆位，也就是说容器最⼩可以使⽤ 0.01 核 CPU。<br>
限制容器只能使⽤ 1.5 核数 CPU</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run --rm -it --cpus 1.5 
progrium/stress --cpu 3 
stress: info: [1] dispatching hogs: 3 cpu, 0 io, 0 vm, 0 hdd
stress: dbug: [1] using backoff sleep of 9000us
stress: dbug: [1] --&gt; hogcpu worker 3 [7] forked
stress: dbug: [1] using backoff sleep of 6000us
stress: dbug: [1] --&gt; hogcpu worker 2 [8] forked
stress: dbug: [1] using backoff sleep of 3000us
stress: dbug: [1] --&gt; hogcpu worker 1 [9] forked
</code></pre>
<p>在容器⾥启动三个 stress 来跑 CPU 压⼒，如果不加限制，这个容器会导致 CPU 的使⽤率为 300% 左右（也就是说会占⽤三个核的计算能⼒）。实际的监控如下图：</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200820013841.png" alt="" loading="lazy"></figure>
<p>可以看到，每个 stress 进程 CPU 使⽤率⼤约在 50%，总共的使⽤率为 150%，符合 1.5 核的设置。<br>
如果设置的 --cpus 值⼤于主机的 CPU 核数，docker 会直接报错：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run --rm -it --cpus 8 
progrium/stress --cpu 3 
docker: Error response from daemon: Range of CPUs is from 0.01 to 4.00, as there are only 4 CPUs available.
See 'docker run --help'.
</code></pre>
<p>如果多个容器都设置了 --cpus ，并且它们之和超过主机的 CPU 核数，并不会导致容器失败或者退出，这些容器之间会竞争使⽤ CPU，具体分配的 CPU 数量取决于主机运⾏情况和容器的 CPU share 值。也就是说 --cpus 只能保证在 CPU 资源充⾜的情况下容器最多能使⽤的CPU 数，docker 并不能保证在任何情况下容器都能使⽤这么多的CPU（因为这根本是不可能的）。</p>
<h4 id="923-cpu-绑定">9.2.3 CPU 绑定</h4>
<p>限制容器运⾏在某些 CPU 核<br>
注：<br>
⼀般并<strong>不推荐</strong>在⽣产中这样使⽤<br>
docker 允许调度的时候限定容器运⾏在哪个 CPU 上。</p>
<p>限制容器运⾏在哪些核上并不是⼀个很好的做法，因为它需要实现知道主机上有多少 CPU 核，⽽且⾮常不灵活。除⾮有特别的需求，⼀般并不推荐在⽣产中这样使⽤。<br>
假如主机上有 4 个核，可以通过 --cpuset 参数让容器只运⾏在前两个核上：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run --rm -it --cpuset-
cpus=0,1 progrium/stress --cpu 2 
stress: info: [1] dispatching hogs: 2 cpu, 0 io, 0 vm, 0 hdd
stress: dbug: [1] using backoff sleep of 6000us
stress: dbug: [1] --&gt; hogcpu worker 2 [7] forked
stress: dbug: [1] using backoff sleep of 3000us
stress: dbug: [1] --&gt; hogcpu worker 1 [8] forked
</code></pre>
<p>这样，监控中可以看到只有前⾯两个核 CPU 达到了 100% 使⽤率。</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200820014059.png" alt="" loading="lazy"></figure>
<p>--cpuset-cpus 参数可以和 -c --cpu-shares ⼀起使⽤，限制容器只能运⾏在某些 CPU 核上，并且配置了使⽤率。</p>
<h3 id="93-mem资源限制">9.3 Mem资源限制</h3>
<p>Docker 默认没有对容器内存进⾏限制，容器可以使⽤主机提供的所有内存。<br>
不限制内存带来的问题：</p>
<p>这是⾮常危险的事情，如果某个容器运⾏了恶意的内存消耗软件，或者代码有内存泄露，很可能会导致主机内存耗尽，因此导致服务不可⽤。可以为每个容器设置内存使⽤的上限，⼀旦超过这个上限，容器会被杀死，⽽不是耗尽主机的内存。<br>
限制内存带来的问题：<br>
限制内存上限虽然能保护主机，但是也可能会伤害到容器⾥的服务。如果为服务设置的内存上限太⼩，会导致服务还在正常⼯作的时候就被 OOM 杀死；如果设置的过⼤，会因为调度器算法浪费内存。<br>
合理做法：</p>
<ol>
<li>为应⽤做内存压⼒测试，理解正常业务需求下使⽤的内存情况，然后才能进⼊⽣产环境使⽤</li>
<li>⼀定要限制容器的内存使⽤上限，尽量保证主机的资源充⾜，⼀旦通过监控发现资源不⾜，就进⾏扩容或者对容器进⾏迁移如果可以（内存资源充⾜的情况）</li>
<li>尽量不要使⽤ swap，swap 的使⽤会导致内存计算复杂，对调度器⾮常不友好<br>
Docker 限制容器内存使⽤量:<br>
docker 启动参数中，和内存限制有关的包括（参数的值⼀般是内存⼤⼩，也就是⼀个正数，后⾯跟着内存单位 b、k、m、g，分别对应bytes、KB、MB、和 GB）：</li>
</ol>
<blockquote>
<p>-m --memory：<br>
容器能使⽤的最⼤内存⼤⼩，最⼩值为 4m<br>
--memory-swap：<br>
容器能够使⽤的 swap ⼤⼩<br>
--memory-swap 必须在 --memory 也配置的情况下才能有⽤。<br>
如果 --memory-swap 的值⼤于 --memory，那么容器能使⽤的总内存（内存 + swap）为 --memory-swap 的值，能使⽤的swap 值为 --memory-swap 减去 --memory 的值<br>
如果 --memory-swap 为 0，或者和 --memory 的值相同，那么容器能使⽤两倍于内存的 swap ⼤⼩，如果 --memory 对应的值是 200M，那么容器可以使⽤ 400M swap<br>
如果 --memory-swap 的值为 -1，那么不限制 swap 的使⽤，也就是说主机有多少 swap，容器都可以使⽤<br>
--memory-swappiness：<br>
默认情况下，主机可以把容器使⽤的匿名⻚（anonymous page）swap 出来，你可以设置⼀个 0-100 之间的值，代表允许swap 出来的⽐例<br>
--memory-reservation：<br>
设置⼀个内存使⽤的 soft limit，如果 docker 发现主机内存不⾜，会执⾏ OOM 操作。这个值必须⼩于 --memory 设置的值<br>
--kernel-memory：<br>
容器能够使⽤的 kernel memory ⼤⼩，最⼩值为 4m。<br>
--oom-kill-disable：<br>
是否运⾏ OOM 的时候杀死容器。只有设置了 -m，才可以把这个选项设置为 false，否则容器会耗尽主机内存，⽽且导致主机应⽤被杀死</p>
</blockquote>
<p>如果限制容器的内存使⽤为 64M，在申请 64M 资源的情况下，容器运⾏正常（如果主机上内存⾮常紧张，并不⼀定能保证这⼀点）：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run --rm -it -m 64m progrium/stress --vm 1 --vm-bytes 64M --vm-hang 0
WARNING: Your kernel does not support swap limit 
capabilities or the cgroup is not mounted. Memory 
limited without swap.
stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd
stress: dbug: [1] using backoff sleep of 3000us
stress: dbug: [1] --&gt; hogvm worker 1 [7] forked
stress: dbug: [7] allocating 67108864 bytes ...
stress: dbug: [7] touching bytes in strides of 4096 bytes ...
stress: dbug: [7] sleeping forever with allocated memory .....
</code></pre>
<p>⽽如果申请 100M 内存，会发现容器⾥的进程被 kill 掉了（worker 7 got signal 9，signal 9 就是 kill 信号）</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run --rm -it -m 64m progrium/stress --vm 1 --vm-bytes 100M --vm-hang 0 
WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd
stress: dbug: [1] using backoff sleep of 3000us
stress: dbug: [1] --&gt; hogvm worker 1 [7] forked
stress: dbug: [7] allocating 104857600 bytes ...
stress: dbug: [7] touching bytes in strides of 4096 bytes ...
stress: FAIL: [1] (415) &lt;-- worker 7 got signal 9
stress: WARN: [1] (417) now reaping child worker processes
stress: FAIL: [1] (421) kill error: No such process
stress: FAIL: [1] (451) failed run completed in 0s
</code></pre>
<h3 id="94-io-资源限制扩展">9.4 IO 资源限制【扩展】</h3>
<p>对于磁盘来说，考量的参数是容量和读写速度，因此对容器的磁盘限制也应该从这两个维度出发。⽬前 docker ⽀持对磁盘的读写速度进⾏限制，但是并没有⽅法能限制容器能使⽤的磁盘容量（⼀旦磁盘mount 到容器⾥，容器就能够使⽤磁盘的所有容量）。<br>
限制磁盘的读写速率<br>
docker 允许你直接限制磁盘的读写速率，对应的参数有：<br>
--device-read-bps：磁盘每秒最多可以读多少⽐特（bytes）<br>
--device-write-bps：磁盘每秒最多可以写多少⽐特（bytes）<br>
上⾯两个参数的值都是磁盘以及对应的速率，限制 limit 为正整数，单位可以是 kb、mb 和 gb。</p>
<p>⽐如可以把设备的读速率限制在 1mb：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run -it --device /dev/sda:/dev/sda --device-read-bps /dev/sda:1mb ubuntu:16.04 bash 
root@6c048edef769# cat /sys/fs/cgroup/blkio/blkio.throttle.read_bps_device 
8:0 1048576
root@6c048edef769# dd iflag=direct,nonblock if=/dev/sda of=/dev/null bs=5M count=10
10+0 records in
10+0 records out
52428800 bytes (52 MB) copied, 50.0154 s, 1.0 MB/s
</code></pre>
<p>从磁盘中读取 50m 花费了 50s 左右，说明磁盘速率限制起了作⽤。</p>
<p>另外两个参数可以限制磁盘读写频率（每秒能执⾏多少次读写操作）：</p>
<blockquote>
<p>--device-read-iops：磁盘每秒最多可以执⾏多少 IO 读操作<br>
--device-write-iops：磁盘每秒最多可以执⾏多少 IO 写操作</p>
</blockquote>
<p>上⾯两个参数的值都是磁盘以及对应的 IO 上限。<br>
⽐如，可以让磁盘每秒最多读 100 次：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run -it --device /dev/sda:/dev/sda --device-read-iops /dev/sda:100 ubuntu:16.04 bash root@2e3026e9ccd2:/[root@qfedu.com 
~]# dd iflag=direct,nonblock if=/dev/sda of=/dev/null bs=1k count=1000
1000+0 records in
1000+0 records out
1024000 bytes (1.0 MB) copied, 9.9159 s, 103 kB/s
</code></pre>
<p>从测试中可以看出，容器设置了读操作的 iops 为 100，在容器内部从 block 中读取 1m 数据（每次 1k，⼀共要读 1000 次），共计耗时约 10s，换算起来就是 100 iops/s，符合预期结果。</p>
<h2 id="10-端口转发">10、端⼝转发</h2>
<p>使⽤端⼝转发解决容器端⼝访问问题</p>
<h3 id="101-mysql应用端口转发">10.1 MySQL应⽤端⼝转发</h3>
<p><strong>-p</strong><br>
创建应⽤容器的时候，⼀般会做端⼝映射，这样是为了让外部能够访问这些容器⾥的应⽤。可以⽤多个-p<strong>指定</strong>多个端⼝映射关系。<br>
本例使⽤-p把本地3307转发到容器的3306，其他参数需要查看发布容器的⻚⾯提示</p>
<pre><code class="language-shell">查看本地地址：
[root@qfedu.com ~]#ip a 
  ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000
  link/ether 00:0c:29:0a:5b:8b brd ff:ff:ff:ff:ff:ff
  inet 192.168.245.134/24 brd 192.168.245.255 scope global dynamic ens33
    valid_lft 1444sec preferred_lft 1444sec

运⾏容器：
[root@qfedu.com ~]# docker run --name mysql1 -p 3307:3306  -e MYSQL_ROOT_PASSWORD=123 daocloud.io/library/mysql

查看Ip地址：
[root@qfedu.com ~]# docker inspect  mysql1 | grep 
IPAddress
      &quot;SecondaryIPAddresses&quot;: null,
      &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,
          &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,
          
通过本地IP：192.168.245.134的3307端⼝访问容器mysql1内的数
据库，出现如下提示恭喜你
[root@qfedu.com ~]# mysql -u root -p123 -h 192.168.245.134 -P3307
Welcome to the MariaDB monitor.  Commands end with ; 
or \g.
Your MySQL connection id is 3
Server version: 5.7.18 MySQL Community Server (GPL)
Copyright (c) 2000, 2016, Oracle, MariaDB 
Corporation Ab and others.
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
MySQL [(none)]&gt; 
</code></pre>
<h3 id="102-redis应用端口转发">10.2 Redis应⽤端⼝转发</h3>
<p><strong>-P</strong><br>
Docker 会<strong>随机映射</strong>⼀个 49000~49900 的端⼝到内部容器开放的⽹络端⼝。如下：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker images
REPOSITORY      TAG         IMAGE ID       CREATED       SIZE
docker.io/redis   latest        e4a35914679d     2weeks ago     182.9 MB
 
[root@qfedu.com ~]# docker run --name myredis -P -d docker.io/redis
805d0e21e531885aad61d3e82395210b50621f1991ec4b7f9a0e
25c815cc0272

[root@qfedu.com ~]# docker ps
CONTAINER ID     IMAGE        COMMAND          
CREATED       STATUS        PORTS           NAMES
805d0e21e531     docker.io/redis   &quot;docker-
entrypoint.sh&quot;  4 seconds ago    Up 3 seconds     
0.0.0.0:32768-&gt;6379/tcp  myredis
从上⾯的结果中可以看出，本地主机的32768端⼝被映射到了redis容器的6379端⼝上，也就是说访问本机的32768端⼝即可访问容器内redis端⼝。

测试看下，登陆redis容器，随意写个数据
[root@qfedu.com ~]# docker run --rm -it --name myredis2 --link myredis:redisdb docker.io/redis /bin/
bash
root@be44d955d6f4:/data[root@qfedu.com ~]# redis-cli -h redisdb -p 6379
redisdb:6379&gt; set wing 123
OK
redisdb:6379&gt;

在别的机器上通过上⾯映射的端⼝32768连接这个容器的redis
[root@qfedu.com ~]# redis-cli -h 192.168.245.134 -p 32768
192.168.1.23:32768&gt; get wing
&quot;123&quot;
</code></pre>
<h2 id="11-容器卷">11、容器卷</h2>
<h3 id="111-容器卷操作">11.1 容器卷操作</h3>
<p>容器卷是容器和宿主机之间的⽂件共享⽅式之⼀</p>
<pre><code class="language-shell">新卷只能在容器创建过程当中挂载
[root@qfedu.com ~]# docker run -it --name=&quot;voltest&quot; -v /tmp:/test  daocloud.io/library/centos:5 /bin/bash

共享其他容器的卷：
[root@qfedu.com ~]# docker run -it --volumes-from bc4181  daocloud.io/library/centos:5  /bin/bash

实际应⽤中可以利⽤多个-v选项把宿主机上的多个⽬录同时共享给新建
容器：

⽐如： 
[root@qfedu.com ~]# docker run -it -v /abc:/abc -v /def:/def 1ae9
[root@qfedu.com ~]# docker run  -v /vol/index.html:/usr/share/nginx/html/index.html -it nginx /bin/bash
</code></pre>
<p>注意：<br>
如果是⽂件共享，数据不能同步更新</p>
<h3 id="112-volume扩展阅读">11.2 Volume【扩展阅读】</h3>
<p>容器技术使⽤了 rootfs 机制和 Mount Namespace，构建出了⼀个同宿主机完全隔离开的⽂件系统环境。这时候，就需要考虑这样两个问题：<br>
容器⾥进程新建的⽂件，怎么才能让宿主机获取到？<br>
宿主机上的⽂件和⽬录，怎么才能让容器⾥的进程访问到？</p>
<p>这正是 Docker Volume 要解决的问题：Volume 机制，允许你将宿主机上指定的⽬录或者⽂件，挂载到容器⾥⾯进⾏读取和修改操作。<br>
在 Docker 项⽬⾥，它⽀持两种 Volume 声明⽅式，可以把宿主机⽬录挂载进容器的 /test ⽬录当中：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run -v /test ...
[root@qfedu.com ~]# docker run -v /home:/test ...
</code></pre>
<p>这两种声明⽅式的本质是相同的：都是把⼀个宿主机的⽬录挂载进了容器的 /test ⽬录。<br>
第⼀种情况没有显示声明宿主机⽬录，Docker 就会默认在宿主机上创建⼀个临时⽬录 /var/lib/docker/volumes/[VOLUME_ID]/_data，然后把它挂载到容器的 /test ⽬录上。<br>
第⼆种情况，Docker 就直接把宿主机的 /home ⽬录挂载到容器的 /test ⽬录上。<br>
那么，Docker ⼜是如何做到把⼀个宿主机上的⽬录或者⽂件，挂载到容器⾥⾯去呢？难道⼜是 Mount Namespace 的⿊科技吗？实际上，并不需要这么麻烦。<br>
已经介绍过，当容器进程被创建之后，尽管开启了 MountNamespace，但是在它执⾏ chroot（或者 pivot_root）之前，容器进程⼀直可以看到宿主机上的整个⽂件系统。<br>
⽽宿主机上的⽂件系统，也⾃然包括了要使⽤的容器镜像。这个镜像的各个层，保存在 /var/lib/docker/aufs/diﬀ ⽬录下，在容器进程启动后，它们会被联合挂载在 /var/lib/docker/aufs/mnt/ ⽬录中，这样容器所需的 rootfs 就准备好了。</p>
<p>所以，只需要在 rootfs 准备好之后，在执⾏ chroot 之前，把Volume 指定的宿主机⽬录（⽐如 /home ⽬录），挂载到指定的容器⽬录（⽐如 /test ⽬录）在宿主机上对应的⽬录（即/var/lib/docker/aufs/mnt/[可读写层 ID]/test）上，这个 Volume 的挂载⼯作就完成了。<br>
由于执⾏这个挂载操作时，&quot;容器进程&quot;已经创建了，也就意味着此时 Mount Namespace 已经开启了。所以，这个挂载事件只在这个容器⾥可⻅。你在宿主机上，是看不⻅容器内部的这个挂载点的。这就保证了容器的隔离性不会被 Volume 打破。<br>
注意：这⾥提到的 &quot; 容器进程 &quot;，是 Docker 创建的⼀个容器初始化进程 (dockerinit)，⽽不是应⽤进程 (ENTRYPOINT + CMD)。dockerinit 会负责完成根⽬录的准备、挂载设备和⽬录、配置hostname 等⼀系列需要在容器内进⾏的初始化操作。最后，它通过execv() 系统调⽤，让应⽤进程取代⾃⼰，成为容器⾥的 PID=1 的进程。<br>
⽽这⾥要使⽤到的挂载技术，就是 Linux 的绑定挂载（bind mount）机制。它的主要作⽤就是，允许你将⼀个⽬录或者⽂件，⽽不是整个设备，挂载到⼀个指定的⽬录上。并且，这时你在该挂载点上进⾏的任何操作，只是发⽣在被挂载的⽬录或者⽂件上，⽽原挂载点的内容则会被隐藏起来且不受影响。<br>
其实，如果你了解 Linux 内核的话，就会明⽩，绑定挂载实际上是⼀个 inode 替换的过程。在 Linux 操作系统中，inode 可以理解为存放⽂件内容的&quot;对象&quot;，⽽ dentry，也叫⽬录项，就是访问这个 inode所使⽤的&quot;指针&quot;<br>
mount --bind /home /test，会将 /home 挂载到 /test 上。其实相当于将 /test 的 dentry，重定向到了 /home 的 inode。这样当修改/test ⽬录时，实际修改的是 /home ⽬录的 inode。这也就是为何，⼀旦执⾏ umount 命令，/test ⽬录原先的内容就会恢复：因为修改真正发⽣在的，是 /home ⽬录⾥。进程在容器⾥对这个 /test ⽬录进⾏的所有操作，都实际发⽣在宿主机的对应⽬录（⽐如，/home，或者/var/lib/docker/volumes/[VOLUME_ID]/_data）⾥，⽽不会影响容器镜像的内容。<br>
这个 /test ⽬录⾥的内容，既然挂载在容器 rootfs 的可读写层，它会不会被 docker commit 提交掉呢？也不会。<br>
原因前⾯提到过。容器的镜像操作，⽐如 docker commit，都是发⽣在宿主机空间的。⽽由于 Mount Namespace 的隔离作⽤，宿主机并不知道这个绑定挂载的存在。所以，在宿主机看来，容器中可读写层的 /test ⽬录（/var/lib/docker/aufs/mnt/[可读写层 ID]/test），始终是空的。<br>
不过，由于 Docker ⼀开始还是要创建 /test 这个⽬录作为挂载点，所以执⾏了 docker commit 之后，新产⽣的镜像⾥，会多出来⼀个空的 /test ⽬录。毕竟，新建⽬录操作，⼜不是挂载操作，MountNamespace 对它可起不到&quot;障眼法&quot;的作⽤。</p>
<pre><code class="language-shell">1.启动⼀个 helloworld 容器，给它声明⼀个 Volume，挂载在容器⾥的 /test ⽬录上：
[root@qfedu.com ~]# docker run -d -v /test helloworld
cf53b766fa6f

2.容器启动之后，查看⼀下这个 Volume 的 ID：
[root@qfedu.com ~]# docker volume ls
DRIVER        VOLUME NAME
local        
cb1c2f7221fa9b0971cc35f68aa1034824755ac44a034c0c0a1d
d318838d3a6d

3.使⽤这个 ID，可以找到它在 Docker ⼯作⽬录下的 volumes 路径：
[root@qfedu.com ~]# ls /var/lib/docker/volumes/cb1c2f7221fa/_data/
这个 _data ⽂件夹，就是这个容器的 Volume 在宿主机上对应的临时⽬录了。

4.在容器的 Volume ⾥，添加⼀个⽂件 text.txt：
[root@qfedu.com ~]# docker exec -it cf53b766fa6f /bin/sh
cd test/
touch text.txt

5.再回到宿主机，就会发现 text.txt 已经出现在了宿主机上对应的临时⽬录⾥：
[root@qfedu.com ~]# ls /var/lib/docker/volumes/cb1c2f7221fa/_data/
text.txt
可是，如果你在宿主机上查看该容器的可读写层，虽然可以看到这个 /test ⽬录，但其内容是空的：
[root@qfedu.com ~]# ls /var/lib/docker/aufs/mnt/6780d0778b8a/test
</code></pre>
<p>可以确认，容器 Volume ⾥的信息，并不会被 docker commit 提交掉；但这个挂载点⽬录 /test 本身，则会出现在新的镜像当中。以上内容，就是 Docker Volume 的核⼼原理了。<br>
<strong>Docker 容器&quot;全景图&quot;：</strong></p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200820020548.png" alt="" loading="lazy"></figure>
<p>⼀个&quot;容器&quot;，实际上是⼀个由 Linux Namespace、Linux Cgroups和 rootfs 三种技术构建出来的进程的隔离环境。</p>
<h2 id="12-优化centos7镜像">12、优化Centos7镜像</h2>
<p>镜像下载：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker pull daocloud.io/library/centos:latest
</code></pre>
<p>包管理:<br>
默认情况下，为了减⼩镜像的尺⼨，在构建 CentOS 镜像时⽤了yum的nodocs选项。 如果您安装⼀个包后发现⽂件缺失，请在/etc/yum.conf中注释掉tsﬂogs=nodocs并重新安装您的包。<br>
systemd 整合:</p>
<p>因为 systemd 要求 CAPSYSADMIN 权限，从⽽得到了读取到宿主机 cgroup 的能⼒，CentOS7 中已经⽤ fakesystemd 代替了 systemd来解决依赖问题。 如果仍然希望使⽤ systemd，可⽤参考下⾯的Dockerﬁle：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# vim Dockerfile
FROM daocloud.io/library/centos:7
MAINTAINER &quot;wing&quot;  wing@qq.com
ENV container docker
RUN yum -y swap -- remove fakesystemd -- install  
systemd systemd-libs
RUN yum -y update; yum clean all; \
(cd /lib/systemd/system/sysinit.target.wants/; for i 
in *; do [ $i == systemd-tmpfiles-setup.service ] || 
rm -f $i; done); \
rm -f /lib/systemd/system/multi-user.target.wants/*;\
rm -f /etc/systemd/system/*.wants/*;\
rm -f /lib/systemd/system/local-fs.target.wants/*; \
rm -f 
/lib/systemd/system/sockets.target.wants/*udev*; \
rm -f 
/lib/systemd/system/sockets.target.wants/*initctl*; 
\
rm -f /lib/systemd/system/basic.target.wants/*;\
rm -f /lib/systemd/system/anaconda.target.wants/*;
VOLUME [ &quot;/sys/fs/cgroup&quot; ]
CMD [&quot;/usr/sbin/init&quot;]
</code></pre>
<p>这个Dockerﬁle删除fakesystemd 并安装了 systemd。然后再构建基础镜像:</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker build --rm -t local/c7- systemd .
</code></pre>
<p>⼀个包含 systemd 的应⽤容器示例<br>
为了使⽤像上⾯那样包含 systemd 的容器，需要创建⼀个类似下⾯的Dockerﬁle：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# vim Dockerfile
FROM local/c7-systemd
RUN yum -y install httpd; yum clean all; systemctl 
enable httpd.service
EXPOSE 80
CMD [&quot;/usr/sbin/init&quot;]
</code></pre>
<p>构建镜像:</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker build --rm -t local/c7-systemd-httpd .
</code></pre>
<p>运⾏包含 systemd 的应⽤容器:<br>
为了运⾏⼀个包含 systemd 的容器，需要使⽤--privileged选项，并且挂载主机的 cgroups ⽂件夹。 下⾯是运⾏包含 systemd 的 httpd容器的示例命令：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run --privileged -ti -v /sys/fs/cgroup:/sys/fs/cgroup:ro -p 80:80 local/c7-systemd-httpd
</code></pre>
<p>注意：上条命令不能添加/bin/bash，添加了会导致服务不可⽤，⽽且有些服务可能会发现之前提到的权限不够的问题，但是如果不加会运⾏在前台(没有⽤-d)，可以⽤ctrl+p+q放到后台去测试可⽤：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# elinks --dump http://docker    //下⾯为apache默认⻚⾯
                      Testing 123..
  This page is used to test the proper operation of the [1]Apache HTTP
  server after it has been installed. If you can read this page it means
  that this site is working properly. This server is powered by [2]CentOS.
</code></pre>
<p>再来个安装openssh-server的例⼦：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# vim Dockerfile
FROM local/c7-systemd
RUN yum -y install openssh-server; yum clean all; 
systemctl enable sshd.service
RUN echo 1 | passwd --stdin root
EXPOSE 22
CMD [&quot;/usr/sbin/init&quot;]

[root@qfedu.com ~]# docker build --rm -t local/c7-systemd-sshd .  
[root@qfedu.com ~]# docker run --privileged -ti -v /sys/fs/cgroup:/sys/fs/cgroup:ro -p 2222:22 local/c7-systemd-sshd  
[root@qfedu.com ~]# ssh docker -p 2222  //docker为我宿主机的主机名称
</code></pre>
<h2 id="13-docker网络">13、Docker⽹络</h2>
<p><strong>容器⽹络</strong><br>
注：⾯试⽤，⽤了编排之后就没有⽤了</p>
<p>Docker安装后，默认会创建三种⽹络类型，bridge、host和none<br>
查看当前⽹络：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker network list
NETWORK  ID      NAME        DRIVER        SCOPE
90b22f633d2f     bridge      bridge        local
e0b365da7fd2     host       host        local
da7b7a090837     none       null         local
</code></pre>
<p>1、bridge:⽹络桥接<br>
默认情况下启动、创建容器都是⽤该模式，所以每次docker容器重启时会按照顺序获取对应ip地址，这就导致容器每次重启，ip都发⽣变化<br>
2、none：⽆指定⽹络<br>
启动容器时，可以通过--network=none,docker容器不会分配局域⽹ip<br>
3、host：主机⽹络<br>
docker容器的⽹络会附属在主机上，两者是互通的。</p>
<p>使⽤host⽹络创建容器：</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run -it --name testnginx1 --net host 27a18801 /bin/bash
</code></pre>
<p>4、固定ip（个⼈认为是bridge）:<br>
<strong>创建固定Ip的容器</strong><br>
4.1、创建⾃定义⽹络类型，并且指定⽹段</p>
<pre><code class="language-shell">[root@qfedu.com ~]#docker network create --subnet=192.168.0.0/16 staticnet
</code></pre>
<p>通过docker network ls可以查看到⽹络类型中多了⼀个staticnet<br>
4.2、使⽤新的⽹络类型创建并启动容器</p>
<pre><code class="language-shell">[root@qfedu.com ~]#docker run -it --name userserver --net staticnet --ip 192.168.0.2 centos:6 /bin/bash
</code></pre>
<p>通过docker inspect可以查看容器ip为192.168.0.2，关闭容器并重启，发现容器ip并未发⽣改变<br>
不能使⽤默认桥接⽹络，不然会报错</p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker run -it --rm --name &quot;test&quot; -v /test/b.txt:/tmp/b.txt -v /tmp:/abc --net bridge --ip 172.17.0.9 1f8fe54 /bin/sh
docker: Error response from daemon: user specified IP address is supported on user defined networks only.
</code></pre>
<p><strong>扩展：异主容器互联</strong></p>
<p>路由⽅式<br>
⼩规模docker环境⼤部分运⾏在单台主机上，如果公司⼤规模采⽤docker，那么多个宿主机上的docker如何互联</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200820021231.png" alt="" loading="lazy"></figure>
<p>Docker默认的内部ip为172.17.42.0⽹段，所以必须要修改其中⼀台的默认⽹段以免ip冲突。</p>
<pre><code class="language-shell">[root@qfedu.com ~]# vim /etc/sysconfig/docker-network
DOCKER_NETWORK_OPTIONS= --bip=172.18.42.1/16
[root@qfedu.com ~]# reboot 


docker 130上：
[root@qfedu.com ~]# route add -net 172.18.0.0/16 gw 192.168.18.128
docker 128上：
[root@qfedu.com ~]# route add -net 172.17.0.0/16 gw 192.168.18.130
</code></pre>
<p>现在两台宿主机⾥的容器就可以通信了。</p>
<h2 id="14-docker数据存储位置">14、Docker数据存储位置</h2>
<p><strong>查看默认存储位置</strong></p>
<pre><code class="language-shell">[root@qfedu.com ~]# docker info | grep Root
Docker Root Dir:  /var/lib/docker
</code></pre>
<p><strong>修改默认存储位置</strong></p>
<p>在dockerd的启动命令后⾯追加--data-root参数指定新的位置</p>
<pre><code class="language-shell">[root@qfedu.com ~]# vim /usr/lib/systemd/system/docker.service
ExecStart=/usr/bin/dockerd -H fd:// --
containerd=/run/containerd/containerd.sock --data-
root=/data
[root@qfedu.com ~]# systemctl daemon-reload
[root@qfedu.com ~]# systemctl restart docker
查看是否⽣效：
[root@qfedu.com ~]# docker info | grep Root
Docker Root Dir: /data
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringMVC]]></title>
        <id>https://jonchan1013.github.io/post/springmvc/</id>
        <link href="https://jonchan1013.github.io/post/springmvc/">
        </link>
        <updated>2020-08-04T07:56:29.000Z</updated>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200804155812.png" alt="" loading="lazy"></figure>
<h2 id="1-回顾mvc">1、回顾MVC</h2>
<h3 id="11-什么是mvc">1.1 什么是MVC?</h3>
<ul>
<li>MVC是模型（model）,视图（view）,控制器(controller)的简写，是一种软件设计规范</li>
<li>是将业务逻辑代码，数据，显示分离的方法来组织代码</li>
<li>MVC主要的作用是<strong>降低了视图与业务逻辑之间的双向耦合</strong></li>
<li>MVC不是一种设置模式，MVC是一种架构模式，当然不同的MVC存在差异。</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200804160234.png" alt="" loading="lazy"></figure>
<p>**Model（模型）：**数据模型，提供要展示的数据，因此包含数据和行为，可以认为是领域模型或JavaBean组件（包含数据和行为），不过现在一般都分离开来：Value Object（数据Dao） 和 服务层（行为Service）。也就是模型提供了模型数据查询和模型数据的状态更新等功能，包括数据和业务。</p>
<p>**View（视图）：**负责进行模型的展示，一般就是我们见到的用户界面，客户想看到的东西。</p>
<p>**Controller（控制器）：**接收用户请求，委托给模型进行处理（状态改变），处理完毕后把返回的模型数据返回给视图，由视图负责展示。 也就是说控制器做了个调度员的工作。</p>
<p><strong>最经典的MVC就是：JSP+Servlet+javabean的模式</strong></p>
<h3 id="12-时代划分">1.2 时代划分</h3>
<p><strong>Model1时代</strong></p>
<ul>
<li>在web早期的开发中，通常采用的都是Model1。</li>
<li>Model1中，主要分为两层，视图层和模型层。</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200804160303.png" alt="" loading="lazy"></figure>
<p><strong>Model2时代</strong></p>
<p>Model2把一个项目分成三部分，包括<strong>视图、控制、模型</strong></p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200804160310.png" alt="" loading="lazy"></figure>
<ol>
<li>用户发送请求</li>
<li>Servlet接受请求数据，并调用对应的业务逻辑方法</li>
<li>业务处理完毕，返回更新后的Servlet</li>
<li>servlet转向JSP,由JSP来渲染页面</li>
<li>响应给前端更新后的页面</li>
</ol>
<p><strong>职业分析</strong></p>
<p><strong>Controller：控制器</strong>（Servlet）</p>
<ol>
<li>取得表单数据</li>
<li>调用业务逻辑</li>
<li>转向指定的页面</li>
</ol>
<p><strong>Model：模型</strong></p>
<ol>
<li>业务逻辑</li>
<li>保存数据的状态</li>
</ol>
<p><strong>View：视图</strong></p>
<h3 id="13-总结">1.3 总结</h3>
<ul>
<li>Model2这样不仅提高的代码的复用率与项目的扩展性，且大大降低了项目的维护成本。</li>
<li>Model 1模式的实现比较简单，适用于快速开发小规模项目，Model1中JSP页面身兼View和Controller两种角色，将控制逻辑和表现逻辑混杂在一起，从而导致代码的重用性非常低，增加了应用的扩展性和维护的难度。Model2消除了Model1的缺点</li>
</ul>
<h2 id="2-hellospringmvc">2、HelloSpringMVC</h2>
<h3 id="21-配置版实现">2.1 配置版实现</h3>
<ol>
<li>新建一个Moudle ， 添加web的支持！</li>
<li>确定导入了SpringMVC 的依赖！</li>
<li>配置web.xml ， 注册DispatcherServlet</li>
</ol>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot;
         version=&quot;4.0&quot;&gt;
    
&lt;!--配置DispatchServlet:这个是SpringMVC的核心，请求分发器，前端控制器--&gt;
    
    &lt;servlet&gt;
        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;
        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;
&lt;!--DispatcherServlet要绑定Spring的配置文件--&gt;
        &lt;init-param&gt;
            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
            &lt;param-value&gt;classpath:springmvc-servlet.xml&lt;/param-value&gt;
        &lt;/init-param&gt;
&lt;!--启动级别：初始化启动--&gt;
        &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;
    &lt;/servlet&gt;

&lt;!--在Springmvc中 / 和 /*的区别
/: 只匹配所有的请求，不会匹配JSP页面
/*:匹配所有的请求，包括jsp页面--&gt;
    &lt;servlet-mapping&gt;
        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;
        &lt;url-pattern&gt;/&lt;/url-pattern&gt;
    &lt;/servlet-mapping&gt;
    
&lt;/web-app&gt;
</code></pre>
<ol start="4">
<li>
<p>编写SpringMVC 的 配置文件！</p>
<p>名称：springmvc-servlet.xml : [servletname]-servlet.xml说明，这里的名称要求是按照官方来的</p>
</li>
</ol>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
      xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
      xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
       http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;

&lt;/beans&gt;
</code></pre>
<ol start="5">
<li>添加处理器映射</li>
</ol>
<pre><code class="language-xml">&lt;!--处理器映射器--&gt;
    &lt;bean class=&quot;org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping&quot;/&gt;
</code></pre>
<ol start="6">
<li>添加处理器适配器</li>
</ol>
<pre><code class="language-xml">&lt;!--处理器适配器--&gt;
&lt;bean class=&quot;org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter&quot;/&gt;
</code></pre>
<ol start="7">
<li>添加视图解析器</li>
</ol>
<pre><code class="language-xml">&lt;!--视图解析器 以后模板引擎会使用：Thymeleaf Freemarker--&gt;
    &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot; id=&quot;internalResourceViewResolver&quot;&gt;
&lt;!-- 前缀和后缀--&gt;
        &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/JSP/&quot;/&gt;
        &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;
    &lt;/bean&gt;
</code></pre>
<ol start="8">
<li>编写我们要操作业务的Controller，要么实现Controller接口，要么增加注解；（需要返回一个ModelandView，封装数据，转发视图）</li>
</ol>
<pre><code class="language-java">package com.zhuuu.Controller;

import org.springframework.web.servlet.ModelAndView;
import org.springframework.web.servlet.mvc.Controller;

import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;

public class HelloController implements Controller {
    public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception {
        
        ModelAndView mv = new ModelAndView();

        //业务代码：封装数据
        String result = &quot;HelloSpringMVC&quot;;
        mv.addObject(&quot;msg&quot;,result);

        //视图跳转
        mv.setViewName(&quot;test&quot;);

        //返回model and view
        return mv;
    }
}
</code></pre>
<ol start="9">
<li>将自己的类交给SpringIOC容器，注册bean</li>
</ol>
<pre><code class="language-xml">&lt;!--BeanNameUrlHandlerMapping:bean--&gt;
    &lt;bean id=&quot;/hello&quot; class=&quot;com.zhuuu.Controller.HelloController&quot;/&gt;
</code></pre>
<ol start="10">
<li>编写需要跳转的页面</li>
</ol>
<pre><code class="language-jsp">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Title&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

${msg}

&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<ol start="11">
<li>配置Tomcat 启动测试！</li>
</ol>
<p><strong>404error的问题</strong></p>
<p><strong>可能遇到的问题：访问出现404，排查步骤：</strong></p>
<ol>
<li>查看控制台输出，看一下是不是缺少了什么jar包。</li>
<li>如果jar包存在，显示无法输出，就在IDEA的项目发布中，添加lib依赖！</li>
<li>重启Tomcat 即可解决！</li>
</ol>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200804161133.png" alt="" loading="lazy"></figure>
<h3 id="22-注解版实现">2.2 注解版实现</h3>
<p><strong>第一步:新建一个Moudle , 添加web支持！</strong></p>
<p><strong>第二步:由于Maven可能存在资源过滤的问题，我们将配置完善</strong></p>
<pre><code class="language-xml">&lt;build&gt;
    &lt;resources&gt;
        &lt;resource&gt;
            &lt;directory&gt;src/main/java&lt;/directory&gt;
            &lt;includes&gt;
                &lt;include&gt;**/*.properties&lt;/include&gt;
                &lt;include&gt;**/*.xml&lt;/include&gt;
            &lt;/includes&gt;
            &lt;filtering&gt;false&lt;/filtering&gt;
        &lt;/resource&gt;
        &lt;resource&gt;
            &lt;directory&gt;src/main/resources&lt;/directory&gt;
            &lt;includes&gt;
                &lt;include&gt;**/*.properties&lt;/include&gt;
                &lt;include&gt;**/*.xml&lt;/include&gt;
            &lt;/includes&gt;
            &lt;filtering&gt;false&lt;/filtering&gt;
        &lt;/resource&gt;
    &lt;/resources&gt;
&lt;/build&gt;
</code></pre>
<p><strong>第三步:在pom.xml文件引入相关的依赖</strong>：<br>
主要有Spring框架核心库、Spring MVC、servlet , JSTL等。我们在父依赖中已经引入了！</p>
<p><strong>第四步:配置web.xml</strong></p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot;
         version=&quot;4.0&quot;&gt;

    &lt;!--1.注册servlet--&gt;
    &lt;servlet&gt;
        &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt;
        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;
        &lt;!--通过初始化参数指定SpringMVC配置文件的位置，进行关联--&gt;
        &lt;init-param&gt;
            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
            &lt;param-value&gt;classpath:springmvc-servlet.xml&lt;/param-value&gt;
        &lt;/init-param&gt;
        &lt;!-- 启动顺序，数字越小，启动越早 --&gt;
        &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;
    &lt;/servlet&gt;

    &lt;!--所有请求都会被springmvc拦截 --&gt;
    &lt;servlet-mapping&gt;
        &lt;servlet-name&gt;SpringMVC&lt;/servlet-name&gt;
        &lt;url-pattern&gt;/&lt;/url-pattern&gt;
    &lt;/servlet-mapping&gt;

&lt;/web-app&gt;
</code></pre>
<p><strong>第五步:添加Spring MVC配置文件</strong></p>
<ul>
<li>让IOC的注解生效</li>
<li>静态资源过滤 ：HTML . JS . CSS . 图片 ， 视频 …..</li>
<li>MVC的注解驱动</li>
<li>配置视图解析器</li>
</ul>
<p>在resource目录下添加springmvc-servlet.xml配置文件，配置的形式与Spring容器配置基本类似，为了支持基于注解的IOC，设置了自动扫描包的功能，具体配置信息如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
       xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans.xsd
        http://www.springframework.org/schema/context
        https://www.springframework.org/schema/context/spring-context.xsd
        http://www.springframework.org/schema/mvc
        https://www.springframework.org/schema/mvc/spring-mvc.xsd&quot;&gt;

    &lt;!-- 自动扫描包，让指定包下的注解生效,由IOC容器统一管理 --&gt;
    &lt;context:component-scan base-package=&quot;com.zhuuu.controller&quot;/&gt;
    &lt;!-- 让Spring MVC不处理静态资源 .css .js .html .mp3 .mp4--&gt;
    &lt;mvc:default-servlet-handler /&gt;
    &lt;!--
    支持mvc注解驱动
        在spring中一般采用@RequestMapping注解来完成映射关系
        要想使@RequestMapping注解生效
        必须向上下文中注册DefaultAnnotationHandlerMapping
        和一个AnnotationMethodHandlerAdapter实例
        这两个实例分别在类级别和方法级别处理。
        而annotation-driven配置帮助我们自动完成上述两个实例的注入。
     --&gt;
    &lt;mvc:annotation-driven /&gt;

    &lt;!-- 视图解析器 --&gt;
    &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;
          id=&quot;internalResourceViewResolver&quot;&gt;
        &lt;!-- 前缀 --&gt;
        &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot; /&gt;
        &lt;!-- 后缀 --&gt;
        &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt;
    &lt;/bean&gt;

&lt;/beans&gt;
</code></pre>
<p><strong>在视图解析器中我们把所有的视图都存放在/WEB-INF/目录下，这样可以保证视图安全，因为这个目录下的文件，客户端不能直接访问。</strong></p>
<p><strong>第六步:创建Controller</strong></p>
<pre><code class="language-java">package com.zhuuu.controller;

import org.springframework.stereotype.Controller;
import org.springframework.ui.Model;
import org.springframework.web.bind.annotation.RequestMapping;

@Controller
public class HelloController{
    @RequestMapping(&quot;/hello&quot;)
    public String hello(Model model){

        //封装数据
        model.addAttribute(&quot;msg&quot;,&quot;hello,Spring MVC annatation&quot;);

        return &quot;hello&quot;; // 会被视图解析器处理
    }
}
</code></pre>
<p><strong>@Controller是为了让Spring IOC容器初始化时达到自动扫描的目的</strong></p>
<p><strong>@RequestMapping是为了映射请求路径</strong></p>
<p><strong>第七步:创建视图层</strong></p>
<p>在WEB-INF/ jsp目录中创建hello.jsp ， 视图可以直接取出并展示从Controller带回的信息；</p>
<p>可以通过EL表示取出Model中存放的值，或者对象；</p>
<pre><code class="language-jsp">&lt;%@ page contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Title&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

${msg}

&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p><strong>第八步:配置Tomcat运行</strong></p>
<p><strong>OK，运行成功！</strong></p>
<p><strong>注意事项:</strong></p>
<pre><code class="language-xml">**/ 和 /\* 的区别：**
&lt; url-pattern &gt; / &lt;/ url-pattern &gt; 不会匹配到.jsp， 只针对我们编写的请求；
即：.jsp 不会进入spring的 DispatcherServlet类 。
&lt; url-pattern &gt; /* &lt;/ url-pattern &gt; 会匹配 *.jsp，
会出现返回 jsp视图 时再次进入spring的DispatcherServlet 类，导致找不到对应的controller所以报404错。
</code></pre>
<h3 id="23-小结">2.3 小结</h3>
<p>实现步骤其实非常简单：</p>
<ol>
<li>新建一个web项目</li>
<li>导入相关jar包</li>
<li>编写web.xml，注册DispatchterServlet</li>
<li>编写SpringMVC配置文件</li>
<li>接下来就要使去创建对应的控制类，controller</li>
<li>最后完善前端试图和controller之间的对应</li>
<li>测试运行调试</li>
</ol>
<p><strong>使用springMVC必须配置的三大件：</strong></p>
<p><strong>处理器映射器、处理器适配器、视图解析器</strong></p>
<p>通常，我们只需要<strong>手动配置视图解析器</strong>，而<strong>处理器映射器</strong>和<strong>处理器适配器</strong>只需要开启<strong>注解驱动</strong>即可，而省去了大段的xml配置</p>
<h2 id="3-restful风格">3、Restful风格</h2>
<h3 id="31-概念">3.1 概念</h3>
<p>Restful就是一个资源定位及资源操作的风格。不是标准也不是协议，只是一种风格。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。</p>
<h3 id="32-功能">3.2 功能</h3>
<ul>
<li>资源：互联网所有的事物都可以被抽象为资源</li>
<li>资源操作：使用POST、DELETE、PUT、GET，使用不同方法对资源进行操作。</li>
<li>分别对应 添加、 删除、修改、查询。</li>
</ul>
<h4 id="321-传统方式操作资源">3.2.1 传统方式操作资源</h4>
<p>通过不同的参数来实现不同的效果！方法单一，post 和 get</p>
<ul>
<li>http://127.0.0.1/item/queryItem.action?id=1 查询,GET</li>
<li>http://127.0.0.1/item/saveItem.action 新增,POST</li>
<li>http://127.0.0.1/item/updateItem.action 更新,POST</li>
<li>http://127.0.0.1/item/deleteItem.action?id=1 删除,GET或POST</li>
</ul>
<h4 id="322-使用restful操作资源">3.2.2 使用RESTful操作资源</h4>
<p>可以通过不同的请求方式来实现不同的效果！如下：请求地址一样，但是功能可以不同！</p>
<ul>
<li>http://127.0.0.1/item/1 查询,GET</li>
<li>http://127.0.0.1/item 新增,POST</li>
<li>http://127.0.0.1/item 更新,PUT</li>
<li>http://127.0.0.1/item/1 删除,DELETE</li>
</ul>
<p><strong>学习测试</strong></p>
<ol>
<li>在新建一个类 RestFulController</li>
</ol>
<pre><code class="language-java">@Controller
public class RestFulController {
}
</code></pre>
<ol start="2">
<li>在Spring MVC中可以使用 @PathVariable 注解，让方法参数的值对应绑定到一个URI模板变量上。</li>
</ol>
<pre><code class="language-java">@Controller
public class RestFulController {

    //映射访问路径
    @RequestMapping(&quot;/commit/{p1}/{p2}&quot;)
    public String index(@PathVariable int p1, @PathVariable int p2, Model model){
        
        int result = p1+p2;
        //Spring MVC会自动实例化一个Model对象用于向视图中传值
        model.addAttribute(&quot;msg&quot;, &quot;结果：&quot;+result);
        //返回视图位置
        return &quot;test&quot;;
    }
    
}
</code></pre>
<ol start="3">
<li>测试请求查看下</li>
</ol>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200804162003.png" alt="" loading="lazy"></figure>
<p>思考：使用路径变量的好处？</p>
<ul>
<li>使得路径变得更加简洁</li>
<li>获得参数更加方便，框架会自动进行类型转换</li>
<li>通过路径变量可以约束访问参数，如果类型不一样，则访问不到对应的请求方法，如这里访问是的路径是/commit/1/a，则路径与方法不匹配，而不会是参数转换失败。</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200804162028.png" alt="" loading="lazy"></figure>
<ol start="4">
<li>我们来修改下对应的参数类型，再次测试</li>
</ol>
<pre><code class="language-java">//映射访问路径
@RequestMapping(&quot;/commit/{p1}/{p2}&quot;)
public String index(@PathVariable int p1, @PathVariable String p2, Model model){

    String result = p1+p2;
    //Spring MVC会自动实例化一个Model对象用于向视图中传值
    model.addAttribute(&quot;msg&quot;, &quot;结果：&quot;+result);
    //返回视图位置
    return &quot;test&quot;;

}
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200804162101.png" alt="" loading="lazy"></figure>
<p><strong>使用method属性指定请求类型</strong></p>
<p>用于约束请求的类型，可以收窄请求范围。指定请求谓词的类型如GET, POST, HEAD, OPTIONS, PUT, PATCH, DELETE, TRACE等</p>
<p>Spring MVC 的 @RequestMapping 注解能够处理 HTTP 请求的方法, 比如 GET, PUT, POST, DELETE 以及 PATCH。</p>
<p><strong>所有的地址栏请求默认都会是 HTTP GET 类型的。</strong></p>
<pre><code>@GetMapping
@PostMapping
@PutMapping
@DeleteMapping
@PatchMapping
</code></pre>
<p>@GetMapping 是一个组合注解</p>
<p>它所扮演的是 @RequestMapping(method =RequestMethod.GET) 的一个快捷方式。</p>
<p>平时使用的会比较多！</p>
<pre><code class="language-java">@Controller
public class RestfulController  {
    @RequestMapping(value = &quot;/commit/{p1}/{p2}&quot;,method = RequestMethod.GET)
    public String index(@PathVariable int p1 , @PathVariable int p2, Model model){
        int result = p1+p2;
        model.addAttribute(&quot;msg&quot;,&quot;结果&quot;+result);
        return &quot;test&quot;;
    }
}
</code></pre>
<h2 id="3-结果跳转方式">3、结果跳转方式</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[综合性 B2C 电子商务平台项目]]></title>
        <id>https://jonchan1013.github.io/post/zong-he-xing-b2c-dian-zi-shang-wu-ping-tai-xiang-mu/</id>
        <link href="https://jonchan1013.github.io/post/zong-he-xing-b2c-dian-zi-shang-wu-ping-tai-xiang-mu/">
        </link>
        <updated>2020-08-03T17:02:00.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="1-项目介绍">1、项目介绍</h2>
<h3 id="11-电商行业发展">1.1 电商行业发展</h3>
<p>商务部统计数据显示，2012 年到 2016 年，我国网络购物用户人数从 2.42 亿人增长至4.67 亿人，增长近一倍。电子商务交易额从 8.1 万亿元增长至 26.1 万亿元，年均增长 34%。其中，网络零售交易额从 1.31 万亿元增长至 5.16 万亿元，年均增长 40%，对社会消费品零售总额增加值的贡献率从 17%增长至 30%。电子商务发展直接和间接带动的就业人数从1500 万人增长至 3700 万人。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="1-项目介绍">1、项目介绍</h2>
<h3 id="11-电商行业发展">1.1 电商行业发展</h3>
<p>商务部统计数据显示，2012 年到 2016 年，我国网络购物用户人数从 2.42 亿人增长至4.67 亿人，增长近一倍。电子商务交易额从 8.1 万亿元增长至 26.1 万亿元，年均增长 34%。其中，网络零售交易额从 1.31 万亿元增长至 5.16 万亿元，年均增长 40%，对社会消费品零售总额增加值的贡献率从 17%增长至 30%。电子商务发展直接和间接带动的就业人数从1500 万人增长至 3700 万人。</p>
<!-- more -->
<p>经过多年发展，目前规模较大电子商务平台企业纷纷开始构建生态系统，平台为商家和消费者提供交易、支付、物流等各方面全周期支持与服务，各大平台与平台商家之间依存越来越紧密，阿里系、腾讯系、百度系、京东系等主体均取得了显著规模效益。</p>
<h3 id="12-电商行业模式">1.2 电商行业模式</h3>
<p>B2B：企业到企业，商家到商家。代表：阿里巴巴。</p>
<p>B2C：商家到客户。代表：京东、淘宝商城（B2B2C）、天猫网。</p>
<p>C2C：客户到客户。淘宝集市、闲鱼、转转。</p>
<p>O2O：线上到线下。</p>
<h3 id="13-百战商城介绍">1.3 百战商城介绍</h3>
<p>百战商城项目是一个综合性的 B2C 电子商务平台，功能类似于淘宝、京东。用户可以在系统中通过搜索商品、查看商品详情、加入购物车、购买商品并生成订单完成购物操作。</p>
<p>百战商城共分为两部分：</p>
<ol>
<li><strong>商城后台管理系统</strong>：</li>
</ol>
<p>主要实现对商品、商品分类、规格参数、CMS 等业务的处理。</p>
<ol start="2">
<li><strong>商城前台系统</strong>：</li>
</ol>
<p>主要提供用户通过访问首页，完成购物流程的处理。</p>
<h2 id="2-项目架构介绍">2、项目架构介绍</h2>
<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805102652.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805102703.png" alt="" loading="lazy"></figure>
<h2 id="3-项目技术介绍">3、 项目技术介绍</h2>
<ul>
<li>
<p>Spring Data</p>
<ul>
<li>Spring Data Redis2.1.9.RELEASE</li>
<li>Spring Data Solr4.0.9.RELEASE</li>
</ul>
</li>
<li>
<p>Spring Boot 2.1.6.RELEASE</p>
<ul>
<li>Spring Boot Data Redis 2.1.6.RELEASE</li>
<li>Spring Boot Data Solr 2.1.6.RELEASE</li>
</ul>
</li>
<li>
<p>Spring Cloud Greenwich.SR2</p>
<ul>
<li>Spring Cloud Netflix Eureka</li>
<li>Spring Cloud Netflix Zuul</li>
<li>Spring Cloud Netflix Hystrix</li>
<li>Spring Cloud OpenFeign</li>
<li>Spring Cloud Config</li>
</ul>
</li>
<li>
<p>TX-LCN 5.0.2.RELEASE</p>
</li>
</ul>
<h2 id="4-搭建项目环境">4、搭建项目环境</h2>
<h3 id="41-创建数据库并导入-sql-文件">4.1 创建数据库并导入 sql 文件</h3>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805104424.png" alt="" loading="lazy"></figure>
<h3 id="42-创建项目">4.2  创建项目</h3>
<h4 id="421-创建父工程">4.2.1 创建父工程</h4>
<ol>
<li>
<p>创建项目</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805104518.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>修改 POM 文件</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.cy&lt;/groupId&gt;
    &lt;artifactId&gt;bz_parent&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;modules&gt;
        &lt;module&gt;common_mapper&lt;/module&gt;
        &lt;module&gt;common_pojo&lt;/module&gt;
    &lt;/modules&gt;
    &lt;packaging&gt;pom&lt;/packaging&gt;

    &lt;!--Spring Boot父工程--&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;
    &lt;/parent&gt;

    &lt;!-- 自定义属性标签 --&gt;
    &lt;properties&gt;
        &lt;mybatis-version&gt;3.5.1&lt;/mybatis-version&gt;
        &lt;mysql-connector-java-version&gt;5.1.38&lt;/mysql-connector-java-version&gt;
        &lt;druid-version&gt;1.0.9&lt;/druid-version&gt;
        &lt;pagehelper-version&gt;1.2.10&lt;/pagehelper-version&gt;
        &lt;logback-version&gt;5.0&lt;/logback-version&gt;
        &lt;spring-mybats-version&gt;2.0.1&lt;/spring-mybats-version&gt;
    &lt;/properties&gt;

    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;!--Spring Cloud Platform--&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;Greenwich.SR2&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;

            &lt;!-- MyBatis --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
                &lt;artifactId&gt;mybatis&lt;/artifactId&gt;
                &lt;version&gt;${mybatis-version}&lt;/version&gt;
            &lt;/dependency&gt;

            &lt;!-- MySql Driver  --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;mysql&lt;/groupId&gt;
                &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
                &lt;version&gt;${mysql-connector-java-version}&lt;/version&gt;
            &lt;/dependency&gt;

            &lt;!--Alibaba DataBase Connection Pool--&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
                &lt;artifactId&gt;druid&lt;/artifactId&gt;
                &lt;version&gt;${druid-version}&lt;/version&gt;
            &lt;/dependency&gt;

            &lt;!--PageHelper--&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;
                &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;
                &lt;version&gt;${pagehelper-version}&lt;/version&gt;
            &lt;/dependency&gt;

            &lt;!--MyBatis And Spring Integration Starter--&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
                &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
                &lt;version&gt;${spring-mybats-version}&lt;/version&gt;
            &lt;/dependency&gt;

            &lt;!--Logback--&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt;
                &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;
                &lt;version&gt;${logback-version}&lt;/version&gt;
            &lt;/dependency&gt;

        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

    &lt;build&gt;
        &lt;pluginManagement&gt;
            &lt;!--Spring Boot Maven Plugin--&gt;
            &lt;plugins&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;/plugin&gt;
            &lt;/plugins&gt;
        &lt;/pluginManagement&gt;
    &lt;/build&gt;


&lt;/project&gt;
</code></pre>
</li>
</ol>
<h4 id="422-创建-mapper-与-pojo">4.2.2 创建 Mapper 与 Pojo</h4>
<p>​	<img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805104706.png" alt="" loading="lazy"></p>
<h4 id="423-使用工具生成-mapper-与-pojo">4.2.3 使用工具生成 Mapper 与 Pojo</h4>
<ol>
<li>
<p>generatorSqlmapCustom 工具的使用</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805104805.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>修改 Mapper 的 POM 文件添加依赖坐标</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;!DOCTYPE generatorConfiguration
  PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot;
  &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;

&lt;generatorConfiguration&gt;
	&lt;context id=&quot;testTables&quot; targetRuntime=&quot;MyBatis3&quot;&gt;
		&lt;commentGenerator&gt;
			&lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt;
			&lt;property name=&quot;suppressAllComments&quot; value=&quot;true&quot; /&gt;
		&lt;/commentGenerator&gt;
		&lt;!--数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt;
		&lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot;
			connectionURL=&quot;jdbc:mysql://localhost:3306/bz_shop&quot; userId=&quot;root&quot;
			password=&quot;root&quot;&gt;
		&lt;/jdbcConnection&gt;
		&lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL 和 
			NUMERIC 类型解析为java.math.BigDecimal --&gt;
		&lt;javaTypeResolver&gt;
			&lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot; /&gt;
		&lt;/javaTypeResolver&gt;

		&lt;!-- targetProject:生成PO类的位置 --&gt;
		&lt;javaModelGenerator targetPackage=&quot;com.cy.pojo&quot;
			targetProject=&quot;.\src&quot;&gt;
			&lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt;
			&lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt;
			&lt;!-- 从数据库返回的值被清理前后的空格 --&gt;
			&lt;property name=&quot;trimStrings&quot; value=&quot;true&quot; /&gt;
		&lt;/javaModelGenerator&gt;
        &lt;!-- targetProject:mapper映射文件生成的位置 --&gt;
		&lt;sqlMapGenerator targetPackage=&quot;com.cy.mapper&quot;
			targetProject=&quot;.\src&quot;&gt;
			&lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt;
			&lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt;
		&lt;/sqlMapGenerator&gt;
		&lt;!-- targetPackage：mapper接口生成的位置 --&gt;
		&lt;javaClientGenerator type=&quot;XMLMAPPER&quot;
			targetPackage=&quot;com.cy.mapper&quot;
			targetProject=&quot;.\src&quot;&gt;
			&lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt;
			&lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt;
		&lt;/javaClientGenerator&gt;
		&lt;!-- 指定数据库表 --&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_content&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_content_category&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_item&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_item_cat&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_item_desc&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_item_param&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_item_param_item&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_order&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_order_item&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_order_shipping&quot;&gt;&lt;/table&gt;
		&lt;table schema=&quot;&quot; tableName=&quot;tb_user&quot;&gt;&lt;/table&gt;
	&lt;/context&gt;
&lt;/generatorConfiguration&gt;

</code></pre>
</li>
<li>
<p>运行GeneratorSqlmap类，并将生成的mapper和pojo拷贝到该项目的mapper和pojo子项目中</p>
</li>
</ol>
<h3 id="43-搭建-eureka-注册中心">4.3 搭建 Eureka 注册中心</h3>
<ol>
<li>
<p>搭建 Eureka 注册中心</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805114120.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>修改 POM 文件添加依赖</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;bz_parent&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;artifactId&gt;common_eureka&lt;/artifactId&gt;

    &lt;dependencies&gt;
    &lt;!--Spring Boot Web Starter--&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;

    &lt;!--Spring Cloud Eureka Server Starter--&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
        &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;/dependencies&gt;

        &lt;build&gt;
        &lt;!--Spring Boot Maven Plugin 必须有这个，否则打包的时候不会将springboot依赖的包打包进来--&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>
</li>
<li>
<p>创建配置文件，添加配置</p>
<pre><code class="language-yaml">spring:
  application:
    name: eureka-server

server:
  port: 8761

# 关闭注册
eureka:
  client:
    register-with-eureka: false
    fetch-registry: false

</code></pre>
</li>
<li>
<p>创建启动类，添加相关注解</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;

/**
 * eureka 注册中心
 */
@SpringBootApplication
@EnableEurekaServer
public class EurekaServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaServerApplication.class, args);
    }
}

</code></pre>
</li>
<li>
<p>将 Eureka 注册中心部署到 Linux 环境中</p>
<ol>
<li>
<p>安装 lrzsz 上传下载工具<br>
安装命令：yum install lrzsz -y</p>
<p>上传命令：rz</p>
<p>下载命令：sz</p>
</li>
<li>
<p>上传注册中心 jar</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805153124.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>上传启动脚本文件(server.sh)</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805153142.png" alt="" loading="lazy"></figure>
</li>
</ol>
</li>
<li>
<p>创建 common_utils 项目(工具集)</p>
<ol>
<li>
<p>创建项目</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805153224.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>添加常用工具类</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805153252.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>修改 POM 文件添加依赖</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;bz_parent&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;artifactId&gt;common_utils&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;!--Spring Boot Web Starter--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;
            &lt;artifactId&gt;httpclient&lt;/artifactId&gt;
            &lt;version&gt;4.5.2&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;commons-net&lt;/groupId&gt;
            &lt;artifactId&gt;commons-net&lt;/artifactId&gt;
            &lt;version&gt;3.6&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
</li>
</ol>
</li>
</ol>
<h2 id="5-开发百战商城后台系统">5、开发百战商城后台系统</h2>
<h3 id="51-百战商城服务设计">5.1 百战商城服务设计</h3>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805162958.png" alt="" loading="lazy"></figure>
<h3 id="52-创建-common_item-服务">5.2  创建 common_item 服务</h3>
<ol>
<li>
<p>创建项目</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805163028.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>修改 POM 文件添加依赖坐标</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;bz_parent&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;artifactId&gt;common_item&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;!--mapper--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.cy&lt;/groupId&gt;
            &lt;artifactId&gt;common_mapper&lt;/artifactId&gt;
            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!--utils--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.cy&lt;/groupId&gt;
            &lt;artifactId&gt;common_utils&lt;/artifactId&gt;
            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!--Spring Boot Web Starter--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!--Spring Cloud Eureka Client Starter--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
</li>
<li>
<p>创建配置文件，添加相关配置</p>
<pre><code class="language-yaml">spring:
  application:
    name: common-item
  datasource:
    driverClassName: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/db_shop?characterEncoding=UTF-8
    username: root
    password: root
    type: com.alibaba.druid.pool.DruidDataSource

server:
  port: 9010

eureka:
  client:
    serviceUrl:
      defaultZone: http://eureka-server:8761/eureka/
</code></pre>
</li>
<li>
<p>修改 common_mapper 项目的 POM 文件，添加资源拷贝<br>
插件</p>
</li>
</ol>
<pre><code class="language-xml">    &lt;build&gt;
    &lt;resources&gt;
        &lt;resource&gt;
            &lt;directory&gt;src/main/java&lt;/directory&gt;
            &lt;includes&gt;
                &lt;include&gt;**/*.xml&lt;/include&gt;
            &lt;/includes&gt;
        &lt;/resource&gt;
        &lt;resource&gt;
            &lt;directory&gt;src/main/resources&lt;/directory&gt;
            &lt;includes&gt;
                &lt;include&gt;**/*.xml&lt;/include&gt;
            &lt;/includes&gt;
        &lt;/resource&gt;
    &lt;/resources&gt;
&lt;/build&gt;
</code></pre>
<ol start="5">
<li>
<p>创建启动类，添加相关注解</p>
<pre><code class="language-java">/**
 * 通用common_item
 */
@SpringBootApplication
@EnableDiscoveryClient
@MapperScan(&quot;com.cy.mapper&quot;)
public class CommonItemApplication {
    public static void main(String[] args) {
        SpringApplication.run(CommonItemApplication.class, args);
    }
}

</code></pre>
</li>
<li>
<p>修改 Host 文件添加注册中心域名与 IP 的映射</p>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805173808.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>启动测试</p>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805173854.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="53-创建-backend_item-服务">5.3 创建 backend_item 服务</h3>
<ol>
<li>
<p>创建项目</p>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805172041.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>修改 POM 文件添加依赖坐标</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;bz_parent&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;artifactId&gt;backend_item&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;!--pojo--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.cy&lt;/groupId&gt;
            &lt;artifactId&gt;common_pojo&lt;/artifactId&gt;
            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!--utils--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.cy&lt;/groupId&gt;
            &lt;artifactId&gt;common_utils&lt;/artifactId&gt;
            &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!--Spring Boot Web Starter--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!--Spring Cloud Eureka Client Starter--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!--Spring Cloud OpenFeign Starter--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
</li>
<li>
<p>创建配置文件，添加相关配置</p>
<pre><code class="language-yaml">spring:
  application:
    name: backend-item

server:
  port: 9011

eureka:
  client:
    serviceUrl:
      defaultZone: http://eureka-server:8761/eureka/
</code></pre>
</li>
<li>
<p>创建启动类，添加相关注解</p>
<pre><code class="language-java">/**
 * BackendItem 服务
 */
@SpringBootApplication
@EnableDiscoveryClient
@EnableFeignClients
public class BackendItemApplication {
    public static void main(String[] args) {
        SpringApplication.run(BackendItemApplication.class, args);
    }
}

</code></pre>
</li>
<li>
<p>启动测试</p>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200805174108.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="54-开发商品管理接口">5.4 开发商品管理接口</h3>
<h4 id="541-实现查询商品接口">5.4.1 实现查询商品接口</h4>
<h5 id="5411-在-common_item-服务中实现查询商品">5.4.1.1 在 common_item 服务中实现查询商品</h5>
<ol>
<li>
<p>在 common_utils 项目中添加 PageResult 模型</p>
<pre><code class="language-java">/**
 * 分页模型
 */
public class PageResult implements Serializable {
    private Integer pageIndex; //当前页
    private Integer totalIndex; //总页数
    private List result; //结果集

    public Integer getPageIndex() {
        return pageIndex;
    }

    public void setPageIndex(Integer pageIndex) {
        this.pageIndex = pageIndex;
    }

    public Integer getTotalIndex() {
        return totalIndex;
    }

    public void setTotalIndex(Integer totalIndex) {
        this.totalIndex = totalIndex;
    }

    public List getResult() {
        return result;
    }

    public void setResult(List result) {
        this.result = result;
    }
}
</code></pre>
</li>
<li>
<p>创建 controller</p>
<pre><code class="language-java">@RestController
@RequestMapping(&quot;/service/item&quot;)
public class ItemController {

    @Autowired
    private ItemService itemService;

    /**
     * 查询商品数据
     */
    @RequestMapping(value = &quot;/selectTbItemAllByPage&quot;,method = RequestMethod.GET)
    public PageResult selectTbItemAllByPage(@RequestParam Integer page, @RequestParam Integer rows) {
        return this.itemService.selectTbItemAllByPage(page,rows);
    }
}
</code></pre>
</li>
<li>
<p>创建 service</p>
<pre><code class="language-java">public interface ItemService {
    PageResult selectTbItemAllByPage(Integer page,Integer rows);
}

</code></pre>
</li>
<li>
<p>创建 serviceImpl</p>
<pre><code class="language-java">@Service
public class ItemServiceImpl implements ItemService {

    @Autowired
    private TbItemMapper tbItemMapper;

    /**
     * 查询所有商品并分页
     * @param page
     * @param rows
     * @return
     */
    @Override
    public PageResult selectTbItemAllByPage(Integer page, Integer rows) {
        PageHelper.startPage(page, rows);
        //查询条件
        TbItemExample tbItemExample = new TbItemExample();
        TbItemExample.Criteria criteria = tbItemExample.createCriteria();
        criteria.andStatusEqualTo((byte) 1);
        List&lt;TbItem&gt; list = this.tbItemMapper.selectByExample(tbItemExample);
        //分页处理
        PageInfo&lt;TbItem&gt; pageInfo = new PageInfo&lt;&gt;(list);
        PageResult pageResult = new PageResult();
        pageResult.setPageIndex(page);
        pageResult.setTotalIndex((int) pageInfo.getTotal());
        pageResult.setResult(list);
        return pageResult;
    }


}
</code></pre>
</li>
</ol>
<h5 id="5412-在-backend_item-服务中实现商品查询">5.4.1.2 在 backend_item 服务中实现商品查询</h5>
<ol>
<li>
<p>创建 controller</p>
<pre><code class="language-java">@RestController
@RequestMapping(&quot;/backend/item&quot;)
public class ItemController {

    @Autowired
    private ItemService itemService;

    /**
     * 查询商品并分页处理
     * @param page
     * @param rows
     * @return
     */
    @RequestMapping(&quot;/selectTbItemAllByPage&quot;)
    public Result selectTbItemAllByPage(@RequestParam(defaultValue = &quot;1&quot;)Integer page,@RequestParam(defaultValue = &quot;2&quot;)Integer rows){

        try {
            return this.itemService.selectTbItemAllByPage(page,rows);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return Result.build(500, &quot;查无结果&quot;);
    }

}
</code></pre>
</li>
<li>
<p>创建 service</p>
<pre><code class="language-java">public interface ItemService {
    Result selectTbItemAllByPage(Integer page,Integer rows);
}
</code></pre>
</li>
<li>
<p>创建 serviceImpl</p>
<pre><code class="language-java">/**
 * 商品管理
 */
@Service
public class ItemServiceImpl implements ItemService {

    @Autowired
    private CommonItemFeignClient commonItemFeignClient;

    @Override
    public Result selectTbItemAllByPage(Integer page, Integer rows) {
        PageResult pageResult = this.commonItemFeignClient.selectTbItemAllByPage(page, rows);
        if (pageResult != null &amp;&amp; pageResult.getResult() != null &amp;&amp; pageResult.getResult().size() &gt;0){
            return Result.ok(pageResult);
        }
            return Result.error(&quot;查无结果&quot;);
    }
}
</code></pre>
</li>
<li>
<p>创建 feignClient</p>
<pre><code class="language-java">@FeignClient(value = &quot;common-item&quot;)
public interface CommonItemFeignClient {
    //------------/service/item
    @GetMapping(&quot;/service/item/selectTbItemAllByPage&quot;)
    PageResult selectTbItemAllByPage(@RequestParam(&quot;page&quot;) Integer page, @RequestParam(&quot;rows&quot;) Integer rows);
}
</code></pre>
</li>
<li>
<p>测试<img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200814205736.png" alt="" loading="lazy"></p>
</li>
</ol>
<h4 id="542-实现添加商品接口">5.4.2 实现添加商品接口</h4>
<h5 id="5421-在-common_item-服务中实现商品分类查询">5.4.2.1  在 common_item 服务中实现商品分类查询</h5>
<ol>
<li>
<p>创建 controller</p>
<pre><code class="language-java">/**
 * 商品类目
 */
@RestController
@RequestMapping(&quot;/service/itemCategory&quot;)
public class ItemCategoryController {

    @Autowired
    private ItemCategoryService itemCategoryService;
    /**
     * 根据分类ID查询子节点
     * @param id
     * @return
     */
    @RequestMapping(&quot;/selectItemCategoryByParentId&quot;)
    public List&lt;TbItemCat&gt; selectItemCategoryByParentId(@RequestParam Long id){
        return this.itemCategoryService.selectItemCategoryByParentId(id);
    }
}
</code></pre>
</li>
<li>
<p>创建 service</p>
<pre><code class="language-java">public interface ItemCategoryService {
    List&lt;TbItemCat&gt; selectItemCategoryByParentId(Long id);
}
</code></pre>
</li>
<li>
<p>创建 serviceImpl</p>
<pre><code class="language-java">/**
 * 商品分类查询
 */
@Service
public class ItemCategoryServiceImpl implements ItemCategoryService {

    @Autowired
    private TbItemCatMapper tbItemCatMapper;

    /**
     * 根据分类ID查询子节点
     * @param id
     * @return
     */
    @Override
    public List&lt;TbItemCat&gt; selectItemCategoryByParentId(Long id) {
        TbItemCatExample tbItemCatExample = new TbItemCatExample();
        TbItemCatExample.Criteria criteria = tbItemCatExample.createCriteria();
        criteria.andParentIdEqualTo(id);
        criteria.andStatusEqualTo(1);
        List&lt;TbItemCat&gt; list = this.tbItemCatMapper.selectByExample(tbItemCatExample);
        return list;
    }
}
</code></pre>
</li>
</ol>
<h5 id="5422-在-backend_item-服务中实现商品分类查询">5.4.2.2 在 backend_item 服务中实现商品分类查询</h5>
<ol>
<li>
<p>创建 controller</p>
<pre><code class="language-java">/**
 * 商品类目Controller
 */
@RestController
@RequestMapping(&quot;/backend/itemCategory&quot;)
public class ItemCategoryController {

    @Autowired
    private ItemCategorySerivce itemCategorySerivce;
    /**
     * 根据类目ID查询当前类目子节点
     * @param id
     * @return
     */
    @RequestMapping(&quot;selectItemCategoryByParentId&quot;)
    public Result selectItemCategoryByParentId(@RequestParam(value = &quot;id&quot;,defaultValue = &quot;0&quot;)Long id){
        try {
            return this.itemCategorySerivce.selectItemCategoryByParentId(id);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return Result.build(500, &quot;查无结果&quot;);
    }
}
</code></pre>
</li>
<li>
<p>创建Service</p>
<pre><code class="language-java">public interface ItemCategorySerivce {
    Result selectItemCategoryByParentId(Long id);
}
</code></pre>
</li>
<li>
<p>创建 serviceImpl</p>
<pre><code class="language-java">/**
 * 商品类目Service
 */
@Service
public class ItemCategoryServiceImpl implements ItemCategorySerivce {

    @Autowired
    private CommonItemFeignClient commonItemFeignClient;

    /**
     * 根据类目ID查询当前类目子节点
     *
     * @param id
     * @return
     */
    @Override
    public Result selectItemCategoryByParentId(Long id) {
        List&lt;TbItemCat&gt; list = this.commonItemFeignClient.selectItemCategoryByParentId(id);
        if (list != null &amp;&amp; list.size() &gt; 0) {
            return Result.ok(list);
        }
        return Result.error(&quot;查无结果&quot;);
    }
}
</code></pre>
</li>
<li>
<p>修改 feignClient</p>
<pre><code class="language-java">//-----------/service/itemCategory
@PostMapping(&quot;/service/itemCategory/selectItemCategoryByParentId&quot;)
List&lt;TbItemCat&gt; selectItemCategoryByParentId(@RequestParam(&quot;id&quot;) Long id);
</code></pre>
</li>
<li>
<p>测试</p>
<figure data-type="image" tabindex="17"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200814211102.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h5 id="5423-在-common_item-服务中实现规格参数模板查询">5.4.2.3 在 common_item 服务中实现规格参数模板查询</h5>
<ol>
<li>
<p>创建 controller</p>
<pre><code class="language-java">/**
 * ItemParam
 */
@RestController
@RequestMapping(&quot;/service/itemParam&quot;)
public class ItemParamController {

    @Autowired
    private ItemParamService itemParamService;

    /**
     * 根据商品分类ID查询规格参数模板
     */
    @RequestMapping(&quot;/selectItemParamByItemCatId&quot;)
    public TbItemParam selectItemParamByItemCatId(@RequestParam Long itemCatId){
        return itemParamService.selectItemParamByItemCatId(itemCatId);
    }
}
</code></pre>
</li>
<li>
<p>创建 service</p>
<pre><code class="language-java">public interface ItemParamService {
    TbItemParam selectItemParamByItemCatId(Long itemCatId);
}
</code></pre>
</li>
<li>
<p>创建 serviceImpl</p>
<pre><code class="language-java">/**
 * ItemParamService
 */
@Service
public class ItemParamServiceImpl implements ItemParamService {

    @Autowired
    private TbItemParamMapper tbItemParamMapper;

    @Override
    public TbItemParam selectItemParamByItemCatId(Long itemCatId) {
        TbItemParamExample tbItemParamExample = new TbItemParamExample();
        TbItemParamExample.Criteria criteria = tbItemParamExample.createCriteria();
        criteria.andItemCatIdEqualTo(itemCatId);
        //如需检索的字段中包含大字段类型时，必须用selectByExampleWithBLOBs，不检索大字段时，用selectByExample就足够了
        List&lt;TbItemParam&gt; list = tbItemParamMapper.selectByExampleWithBLOBs(tbItemParamExample);
        if (list != null &amp;&amp; list.size() &gt; 0) {
            return list.get(0);
        }
        return null;
    }
}

</code></pre>
</li>
</ol>
<h5 id="5424-在-backend_item-服务中实现规格参数模板查询">5.4.2.4  在 backend_item 服务中实现规格参数模板查询</h5>
<ol>
<li>
<pre><code class="language-java">/**
 * ItemParam
 */
@RestController
@RequestMapping(&quot;/backend/itemParam&quot;)
public class ItemParamController {

    @Autowired
    private ItemParamService itemParamService;
    /**
     * 根据商品类目ID查询规格参数模板
     */
    @RequestMapping(&quot;/selectItemParamByItemCatId/{itemCatId}&quot;)
    public Result selectItemParamByItemCatId(@PathVariable(&quot;itemCatId&quot;) Long itemCatId){
        try {
            return this.itemParamService.selectItemParamByItemCatId(itemCatId);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return Result.build(500, &quot;查无结果&quot;);
    }
}
</code></pre>
</li>
<li>
<p>创建 service</p>
<pre><code class="language-java">public interface ItemParamService {
    Result selectItemParamByItemCatId(Long itemCatId);
}
</code></pre>
</li>
<li>
<p>创建 serviceImpl</p>
<pre><code class="language-java">/**
 * ItemParamService
 */
@Service
public class ItemParamServiceImpl implements ItemParamService {

    @Autowired
    private CommonItemFeignClient commonItemFeignClient;

    /**
     * 根据商品类目Id查询规格参数模板
     */
    @Override
    public Result selectItemParamByItemCatId(Long itemCatId) {
        TbItemParam tbItemParam = this.commonItemFeignClient.selectItemParamByItemCatId(itemCatId);
        if (tbItemParam != null) {
            return Result.ok(tbItemParam);
        }
        return Result.error(&quot;查无结果&quot;);
    }

}

</code></pre>
</li>
<li>
<p>修改 feignClient</p>
<pre><code class="language-java">/**
 * @author cy
 * @date 2020-08-10 14:22
 */
@FeignClient(value = &quot;common-item&quot;)
public interface CommonItemFeignClient {
    //------------/service/item
    @GetMapping(&quot;/service/item/selectTbItemAllByPage&quot;)
    PageResult selectTbItemAllByPage(@RequestParam(&quot;page&quot;) Integer page, @RequestParam(&quot;rows&quot;) Integer rows);
    
    //-----------/service/itemCategory
    @PostMapping(&quot;/service/itemCategory/selectItemCategoryByParentId&quot;)
    List&lt;TbItemCat&gt; selectItemCategoryByParentId(@RequestParam(&quot;id&quot;) Long id);

    //-----------/service/itemParam
    @PostMapping(&quot;/service/itemParam/selectItemParamByItemCatId&quot;)
    TbItemParam selectItemParamByItemCatId(@RequestParam(&quot;itemCatId&quot;) Long itemCatId);
}
</code></pre>
</li>
</ol>
<h5 id="5425-在-backend_item-服务中处理图片上传">5.4.2.5 在 backend_item 服务中处理图片上传</h5>
<ol>
<li>
<p>添加 FtpUtil 工具类<img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200814211638.png" alt="" loading="lazy"></p>
</li>
<li>
<p>创建 controller</p>
<pre><code class="language-java">/**
 * 图片上传Controller
 */
@RestController
@RequestMapping(&quot;/file&quot;)
public class FileUploadController {

    @Autowired
    private FileUploadService fileUploadService;

    /**
     * 图片上传
     *
     * @param file
     * @return
     */
    @RequestMapping(&quot;/upload&quot;)
    public Result fileUpload(MultipartFile file) {
        try {
            return this.fileUploadService.fileUpload(file);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return Result.build(500, &quot;error&quot;);

    }
}
</code></pre>
</li>
<li>
<p>创建 service</p>
<pre><code class="language-java">public interface FileUploadService {
    Result fileUpload(MultipartFile file);
}
</code></pre>
</li>
<li>
<p>创建 serviceImpl</p>
<pre><code class="language-java">/**
 * 图片上传Service
 */
@Service
public class FileUploadServiceImpl implements FileUploadService {

    /*FTP_HOST: 192.168.92.129
    FTP_PORT: 21
    FTP_USERNAME: ftpuser
    FTP_PASSWORD: ftpuser
    FTP_BASEPATH: /usr/local/ftp/ftpuser*/
    @Value(&quot;${FTP_HOST}&quot;)
    private String FTP_HOST;

    @Value(&quot;${FTP_PORT}&quot;)
    private int FTP_PORT;

    @Value(&quot;${FTP_USERNAME}&quot;)
    private String FTP_USERNAME;

    @Value(&quot;${FTP_PASSWORD}&quot;)
    private String FTP_PASSWORD;

    @Value(&quot;${FTP_BASEPATH}&quot;)
    private String FTP_BASEPATH;

    @Override
    public Result fileUpload(MultipartFile file) {
        try {
            //定义上传图片的目录结构
            SimpleDateFormat sd = new SimpleDateFormat(&quot;/yyyy/MM/dd/&quot;);
            String path = sd.format(new Date());

            //设置新的文件名
            String newFileName = IDUtils.genImageName() + file.getOriginalFilename().substring(file.getOriginalFilename().lastIndexOf(&quot;.&quot;));
            FtpUtil.uploadFile(this.FTP_HOST, this.FTP_PORT, this.FTP_USERNAME, this.FTP_PASSWORD, this.FTP_BASEPATH, path, newFileName, file.getInputStream());
            String imageURL = &quot;http://&quot; + this.FTP_HOST + path + newFileName;
            return Result.ok(imageURL);
        } catch (IOException e) {
            e.printStackTrace();
        }
        return null;
    }
}

</code></pre>
</li>
<li>
<p>在配置文件中添相关配置</p>
<pre><code class="language-yaml">FTP_HOST: 192.168.92.129
FTP_PORT: 21
FTP_USERNAME: ftpuser
FTP_PASSWORD: ftpuser
FTP_BASEPATH: /usr/local/ftp/ftpuser
</code></pre>
</li>
</ol>
<h5 id="5426-在-common_item-服务中实现商品添加">5.4.2.6 在 common_item 服务中实现商品添加</h5>
<ol>
<li>
<p>修改 controller</p>
<pre><code class="language-java">@RestController
@RequestMapping(&quot;/service/item&quot;)
public class ItemController {

    @Autowired
    private ItemService itemService;

    /**
     * 查询商品数据
     */
    @RequestMapping(value = &quot;/selectTbItemAllByPage&quot;,method = RequestMethod.GET)
    public PageResult selectTbItemAllByPage(@RequestParam Integer page, @RequestParam Integer rows) {
        return this.itemService.selectTbItemAllByPage(page,rows);
    }

    /**
     * 商品的增加
     */
    @RequestMapping(&quot;/insertTbItem&quot;)
    public Integer insertTbItem(@RequestBody TbItem tbItem){
        return this.itemService.insertTbItem(tbItem);
    }

}
</code></pre>
</li>
<li>
<p>修改 service</p>
<pre><code class="language-java">public interface ItemService {
    PageResult selectTbItemAllByPage(Integer page,Integer rows);
    Integer insertTbItem(TbItem tbItem);
}
</code></pre>
</li>
<li>
<p>修改 serviceImpl</p>
<pre><code class="language-java">@Service
public class ItemServiceImpl implements ItemService {

    @Autowired
    private TbItemMapper tbItemMapper;

    /**
     * 查询所有商品并分页
     * @param page
     * @param rows
     * @return
     */
    @Override
    public PageResult selectTbItemAllByPage(Integer page, Integer rows) {
        PageHelper.startPage(page, rows);
        //查询条件
        TbItemExample tbItemExample = new TbItemExample();
        TbItemExample.Criteria criteria = tbItemExample.createCriteria();
        criteria.andStatusEqualTo((byte) 1);
        List&lt;TbItem&gt; list = this.tbItemMapper.selectByExample(tbItemExample);
        //分页处理
        PageInfo&lt;TbItem&gt; pageInfo = new PageInfo&lt;&gt;(list);
        PageResult pageResult = new PageResult();
        pageResult.setPageIndex(page);
        pageResult.setTotalIndex((int) pageInfo.getTotal());
        pageResult.setResult(list);
        return pageResult;
    }

    /**
     * 商品的增加
     */
    @Override
    public Integer insertTbItem(TbItem tbItem) {
        return this.tbItemMapper.insert(tbItem);
    }

}
</code></pre>
</li>
</ol>
<h5 id="5427-在-common_item-服务中实现添加商品描述">5.4.2.7  在 common_item 服务中实现添加商品描述</h5>
<ol>
<li>
<p>创建 controller</p>
<pre><code class="language-java">/**
 * itemDescController
 */
@RestController
@RequestMapping(&quot;/service/itemDesc&quot;)
public class ItemDescController {

    @Autowired
    private ItemDescService itemDescService;

    /**
     * 添加商品描述
     */
    @RequestMapping(&quot;/insertItemDesc&quot;)
    public Integer insertItemDesc(@RequestBody TbItemDesc tbItemDesc){
        return itemDescService.insertItemDesc(tbItemDesc);
    }
}
</code></pre>
</li>
<li>
<p>创建 service</p>
<pre><code class="language-java">public interface ItemDescService {
    Integer insertItemDesc(TbItemDesc tbItemDesc);
}
</code></pre>
</li>
<li>
<p>创建serviceImpl</p>
<pre><code class="language-java">@Service
public class ItemDescServiceImpl implements ItemDescService {
    @Autowired
    private TbItemDescMapper tbItemDescMapper;

    /**
     * 添加商品描述
     * @param tbItemDesc
     * @return
     */
    @Override
    public Integer insertItemDesc(TbItemDesc tbItemDesc) {
        return this.tbItemDescMapper.insert(tbItemDesc);
    }
}
</code></pre>
</li>
</ol>
<h5 id="5428-在-common_item-服务中实现商品规格参数的添加">5.4.2.8 在 common_item 服务中实现商品规格参数的添加</h5>
<ol>
<li>
<p>创建 controller</p>
<pre><code class="language-java">@RestController
@RequestMapping(&quot;/service/itemParamItem&quot;)
public class ItemParamItemController {

    @Autowired
    private ItemParamItemService itemParamItemService;
    /**
     * 添加商品规格参数
     */
    @RequestMapping(&quot;/insertTbItemParamItem&quot;)
    public Integer insertTbItemParamItem(@RequestBody TbItemParamItem tbItemParamItem) {
        return this.itemParamItemService.insertItemParamItem(tbItemParamItem);
    }
}
</code></pre>
</li>
<li>
<p>创建 service</p>
<pre><code class="language-java">public interface ItemParamItemService {
    Integer insertItemParamItem(TbItemParamItem tbItemParamItem);
}
</code></pre>
</li>
<li>
<p>创建 serviceImpl</p>
<pre><code class="language-java">@Service
public class ItemParamItemServiceImpl implements ItemParamItemService {

    @Autowired
    private TbItemParamItemMapper tbItemParamItemMapper;
    /**
     * 添加商品规格参数
     * @param tbItemParamItem
     * @return
     */
    @Override
    public Integer insertItemParamItem(TbItemParamItem tbItemParamItem) {
        return this.tbItemParamItemMapper.insert(tbItemParamItem);
    }
}
</code></pre>
</li>
</ol>
<h5 id="5429-在-backend_item-服务中实现商品添加">5.4.2.9  在 backend_item 服务中实现商品添加</h5>
<ol>
<li>
<p>修改前台代码注释掉商品规格参数</p>
<figure data-type="image" tabindex="18"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200815010329.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>修改 controller</p>
<pre><code class="language-java">@RestController
@RequestMapping(&quot;/backend/item&quot;)
public class ItemController {

    @Autowired
    private ItemService itemService;

    /**
     * 查询商品并分页处理
     * @param page
     * @param rows
     * @return
     */
    @RequestMapping(&quot;/selectTbItemAllByPage&quot;)
    public Result selectTbItemAllByPage(@RequestParam(defaultValue = &quot;1&quot;)Integer page,@RequestParam(defaultValue = &quot;2&quot;)Integer rows){

        try {
            return this.itemService.selectTbItemAllByPage(page,rows);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return Result.build(500, &quot;查无结果&quot;);
    }

    /**
     * 商品添加
     * @param tbItem
     * @param desc
     * @param itemParams
     * @return
     */
    @RequestMapping(&quot;/insertTbItem&quot;)
    public Result insertTbItem(TbItem tbItem,String desc,String itemParams){
        try {
            return this.itemService.insertTbItem(tbItem, desc, itemParams);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return Result.build(500, &quot;查无结果&quot;);
    }

}
</code></pre>
</li>
<li>
<p>修改 service</p>
<pre><code class="language-java">public interface ItemService {
    Result selectTbItemAllByPage(Integer page,Integer rows);
    Result insertTbItem(TbItem tbItem, String desc, String itemParams);
}
</code></pre>
</li>
<li>
<p>修改 serviceImpl</p>
<pre><code class="language-java">/**
 * 商品管理
 */
@Service
public class ItemServiceImpl implements ItemService {

    @Autowired
    private CommonItemFeignClient commonItemFeignClient;

    @Override
    public Result selectTbItemAllByPage(Integer page, Integer rows) {
        PageResult pageResult = this.commonItemFeignClient.selectTbItemAllByPage(page, rows);
        if (pageResult != null &amp;&amp; pageResult.getResult() != null &amp;&amp; pageResult.getResult().size() &gt;0){
            return Result.ok(pageResult);
        }
            return Result.error(&quot;查无结果&quot;);
    }

    /**
     * 添加TbItem，添加TbitemDesc，添加TbItemParamItem
     * @param tbItem
     * @param desc
     * @param itemParams
     * @return
     */
    @Override
    public Result insertTbItem(TbItem tbItem, String desc, String itemParams) {
        //补齐 Tbitem 数据
        Date date = new Date();
        long itemId = IDUtils.genItemId();
        tbItem.setId(itemId);
        tbItem.setStatus((byte) 1);
        tbItem.setCreated(date);
        tbItem.setUpdated(date);
        Integer tbItemNum = this.commonItemFeignClient.insertTbItem(tbItem);

        //补齐商品描述对象
        TbItemDesc tbItemDesc = new TbItemDesc();
        tbItemDesc.setItemId(itemId);
        tbItemDesc.setItemDesc(desc);
        tbItemDesc.setCreated(date);
        tbItemDesc.setUpdated(date);
        Integer itemDescNum = this.commonItemFeignClient.insertItemDesc(tbItemDesc);

        //补齐商品规格参数
        TbItemParamItem tbItemParamItem = new TbItemParamItem();
        tbItemParamItem.setItemId(itemId);
        tbItemParamItem.setParamData(itemParams);
        tbItemParamItem.setCreated(date);
        tbItemParamItem.setUpdated(date);
        Integer itemParamItemNum = this.commonItemFeignClient.insertTbItemParamItem(tbItemParamItem);

        return Result.ok();
    }
}
</code></pre>
</li>
</ol>
<h5 id="54210-添加分布式事务-tx-lcn">5.4.2.10  添加分布式事务 TX-LCN</h5>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringCloud]]></title>
        <id>https://jonchan1013.github.io/post/springcloud/</id>
        <link href="https://jonchan1013.github.io/post/springcloud/">
        </link>
        <updated>2020-08-03T16:28:58.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200730014043.png" alt="" loading="lazy"></figure>
<h2 id="1-系统架构演变">1、系统架构演变</h2>
<p>随着互联网的发展，网站应用的规模不断扩大。需求的激增，带来的是技术上的压力。系统架构也因此也不断的演进、升级、迭代。从单一应用，到垂直拆分，到分布式服务，到SOA，以及现在火热的微服务架构，还有在Google带领下来势汹涌的Service Mesh。我们到底是该乘坐微服务的船只驶向远方，还是偏安逸得过且过？</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200730014043.png" alt="" loading="lazy"></figure>
<h2 id="1-系统架构演变">1、系统架构演变</h2>
<p>随着互联网的发展，网站应用的规模不断扩大。需求的激增，带来的是技术上的压力。系统架构也因此也不断的演进、升级、迭代。从单一应用，到垂直拆分，到分布式服务，到SOA，以及现在火热的微服务架构，还有在Google带领下来势汹涌的Service Mesh。我们到底是该乘坐微服务的船只驶向远方，还是偏安逸得过且过？</p>
<!-- more -->
<h3 id="11-集中式架构">1.1 集中式架构</h3>
<p>当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731105554.png" alt="" loading="lazy"></figure>
<ul>
<li>优点：<br>
系统开发速度快<br>
维护成本低<br>
适用于并发要求较低的系统</li>
<li>缺点：<br>
代码耦合度高，后期维护困难<br>
无法针对不同模块进行针对性优化<br>
无法水平扩展<br>
单点容错率低，并发能力差</li>
</ul>
<h3 id="12-垂直拆分">1.2 垂直拆分</h3>
<p>当访问量逐渐增大，单一应用无法满足需求，此时为了应对更高的并发和业务需求，我们根据业务功能对系统进行拆分：</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731105826.png" alt="" loading="lazy"></figure>
<ul>
<li>优点：<br>
系统拆分实现了流量分担，解决了并发问题<br>
可以针对不同模块进行优化<br>
方便水平扩展，负载均衡，容错率提高</li>
<li>缺点：<br>
系统间相互独立，会有很多重复开发工作，影响开发效率</li>
</ul>
<h3 id="13-分布式服务">1.3 分布式服务</h3>
<p>当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731110007.png" alt="" loading="lazy"></figure>
<ul>
<li>优点：<br>
将基础服务进行了抽取，系统间相互调用，提高了代码复用和开发效率</li>
<li>缺点：<br>
系统间耦合度变高，调用关系错综复杂，难以维护</li>
</ul>
<h3 id="14-面向服务架构soa">1.4 面向服务架构（SOA）</h3>
<p>SOA（Service Oriented Architecture）面向服务的架构：它是一种设计方法，其中包含多个服务， 服务之间通过相互依赖最终提供一系列的功能。一个服务 通常以独立的形式存在与操作系统进程中。各个服务之间 通过网络调用。<br>
SOA结构图：</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731110053.png" alt="" loading="lazy"></figure>
<p><code>ESB（企业服务总线），简单 来说 ESB 就是一根管道，用来连接各个服务节点。为了集 成不同系统，不同协议的服务，ESB 做了消息的转化解释和路由工作，让不同的服务互联互通。</code></p>
<p><strong>SOA缺点</strong>：每个供应商提供的ESB产品有偏差，自身实现较为复杂；应用服务粒度较大，ESB集成整合所有服务和协议、数据转换使得运维、测试部署困难。所有服务都通过一个通路通信，直接降低了通信速度。</p>
<h3 id="15-微服务架构">1.5 微服务架构</h3>
<p><strong>微服务架构是使用一套小服务来开发单个应用的方式或途径</strong>，每个服务基于单一业务能力构建，运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API，并能够通过自动化部署机制来独立部署。这些服务可以使用不同的编程语言实现，以及不同数据存储技术，并保持最低限度的集中式管理。<br>
微服务结构图：</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731110312.png" alt="" loading="lazy"></figure>
<p><code>API Gateway网关是一个服务器，是系统的唯一入口。为每个客户端提供一个定制的API。API网关核心是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。如它还可以具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。通常，网关提供RESTful/HTTP的方式访问服务。而服务端通过服务注册中心进行服务注册和管理。</code></p>
<ul>
<li>微服务的特点：<br>
单一职责：微服务中每一个服务都对应唯一的业务能力，做到单一职责<br>
微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务。每个服务虽小，但“五脏俱全”。<br>
面向服务：面向服务是说每个服务都要对外暴露Rest风格服务接口API。并不关心服务的技术实现，做到与平台和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可。<br>
自治：自治是说服务间互相独立，互不干扰
<ul>
<li>团队独立：每个服务都是一个独立的开发团队，人数不能过多。</li>
<li>技术独立：因为是面向服务，提供Rest接口，使用什么技术没有别人干涉</li>
<li>前后端分离：采用前后端分离开发，提供统一Rest接口，后端不用再为PC、移动端开发不同接口</li>
<li>数据库分离：每个服务都使用自己的数据源</li>
<li>部署独立，服务间虽然有调用，但要做到服务重启不影响其它服务。有利于持续集成和持续交付。每个服务都是独立的组件，可复用，可替换，降低耦合，易维护</li>
</ul>
</li>
</ul>
<p>微服务架构与SOA都是对系统进行拆分；微服务架构基于SOA思想，可以把微服务当做去除了ESB的SOA。ESB是SOA架构中的中心总线，设计图形应该是星形的，而微服务是去中心化的分布式软件架构。两者比较类似，但其实也有一些差别：</p>
<table>
<thead>
<tr>
<th style="text-align:center">功能</th>
<th style="text-align:center">SOA</th>
<th style="text-align:center">微服务</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">组件大小</td>
<td style="text-align:center">大块业务逻辑</td>
<td style="text-align:center">单独任务或小块业务逻辑</td>
</tr>
<tr>
<td style="text-align:center">耦合</td>
<td style="text-align:center">通常松耦合</td>
<td style="text-align:center">总是松耦合</td>
</tr>
<tr>
<td style="text-align:center">管理</td>
<td style="text-align:center">着重中央管理</td>
<td style="text-align:center">着重分散管理</td>
</tr>
<tr>
<td style="text-align:center">目标</td>
<td style="text-align:center">确保应用能够交互操作</td>
<td style="text-align:center">易维护、易扩展、更轻量级的交互</td>
</tr>
</tbody>
</table>
<h2 id="2-服务调用方式">2、服务调用方式</h2>
<h3 id="21-rpc和http">2.1 RPC和HTTP</h3>
<p>无论是微服务还是SOA，都面临着服务间的远程调用。那么服务间的远程调用方式有哪些呢？<br>
常见的远程调用方式有以下2种：</p>
<ul>
<li><strong>RPC</strong>：Remote Produce Call远程过程调用，<strong>RPC基于Socket，工作在会话层。自定义数据格式</strong>，速度快，效率高。早期的webservice，现在热门的dubbo，都是RPC的典型代表</li>
<li><strong>Http</strong>：http其实是**一种网络传输协议，基于TCP，工作在应用层，规定了数据传输的格式。**现在客户端浏览器与服务端通信基本都是采用Http协议，也可以用来进行远程服务调用。缺点是消息封装臃肿，优势是对服务的提供和调用方没有任何技术限定，自由灵活，更符合微服务理念。</li>
</ul>
<p>现在热门的Rest风格，就可以通过http协议来实现。<br>
<strong>区别</strong>：RPC的机制是根据语言的API（language API）来定义的，而不是根据基于网络的应用来定义的。<br>
如果你们公司全部采用Java技术栈，那么使用Dubbo作为微服务架构是一个不错的选择。<br>
相反，如果公司的技术栈多样化，而且你更青睐Spring家族，那么Spring Cloud搭建微服务是不二之选。在我们的项目中，会选择Spring Cloud套件，因此会使用Http方式来实现服务间调用。</p>
<h3 id="22-http客户端工具">2.2 Http客户端工具</h3>
<p>既然微服务选择了Http，那么我们就需要考虑自己来实现对请求和响应的处理。不过开源世界已经有很多的http客户端工具，能够帮助我们做这些事情，例如：</p>
<ul>
<li>HttpClient</li>
<li>OKHttp</li>
<li>URLConnection<br>
不过这些不同的客户端，API各不相同。而Spring也有对http的客户端进行封装，提供了工具类叫RestTemplate。</li>
</ul>
<h3 id="23-spring的resttemplate">2.3 Spring的RestTemplate</h3>
<p>Spring提供了一个RestTemplate模板工具类，对基于Http的客户端进行了封装，并且实现了对象与json的序列化和反序列化，非常方便。RestTemplate并没有限定Http的客户端类型，而是进行了抽象，目前常用的3种都有支持：</p>
<ul>
<li>HttpClient</li>
<li>OkHttp</li>
<li>JDK原生的URLConnection（默认的）</li>
</ul>
<p>在项目中的 HttpDemoApplication 注册一个RestTemplate 对象，可以在启动类位置注册：</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.web.client.RestTemplate;

@SpringBootApplication
public class HttpDemoApplication {
    public static void main(String[] args) {
        SpringApplication.run(HttpDemoApplication.class, args);
    }

    @Bean
    public RestTemplate restTemplate(){
         return new RestTemplate();
    }
}
</code></pre>
<p>启动springboot项目，在项目中的测试类中直接@Autowired 注入：</p>
<pre><code class="language-java">@RunWith(SpringRunner.class)
@SpringBootTest
public class RestTemplateTest {

    @Autowired
    private RestTemplate restTemplate;

    @Test
    public void test(){
        //如果要测试需要启动spring boot项目，以便获取数据
        String url = &quot;http://localhost/user/8&quot;;
        User user = restTemplate.getForObject(url, User.class);
        System.out.println(user);
    }
}
</code></pre>
<p>通过RestTemplate的getForObject()方法，传递url地址及实体类的字节码，RestTemplate会自动发起请求，接收响应，并且帮我们对响应结果进行反序列化。</p>
<p>了解完Http客户端工具，接下来就可以正式学习微服务了。</p>
<h2 id="3-初识spring-cloud">3、 初识Spring Cloud</h2>
<p>微服务是一种架构方式，最终肯定需要技术架构去实施。<br>
微服务的实现方式很多，但是最火的莫过于Spring Cloud了。为什么？</p>
<ul>
<li>后台硬：作为Spring家族的一员，有整个Spring全家桶靠山，背景十分强大。</li>
<li>技术强：Spring作为Java领域的前辈，可以说是功力深厚。有强力的技术团队支撑，一般人还真比不了</li>
<li>群众基础好：可以说大多数程序员的成长都伴随着Spring框架，试问：现在有几家公司开发不用Spring？</li>
<li>Spring Cloud与Spring的各个框架无缝整合，对大家来说一切都是熟悉的配方，熟悉的味道。</li>
<li>使用方便：相信大家都体会到了SpringBoot给我们开发带来的便利，而Spring Cloud完全支持Spring Boot的开发，用很少的配置就能完成微服务框架的搭建</li>
</ul>
<h3 id="31-简介">3.1 简介</h3>
<p>Spring Cloud是Spring旗下的项目之一，官网地址：http://projects.spring.io/spring-cloud/Spring最擅长的就是集成，把世界上最好的框架拿过来，集成到自己的项目中。<br>
Spring Cloud也是一样，它将现在非常流行的一些技术整合到一起，实现了诸如：配置管理，服务发现，智能路由，负载均衡，熔断器，控制总线，集群状态等功能；协调分布式环境中各个系统，为各类服务提供模板性配置。其主要<br>
涉及的组件包括：</p>
<ul>
<li>Eureka：注册中心</li>
<li>Zuul、Gateway：服务网关</li>
<li>Ribbon：负载均衡</li>
<li>Feign：服务调用</li>
<li>Hystrix或Resilience4j：熔断器<br>
以上只是其中一部分，架构图：</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731111940.png" alt="" loading="lazy"></figure>
<h3 id="32-版本">3.2 版本</h3>
<p>Spring Cloud不是一个组件，而是许多组件的集合；它的版本命名比较特殊，是以A到Z的为首字母的一些单词（其实是伦敦地铁站的名字）组成：</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731111959.png" alt="" loading="lazy"></figure>
<p>我们在项目中，使用最新稳定的Greenwich版本。</p>
<h2 id="4-微服务场景模拟">4、 微服务场景模拟</h2>
<p>首先，我们需要模拟一个服务调用的场景。方便后面学习微服务架构</p>
<h3 id="41-创建父工程">4.1 创建父工程</h3>
<p>微服务中需要同时创建多个项目，为了方便课堂演示，先创建一个父工程，然后后续的工程都以这个工程为父，实现maven的聚合。这样可以在一个窗口看到所有工程，方便讲解。<strong>在实际开发中，每个微服务可独立一个工程。</strong></p>
<p>修改pom文件：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;groupId&gt;com.cy&lt;/groupId&gt;
    &lt;artifactId&gt;heima-springcloud&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;
        &lt;relativePath/&gt;
    &lt;/parent&gt;

    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt;
        &lt;mapper.starter.version&gt;2.1.5&lt;/mapper.starter.version&gt;
        &lt;mysql.version&gt;5.1.46&lt;/mysql.version&gt;
    &lt;/properties&gt;

    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;!-- springCloud --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
            &lt;!-- 通用Mapper启动器 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;tk.mybatis&lt;/groupId&gt;
                &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;
                &lt;version&gt;${mapper.starter.version}&lt;/version&gt;
            &lt;/dependency&gt;
            &lt;!-- mysql驱动 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;mysql&lt;/groupId&gt;
                &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
                &lt;version&gt;${mysql.version}&lt;/version&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>
<p>这里已经对大部分要用到的依赖的版本进行了 管理，方便后续使用</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731112314.png" alt="" loading="lazy"></figure>
<h3 id="42-服务提供者">4.2 服务提供者</h3>
<p>新建一个项目user-service，对外提供查询用户的服务。</p>
<ol>
<li>
<p><strong>创建module</strong><br>
选中父工程：springclouddemo创建module</p>
</li>
<li>
<p><strong>添加依赖</strong><br>
pom.xml 文件中的内容如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;springcloud-demo&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;artifactId&gt;user-service&lt;/artifactId&gt;

&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;!-- 通用Mapper启动器 --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;tk.mybatis&lt;/groupId&gt;
        &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;!-- mysql驱动 --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;mysql&lt;/groupId&gt;
        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>
</li>
<li>
<p><strong>编写配置文件</strong></p>
<p>创建user-service\src\main\resources\application.yml 属性文件,这里我们采用了yaml语法，而不是properties：</p>
<pre><code class="language-yaml">server:
  port: 9091
spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/springcloud
    username: root
    password: root
mybatis:
  type-aliases-package: com.cy.user.pojo
</code></pre>
<p>使用mysql图形界面工具创建springcloud 数据库，将tb_user.sql 导入；</p>
</li>
<li>
<p><strong>编写代码</strong></p>
<p>编写启动类</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import tk.mybatis.spring.annotation.MapperScan;

@SpringBootApplication
@MapperScan(&quot;com.cy.user.mapper&quot;)
public class UserApplication {
    public static void main(String[] args) {
        SpringApplication.run(UserApplication.class, args);
    }
}
</code></pre>
<p>编写实体类</p>
<pre><code class="language-java">import lombok.Data;
import tk.mybatis.mapper.annotation.KeySql;

import javax.persistence.Id;
import javax.persistence.Table;
import java.util.Date;

@Table(name = &quot;tb_user&quot;)
@Data
public class User {

    @Id
    @KeySql(useGeneratedKeys = true)
    private Long id;

    private String userName; // 用户名

    private String password; // 密码

    private String name;// 姓名

    private Integer age;// 年龄

    private Integer sex;// 性别，1男性，2女性

    private Date birthday;// 出生日期

    private Date created;// 创建时间

    private Date updated;// 更新时间

    private String note;// 备注
}
</code></pre>
<p>编写UserMapper</p>
<pre><code class="language-java">import com.cy.user.pojo.User;
import tk.mybatis.mapper.common.Mapper;

public interface UserMapper extends Mapper&lt;User&gt; {
}
</code></pre>
<p>编写UserService</p>
<pre><code class="language-java">import com.cy.user.mapper.UserMapper;
import com.cy.user.pojo.User;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

@Service
public class UserService {

    @Autowired
    private UserMapper userMapper;

    public User queryById(Long id){
        return userMapper.selectByPrimaryKey(id);
    }
}
</code></pre>
<p>添加一个对外查询的接口处理器</p>
<pre><code class="language-java">import com.cy.user.pojo.User;
import com.cy.user.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping(&quot;/user&quot;)
public class UserController {

    @Autowired
    private UserService userService;
     @GetMapping(&quot;/{id}&quot;)
    public User queryById(@PathVariable Long id){
        return userService.queryById(id);
    }
}
</code></pre>
<p>创建完上述代码后项目结构：</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731132923.png" alt="" loading="lazy"></figure>
</li>
<li>
<p><strong>启动并测试</strong></p>
<p>启动 user-service 项目，访问接口：http://localhost:9091/user/8</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731133358.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="43-服务调用者">4.3 服务调用者</h3>
<ol>
<li>
<p><strong>创建工程</strong><br>
与上面类似，这里不再赘述，需要注意的是，我们调用user-service 的功能，因此不需要mybatis相关依赖了。</p>
<p>修改pom文件</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;springclouddemo&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.cy&lt;/groupId&gt;
    &lt;artifactId&gt;consumer-demo&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>
</li>
<li>
<p><strong>编写代码</strong></p>
</li>
</ol>
<p>编写启动类 consumer-demo\src\main\java\com\cy\consumer\ConsumerApplication.java 并在其中注册RestTemplate 具体如下：</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.web.client.RestTemplate;

@SpringBootApplication
public class ConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
</code></pre>
<p>创建实体类 consumer-demo\src\main\java\com\cy\consumer\pojo\User.java</p>
<pre><code class="language-java">import lombok.Data;

import java.util.Date;

@Data
public class User {

    private Long id;

    private String userName; // 用户名

    private String password; // 密码

    private String name;// 姓名

    private Integer age;// 年龄

    private Integer sex;// 性别，1男性，2女性

    private Date birthday;// 出生日期

    private Date created;// 创建时间

    private Date updated;// 更新时间

    private String note;// 备注

}
</code></pre>
<p>编写consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java ，在controller中直接调用RestTemplate，远程访问user-service 的服务接口：</p>
<pre><code class="language-java">import com.cy.consumer.pojo.User;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

@RestController
@RequestMapping(&quot;/consumer&quot;)
public class ConsumerController {

    @Autowired
    private RestTemplate restTemplate;

    @GetMapping(&quot;{id}&quot;)
    public User queryById(@PathVariable Long id){
        String url = &quot;http://localhost:9091/user/&quot; + id;
        return restTemplate.getForObject(url, User.class);
    }

}
</code></pre>
<p>服务调用者项目结构：</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731133845.png" alt="" loading="lazy"></figure>
<ol start="3">
<li>
<p><strong>启动测试</strong><br>
启动 consumer-demo 引导启动类；因为 consumer-demo 项目没有配置端口，那么默认就是8080，</p>
<p>我们访问：http://localhost:8080/consumer/8</p>
<p>一个简单的远程服务调用案例就实现了。</p>
</li>
</ol>
<h3 id="44-思考问题">4.4 思考问题</h3>
<p>简单回顾一下，刚才我们写了什么：<br>
user-service：对外提供了查询用户的接口<br>
consumer-demo：通过RestTemplate访问http://locahost:9091/user/{id} 接口，查询用户数据<br>
存在什么问题？</p>
<ul>
<li>
<p>在consumer中，我们把url地址硬编码到了代码中，不方便后期维护</p>
</li>
<li>
<p>consumer需要记忆user-service的地址，如果出现变更，可能得不到通知，地址将失效</p>
</li>
<li>
<p>consumer不清楚user-service的状态，服务宕机也不知道</p>
</li>
<li>
<p>user-service只有1台服务，不具备高可用性</p>
</li>
<li>
<p>即便user-service形成集群，consumer还需自己实现负载均衡</p>
</li>
</ul>
<p>其实上面说的问题，概括一下就是分布式服务必然要面临的问题：</p>
<ul>
<li>
<p>服务管理</p>
</li>
<li>
<p>如何自动注册和发现</p>
</li>
<li>
<p>如何实现状态监管</p>
</li>
<li>
<p>如何实现动态路由</p>
</li>
<li>
<p>服务如何实现负载均衡</p>
</li>
<li>
<p>服务如何解决容灾问题</p>
</li>
<li>
<p>服务如何实现统一配置<br>
以上的问题，都将在SpringCloud中得到答案。</p>
</li>
</ul>
<h2 id="5-eureka注册中心">5、Eureka注册中心</h2>
<h3 id="51-认识eureka">5.1 认识Eureka</h3>
<p>首先我们来解决第一问题，服务的管理。<br>
<strong>问题分析</strong><br>
在刚才的案例中，user-service对外提供服务，需要对外暴露自己的地址。而consumer-demo（调用者）需要记录服务提供者的地址。将来地址出现变更，还需要及时更新。这在服务较少的时候并不觉得有什么，但是在现在日益复杂的互联网环境，一个项目可能会拆分出十几，甚至几十个微服务。此时如果还人为管理地址，不仅开发困难，将来测试、发布上线都会非常麻烦，这与DevOps的思想是背道而驰的。<br>
DevOps的思想是系统可以通过一组过程、方法或系统；提高应用发布和运维的效率,降低管理成本。<br>
<strong>网约车</strong><br>
这就好比是 网约车出现以前，人们出门叫车只能叫出租车。一些私家车想做出租却没有资格，被称为黑车。而很多人想要约车，但是无奈出租车太少，不方便。私家车很多却不敢拦，而且满大街的车，谁知道哪个才是愿意载人的。一个想要，一个愿意给，就是缺少引子，缺乏管理啊。<br>
此时滴滴这样的网约车平台出现了，所有想载客的私家车全部到滴滴注册，记录你的车型（服务类型），身份信息（联系方式）。这样提供服务的私家车，在滴滴那里都能找到，一目了然。<br>
此时要叫车的人，只需要打开APP，输入你的目的地，选择车型（服务类型），滴滴自动安排一个符合需求的车到你面前，为你服务，完美！<br>
<strong>Eureka做什么？</strong><br>
Eureka就好比是滴滴，负责管理、记录服务提供者的信息。服务调用者无需自己寻找服务，而是把自己的需求告诉Eureka，然后Eureka会把符合你需求的服务告诉你。<br>
同时，服务提供方与Eureka之间通过“心跳” 机制进行监控，当某个服务提供方出现问题，Eureka自然会把它从服务列表中剔除。<br>
这就实现了服务的自动注册、发现、状态监控。</p>
<h3 id="52-原理图">5.2 原理图</h3>
<p><strong>基本架构：</strong></p>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/1560439174201.png" alt="" loading="lazy"></figure>
<ul>
<li>Eureka：就是服务注册中心（可以是一个集群），对外暴露自己的地址</li>
<li>提供者：启动后向Eureka注册自己信息（地址，提供什么服务）</li>
<li>消费者：向Eureka订阅服务，Eureka会将对应服务的所有提供者地址列表发送给消费者，并且定期更新</li>
<li>心跳(续约)：提供者定期通过http方式向Eureka刷新自己的状态</li>
</ul>
<h3 id="53-入门案例">5.3  入门案例</h3>
<ol>
<li>
<p><strong>搭建eureka-server工程</strong><br>
接下来创建一个项目eureka-server ，启动一个Eureka Server Application服务注册中心。</p>
<p>项目中的pom.xml 文件如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;heima-springcloud&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.cy&lt;/groupId&gt;
    &lt;artifactId&gt;eureka-server&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
<p>编写启动类</p>
<p>eureka-server\src\main\java\com\cy\EurekaServerApplication.java</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;

//声明当前应用为eureka服务
@EnableEurekaServer
@SpringBootApplication
public class EurekaServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaServerApplication.class);
    }
}
</code></pre>
</li>
<li>
<p><strong>编写配置文件</strong></p>
</li>
</ol>
<p>eureka-server\src\main\resources\application.yml</p>
<pre><code class="language-yaml">server:
  port: 10086
spring:
  application:
    name: eureka-server # 应用名称，会在Eureka中作为服务的id标识（serviceId）
eureka:
  client:
    service-url: # EurekaServer的地址，现在是自己的地址，如果是集群，需要写其它Server的地址。
      defaultZone: http://127.0.0.1:10086/eureka
    register-with-eureka: false # 不注册自己
    fetch-registry: false #不拉取
</code></pre>
<ol start="3">
<li>
<p><strong>启动服务</strong><br>
启动 eureka-server 访问：http://127.0.0.1:10086</p>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731134955.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731135002.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="54-服务注册">5.4 服务注册</h3>
<p>注册服务，就是在服务上添加Eureka的客户端依赖，客户端代码会自动把服务注册到EurekaServer中。</p>
<ol>
<li><strong>添加依赖</strong><br>
我们在user-service中添加Eureka客户端依赖：</li>
</ol>
<pre><code class="language-xml">&lt;!-- Eureka客户端 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ol start="2">
<li><strong>修改启动类</strong><br>
在启动类上开启Eureka客户端功能<br>
通过添加@EnableDiscoveryClient 来开启Eureka客户端功能</li>
</ol>
<pre><code class="language-java">@SpringBootApplication
@MapperScan(&quot;com.cy.user.mapper&quot;)
@EnableDiscoveryClient // 开启Eureka客户端发现功能
public class UserServiceDemoApplication {
    public static void main(String[] args) {
        SpringApplication.run(UserServiceDemoApplication.class, args);
    }
}
</code></pre>
<ol start="3">
<li>
<p><strong>修改配置文件</strong></p>
<p>编写user-service\src\main\resources\application.yml配置文件为如下：</p>
</li>
</ol>
<pre><code class="language-yaml">server:
  port: 9091
spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/springcloud
    username: root
    password: root
  application:
    #应用名
    name: user-service
mybatis:
  type-aliases-package: cn.itcast.user.pojo
eureka:
  client:
    service-url:
      defaultZone: http://localhost:10086/eureka
</code></pre>
<p>注意：</p>
<ul>
<li>这里我们添加了spring.application.name属性来指定应用名称，将来会作为服务的id使用。</li>
</ul>
<ol start="4">
<li><strong>测试</strong><br>
重启 user-service 项目，访问Eureka监控页面</li>
</ol>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731135225.png" alt="" loading="lazy"></figure>
<p>我们发现user-service服务已经注册成功了</p>
<h3 id="55-服务发现">5.5 服务发现</h3>
<p>接下来我们修改consumer-demo ，尝试从EurekaServer获取服务。<br>
方法与服务提供者类似，只需要在项目中添加EurekaClient依赖，就可以通过服务名称来获取信息了！</p>
<ol>
<li><strong>添加依赖</strong><br>
找到 consumer-demo\pom.xml 添加如下依赖</li>
</ol>
<pre><code class="language-xml">&lt;!-- Eureka客户端 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ol start="2">
<li>
<p><strong>修改启动类</strong></p>
<p>修改 consumer-demo\src\main\java\com\cy\consumer\ConsumerApplication.java 开启Eureka客户端</p>
</li>
</ol>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;
import org.springframework.context.annotation.Bean;
import org.springframework.web.client.RestTemplate;

@SpringBootApplication
@EnableDiscoveryClient
public class ConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
</code></pre>
<ol start="3">
<li><strong>新增配置文件</strong></li>
</ol>
<p>新增 consumer-demo\src\main\resources\application.yml 配置文件</p>
<pre><code class="language-yaml">server:
  port: 8080
spring:
  application:
    name: consumer-demo # 应用名称
eureka:
  client:
    service-url: # EurekaServer地址
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
<ol start="4">
<li><strong>修改处理器</strong><br>
修改 consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java 代码，用DiscoveryClient类的方法，根据服务名称，获取服务实例。</li>
</ol>
<pre><code class="language-java">import com.cy.consumer.pojo.User;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.client.ServiceInstance;
import org.springframework.cloud.client.discovery.DiscoveryClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

import java.util.List;

@RestController
@RequestMapping(&quot;/consumer&quot;)
public class ConsumerController {

    @Autowired
    private RestTemplate restTemplate;

    @Autowired
    private DiscoveryClient discoveryClient;

    @GetMapping(&quot;{id}&quot;)
    public User queryById(@PathVariable Long id){
        String url = &quot;http://localhost:9091/user/&quot; + id;

        //获取eureka中注册的user-service实例列表
        List&lt;ServiceInstance&gt; serviceInstanceList = 
discoveryClient.getInstances(&quot;user-service&quot;);
        ServiceInstance serviceInstance = serviceInstanceList.get(0);

        url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort() 
+ &quot;/user/&quot; + id;
        return restTemplate.getForObject(url, User.class);
    }

}
</code></pre>
<ol start="5">
<li><strong>Debug跟踪运行</strong></li>
</ol>
<p>重启 consumer-demo 项目；然后再浏览器中再次访问 http://localhost:8080/consumer/8 ；在代码中debug跟进查看最终拼接要访问的URL：</p>
<figure data-type="image" tabindex="17"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731135743.png" alt="" loading="lazy"></figure>
<h3 id="56-eureka详解">5.6 Eureka详解</h3>
<h4 id="561-基础架构">5.6.1 基础架构</h4>
<p>Eureka架构中的三个核心角色：</p>
<ul>
<li>服务注册中心<br>
Eureka的服务端应用，提供服务注册和发现功能，就是刚刚我们建立的eureka-server</li>
<li>服务提供者<br>
提供服务的应用，可以是SpringBoot应用，也可以是其它任意技术实现，只要对外提供的是Rest风格服务即可。本例中就是我们实现的user-service</li>
<li>服务消费者<br>
消费应用从注册中心获取服务列表，从而得知每个服务方的信息，知道去哪里调用服务方。本例中就是我们实现的consumer-demo</li>
</ul>
<h4 id="562-高可用的eureka-server">5.6.2 高可用的Eureka Server</h4>
<p>Eureka Server即服务的注册中心，在刚才的案例中，我们只有一个EurekaServer，事实上EurekaServer也可以是一个集群，形成高可用的Eureka中心。<br>
<strong>服务同步</strong><br>
多个Eureka Server之间也会互相注册为服务，当服务提供者注册到Eureka Server集群中的某个节点时，该节点会把服务的信息同步给集群中的每个节点，从而实现<strong>数据同步</strong>。因此，无论客户端访问到Eureka Server集群中的任意一个节点，都可以获取到完整的服务列表信息。<br>
而作为客户端，需要把信息注册到每个Eureka中：</p>
<figure data-type="image" tabindex="18"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140001.png" alt="" loading="lazy"></figure>
<p>如果有三个Eureka，则每一个EurekaServer都需要注册到其它几个Eureka服务中，例如：有三个分别为10086、10087、10088，则：<br>
10086要注册到10087和10088上<br>
10087要注册到10086和10088上<br>
10088要注册到10086和10087上<br>
<strong>动手搭建高可用的EurekaServer</strong><br>
我们假设要搭建两台EurekaServer的集群，端口分别为：10086和10087<br>
1）修改原来的EurekaServer配置；修改 eureka-server\src\main\resources\application.yml 如下：</p>
<pre><code class="language-yaml">server:
  port: ${port:10086}

spring:
  application:
    # 应用名称，会在eureka中作为服务的id(serviceId)
    name: eureka-server
eureka:
  client:
    service-url:
      # eureka服务地址；如果是集群则是其它服务器地址，后面要加/eureka
      defaultZone: ${defaultZone:http://127.0.0.1:10086/eureka}
    # 是否注册自己，自身不提供服务所以不注册
    #register-with-eureka: false
    # 是否拉取服务
    #fetch-registry: false
</code></pre>
<p>所谓的高可用注册中心，其实就是把EurekaServer自己也作为一个服务，注册到其它EurekaServer上，这样多个EurekaServer之间就能互相发现对方，从而形成集群。因此我们做了以下修改：</p>
<p>注意:</p>
<ul>
<li>把register-with-eureka和fetch-registry修改为true或者注释掉</li>
<li>在上述配置文件中的${}表示在jvm启动时候若能找到对应port或者defaultZone参数则使用，若无则使用后面的默认值</li>
<li>把service-url的值改成了另外一台EurekaServer的地址，而不是自己</li>
</ul>
<p>2）另外一台在启动的时候可以指定端口port和defaultZone配置：</p>
<figure data-type="image" tabindex="19"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140210.png" alt="" loading="lazy"></figure>
<p>修改原来的启动配置组件；在如下界面中的 VM options 中<br>
设置 -DdefaultZone=http:127.0.0.1:10087/eureka</p>
<figure data-type="image" tabindex="20"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140228.png" alt="" loading="lazy"></figure>
<p>复制一份并修改；在如下界面中的 VM options 中<br>
设置 -Dport=10087 -DdefaultZone=http:127.0.0.1:10086/eureka</p>
<figure data-type="image" tabindex="21"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140239.png" alt="" loading="lazy"></figure>
<p>3）启动测试；同时启动两台eureka server</p>
<figure data-type="image" tabindex="22"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140248.png" alt="" loading="lazy"></figure>
<p>4）客户端注册服务到集群<br>
因为EurekaServer不止一个，因此user-service 项目注册服务或者consumer-demo 获取服务的时候，service-url参数需要修改为如下：</p>
<pre><code class="language-yaml">eureka:
  client:
    service-url: # EurekaServer地址,多个地址以','隔开
      defaultZone: http://127.0.0.1:10086/eureka,http://127.0.0.1:10087/eureka
</code></pre>
<p>为了方便后面内容的修改，在测试完上述配置后可以再次改回单个eureka server的方式。</p>
<h4 id="563-eureka客户端">5.6.3 Eureka客户端</h4>
<p>服务提供者要向EurekaServer注册服务，并且完成服务续约等工作。<br>
<strong>服务注册</strong><br>
服务提供者在启动时，会检测配置属性中的：eureka.client.register-with-erueka=true 参数是否正确，事实上默认就是true。如果值确实为true，则会向EurekaServer发起一个Rest请求，并携带自己的元数据信息，Eureka<br>
Server会把这些信息保存到一个双层Map结构中。</p>
<ul>
<li>
<p>第一层Map的Key就是服务id，一般是配置中的spring.application.name 属性</p>
</li>
<li>
<p>第二层Map的key是服务的实例id。一般host+ serviceId + port，例如：localhost:user-service:8081</p>
</li>
<li>
<p>值则是服务的实例对象，也就是说一个服务，可以同时启动多个不同实例，形成集群。</p>
</li>
</ul>
<p>默认注册时使用的是主机名或者localhost，如果想用ip进行注册，可以在user-service 中添加配置如下：</p>
<pre><code class="language-yaml">eureka:
  instance:
    ip-address: 127.0.0.1 # ip地址
    prefer-ip-address: true # 更倾向于使用ip，而不是host名
</code></pre>
<p>修改完后先后重启user-service 和consumer-demo ；在调用服务的时候就已经变成ip地址；需要注意的是：不是在eureka中的控制台服务实例状态显示。</p>
<p><strong>服务续约</strong></p>
<p>在注册服务完成以后，服务提供者会维持一个心跳（定时向EurekaServer发起Rest请求），告诉EurekaServer：“我还活着”。这个我们称为服务的续约（renew）；<br>
有两个重要参数可以修改服务续约的行为；可以在 user-service 中添加如下配置项：</p>
<pre><code class="language-yaml">eureka:
  instance:
    lease-expiration-duration-in-seconds: 90
    lease-renewal-interval-in-seconds: 30
</code></pre>
<ul>
<li>lease-renewal-interval-in-seconds：服务续约(renew)的间隔，默认为30秒</li>
<li>lease-expiration-duration-in-seconds：服务失效时间，默认值90秒</li>
</ul>
<p>也就是说，默认情况下每隔30秒服务会向注册中心发送一次心跳，证明自己还活着。如果超过90秒没有发送心跳，EurekaServer就会认为该服务宕机，会定时（eureka.server.eviction-interval-timer-in-ms设定的时间）从服务列表中移除，这两个值在生产环境不要修改，默认即可。</p>
<p><strong>获取服务列表</strong><br>
当服务消费者启动时，会检测eureka.client.fetch-registry=true 参数的值，如果为true，则会从EurekaServer服务的列表拉取只读备份，然后缓存在本地。并且每隔30秒会重新拉取并更新数据。可以在consumer-demo项目中通过下面的参数来修改：</p>
<pre><code class="language-yaml">eureka:
  client:
    registry-fetch-interval-seconds: 30
</code></pre>
<h4 id="564-失效剔除和自我保护">5.6.4 失效剔除和自我保护</h4>
<p>如下的配置都是在Eureka Server服务端进行：<br>
<strong>服务下线</strong><br>
当服务进行正常关闭操作时，它会触发一个服务下线的REST请求给Eureka Server，告诉服务注册中心：“我要下线了”。服务中心接受到请求之后，将该服务置为下线状态。<br>
<strong>失效剔除</strong><br>
有时我们的服务可能由于内存溢出或网络故障等原因使得服务不能正常的工作，而服务注册中心并未收到“服务下线”的请求。相对于服务提供者的“服务续约”操作，服务注册中心在启动时会创建一个定时任务，默认每隔一段时间（默认为60秒）将当前清单中超时（默认为90秒）没有续约的服务剔除，这个操作被称为失效剔除。<br>
可以通过eureka.server.eviction-interval-timer-in-ms 参数对其进行修改，单位是毫秒。<br>
<strong>自我保护</strong><br>
我们关停一个服务，很可能会在Eureka面板看到一条警告：</p>
<figure data-type="image" tabindex="23"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140915.png" alt="" loading="lazy"></figure>
<p>这是触发了Eureka的自我保护机制。当服务未按时进行心跳续约时，Eureka会统计服务实例最近15分钟心跳续约的比例是否低于了85%。在生产环境下，因为网络延迟等原因，心跳失败实例的比例很有可能超标，但是此时就把服务剔除列表并不妥当，因为服务可能没有宕机。Eureka在这段时间内不会剔除任何服务实例，直到网络恢复正常。生产环境下这很有效，保证了大多数服务依然可用，不过也有可能获取到失败的服务实例，因此服务调用者必须做好服务的失败容错。<br>
可以通过下面的配置来关停自我保护：</p>
<pre><code class="language-yaml">eureka:
  server:
    enable-self-preservation: false # 关闭自我保护模式（缺省为打开）
</code></pre>
<h2 id="6-负载均衡ribbon">6、负载均衡Ribbon</h2>
<p>在刚才的案例中，我们启动了一个user-service ，然后通过DiscoveryClient来获取服务实例信息，然后获取ip和端口来访问。</p>
<p>但是实际环境中，往往会开启很多个user-service 的集群。此时获取的服务列表中就会有多个，到底该访问哪一个呢？<br>
一般这种情况下就需要编写负载均衡算法，在多个实例列表中进行选择。<br>
不过Eureka中已经集成了负载均衡组件：Ribbon，简单修改代码即可使用。<br>
什么是Ribbon：</p>
<figure data-type="image" tabindex="24"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731141223.png" alt="" loading="lazy"></figure>
<p>接下来，我们就来使用Ribbon实现负载均衡。</p>
<h3 id="61-启动两个服务实例">6.1 启动两个服务实例</h3>
<p>首先我们配置启动两个user-service 实例，一个9091，一个9092。</p>
<figure data-type="image" tabindex="25"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731141249.png" alt="" loading="lazy"></figure>
<p>Eureka监控面板：</p>
<figure data-type="image" tabindex="26"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731141259.png" alt="" loading="lazy"></figure>
<h3 id="62-开启负载均衡">6.2 开启负载均衡</h3>
<p>因为Eureka中已经集成了Ribbon，所以我们无需引入新的依赖。<br>
直接修改 consumer-demo\src\main\java\com\cy\consumer\ConsumerApplication.java<br>
在RestTemplate的配置方法上添加@LoadBalanced 注解：</p>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaClient //开启eureka客户端发现
public class ConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class,args);
    }

    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
</code></pre>
<p>修改consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java 调用方式，不再手动获取ip和端口，而是直接通过服务名称调用；</p>
<pre><code class="language-java">@GetMapping(&quot;{id}&quot;)
public User queryById(@PathVariable(&quot;id&quot;) Long id){
    String url = &quot;http://user-service/user/&quot; + id;
    User user = restTemplate.getForObject(url, User.class);
    return user;
}
</code></pre>
<p>访问页面，查看结果；并可以在9091和9092的控制台查看执行情况：</p>
<p>了解：Ribbon默认的负载均衡策略是轮询。SpringBoot也帮提供了修改负载均衡规则的配置入口在consumer-demo的配置文件中添加如下，就变成随机的了：</p>
<pre><code class="language-yaml">user-service:
  ribbon:
    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule
</code></pre>
<p>格式是：{服务名称}.ribbon.NFLoadBalancerRuleClassName</p>
<h3 id="63-源码跟踪">6.3 源码跟踪</h3>
<p>为什么只输入了service名称就可以访问了呢？之前还要获取ip和端口。<br>
显然是有组件根据service名称，获取到了服务实例的ip和端口。因为consumer-demo 使用的是RestTemplate，spring的负载均衡自动配置类 LoadBalancerAutoConfiguration.LoadBalancerInterceptorConfig 会自动配置负载均衡拦截器（在spring-cloud-commons-**.jar包中的spring.factories中定义的自动配置类）， 它就是LoadBalancerInterceptor ，这个类会在对RestTemplate的请求进行拦截，然后从Eureka根据服务id获取服务列表，随后利用负载均衡算法得到真实的服务地址信息，替换服务id。<br>
我们进行源码跟踪：</p>
<figure data-type="image" tabindex="27"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731142533.png" alt="" loading="lazy"></figure>
<p>继续跟入execute方法：发现获取了9092端口的服务</p>
<figure data-type="image" tabindex="28"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731142740.png" alt="" loading="lazy"></figure>
<p>再跟下一次，发现获取的是9091、9092之间切换：</p>
<figure data-type="image" tabindex="29"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143101.png" alt="" loading="lazy"></figure>
<p>多次访问consumer-demo 的请求地址；然后跟进代码，发现其果然实现了负载均衡。</p>
<h2 id="7-熔断器hystrix">7、熔断器Hystrix</h2>
<h3 id="71-简介">7.1 简介</h3>
<p>Hystrix 在英文里面的意思是 豪猪，它的logo 看下面的图是一头豪猪，它在微服务系统中是一款提供保护机制的组件，和eureka一样也是由netﬂix公司开发。<br>
主页：https://github.com/Netﬂix/Hystrix/</p>
<figure data-type="image" tabindex="30"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143149.png" alt="" loading="lazy"></figure>
<p>那么Hystrix的作用是什么呢？具体要保护什么呢？<br>
Hystrix是Netﬂix开源的一个延迟和容错库，用于隔离访问远程服务、第三方库，防止出现级联失败。</p>
<h3 id="72-雪崩问题">7.2 雪崩问题</h3>
<p>微服务中，服务间调用关系错综复杂，一个请求，可能需要调用多个微服务接口才能实现，会形成非常复杂的调用链路：</p>
<figure data-type="image" tabindex="31"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143246.png" alt="" loading="lazy"></figure>
<p>如图，一次业务请求，需要调用A、P、H、I四个服务，这四个服务又可能调用其它服务。<br>
如果此时，某个服务出现异常：</p>
<figure data-type="image" tabindex="32"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143314.png" alt="" loading="lazy"></figure>
<p>例如：微服务I 发生异常，请求阻塞，用户请求就不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞：</p>
<figure data-type="image" tabindex="33"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143344.png" alt="" loading="lazy"></figure>
<p>服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，形成雪崩效应。<br>
这就好比，一个汽车生产线，生产不同的汽车，需要使用不同的零件，如果某个零件因为种种原因无法使用，那么就会造成整台车无法装配，陷入等待零件的状态，直到零件到位，才能继续组装。  此时如果有很多个车型都需要这个零件，那么整个工厂都将陷入等待的状态，导致所有生产都陷入瘫痪。一个零件的波及范围不断扩大。</p>
<p>Hystrix解决雪崩问题的手段主要是服务降级，包括：</p>
<ul>
<li>线程隔离</li>
<li>服务熔断</li>
</ul>
<h3 id="73-线程隔离服务降级">7.3 线程隔离&amp;服务降级</h3>
<h4 id="731-原理">7.3.1 原理</h4>
<p>线程隔离示意图：</p>
<figure data-type="image" tabindex="34"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143445.png" alt="" loading="lazy"></figure>
<p>解读：</p>
<ul>
<li>Hystrix为每个依赖服务调用分配一个小的线程池，如果线程池已满调用将被立即拒绝，默认不采用排队，<strong>加速失败判定时间。</strong></li>
<li>用户的请求将不再直接访问服务，而是通过线程池中的空闲线程来访问服务，如果线程池已满，或者请求超时，则会进行降级处理，什么是服务降级？<br>
<strong>服务降级：优先保证核心服务，而非核心服务不可用或弱可用。</strong><br>
用户的请求故障时，不会被阻塞，更不会无休止的等待或者看到系统崩溃，至少可以看到一个执行结果（例如返回友好的提示信息） 。<br>
<strong>服务降级虽然会导致请求失败，但是不会导致阻塞，而且最多会影响这个依赖服务对应的线程池中的资源，对其它服务没有响应。</strong><br>
<strong>触发Hystrix服务降级的情况：</strong>
<ul>
<li>线程池已满</li>
<li>请求超时</li>
</ul>
</li>
</ul>
<h4 id="732-动手实践">7.3.2 动手实践</h4>
<p>1）引入依赖<br>
在consumer-demo 消费端系统的pom.xml文件添加如下依赖：</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>2）开启熔断<br>
在启动类ConsumerApplication 上添加注解：@EnableCircuitBreaker</p>
<pre><code class="language-java">@SpringBootApplication
@EnableDiscoveryClient
@EnableCircuitBreaker
public class ConsumerApplication {
    // ...
}
</code></pre>
<p>可以看到，我们类上的注解越来越多，在微服务中，经常会引入上面的三个注解，于是Spring就提供了一个组合注解：@SpringCloudApplication</p>
<figure data-type="image" tabindex="35"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731145640.png" alt="" loading="lazy"></figure>
<p>因此，我们可以使用这个组合注解来代替之前的3个注解。</p>
<pre><code class="language-java">@SpringCloudApplication
public class ConsumerApplication {
    // ...
}
</code></pre>
<p>3）编写降级逻辑<br>
当目标服务的调用出现故障，我们希望快速失败，给用户一个友好提示。因此需要提前编写好失败时的降级处理逻辑，要使用HystrixCommand来完成。<br>
改造consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java 处理器类，如下：</p>
<pre><code class="language-java">import com.cy.consumer.pojo.User;
import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.client.ServiceInstance;
import org.springframework.cloud.client.discovery.DiscoveryClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

import java.util.List;

@RestController
@RequestMapping(&quot;/consumer&quot;)
@Slf4j
public class ConsumerController {

    @Autowired
    private RestTemplate restTemplate;

    @Autowired
    private DiscoveryClient discoveryClient;

    @GetMapping(&quot;{id}&quot;)
    @HystrixCommand(fallbackMethod = &quot;queryByIdFallback&quot;)
    public String queryById(@PathVariable Long id){
        String url = &quot;http://localhost:9091/user/&quot; + id;

        //获取eureka中注册的user-service实例列表
        /*List&lt;ServiceInstance&gt; serviceInstanceList = 
discoveryClient.getInstances(&quot;user-service&quot;);
        ServiceInstance serviceInstance = serviceInstanceList.get(0);
    url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort() 
+ &quot;/user/&quot; + id;*/
        url = &quot;http://user-service/user/&quot; + id;

        return restTemplate.getForObject(url, String.class);
    }

    public String queryByIdFallback(Long id){
        log.error(&quot;查询用户信息失败。id：{}&quot;, id);
        return &quot;对不起，网络太拥挤了！&quot;;
    }

}     
</code></pre>
<p><code>要注意；因为熔断的降级逻辑方法必须跟正常逻辑方法保证：相同的参数列表和返回值声明。 失败逻辑中返回User对象没有太大意义，一般会返回友好提示。所以把queryById的方法改造为返回String，反正也是Json数据。这样失败逻辑中返回一个错误说明，会比较方便。</code></p>
<p>说明：</p>
<ul>
<li>@HystrixCommand(fallbackMethod = &quot;queryByIdFallBack&quot;)：用来声明一个降级逻辑的方法<br>
测试：<br>
当user-service 正常提供服务时，访问与以前一致。但是当将user-service 停机时，会发现页面返回了降级处理信息：</li>
</ul>
<figure data-type="image" tabindex="36"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731150137.png" alt="" loading="lazy"></figure>
<p>4）默认的Fallback<br>
刚才把fallback写在了某个业务方法上，如果这样的方法很多，那岂不是要写很多。所以可以把Fallback配置加在类上，实现默认fallback；<br>
再次改造 consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java</p>
<pre><code class="language-java">import com.cy.consumer.pojo.User;
import com.netflix.hystrix.contrib.javanica.annotation.DefaultProperties;
import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.client.ServiceInstance;
import org.springframework.cloud.client.discovery.DiscoveryClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

import java.util.List;

@RestController
@RequestMapping(&quot;/consumer&quot;)
@Slf4j
@DefaultProperties(defaultFallback = &quot;defaultFallback&quot;)
public class ConsumerController {

    @Autowired
    private RestTemplate restTemplate;

    @Autowired
    private DiscoveryClient discoveryClient;

    @GetMapping(&quot;{id}&quot;)
    //@HystrixCommand(fallbackMethod = &quot;queryByIdFallback&quot;)
    @HystrixCommand
    public String queryById(@PathVariable Long id){
        String url = &quot;http://localhost:9091/user/&quot; + id;

        //获取eureka中注册的user-service实例列表
        /*List&lt;ServiceInstance&gt; serviceInstanceList = 
discoveryClient.getInstances(&quot;user-service&quot;);
        ServiceInstance serviceInstance = serviceInstanceList.get(0);

        url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort() 
+ &quot;/user/&quot; + id;*/
        url = &quot;http://user-service/user/&quot; + id;

        return restTemplate.getForObject(url, String.class);
    }

    public String queryByIdFallback(Long id){
        log.error(&quot;查询用户信息失败。id：{}&quot;, id);
        return &quot;对不起，网络太拥挤了！&quot;;
    }

    public String defaultFallback(){
        return &quot;默认提示：对不起，网络太拥挤了！&quot;;
    }

}
</code></pre>
<ul>
<li>@DefaultProperties(defaultFallback = &quot;defaultFallBack&quot;)：在类上指明统一的失败降级方法；该类中所有方法返回类型要与处理失败的方法的返回类型一致。</li>
</ul>
<figure data-type="image" tabindex="37"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731150351.png" alt="" loading="lazy"></figure>
<p>5）超时设置<br>
在之前的案例中，请求在超过1秒后都会返回错误信息，这是因为Hystrix的默认超时时长为1，我们可以通过配置修改这个值；修改 consumer-demo\src\main\resources\application.yml 添加如下配置：</p>
<pre><code class="language-yaml">hystrix:
  command:
    default:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 2000
</code></pre>
<p>这个配置会作用于全局所有方法。为了方便复制到yml配置文件中，可以复制<br>
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=2000 到yml文件中会自动格式化后再进行修改。</p>
<p>为了触发超时，可以在user-service\src\main\java\com\cy\user\service\UserService.java 的方法中休眠2秒；</p>
<pre><code class="language-java">@Service
public class UserService {

    @Autowired
    private UserMapper userMapper;

    public User queryById(Long id) {
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return userMapper.selectByPrimaryKey(id);
    }
}
</code></pre>
<p>测试：</p>
<figure data-type="image" tabindex="38"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731150557.png" alt="" loading="lazy"></figure>
<p>可以发现，请求的时长已经到了2s+，证明配置生效了。如果把修改时间修改到2秒以下，又可以正常访问。</p>
<h3 id="74-服务熔断">7.4 服务熔断</h3>
<h4 id="741-熔断原理">7.4.1  熔断原理</h4>
<p>在服务熔断中，使用的熔断器，也叫断路器，其英文单词为：Circuit Breaker<br>
熔断机制与家里使用的电路熔断原理类似；当如果电路发生短路的时候能立刻熔断电路，避免发生灾难。在分布式系统中应用服务熔断后；服务调用方可以自己进行判断哪些服务反应慢或存在大量超时，可以针对这些服务进行主动熔断，防止整个系统被拖垮。<br>
Hystrix的服务熔断机制，可以实现弹性容错；当服务请求情况好转之后，可以自动重连。通过断路的方式，将后续请求直接拒绝，一段时间（默认5秒）之后允许部分请求通过，如果调用成功则回到断路器关闭状态，否则继续打<br>
开，拒绝请求的服务。<br>
Hystrix的熔断状态机模型：</p>
<figure data-type="image" tabindex="39"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/1560682028169.png" alt="" loading="lazy"></figure>
<p>状态机有3个状态：</p>
<ul>
<li>Closed：关闭状态（断路器关闭），所有请求都正常访问。</li>
<li>Open：打开状态（断路器打开），所有请求都会被降级。Hystrix会对请求情况计数，当一定时间内失败请求百分比达到阈值，则触发熔断，断路器会完全打开。默认失败比例的阈值是50%，请求次数最少不低于20次。</li>
<li>Half Open：半开状态，不是永久的，断路器打开后会进入休眠时间（默认是5S）。随后断路器会自动进入半开状态。此时会释放部分请求通过，若这些请求都是健康的，则会关闭断路器，否则继续保持打开，再次进行休眠计时</li>
</ul>
<h4 id="742-动手实践">7.4.2 动手实践</h4>
<p>为了能够精确控制请求的成功或失败，在consumer-demo 的处理器业务方法中加入一段逻辑；<br>
修改 consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java</p>
<pre><code class="language-java">@GetMapping(&quot;{id}&quot;)
@HystrixCommand
public String queryById(@PathVariable(&quot;id&quot;) Long id){
    if(id == 1){
        throw new RuntimeException(&quot;太忙了&quot;);
    }
    String url = &quot;http://user-service/user/&quot; + id;
    String user = restTemplate.getForObject(url, String.class);
    return user;
}
</code></pre>
<p>这样如果参数是id为1，一定失败，其它情况都成功。（不要忘了清空user-service中的休眠逻辑）<br>
我们准备两个请求窗口：</p>
<ul>
<li>一个请求：http://localhost:8080/consumer/1，注定失败</li>
<li>一个请求：http://localhost:8080/consumer/2，肯定成功<br>
当我们疯狂访问id为1的请求时（超过20次），就会触发熔断。断路器会打开，一切请求都会被降级处理。<br>
此时你访问id为2的请求，会发现返回的也是失败，而且失败时间很短，只有20毫秒左右；因进入半开状态之后2是可以的。</li>
</ul>
<figure data-type="image" tabindex="40"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803023239.png" alt="" loading="lazy"></figure>
<p>不过，默认的熔断触发要求较高，休眠时间窗较短，为了测试方便，我们可以通过配置修改熔断策略：</p>
<pre><code class="language-yaml"># 配置熔断策略：
hystrix:
  command:
    default:
      circuitBreaker:
        errorThresholdPercentage: 50 # 触发熔断错误比例阈值，默认值50%
        sleepWindowInMilliseconds: 10000 # 熔断后休眠时长，默认值5秒
        requestVolumeThreshold: 10 # 熔断触发最小请求次数，默认值是20
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 2000 # 熔断超时设置，默认为1秒
</code></pre>
<p>为了方便复制上述配置，可以使用如下格式复制到yml文件中会自动格式化：</p>
<pre><code class="language-properties">hystrix.command.default.circuitBreaker.requestVolumeThreshold=10
hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds=10000
hystrix.command.default.circuitBreaker.errorThresholdPercentage=50
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=2000
</code></pre>
<p>上述的配置项可以参考 HystrixCommandProperties 类中。</p>
<h2 id="8-feign">8、Feign</h2>
<p>在前面的学习中，使用了Ribbon的负载均衡功能，大大简化了远程调用时的代码：</p>
<pre><code class="language-java">String url = &quot;http://user-service/user/&quot; + id;
User user = this.restTemplate.getForObject(url, User.class)
</code></pre>
<p>如果就学到这里，可能以后需要编写类似的大量重复代码，格式基本相同，无非参数不一样。有没有更优雅的方式，来对这些代码再次优化呢？<br>
这就是接下来要学的Feign的功能了。</p>
<h3 id="81-简介">8.1 简介</h3>
<p>Feign也叫伪装：<br>
Feign可以把Rest的请求进行隐藏，伪装成类似SpringMVC的Controller一样。你不用再自己拼接url，拼接参数等等操作，一切都交给Feign去做。</p>
<p>项目主页：https://github.com/OpenFeign/feign</p>
<h3 id="82-快速入门">8.2 快速入门</h3>
<ol>
<li>
<p>导入依赖<br>
在consumer-demo 项目的pom.xml 文件中添加如下依赖</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li>
<p>Feign的客户端</p>
<p>在consumer-demo 中编写如下Feign客户端接口类：</p>
<pre><code class="language-java">package com.itheima.consumer.client;

import com.itheima.consumer.pojo.User;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;

@FeignClient(&quot;user-service&quot;)
public interface UserClient {

    @GetMapping(&quot;/user/{id}&quot;)
    User queryById(@PathVariable(&quot;id&quot;) Long id);
}
</code></pre>
<ul>
<li>首先这是一个接口，Feign会通过动态代理，帮我们生成实现类。这点跟mybatis的mapper很像</li>
<li>@FeignClient ，声明这是一个Feign客户端，同时通过value 属性指定服务名称</li>
<li>接口中的定义方法，完全采用SpringMVC的注解，Feign会根据注解帮我们生成URL，并访问获取结果</li>
<li>@GetMapping中的/user，请不要忘记；因为Feign需要拼接可访问的地址</li>
</ul>
<p>编写新的控制器类ConsumerFeignController ，使用UserClient访问：</p>
<pre><code class="language-java">package com.itheima.consumer.controller;

import com.itheima.consumer.client.UserClient;
import com.itheima.consumer.pojo.User;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping(&quot;/cf&quot;)
public class ConsumerFeignController {

    @Autowired
    private UserClient userClient;

    @GetMapping(&quot;/{id}&quot;)
    public User queryById(@PathVariable Long id){
        return userClient.queryById(id);
    }
}
</code></pre>
</li>
<li>
<p>开启Feign功能<br>
在ConsumerApplication 启动类上，添加注解，开启Feign功能</p>
<pre><code class="language-java">package com.itheima.consumer;

import org.springframework.boot.SpringApplication;
import org.springframework.cloud.client.SpringCloudApplication;
import org.springframework.cloud.client.loadbalancer.LoadBalanced;
import org.springframework.cloud.openfeign.EnableFeignClients;
import org.springframework.context.annotation.Bean;
import org.springframework.web.client.RestTemplate;

/*@SpringBootApplication
@EnableDiscoveryClient
@EnableCircuitBreaker*/
@SpringCloudApplication
@EnableFeignClients//开启Feign功能
public class ConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

    @Bean
    @LoadBalanced
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
</code></pre>
<p>Feign中已经自动集成了Ribbon负载均衡，因此不需要自己定义RestTemplate进行负载均衡的配置。</p>
</li>
<li>
<p>启动测试</p>
<p>访问接口：http://localhost:8080/cf/2</p>
<figure data-type="image" tabindex="41"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803023919.png" alt="" loading="lazy"></figure>
<p>正常获取到了结果。</p>
</li>
</ol>
<h3 id="83-负载均衡">8.3 负载均衡</h3>
<p>Feign中本身已经集成了Ribbon依赖和自动配置：</p>
<figure data-type="image" tabindex="42"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024003.png" alt="" loading="lazy"></figure>
<p>因此不需要额外引入依赖，也不需要再注册RestTemplate 对象。</p>
<p>Fegin内置的ribbon默认设置了请求超时时长，默认是1000，我们可以通过手动配置来修改这个超时时长：</p>
<pre><code class="language-yaml">ribbon:
  ReadTimeout: 2000 # 读取超时时长
  ConnectTimeout: 1000 # 建立链接的超时时长
</code></pre>
<p>因为ribbon内部有重试机制，一旦超时，会自动重新发起请求。如果不希望重试，可以添加配置：<br>
修改 consumer-demo\src\main\resources\application.yml 添加如下配置：</p>
<pre><code class="language-yaml">ribbon:
  ConnectTimeout: 1000 # 连接超时时长
  ReadTimeout: 2000 # 数据通信超时时长
  MaxAutoRetries: 0 # 当前服务器的重试次数
  MaxAutoRetriesNextServer: 0 # 重试多少次服务
  OkToRetryOnAllOperations: false # 是否对所有的请求方式都重试
</code></pre>
<p>重新给UserService的方法设置上线程沉睡时间2秒可以测试上述配置</p>
<h3 id="84-hystrix支持了解">8.4 Hystrix支持(了解)</h3>
<p>Feign默认也有对Hystrix的集成：</p>
<figure data-type="image" tabindex="43"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024124.png" alt="" loading="lazy"></figure>
<p>只不过，默认情况下是关闭的。需要通过下面的参数来开启；<br>
修改 consumer-demo\src\main\resources\application.yml 添加如下配置：</p>
<pre><code class="language-yaml">feign:
  hystrix:
    enabled: true # 开启Feign的熔断功能
</code></pre>
<p>但是，Feign中的Fallback配置不像Ribbon中那样简单了。<br>
1）首先，要定义一个类，实现刚才编写的UserFeignClient，作为fallback的处理类</p>
<pre><code class="language-java">package com.itheima.consumer.client.fallback;

import com.itheima.consumer.client.UserClient;
import com.itheima.consumer.pojo.User;
import org.springframework.stereotype.Component;

@Component
public class UserClientFallback implements UserClient {
    @Override
    public User queryById(Long id) {
        User user = new User();
        user.setId(id);
        user.setName(&quot;用户异常&quot;);
        return user;
    }
}
</code></pre>
<p>2）然后在UserFeignClient中，指定刚才编写的实现类</p>
<pre><code class="language-java">@FeignClient(value = &quot;user-service&quot;, fallback = UserClientFallback.class)
public interface UserClient {

    @GetMapping(&quot;/user/{id}&quot;)
    User queryById(@PathVariable(&quot;id&quot;) Long id);
}
</code></pre>
<p>3）重启测试<br>
重启启动 consumer-demo 并关闭user-service 服务，然后在页面访问：http://localhost:8080/cf/8</p>
<figure data-type="image" tabindex="44"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024404.png" alt="" loading="lazy"></figure>
<h3 id="85-请求压缩了解">8.5 请求压缩(了解)</h3>
<p>Spring Cloud Feign 支持对请求和响应进行GZIP压缩，以减少通信过程中的性能损耗。通过下面的参数即可开启请求与响应的压缩功能：</p>
<pre><code class="language-yaml">feign:
  compression:
    request:
      enabled: true # 开启请求压缩
    response:
      enabled: true # 开启响应压缩
</code></pre>
<p>同时，我们也可以对请求的数据类型，以及触发压缩的大小下限进行设置：</p>
<pre><code class="language-yaml">feign:
  compression:
    request:
      enabled: true # 开启请求压缩
      mime-types: text/html,application/xml,application/json # 设置压缩的数据类型
      min-request-size: 2048 # 设置触发压缩的大小下限
</code></pre>
<p>注：上面的数据类型、压缩大小下限均为默认值。</p>
<h3 id="86-日志级别了解">8.6  日志级别(了解)</h3>
<p>前面讲过，通过logging.level.xx=debug 来设置日志级别。然而这个对Fegin客户端而言不会产生效果。因为@FeignClient 注解修改的客户端在被代理时，都会创建一个新的Fegin.Logger实例。我们需要额外指定这个日志的<br>
级别才可以。<br>
1）在consumer-demo 的配置文件中设置com.itheima包下的日志级别都为 debug<br>
修改 consumer-demo\src\main\resources\application.yml 添加如下配置：</p>
<pre><code class="language-yaml">logging:
  level:
    com.itheima: debug
</code></pre>
<p>2）在consumer-demo 编写FeignConﬁg配置类，定义日志级别</p>
<pre><code class="language-java">package com.itheima.consumer.config;

import feign.Logger;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class FeignConfig {

    @Bean
    Logger.Level feignLoggerLevel(){
        //记录所有请求和响应的明细，包括头信息、请求体、元数据
        return Logger.Level.FULL;
    }
}
</code></pre>
<p>这里指定的Level级别是FULL，Feign支持4种级别：<br>
NONE：不记录任何日志信息，这是默认值。<br>
BASIC：仅记录请求的方法，URL以及响应状态码和执行时间<br>
HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息<br>
FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。</p>
<p>3）在consumer-demo 的UserClient 接口类上的@FeignClient注解中指定配置类：</p>
<pre><code class="language-java">package com.itheima.consumer.client;

import com.itheima.consumer.client.fallback.UserClientFallback;
import com.itheima.consumer.config.FeignConfig;
import com.itheima.consumer.pojo.User;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;

@FeignClient(value = &quot;user-service&quot;, fallback = UserClientFallback.class,
configuration = FeignConfig.class)
public interface UserClient {

    @GetMapping(&quot;/user/{id}&quot;)
    User queryById(@PathVariable Long id);
}
</code></pre>
<p>4）重启项目，访问：http://localhost:8080/cf/8 ；即可看到每次访问的日志：</p>
<figure data-type="image" tabindex="45"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024710.png" alt="" loading="lazy"></figure>
<h2 id="9-spring-cloud-gateway网关">9、Spring Cloud Gateway网关</h2>
<h3 id="91-简介">9.1 简介</h3>
<ul>
<li>Spring Cloud Gateway是Spring官网基于Spring 5.0、 Spring Boot 2.0、Project Reactor等技术开发的网关服务。</li>
<li>Spring Cloud Gateway基于Filter链提供网关基本功能：安全、监控／埋点、限流等。</li>
<li>Spring Cloud Gateway为微服务架构提供简单、有效且统一的API路由管理方式。</li>
<li>Spring Cloud Gateway是替代Netﬂix Zuul的一套解决方案。<br>
Spring Cloud Gateway组件的核心是一系列的过滤器，通过这些过滤器可以将客户端发送的请求转发（路由）到对应的微服务。 Spring Cloud Gateway是加在整个微服务最前沿的防火墙和代理器，隐藏微服务结点IP端口信息，从而加强安全保护。Spring Cloud Gateway本身也是一个微服务，需要注册到Eureka服务注册中心。<br>
网关的核心功能是：<strong>过滤和路由</strong></li>
</ul>
<h3 id="92-gateway加入后的架构">9.2 Gateway加入后的架构</h3>
<figure data-type="image" tabindex="46"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024952.png" alt="" loading="lazy"></figure>
<ul>
<li>不管是来自于客户端（PC或移动端）的请求，还是服务内部调用。一切对服务的请求都可经过网关，然后再由网关来实现 鉴权、动态路由等等操作。Gateway就是我们服务的统一入口。</li>
</ul>
<h3 id="93-核心概念">9.3 核心概念</h3>
<ul>
<li><strong>路由（route）</strong> 路由信息的组成：由一个ID、一个目的URL、一组断言工厂、一组Filter组成。如果路由断言为真，说明请求URL和配置路由匹配。</li>
<li><strong>断言（Predicate）</strong> Spring Cloud Gateway中的断言函数输入类型是Spring 5.0框架中的ServerWebExchange。Spring Cloud Gateway的断言函数允许开发者去定义匹配来自于Http Request中的任何信息比如请求头和参数。</li>
<li><strong>过滤器（Filter）</strong> 一个标准的Spring WebFilter。 Spring Cloud Gateway中的Filter分为两种类型的Filter，分别是Gateway Filter和Global Filter。过滤器Filter将会对请求和响应进行修改处理。</li>
</ul>
<h3 id="94-快速入门">9.4 快速入门</h3>
<ol>
<li>
<p><strong>新建工程</strong></p>
<p>打开 heima-springcloud\heima-gateway\pom.xml 文件修改为如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;heima-springcloud&lt;/artifactId&gt;
        &lt;groupId&gt;com.itheima&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.itheima&lt;/groupId&gt;
    &lt;artifactId&gt;heima-gateway&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
</li>
<li>
<p><strong>编写启动类</strong><br>
在heima-gateway中创建com.itheima.gateway.GatewayApplication 启动类</p>
<pre><code class="language-java">package com.itheima.gateway;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;

@SpringBootApplication
@EnableDiscoveryClient
public class GatewayApplication {
    public static void main(String[] args) {
        SpringApplication.run(GatewayApplication.class, args);
    }
}
</code></pre>
</li>
<li>
<p><strong>创建heima-gateway\src\main\resources\application.yml 文件，内容如下：</strong></p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway

eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
</li>
<li>
<p><strong>编写路由规则</strong><br>
需要用网关来代理user-service 服务，先看一下控制面板中的服务状态：</p>
<figure data-type="image" tabindex="47"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803154326.png" alt="" loading="lazy"></figure>
<ul>
<li>ip为：127.0.0.1</li>
<li>端口为：9091<br>
修改heima-gateway\src\main\resources\application.yml 文件为：</li>
</ul>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址
          uri: http://127.0.0.1:9091
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/user/**
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>将符合Path 规则的一切请求，都代理到 uri 参数指定的地址<br>
本例中，我们将路径中包含有 /user/** 开头的请求，代理到http://127.0.0.1:9091</p>
</li>
<li>
<p><strong>启动测试</strong><br>
访问的路径中需要加上配置规则的映射路径，我们访问：http://localhost:10010/user/8</p>
<figure data-type="image" tabindex="48"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803154523.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="95-面向服务的路由">9.5 面向服务的路由</h3>
<p>在刚才的路由规则中，把路径对应的服务地址写死了！如果同一服务有多个实例的话，这样做显然不合理。应该根据服务的名称，去Eureka注册中心查找服务对应的所有实例列表，然后进行动态路由！</p>
<ol>
<li>
<p><strong>修改映射配置，通过服务名称获取</strong><br>
因为已经配置了Eureka客户端，可以从Eureka获取服务的地址信息。<br>
修改heima-gateway\src\main\resources\application.yml 文件如下：</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/user/**
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>路由配置中uri所用的协议为lb时（以uri: lb://user-service为例），gateway将使用 LoadBalancerClient把user-service通过eureka解析为实际的主机和端口，并进行ribbon负载均衡。</p>
</li>
<li>
<p><strong>启动测试</strong><br>
再次启动 heima-gateway ，这次gateway进行代理时，会利用Ribbon进行负载均衡访问：<br>
http://localhost:10010/user/8<br>
日志中可以看到使用了负载均衡器：</p>
<figure data-type="image" tabindex="49"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155238.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="96-路由前缀">9.6 路由前缀</h3>
<h4 id="961-添加前缀">9.6.1 添加前缀</h4>
<p>在gateway中可以通过配置路由的过滤器PreﬁxPath，实现映射路径中地址的添加；<br>
修改heima-gateway\src\main\resources\application.yml 文件：</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
    cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/**
          filters:
            # 添加请求路径的前缀
            - PrefixPath=/user
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>通过PrefixPath=/xxx 来指定了路由要添加的前缀。<br>
也就是：<br>
PrefixPath=/user http://localhost:10010/8 --》http://localhost:9091/user/8<br>
PrefixPath=/user/abc http://localhost:10010/8 --》http://localhost:9091/user/abc/8<br>
以此类推。</p>
<figure data-type="image" tabindex="50"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155358.png" alt="" loading="lazy"></figure>
<h4 id="962-去除前缀">9.6.2 去除前缀</h4>
<p>在gateway中可以通过配置路由的过滤器StripPreﬁx，实现映射路径中地址的去除；</p>
<p>修改heima-gateway\src\main\resources\application.yml 文件：</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/api/user/**
          filters:
            # 表示过滤1个路径，2表示两个路径，以此类推
            - StripPrefix=1
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>通过StripPrefix=1 来指定了路由要去掉的前缀个数。如：路径/api/user/1 将会被代理到/user/1 。<br>
也就是：<br>
StripPrefix=1 http://localhost:10010/api/user/8 --》http://localhost:9091/user/8<br>
StripPrefix=2 http://localhost:10010/api/user/8 --》http://localhost:9091/8<br>
以此类推。</p>
<figure data-type="image" tabindex="51"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155500.png" alt="" loading="lazy"></figure>
<h3 id="97-过滤器">9.7  过滤器</h3>
<h4 id="971-简介">9.7.1 简介</h4>
<p>Gateway作为网关的其中一个重要功能，就是实现请求的鉴权。而这个动作往往是通过网关提供的过滤器来实现的。<br>
前面的 路由前缀 章节中的功能也是使用过滤器实现的。</p>
<p>Gateway自带过滤器有几十个，常见自带过滤器有：</p>
<table>
<thead>
<tr>
<th style="text-align:center">过滤器名称</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">AddRequestHeader</td>
<td style="text-align:center">对匹配上的请求加上Header</td>
</tr>
<tr>
<td style="text-align:center">AddRequestParameters</td>
<td style="text-align:center">对匹配上的请求路由添加参数</td>
</tr>
<tr>
<td style="text-align:center">AddResponseHeader</td>
<td style="text-align:center">对从网关返回的响应添加Header</td>
</tr>
<tr>
<td style="text-align:center">StripPreﬁx</td>
<td style="text-align:center">对匹配上的请求路径去除前缀</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="52"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155639.png" alt="" loading="lazy"></figure>
<p>详细的说明在官网链接</p>
<p><strong>配置全局默认过滤器</strong><br>
这些自带的过滤器可以和使用 路由前缀 章节中的用法类似，也可以将这些过滤器配置成不只是针对某个路由；而是可以对所有路由生效，也就是配置默认过滤器：<br>
了解如下：</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      # 默认过滤器，对所有路由生效
       default-filters:
        # 响应头过滤器，对输出的响应设置其头部属性名称为X-Response-Default-MyName，值为itcast；
如果有多个参数多则重写一行设置不同的参数
        - AddResponseHeader=X-Response-Default-MyName, itcast
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/api/user/**
          filters:
            # 表示过滤1个路径，2表示两个路径，以此类推
            - StripPrefix=1
</code></pre>
<p>上述配置后，再访问 http://localhost:10010/api/user/8 的话；那么可以从其响应中查看到如下信息：</p>
<figure data-type="image" tabindex="53"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155843.png" alt="" loading="lazy"></figure>
<p><strong>过滤器类型</strong>：Gateway实现方式上，有两种过滤器；</p>
<ol>
<li><strong>局部</strong>过滤器：通过spring.cloud.gateway.routes.filters 配置在具体路由下，只作用在当前路由上；自带的过滤器都可以配置或者自定义按照自带过滤器的方式。如果配置spring.cloud.gateway.default-filters 上会对所有路由生效也算是全局的过滤器；但是这些过滤器的实现上都是要实现GatewayFilterFactory接口。</li>
<li><strong>全局</strong>过滤器：不需要在配置文件中配置，作用在所有的路由上；实现 GlobalFilter 接口即可。</li>
</ol>
<h4 id="972-执行生命周期">9.7.2 执行生命周期</h4>
<p>Spring Cloud Gateway 的 Filter 的生命周期也类似Spring MVC的拦截器有两个：“pre” 和 “post”。“pre”和 “post” 分别会在请求被执行前调用和被执行后调用。</p>
<figure data-type="image" tabindex="54"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155949.png" alt="" loading="lazy"></figure>
<p>这里的 pre 和 post 可以通过过滤器的GatewayFilterChain 执行ﬁlter方法前后来实现。</p>
<h4 id="973-使用场景">9.7.3 使用场景</h4>
<p>常见的应用场景如下：</p>
<ul>
<li>请求鉴权：一般GatewayFilterChain 执行ﬁlter方法前，如果发现没有访问权限，直接就返回空。</li>
<li>异常处理：一般GatewayFilterChain 执行ﬁlter方法后，记录异常并返回。</li>
<li>服务调用时长统计：GatewayFilterChain 执行ﬁlter方法前后根据时间统计。</li>
</ul>
<h3 id="98-自定义过滤器">9.8 自定义过滤器</h3>
<h4 id="981-自定义局部过滤器">9.8.1 自定义局部过滤器</h4>
<p>需求：在application.yml中对某个路由配置过滤器，该过滤器可以在控制台输出配置文件中指定名称的请求参数的值。</p>
<p><strong>1）编写过滤器</strong><br>
在heima-gateway工程编写过滤器工厂类MyParamGatewayFilterFactory</p>
<pre><code class="language-java">package com.itheima.gateway.filter;

import org.springframework.cloud.gateway.filter.GatewayFilter;
import org.springframework.cloud.gateway.filter.factory.AbstractGatewayFilterFactory;
import org.springframework.http.server.reactive.ServerHttpRequest;
import org.springframework.stereotype.Component;

import java.util.Arrays;
import java.util.List;

@Component
public class MyParamGatewayFilterFactory extends 
AbstractGatewayFilterFactory&lt;MyParamGatewayFilterFactory.Config&gt; {

    public static final String PARAM_NAME = &quot;param&quot;;

    public MyParamGatewayFilterFactory() {
        super(Config.class);
    }

    @Override
    public List&lt;String&gt; shortcutFieldOrder() {
        return Arrays.asList(PARAM_NAME);
    }

    @Override
    public GatewayFilter apply(Config config) {
        return (exchange, chain) -&gt; {
            ServerHttpRequest request = exchange.getRequest();

            if (request.getQueryParams().containsKey(config.param)) {
                request.getQueryParams().get(config.param)
                        .forEach(value -&gt; System.out.printf(&quot;----------局部过滤器-----%s 
= %s-----&quot;,
                                config.param, value));
            }

            return chain.filter(exchange);
        };
    }

    public static class Config {
        private String param;

        public String getParam() {
            return param;
        }

        public void setParam(String param) {
            this.param = param;
        }
    }

}
</code></pre>
<p>2）修改配置文件<br>
在heima-gateway工程修改heima-gateway\src\main\resources\application.yml 配置文件</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/api/user/**
          filters:
            # 表示过滤1个路径，2表示两个路径，以此类推
            - StripPrefix=1
            # 自定义过滤器
            - MyParam=name
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>注意：自定义过滤器的命名应该为：***GatewayFilterFactory</p>
<p>测试访问：http://localhost:10010/api/user/8?name=itcast 检查后台是否输出name和itcast；但是若访问http://localhost:10010/api/user/8?name2=itcast 则是不会输出的。</p>
<h4 id="982-自定义全局过滤器">9.8.2 自定义全局过滤器</h4>
<p><strong>需求</strong>：模拟一个登录的校验。基本逻辑：如果请求中有token参数，则认为请求有效，放行。</p>
<p>在heima-gateway工程编写全局过滤器类MyGlobalFilter</p>
<pre><code class="language-java">package com.itheima.gateway.filter;

import org.apache.commons.lang.StringUtils;
import org.springframework.cloud.gateway.filter.GatewayFilterChain;
import org.springframework.cloud.gateway.filter.GlobalFilter;
import org.springframework.core.Ordered;
import org.springframework.http.HttpStatus;
import org.springframework.stereotype.Component;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Mono;

@Component
public class MyGlobalFilter implements GlobalFilter, Ordered {
    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        System.out.println(&quot;-----------------全局过滤器MyGlobalFilter-------------------
--&quot;);
        String token = exchange.getRequest().getQueryParams().getFirst(&quot;token&quot;);
        if (StringUtils.isBlank(token)) {
            exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED);
            return exchange.getResponse().setComplete();
        }
        return chain.filter(exchange);
    }

    @Override
    public int getOrder() {
        //值越小越先执行
        return 1;
    }
}
</code></pre>
<p>访问 http://localhost:10010/api/user/8</p>
<figure data-type="image" tabindex="55"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803170715.png" alt="" loading="lazy"></figure>
<p>访问 http://localhost:10010/api/user/8?token=abc</p>
<figure data-type="image" tabindex="56"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803170749.png" alt="" loading="lazy"></figure>
<h3 id="99-负载均衡和熔断了解">9.9 负载均衡和熔断（了解）</h3>
<p>Gateway中默认就已经集成了Ribbon负载均衡和Hystrix熔断机制。但是所有的超时策略都是走的默认值，比如熔断超时时间只有1S，很容易就触发了。因此建议手动进行配置：</p>
<pre><code class="language-yaml">hystrix:
  command:
    default:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 6000
ribbon:
  ConnectTimeout: 1000
  ReadTimeout: 2000
  MaxAutoRetries: 0
  MaxAutoRetriesNextServer: 0
</code></pre>
<h3 id="910-gateway跨域配置">9.10 Gateway跨域配置</h3>
<p>一般网关都是所有微服务的统一入口，必然在被调用的时候会出现跨域问题。<br>
<strong>跨域</strong>：在js请求访问中，如果访问的地址与当前服务器的域名、ip或者端口号不一致则称为跨域请求。若不解决则不能获取到对应地址的返回结果。<br>
如：从在http://localhost:9090中的js访问 http://localhost:9000的数据，因为端口不同，所以也是跨域请求。</p>
<p>在访问Spring Cloud Gateway网关服务器的时候，出现跨域问题的话；可以在网关服务器中通过配置解决，允许哪些服务是可以跨域请求的；具体配置如下：</p>
<pre><code class="language-yaml">spring:
  cloud:
    gateway:
      globalcors:
        corsConfigurations:
          '[/**]':
            #allowedOrigins: * # 这种写法或者下面的都可以，*表示全部
            allowedOrigins:
            - &quot;http://docs.spring.io&quot;
            allowedMethods:
            - GET
</code></pre>
<p>上述配置表示：可以允许来自 http://docs.spring.io 的get请求方式获取服务数据。<br>
allowedOrigins 指定允许访问的服务器地址，如：http://localhost:10000 也是可以的。<br>
'[/**]' 表示对所有访问到网关服务器的请求地址<br>
官网具体说明：https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.1.1.RELEASE/multi/multi__cors_conﬁguration.html</p>
<h3 id="911-gateway的高可用了解">9.11 Gateway的高可用（了解）</h3>
<p>启动多个Gateway服务，自动注册到Eureka，形成集群。如果是服务内部访问，访问Gateway，自动负载均衡，没问题。<br>
但是，Gateway更多是外部访问，PC端、移动端等。它们无法通过Eureka进行负载均衡，那么该怎么办？<br>
此时，可以使用其它的服务网关，来对Gateway进行代理。比如：Nginx</p>
<h3 id="912-gateway与feign的区别">9.12 Gateway与Feign的区别</h3>
<ul>
<li>Gateway 作为整个应用的流量入口，接收所有的请求，如PC、移动端等，并且将不同的请求转发至不同的处理微服务模块，其作用可视为nginx；大部分情况下用作权限鉴定、服务端流量控制</li>
<li>Feign 则是将当前微服务的部分服务接口暴露出来，并且主要用于各个微服务之间的服务调用</li>
</ul>
<h2 id="10-spring-cloud-config分布式配置中心">10、Spring Cloud Conﬁg分布式配置中心</h2>
<h3 id="101-简介">10.1 简介</h3>
<p>在分布式系统中，由于服务数量非常多，配置文件分散在不同的微服务项目中，管理不方便。为了方便配置文件集中管理，需要分布式配置中心组件。在Spring Cloud中，提供了Spring Cloud Conﬁg，它支持配置文件放在配置服务的本地，也支持放在远程Git仓库（GitHub、码云）。<br>
使用Spring Cloud Conﬁg配置中心后的架构如下图：</p>
<figure data-type="image" tabindex="57"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171244.png" alt="" loading="lazy"></figure>
<p>配置中心本质上也是一个微服务，同样需要注册到Eureka服务注册中心！</p>
<h3 id="102-git配置管理">10.2 Git配置管理</h3>
<ol>
<li>
<p><strong>远程Git仓库</strong></p>
<p>知名的Git远程仓库有国外的GitHub和国内的码云（gitee）；但是使用GitHub时，国内的用户经常遇到的问题是访问速度太慢，有时候还会出现无法连接的情况。如果希望体验更好一些，可以使用国内的Git托管服务——码云（gitee.com）。<br>
与GitHub相比，码云也提供免费的Git仓库。此外，还集成了代码质量检测、项目演示等功能。对于团队协作开发，码云还提供了项目管理、代码托管、文档管理的服务。本章中使用的远程Git仓库是码云。<br>
码云访问地址：https://gitee.com/</p>
</li>
<li>
<p><strong>创建远程仓库</strong></p>
<p>首先要使用码云上的私有远程git仓库需要先注册帐号；请先自行访问网站并注册帐号，然后使用帐号登录码云控制台并创建公开仓库。</p>
</li>
<li>
<p><strong>创建配置文件</strong></p>
<p>在新建的仓库中创建需要被统一配置管理的配置文件。<br>
配置文件的命名方式：{application}-{proﬁle}.yml 或 {application}-{proﬁle}.properties<br>
application为应用名称<br>
proﬁle用于区分开发环境，测试环境、生产环境等<br>
如user-dev.yml，表示用户微服务开发环境下使用的配置文件。<br>
这里将user-service工程的配置文件application.yml文件的内容复制作为user-dev.yml文件的内容，具体配置如下：</p>
<figure data-type="image" tabindex="58"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171438.png" alt="" loading="lazy"></figure>
<p>创建 user-dev.yml ；内容来自 user-service\src\main\resources\application.yml （方便后面测试user-service项目的配置），可以如下：</p>
<pre><code class="language-yaml">server:
  port: ${port:9091}
spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/springcloud
    username: root
    password: root
  application:
    #应用名
    name: user-service
mybatis:
  type-aliases-package: com.itheima.user.pojo
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
  	ip-address: 127.0.0.1
    	prefer-ip-address: true
    	lease-expiration-duration-in-seconds: 90
    	lease-renewal-interval-in-seconds: 30
</code></pre>
<figure data-type="image" tabindex="59"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171549.png" alt="" loading="lazy"></figure>
<p>创建完user-dev.yml配置文件之后，gitee中的仓库如下：</p>
<figure data-type="image" tabindex="60"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171601.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="103-搭建配置中心微服务">10.3 搭建配置中心微服务</h3>
<ol>
<li>
<p><strong>创建工程</strong></p>
<p>创建配置中心微服务工程 config-server：</p>
<p>添加依赖，修改config-server\pom.xml 如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;heima-springcloud&lt;/artifactId&gt;
        &lt;groupId&gt;com.itheima&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.itheima&lt;/groupId&gt;
    &lt;artifactId&gt;config-server&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>
</li>
<li>
<p><strong>启动类</strong></p>
<p>创建配置中心工程config-server 的启动类；<br>
config-server\src\main\java\com\itheima\config\ConfigServerApplication.java 如下：</p>
<pre><code class="language-java">package com.itheima.config;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.config.server.EnableConfigServer;

@SpringBootApplication
@EnableConfigServer
public class ConfigServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConfigServerApplication.class, args);
    }
}
</code></pre>
</li>
<li>
<p><strong>配置文件</strong><br>
创建配置中心工程config-server 的配置文件；<br>
config-server\src\main\resources\application.yml 如下：</p>
<pre><code class="language-yaml">server:
  port: 12000
spring:
  application:
    name: config-server
  cloud:
    config:
      server:
        git:
          uri: https://gitee.com/liaojianbin/heima-config.git
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
<p>注意上述的 spring.cloud.conﬁg.server.git.uri 则是在码云创建的仓库地址；可修改为自己创建的仓库地址</p>
</li>
<li>
<p><strong>启动测试</strong><br>
启动eureka注册中心和配置中心；然后访问http://localhost:12000/user-dev.yml ，查看能否输出在码云存储管理的user-dev.yml文件。并且可以在gitee上修改user-dev.yml然后刷新上述测试地址也能及时到最新数据。</p>
</li>
</ol>
<figure data-type="image" tabindex="61"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171928.png" alt="" loading="lazy"></figure>
<h3 id="104-获取配置中心配置">10.4 获取配置中心配置</h3>
<p>前面已经完成了配置中心微服务的搭建，下面我们就需要改造一下用户微服务user-service ，配置文件信息不再由微服务项目提供，而是从配置中心获取。如下对user-service 工程进行改造。</p>
<ol>
<li>
<p><strong>添加依赖</strong></p>
<p>在user-service 工程中的pom.xml文件中添加如下依赖：</p>
<pre><code class="language-xml">		&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;
            &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
</li>
<li>
<p><strong>修改配置</strong></p>
<ol>
<li>删除user-service 工程的user-service\src\main\resources\application.yml 文件（因为该文件从配置中心获取）</li>
<li>创建user-service 工程user-service\src\main\resources\bootstrap.yml 配置文件</li>
</ol>
<pre><code class="language-yaml">spring:
  cloud:
    config:
      # 与远程仓库中的配置文件的application保持一致
      name: user
      # 远程仓库中的配置文件的profile保持一致
      profile: dev
      # 远程仓库中的版本保持一致
      label: master
      discovery:
        # 使用配置中心
        enabled: true
        # 配置中心服务id
        service-id: config-server
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
<p>bootstrap.yml文件也是Spring Boot的默认配置文件，而且其加载的时间相比于application.yml更早。<br>
application.yml和bootstrap.yml虽然都是Spring Boot的默认配置文件，但是定位却不相同。bootstrap.yml可以理解成系统级别的一些参数配置，这些参数一般是不会变动的。application.yml 可以用来定义应用级别的参数，如果搭配 spring cloud conﬁg 使用，application.yml 里面定义的文件可以实现动态替换。</p>
<p>总结就是，bootstrap.yml文件相当于项目启动时的引导文件，内容相对固定。application.yml文件是微服务的一些常规配置参数，变化比较频繁。</p>
</li>
<li>
<p><strong>启动测试</strong><br>
启动注册中心eureka-server 、配置中心config-server 、用户服务user-service ，如果启动没有报错其实已经使用上配置中心内容，可以到注册中心查看，也可以检验user-service 的服务。</p>
<figure data-type="image" tabindex="62"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803172413.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h2 id="11-spring-cloud-bus服务总线">11、Spring Cloud Bus服务总线</h2>
<h3 id="111-问题">11.1 问题</h3>
<p>前面已经完成了将微服务中的配置文件集中存储在远程Git仓库，并且通过配置中心微服务从Git仓库拉取配置文件，当用户微服务启动时会连接配置中心获取配置信息从而启动用户微服务。<br>
如果我们更新Git仓库中的配置文件，那用户微服务是否可以及时接收到新的配置信息并更新呢？</p>
<ol>
<li>
<p><strong>修改远程Git配置</strong><br>
修改在码云上的user-dev.yml文件，添加一个属性test.name。</p>
<figure data-type="image" tabindex="63"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803172557.png" alt="" loading="lazy"></figure>
</li>
<li>
<p><strong>修改UserController</strong><br>
修改user-service 工程中的处理器类；<br>
user-service\src\main\java\com\itheima\user\controller\UserController.java 如下：</p>
<pre><code class="language-java">package com.itheima.user.controller;

import com.itheima.user.pojo.User;
import com.itheima.user.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping(&quot;/user&quot;)
public class UserController {
        @Autowired
    private UserService userService;

    @Value(&quot;${test.name}&quot;)
    private String name;

    @GetMapping(&quot;/{id}&quot;)
    public User queryById(@PathVariable Long id){
        System.out.println(&quot;配置文件中的test.name = &quot; + name);
        return userService.queryById(id);
    }
}
</code></pre>
</li>
<li>
<p><strong>测试</strong><br>
依次启动注册中心eureka-server 、配置中心config-server 、用户服务user-service ；然后修改Git仓库中的配置信息，访问用户微服务，查看输出内容。</p>
<p>**结论：**通过查看用户微服务控制台的输出结果可以发现，我们对于Git仓库中配置文件的修改并没有及时更新到用户微服务，只有重启用户微服务才能生效。<br>
如果想在不重启微服务的情况下更新配置该如何实现呢? <strong>可以使用Spring Cloud Bus来实现配置的自动更新。</strong></p>
<p>需要注意的是Spring Cloud Bus底层是基于RabbitMQ实现的，默认使用本地的消息队列服务，所以需要提前启动本地RabbitMQ服务（安装RabbitMQ以后才有），如下：</p>
<figure data-type="image" tabindex="64"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803172726.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="112-spring-cloud-bus简介">11.2 Spring Cloud Bus简介</h3>
<p>Spring Cloud Bus是用轻量的消息代理将分布式的节点连接起来，可以用于广播配置文件的更改或者服务的监控管理。也就是消息总线可以为微服务做监控，也可以实现应用程序之间相互通信。 Spring Cloud Bus可选的消息代理<br>
有RabbitMQ和Kafka。</p>
<p>使用了Bus之后：</p>
<figure data-type="image" tabindex="65"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803172800.png" alt="" loading="lazy"></figure>
<h3 id="113-改造配置中心">11.3 改造配置中心</h3>
<ol>
<li>
<p>在config-server 项目的pom.xml文件中加入Spring Cloud Bus相关依赖</p>
<pre><code class="language-xml">        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
</li>
<li>
<p>在config-server 项目修改application.yml文件如下：</p>
<pre><code class="language-yaml">server:
  port: 12000
spring:
  application:
    name: config-server
  cloud:
    config:
      server:
        git:
          uri: https://gitee.com/liaojianbin/heima-config.git
  # rabbitmq的配置信息；如下配置的rabbit都是默认值，其实可以完全不配置
  rabbitmq:
    host: localhost
    port: 5672
    username: guest
    password: guest
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
management:
  endpoints:
    web:
      exposure:
        # 暴露触发消息总线的地址
        include: bus-refresh
</code></pre>
</li>
</ol>
<h3 id="114-改造用户服务">11.4  改造用户服务</h3>
<ol>
<li>
<p>在用户微服务user-service 项目的pom.xml中加入Spring Cloud Bus相关依赖</p>
<pre><code class="language-xml">        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
</li>
<li>
<p>修改user-service 项目的bootstrap.yml如下：</p>
<pre><code class="language-yaml">spring:
  cloud:
    config:
      # 与远程仓库中的配置文件的application保持一致
      name: user
      # 远程仓库中的配置文件的profile保持一致
      profile: dev
      # 远程仓库中的版本保持一致
      label: master
      discovery:
        # 使用配置中心
        enabled: true
        # 配置中心服务id
        service-id: config-server
  # rabbitmq的配置信息；如下配置的rabbit都是默认值，其实可以完全不配置
  rabbitmq:
    host: localhost
    port: 5672
    username: guest
    password: guest
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
</li>
<li>
<p>改造用户微服务user-service 项目的UserController</p>
<figure data-type="image" tabindex="66"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803173237.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="115-测试">11.5 测试</h3>
<p>前面已经完成了配置中心微服务和用户微服务的改造，下面来测试一下，当我们修改了Git仓库中的配置文件，用户微服务是否能够在不重启的情况下自动更新配置信息。<br>
<strong>测试步骤：</strong><br>
第一步：依次启动注册中心eureka-server 、配置中心config-server 、用户服务user-service<br>
第二步：访问用户微服务http://localhost:9091/user/8；查看IDEA控制台输出结果</p>
<p>第三步：修改Git仓库中配置文件user-dev.yml 的test.name 内容<br>
第四步：使用Postman或者RESTClient工具发送POST方式请求访问地址http://127.0.0.1:12000/actuator/bus-refresh</p>
<figure data-type="image" tabindex="67"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803173322.png" alt="" loading="lazy"></figure>
<p>第五步：访问用户微服务系统控制台查看输出结果</p>
<p>说明：<br>
1、Postman或者RESTClient是一个可以模拟浏览器发送各种请求（POST、GET、PUT、DELETE等）的工具<br>
2、请求地址http://127.0.0.1:12000/actuator/bus-refresh中 /actuator是固定的，/bus-refresh对应的是配置中心conﬁg-server中的application.yml文件的配置项include的内容<br>
3、请求http://127.0.0.1:12000/actuator/bus-refresh地址的作用是访问配置中心的消息总线服务，消息总线服务接收到请求后会向消息队列中发送消息，各个微服务会监听消息队列。当微服务接收到队列中的消息后，会重新从配置中心获取最新的配置信息。</p>
<h3 id="116-spring-cloud-体系技术综合应用概览">11.6 Spring Cloud 体系技术综合应用概览</h3>
<figure data-type="image" tabindex="68"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803173833.png" alt="" loading="lazy"></figure>
<h2 id="12-思维导图">12、思维导图</h2>
<figure data-type="image" tabindex="69"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803174547.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Session]]></title>
        <id>https://jonchan1013.github.io/post/spring-session/</id>
        <link href="https://jonchan1013.github.io/post/spring-session/">
        </link>
        <updated>2020-07-24T02:12:46.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724102425.png" alt="" loading="lazy"></figure>
<h2 id="1-httpsession-回顾">1、HttpSession 回顾</h2>
<h3 id="11-什么是-httpsession">1.1  什么是 HttpSession</h3>
<p>是JavaWeb 服务端提供的用来建立与客户端会话状态的对象。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724102425.png" alt="" loading="lazy"></figure>
<h2 id="1-httpsession-回顾">1、HttpSession 回顾</h2>
<h3 id="11-什么是-httpsession">1.1  什么是 HttpSession</h3>
<p>是JavaWeb 服务端提供的用来建立与客户端会话状态的对象。</p>
<!-- more -->
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Logstash_Kibana]]></title>
        <id>https://jonchan1013.github.io/post/logstash_kibana/</id>
        <link href="https://jonchan1013.github.io/post/logstash_kibana/">
        </link>
        <updated>2020-07-22T19:02:44.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200723030527.png" alt="" loading="lazy"></figure>
<h2 id="1-logstash-简介">1、LogStash 简介</h2>
<h3 id="11-什么是logstash">1.1 什么是LogStash</h3>
<p>官方文字说明：Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。<br>
通俗说明：Logstash 是一款强大的数据处理工具，常用作日志处理。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200723030527.png" alt="" loading="lazy"></figure>
<h2 id="1-logstash-简介">1、LogStash 简介</h2>
<h3 id="11-什么是logstash">1.1 什么是LogStash</h3>
<p>官方文字说明：Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。<br>
通俗说明：Logstash 是一款强大的数据处理工具，常用作日志处理。</p>
<!-- more -->
<p><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200723030716.png" alt="" loading="lazy"><br>
到目前为止，Logstash 已经有超过 200 个可用的插件，以及创建和贡献自己的灵活性。社区生态非常完善，对于我们可以放心的使用。</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724091204.png" alt="" loading="lazy"></figure>
<h3 id="12-为什么使用logstash">1.2 为什么使用Logstash</h3>
<p>通常当系统发生故障时，工程师需要登录到各个服务器上，使用 grep / sed / awk 等Linux 脚本工具去日志里查找故障原因。在没有日志系统的情况下，首先需要定位处理请求的服务器，如果这台服务器部署了多个实例，则需要去每个应用实例的日志目录下去找日志文件。每个应用实例还会设置日志滚动策略（如：每天生成一个文件），还有日志压缩归档策略等。</p>
<p>这样一系列流程下来，对于我们排查故障以及及时找到故障原因，造成了比较大的麻烦。因此，如果我们能***把这些日志集中管理***，并提供集中检索功能，不仅可以提高诊断的效率，同时对系统情况有个全面的理解，避免事后救火的被动。<br>
所以日志集中管理功能就可以使用 ELK 技术栈进行实现。Elasticsearch 只有数据存储和分析的能力，Kibana 就是可视化管理平台。还缺少数据收集和整理的角色，这个功能就是Logstash 负责的。</p>
<h3 id="13-logstash-工作原理">1.3  Logstash 工作原理</h3>
<h4 id="131-data-source">1.3.1 Data Source</h4>
<p>Logstash 支持的数据源有很多。例如对于日志功能来说只能能有日志记录和日志传递功能的日志都支持，Spring Boot 中默认推荐 logback 支持日志输出功能（输出到数据库、数据出到文件）。<br>
我们就使用 logback 进行日志输出给 Logstash。</p>
<h4 id="132-logstash-pipeline">1.3.2 Logstash Pipeline</h4>
<p>整个整体就是 Logstash 的功能。<br>
在 Logstash 中包含非常重要的三个功能：<br>
a) Input<br>
输入源，一般配置为自己监听的主机及端口。DataSource 向指定的 ip 及端口输出日志，Input 输入源监听到数据信息就可以进行收集。<br>
b) Filter<br>
过滤功能，对收集到的信息进行过滤（额外处理），也可以省略这个配置（不做处理）<br>
c) Output<br>
把收集到的信息发送给谁。在 ELK 技术栈中都是输出给 Elasticsearch，后面数据检索和数据分析的过程就给 Elasticsearch 了。</p>
<p><strong>最终效果：通过整体步骤就可以把原来一行日志信息转换为 Elasticsearch 支持的Document 形式（键值对形式）的数据进行存储。</strong></p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724091938.png" alt="" loading="lazy"></figure>
<h2 id="2-安装logstash">2、安装Logstash</h2>
<p>前面已经安装好了 Elasticsearch 和 Kibana。下面是安装 Logstash 的步骤<br>
Logstash 是不需要必须和 Elasticsearch 安装到一起，如果独立安装到一台服务器，需要在服务器中先配置好 JDK 环境变量。在课堂中把 ELK 三个软件都装到一台服务器中。</p>
<h3 id="21-安装logstash">2.1 安装Logstash</h3>
<ol>
<li>
<p>上传 Logstash 并解压</p>
<p>上传压缩包到/usr/local/tmp 中后，解压压缩包。</p>
<p>tar zxf logstash-6.8.4.tar.gz</p>
<p>剪切到/usr/local 中并命名为 logstash</p>
<p>mv logstash-6.8.4 ../logstash</p>
</li>
<li>
<p>进入到 logstash 配置文件夹中</p>
<p>cd /usr/local/logstash/config/</p>
<p>创建配置文件，名称自定义。</p>
<p>vim mylogstash.conf</p>
<p>配置解释说明：<br>
input:接收日志输入配置<br>
tcp: 协议<br>
mode: logstash 服务<br>
host:logstash 主机 ip<br>
port：端口，自己指定。默认 4560<br>
output：日志处理输出<br>
elasticsearch: 交给 es 处理<br>
action：es 中 index 命令。也就是新增命令。<br>
hosts：es 的主机<br>
index:存储日志的索引。如果不存在可以自动创建。默认的 type 名称为 doc<br>
一定要先启动编辑状态（点击键盘i 键）在粘贴，如果没启用第一行是nput{少个i。</p>
<pre><code class="language-xml">input {
		tcp {
			mode =&gt; &quot;server&quot;
			host =&gt; &quot;192.168.8.140&quot;
			port =&gt; 4560
		}
}
filter {
}
output {
		elasticsearch {
			action =&gt; &quot;index&quot;
			hosts =&gt; &quot;192.168.8.140:9200&quot;
			index =&gt; &quot;test_log&quot;
		}
}
</code></pre>
</li>
<li>
<p>启动 Logstash<br>
进入到 bin 目录</p>
<p>cd /usr/local/logstash/bin</p>
<p>需要先启动 Elasticsearch 否则会频繁提示无法连接到 Elasticsearch</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724092726.png" alt="" loading="lazy"></figure>
<p>启动 logstash</p>
<p>./logstash -f /usr/local/logstash/config/mylogstash.conf</p>
<p>如果启动完成没有出异常，提示 Successfully 说明安装成功。</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724092738.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h2 id="3-使用logback-向logstash-中输出日志">3、使用Logback 向Logstash 中输出日志</h2>
<p>需求：随意新建一个项目把输出到控制台的日志信息也输出到 Logstash 中。</p>
<ol>
<li>
<p>修改pom.xml<br>
logstash-logback-encoder 就是转码后向 logstash 中输入的依赖。<br>
注意：</p>
<p>如果导入的是 6.x 版本不会在控制台看见任何额外日志信息。<br>
如果导入的是 5.x 版本会在控制台看见 logback.xml 加载的信息。</p>
<pre><code class="language-xml">&lt;parent&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
	&lt;version&gt;2.2.6.RELEASE&lt;/version&gt;
&lt;/parent&gt;
&lt;dependencies&gt;
	&lt;dependency&gt;
		&lt;groupId&gt;net.logstash.logback&lt;/groupId&gt;
		&lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;
		&lt;version&gt;6.3&lt;/version&gt;
	&lt;/dependency&gt;
	&lt;dependency&gt;
		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
		&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
	&lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
</li>
<li>
<p>导入logback.xml<br>
将logback.xml文件粘贴到 resources 中。</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724093405.png" alt="" loading="lazy"></figure>
<p>logback.xml 文件内容如下，红色部分表示向 logstash 中输出日志信息。<br>
红色中<destination>配置的是 logstash 配置文件中 input 里面 host 和 post 的信息。</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!--该日志将日志级别不同的 log 信息保存到不同的文件中 --&gt;
&lt;configuration&gt;
    &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot;&gt;&lt;/include&gt;
    &lt;springProperty scope=&quot;context&quot; name=&quot;egoSearchLogback&quot; source=&quot;spring.application.name&quot;/&gt;

    &lt;!-- 日志在工程中的输出位置 --&gt;
    &lt;property name=&quot;EGO-LOG-APPENDER&quot; value=&quot;%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}&quot;&gt;&lt;/property&gt;
    &lt;!-- 控制台的日志输出样式 --&gt;
    &lt;appender name=&quot;consoleAppender&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;
            &lt;level&gt;INFO&lt;/level&gt;
        &lt;/filter&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;${EGO-LOG-APPENDER}&lt;/pattern&gt;
            &lt;charset&gt;utf8&lt;/charset&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;
    &lt;!-- logstash 输出 --&gt;
    &lt;appender name=&quot;logstashAppender&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt;
        &lt;destination&gt;192.168.89.141:5044&lt;/destination&gt;
        &lt;!-- 日志输出编码 --&gt;
        &lt;encoder charset=&quot;UTF-8&quot; class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot;&gt;&lt;/encoder&gt;
    &lt;/appender&gt;
    &lt;!-- logstash 远程日志配置--&gt;
&lt;appender name=&quot;logstash&quot;
class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt;
&lt;destination&gt;192.168.8.140:4560&lt;/destination&gt;
&lt;encoder charset=&quot;UTF-8&quot;
class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot; /&gt;
&lt;/appender&gt;
    &lt;root level=&quot;DEBUG&quot;&gt;
        &lt;appender-ref ref=&quot;consoleAppender&quot;/&gt;
        &lt;appender-ref ref=&quot;logstashAppender&quot;/&gt;
    &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>
</li>
<li>
<p>新建启动类</p>
</li>
</ol>
<p>新建 com.cy.DemoApplication</p>
<pre><code class="language-java">@SpringBootApplication
public class DemoApplication {
	public static void main(String[] args) {
		SpringApplication.run(DemoApplication.class,args);
	}
}
</code></pre>
<h2 id="4-在kibana-中查看日志信息">4、在Kibana 中查看日志信息</h2>
<h3 id="41-使用命令方式查看">4.1 使用命令方式查看</h3>
<p>可以直接在 Dev Tools 中输入命令查看日志信息。<br>
输入： GET test_log/_search 查看全部。</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094359.png" alt="" loading="lazy"></figure>
<h3 id="42-是kibana-界面查看">4.2  是Kibana 界面查看</h3>
<p>进入到 Kibana 后按图所示点击。创建索引表达式</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094419.png" alt="" loading="lazy"></figure>
<p>选择没有时间过滤后，点击“Create index pattern”按钮</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094434.png" alt="" loading="lazy"></figure>
<p>点击菜单中 Discover，选择右侧 test_log</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094507.png" alt="" loading="lazy"></figure>
<p>每条日志在 Elasticsearch 中存储形式</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094920.png" alt="" loading="lazy"></figure>
<p>IDEA 中控制台打印的原日志内容是下面内容。Logstash 作用就是把下面内容转换为上面Elasticsearch 存储的内容。在中间做了数据格式转换，收集数据放入 Elasticsearch 中的工作。</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094935.png" alt="" loading="lazy"></figure>
<h2 id="5-搭建日志系统">5、搭建日志系统</h2>
<p>绝大多数项目在后台管理中都有日志管理。以前的日志信息是存储在 MySQL 中，日志随着项目运行时间会越来越多，一直存储在 MySQL 会导致查询降低。现在的日志信息通过ELK 技术栈进行操作。存储在 Elasticsearch 中，可以更好的分析日志内容及更快查询效率。</p>
<p>给定简单需求：<br>
搭建日志系统，提供查询 Elasticsearch 中日志信息的接口。</p>
<ol>
<li>
<p>新建项目<br>
名称为 ELK_Demo</p>
</li>
<li>
<p>修改pom.xml<br>
搭建最基本的环境，实现需求，没有考虑 Spring Cloud 相关环境，如果考虑 Spring Cloud还需要配置 Eureka 等信息。</p>
</li>
</ol>
<pre><code class="language-xml">&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
            &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;

&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<ol start="3">
<li>
<p>创建配置文件<br>
在 resources 下新建 application.yml 配置文件。<br>
配置 Elasticsearch 相关配置信息。</p>
<pre><code class="language-yaml">elasticsearch:
  rest:  # 配置ElasticsearchRestTemplate客户端的属性，是现在推荐使用的。
    uris:
      - http://192.168.89.140:9200
      - http://192.168.89.141:9200
</code></pre>
</li>
<li>
<p>新建实体<br>
根据 kibana 中查看到日志信息可以得出看出，除了 message 是类类型，里面包含一些其他属性外，其他的属性都是简单类型属性。</p>
</li>
</ol>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724095948.png" alt="" loading="lazy"></figure>
<p>新建 com.cy.pojo.Log。</p>
<p>注意@version 和@timestamp 要使用@JsonProperty 进行接收。</p>
<pre><code class="language-java">@Data
@Document(indexName = &quot;test_log&quot;,type = &quot;doc&quot;)
public class Log {
	@Id
	private String id;
	@Field(type= FieldType.Text)
	private String host;
	@Field(type= FieldType.Text)
	private String message;
	@Field(type= FieldType.Long)
	private Long port;
	@Field(type = FieldType.Date)
	@JsonProperty(&quot;@timestamp&quot;)
	private Date timestamp;
	@Field(type = FieldType.Text)
	@JsonProperty(&quot;@version&quot;)
	private String version;
}
</code></pre>
<ol start="5">
<li>
<p>新建service 及实现类</p>
<p>新建 com.cy.service.LogService 及实现类</p>
<pre><code class="language-java">public interface LogService {
    List&lt;Log&gt; selectByPage(int page,int size);
}

------------------------------------------------
    @Service
public class LogServiceImpl implements LogService {
	@Autowired
	private ElasticsearchTemplate elasticsearchTemplate;
	@Override
	public List&lt;Log&gt; selectByPage(int page, int size) {
		SearchQuery sq = new NativeSearchQuery(QueryBuilders.matchAllQuery());
		sq.setPageable(PageRequest.of(page-1,size));
		return elasticsearchTemplate.queryForList(sq,Log.class);
	}
}
</code></pre>
</li>
<li>
<p>新建控制器</p>
</li>
</ol>
<p>新建 com.cy.controller.LogController</p>
<pre><code class="language-java">@Controller
public class LogController {
	@Autowired
	private LogService logService;
	@RequestMapping(&quot;/page&quot;)
	@ResponseBody
	public List&lt;Log&gt; showPage(int page,int size){
		return logService.selectByPage(page,size);
	}
}
</code></pre>
<ol start="7">
<li>
<p>测试结果</p>
<p>在浏览器输入: http://localhost:8080/page?page=1&amp;size=2</p>
<p>会看见下面的结果。</p>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724100358.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h2 id="6-logstashmysqlelasticsearch-实现数据增量导入双写一致">6、LogStash+MySQL+Elasticsearch 实现数据增量导入（双写一致）</h2>
<p>原有系统中，如果使用了缓存应用，全文搜索服务等额外数据存储，则在代码实现中，要保证双写一致，即写数据库的同时，把数据的变量同步到其他存储中。<br>
如果使用 LogStash，则可以实现数据的增量导入。<br>
思路：写数据到数据库，LogStash 监听数据库中数据的变化，把增量数据读取，并保存到 ES 中。</p>
<h3 id="61-环境准备">6.1 环境准备</h3>
<ol>
<li>
<p>上传数据库驱动<br>
LogStash 本身不提供数据库驱动，需要使用者提供数据库的驱动包，且 LogStash 中的数据库 JDBC 插件就是 Java 开发的。需要上传数据库驱动到 LogStash 所在主机。<br>
Logstash5.x &amp; 6.3.*以下版本，上传驱动不需要固定位置，任意位置即可。<br>
Logstash6.8.4 版本的上传位置固定是：$LogStash_HOME/logstash_core/lib/jars/</p>
</li>
<li>
<p>准备数据库表格<br>
案例中使用电商项目中的商品表格，建表语句如下：</p>
<pre><code class="language-mysql">CREATE TABLE `tb_item` (
`id` bigint(20) NOT NULL COMMENT '商品 id，同时也是商品编号',
`title` varchar(100) NOT NULL COMMENT '商品标题',
`sell_point` varchar(500) DEFAULT NULL COMMENT '商品卖点',
`price` bigint(20) NOT NULL COMMENT '商品价格，单位为：分',
   `num` int(10) NOT NULL COMMENT '库存数量',
`barcode` varchar(30) DEFAULT NULL COMMENT '商品条形码',
`image` varchar(500) DEFAULT NULL COMMENT '商品图片',
`cid` bigint(10) NOT NULL COMMENT '所属类目，叶子类目',
`status` tinyint(4) NOT NULL DEFAULT '1' COMMENT '商品状态，1-正常，2-下架，3-删除',
`created` datetime NOT NULL COMMENT '创建时间',
`updated` datetime NOT NULL COMMENT '更新时间',
PRIMARY KEY (`id`),
KEY `cid` (`cid`),
KEY `status` (`status`),
KEY `updated` (`updated`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='商品表'; 
</code></pre>
<p>LogStash 实现增量导入，需要有一个定位字段，这个字段的数据，可以表示数据的新旧，代表这个数据是否是一个需要导入到 ES 中的数据。案例中使用表格的 updated 字段作为定位字段，每次读取数据的时候，都会记录一个最大的 updated 时间，每次读取数据的时候，都读取 updated 大于等于记录的定位字段数据。每次查询的就都是最新的，要导入到 ES 中的数据。</p>
</li>
</ol>
<h3 id="62-编写logstash-配置文件">6.2 编写LogStash 配置文件</h3>
<p>在$LogStash_home/config/目录中，编写配置文件 ego-items-db2es.conf<br>
vim config/ego-items-db2es.conf</p>
<pre><code class="language-xml">input {
  jdbc {
	# 连接地址
    jdbc_connection_string =&gt; &quot;jdbc:mysql://192.168.1.2:3306/ego?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=GMT%2B8&quot;
	
	# 数据库用户名和密码
    jdbc_user =&gt; &quot;root&quot;
    jdbc_password =&gt; &quot;root&quot;

	# 驱 动 类 ， 如 果 使 用 低 版 本 的 logstash ， 需 要 再 增 加 配 置jdbc_driver_library，配置驱动包所在位置
    jdbc_driver_class =&gt; &quot;com.mysql.cj.jdbc.Driver&quot;
	# 是否开启分页逻辑
    jdbc_paging_enabled =&gt; true
	# 分页的长度是多少
    jdbc_page_size =&gt; &quot;2000&quot;
	# 时区
    jdbc_default_timezone =&gt; &quot;Asia/Shanghai&quot;

	# 执行的 SQL
    statement =&gt; &quot;select id, title, sell_point, price, image, updated from tb_item where updated &gt;= :sql_last_value order by updated asc&quot;

	# 执行 SQL 的周期， [秒] 分钟 小时 天 月 年
    schedule =&gt; &quot;* * * * *&quot;
	# 是否使用字段的值作为比较策略
    use_column_value =&gt; true
	# 作为比较策略的字段名称
    tracking_column =&gt; &quot;updated&quot;
	# 作为比较策略的字段类型，可选为 numberic 和 timestamp
    tracking_column_type =&gt; &quot;timestamp&quot;
	# 记录最近的比较策略字段值的文件是什么，相对寻址路径是 logstash 的安装路径
    last_run_metadata_path =&gt; &quot;./ego-items-db2es-last-value&quot;
	# 是否每次执行 SQL 的时候，都删除 last_run_metadata_path 文件内容
    clean_run =&gt; false
	# 是否强制把 ES 中的字段名都定义为小写。
    lowercase_column_names =&gt; false
  }
}

output {
  elasticsearch {
    hosts =&gt; [&quot;http://192.168.89.140:9200&quot;, &quot;http://192.168.89.141:9200&quot;]
    index =&gt; &quot;ego-items-index&quot;
    action =&gt; &quot;index&quot;
    document_id =&gt; &quot;%{id}&quot;
  }
}

</code></pre>
<h3 id="63-安装logstash-input-jdbc-插件">6.3  安装logstash-input-jdbc 插件</h3>
<p>在 LogStash6.3.x 和 5.x 版本中，logstash-input-jdbc 插件是默认安装的。在 6.8.4 版本的LogStash 中是未安装的，需要手工安装。安装命令如下：<br>
$Logstash_HOME/bin/logstash-plugin install logstash-input-jdbc</p>
<h3 id="64-启动测试">6.4 启动测试</h3>
<p>启动 LogStash 命令不变：<br>
bin/logstash -f 配置文件</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ElasticSearch]]></title>
        <id>https://jonchan1013.github.io/post/elasticsearch/</id>
        <link href="https://jonchan1013.github.io/post/elasticsearch/">
        </link>
        <updated>2020-07-18T17:38:47.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200719014000.png" alt="" loading="lazy"></figure>
<h2 id="1-什么是-elastic-search">1、什么是 Elastic Search</h2>
<p>ElasticSearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式的全文搜索引擎，其对外服务是基于 RESTful web 接口发布的。Elasticsearch 是用 Java 开发的应用，并作为 Apache 许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到近实时搜索，稳定，可靠，快速，安装使用方便。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200719014000.png" alt="" loading="lazy"></figure>
<h2 id="1-什么是-elastic-search">1、什么是 Elastic Search</h2>
<p>ElasticSearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式的全文搜索引擎，其对外服务是基于 RESTful web 接口发布的。Elasticsearch 是用 Java 开发的应用，并作为 Apache 许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到近实时搜索，稳定，可靠，快速，安装使用方便。</p>
<!-- more -->
<h3 id="11-相关概念">1.1 相关概念</h3>
<h4 id="111-cluster">1.1.1  cluster</h4>
<p>集群。ElasticSearch 集群由一或多个节点组成，其中有一个主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。ElasticSearch 的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部看 ElasticSearch集群，在逻辑上是个整体，你与集群中的任何一个节点通信和与整个 ElasticSearch 集群通信是等价的。也就是说，主节点的存在不会产生单点安全隐患、并发访问瓶颈等问题。</p>
<h4 id="112-shards">1.1.2 shards</h4>
<p>primary shard：代表索引的主分片，ElasticSearch 可以把一个完整的索引分成多个primary shard，这样的好处是可以把一个大的索引拆分成多个分片，分布存储在不同的ElasticSearch 节点上，从而形成分布式存储，并为搜索访问提供分布式服务，提高并发处理能。primary shard 的数量只能在索引创建时指定，并且索引创建后不能再更改 primaryshard 数量。</p>
<h4 id="113-replicas">1.1.3 replicas</h4>
<p>replica shard：代表索引主分片的副本，ElasticSearch 可以设置多个 replica shard。replica shard 的作用：一是提高系统的容错性，当某个节点某个 primary shard 损坏或丢失时可以从副本中恢复。二是提高 ElasticSearch 的查询效率，ElasticSearch 会自动对搜索请求进行负载均衡，将并发的搜索请求发送给合适的节点，增强并发处理能力。</p>
<h4 id="114-index">1.1.4  Index</h4>
<p>索引。相当于关系型数据库中的表。其中存储若干相似结构的 Document 数据。如：客户索引，订单索引，商品索引等。ElasticSearch 中的索引不像数据库表格一样有强制的数据结构约束，在理论上，可以存储任意结构的数据。但了为更好的为业务提供搜索数据支撑，还是要设计合适的索引体系来存储不同的数据。</p>
<h4 id="115-type">1.1.5 Type</h4>
<p>类型。每个索引中都必须有唯一的一个 Type，Type 是 Index 中的一个逻辑分类。ElasticSearch 中的数据 Document 是存储在索引下的 Type 中的。</p>
<p><em><strong>注 意 ： ElasticSearch5.x 及 更 低 版 本 中 ， 一 个 Index 中 可 以 有 多 个 Type 。ElasticSearch6.x 版本之后，type 概念被弱化，一个 index 中只能有唯一的一个 type。且在 7.x 版本之后，删除 type 定义。</strong></em></p>
<h4 id="116-document">1.1.6  Document</h4>
<p>文档。ElasticSearch 中的最小数据单元。一个 Document 就是一条数据，一般使用JSON 数据结构表示。每个 Index 下的 Type 中都可以存储多个 Document。一个 Document中可定义多个 field，field 就是数据字段。如：学生数据（{&quot;name&quot;:&quot;张三&quot;, &quot;age&quot;:20,&quot;gender&quot;:&quot;男&quot;}）。</p>
<h4 id="117-反向索引倒排索引">1.1.7 反向索引|倒排索引</h4>
<p>对数据进行分析，抽取出数据中的词条，以词条作为 key，对应数据的存储位置作为value，实现索引的存储。这种索引称为倒排索引。倒排索引是 Document 写入 ElasticSearch时分析维护的。</p>
<p>如：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">数据</th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">商品主键</td>
<td style="text-align:center">商品名</td>
<td style="text-align:center">商品描述</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">荣耀 10</td>
<td style="text-align:center">更贵的手机</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">荣耀 8</td>
<td style="text-align:center">相对便宜的手机</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">IPHONE X</td>
<td style="text-align:center">要卖肾买的手机</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200720091147.png" alt="" loading="lazy"></figure>
<h3 id="12-elasticsearch-常见使用场景">1.2 ElasticSearch 常见使用场景</h3>
<p>维基百科：全文检索，高亮显示，搜索推荐</p>
<p>The Guardian（国外的一个新闻网站），此平台可以对用户的行为（点击、浏览、收藏、评论）、社区网络数据（对新闻的评论等）进行数据分析，为新闻的发布者提供相关的公众反馈。</p>
<p>Stack Overflow（国外的程序异常讨论论坛）</p>
<p>Github（开源代码管理），在千亿级别的代码行中搜索信息</p>
<p>电子商务平台等。</p>
<h3 id="13-为什么不用数据库做搜索">1.3 为什么不用数据库做搜索？</h3>
<h4 id="131-查询语法复杂度高">1.3.1  查询语法复杂度高。</h4>
<p>如：电商系统中搜索商品数据 - select * from products where name like '%关键字%' and price bewteen xxx and yyy and ......。不同的用户提供的查询条件不同，需要提供的动态 SQL 过于复杂。</p>
<h4 id="132-关键字索引不全面搜索结果不符合要求">1.3.2 关键字索引不全面，搜索结果不符合要求</h4>
<p>如：电商系统中查询商品数据，条件为商品名包含'笔记本电脑'。那么对此关键字的分析结果为-笔记本、电脑、笔记等。对应的查询语法应该为 - select * from products where name like '%笔记本%' or name like '%电脑%' .......</p>
<h4 id="133-效率问题">1.3.3 效率问题</h4>
<p>数据量越大，查询反应效率越低。</p>
<h2 id="2-linux-安装-elasticsearch">2、Linux 安装 ElasticSearch</h2>
<p>使用的 ElasticSearch 的版本是 6.8.4。ElasticSearch6.x 要求 Linux 内核必须是 3.5+版本以上。</p>
<p>在 linux 操作系统中，查看内核版本的命令是： uname -a</p>
<p>课堂使用的 Linux 是 CentOS8。内核使用的是 4.4。</p>
<p>ElasticSearch6.X 版本要求 JDK 版本至少是 1.8.0_131。 提供 1.8.0_161JDK 安装包。</p>
<h3 id="21-为-elasticsearch-提供完善的系统配置">2.1  为 ElasticSearch 提供完善的系统配置</h3>
<p>ElasticSearch 在 Linux 中安装部署的时候，需要系统为其提供若干系统配置。如：应用可启动的线程数、应用可以在系统中划分的虚拟内存、应用可以最多创建多少文件等。</p>
<ol>
<li>
<p>修改限制信息<br>
vi /etc/security/limits.conf</p>
<p>是修改系统中允许应用最多创建多少文件等的限制权限。Linux 默认来说，一般限制应用最多创建的文件是 65535 个。但是 ElasticSearch 至少需要 65536 的文件创建权限。修改后的内容为：</p>
<p><code>* soft nofile 65536</code></p>
<p><code>* hard nofile 65536</code></p>
</li>
<li>
<p>修改线程开启限制<br>
在 CentOS6.5 版本中编辑下述的配置文件</p>
</li>
</ol>
<p>vi /etc/security/limits.d/90-nproc.conf</p>
<p>在 CentOS7+版本中编辑配置文件是：</p>
<p>vi /etc/security/limits.conf</p>
<p>是修改系统中允许用户启动的进程开启多少个线程。默认的 Linux 限制 root 用户开启的进程可以开启任意数量的线程，其他用户开启的进程可以开启 1024 个线程。必须修改限制数为 4096+。因为 ElasticSearch 至少需要 4096 的线程池预备。ElasticSearch 在 5.x版本之后，强制要求在 linux 中不能使用 root 用户启动 ElasticSearch 进程。所以必须使用其他用户启动 ElasticSearch 进程才可以。</p>
<p><code>* soft nproc 4096</code></p>
<p><code>root soft nproc unlimited</code></p>
<p>注意：Linux 低版本内核为线程分配的内存是 128K。4.x 版本的内核分配的内存更大。如果虚拟机的内存是 1G，最多只能开启 3000+个线程数。至少为虚拟机分配 1.5G 以上的内存。</p>
<ol start="3">
<li>
<p>修改系统控制权限<br>
CentOS6.5 中的配置文件为：</p>
<p>vi /etc/sysctl.conf</p>
<p>CentOS8 中的配置文件为：</p>
<p>vi /etc/sysctl.d/99-sysctl.conf</p>
<p>系统控制文件是管理系统中的各种资源控制的配置文件。ElasticSearch 需要开辟一个65536 字节以上空间的虚拟内存。Linux 默认不允许任何用户和应用直接开辟虚拟内存。</p>
<p>新增内容为：</p>
<p>vm.max_map_count=655360</p>
<p>使用命令： sysctl -p 。 让系统控制权限配置生效。</p>
</li>
</ol>
<h3 id="22-安装-elasticsearch">2.2 安装 ElasticSearch</h3>
<p>ElasticSearch 是 java 开发的应用。在 6.8.4 版本中，要求 JDK 至少是 1.8.0_131 版本以上。</p>
<p>ElasticSearch 的安装过程非常简单。解压立刻可以使用。</p>
<ol>
<li>
<p>解压缩安装压缩包<br>
tar -zxf elasticsearch-6.8.4.tar.gz</p>
</li>
<li>
<p>移动 ElasticSearch<br>
mv elasticsearch-6.8.4 /usr/local/elasticsearch/</p>
</li>
<li>
<p>修改 ElasticSearch 应用的所有者<br>
因为 ElasticSearch 不允许 root 用户启动，而课堂案例中，ElasticSearch 是 root 用户 解 压 缩 的 。 所 以 解 压 后 的 ElasticSearch 应 用 属 于 root 用 户 。 所 以 我 们 需 要 将ElasticSearch 应用的所有者修改为其他用户。</p>
</li>
</ol>
<p>chown -R user.user  /usr/local/elasticsearch</p>
<ol start="4">
<li>
<p>切换用户</p>
<p>su user</p>
</li>
<li>
<p>修改配置<br>
修改 config/elasticsearch 的配置文件，设置可访问的客户端。0.0.0.0 代表任意客户端访问。</p>
<p>vi config/elasticsearch.yml</p>
<p>增加下述内容：</p>
<p>network.host: 0.0.0.0</p>
</li>
<li>
<p>启动<br>
前台启动</p>
<p>/usr/local/elasticsearch/bin/elasticsearch</p>
<p>关闭： ctrl + c</p>
<p>后台启动</p>
<p>/usr/local/elasticsearch/bin/elasticsearch -d</p>
<p>关闭：</p>
<p>jps 命令查看 ElasticSearch 线程的编号</p>
<p>kill -9 ElasticSearch 线程编号</p>
</li>
<li>
<p>测试连接<br>
curl http://localhost:9200</p>
<p>返回如下结果：</p>
<p>{</p>
<p>&quot;name&quot; : &quot;L6WdN7y&quot;,</p>
<p>&quot;cluster_name&quot; : &quot;elasticsearch&quot;,</p>
<p>&quot;cluster_uuid&quot; : &quot;s7_GSd9YQnaH10VQBKCQ5w&quot;,</p>
<p>&quot;version&quot; : {</p>
<p>&quot;number&quot; : &quot;6.3.1&quot;,</p>
<p>&quot;build_flavor&quot; : &quot;default&quot;,</p>
<p>&quot;build_type&quot; : &quot;tar&quot;,</p>
<p>&quot;build_hash&quot; : &quot;eb782d0&quot;,</p>
<p>&quot;build_date&quot; : &quot;2019-06-29T21:59:26.107521Z&quot;,</p>
<p>&quot;build_snapshot&quot; : false,</p>
<p>&quot;lucene_version&quot; : &quot;7.3.1&quot;,****</p>
<p>&quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,</p>
<p>&quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;</p>
<p>},</p>
<p>&quot;tagline&quot; : &quot;You Know, for Search&quot;</p>
<p>}</p>
</li>
</ol>
<h3 id="23-搭建集群">2.3 搭建集群</h3>
<p>修改配置文件$elasticsearch_home/config/elasticsearch.yml</p>
<p>增加配置：</p>
<p>发现的节点 IP</p>
<p>discovery.zen.ping.unicast.hosts: [&quot;ip1&quot;, &quot;ip2&quot;]</p>
<p>最小集群数：常用计算公式 - 总数/2 + 1</p>
<p>discovery.zen.minimum_master_nodes: min_nodes_count</p>
<h3 id="24-安装-kibana">2.4 安装 Kibana</h3>
<p>Kibana 是一个基于 WEB 的 ElasticSearch 管理控制台。现阶段安装 Kibana 主要是为了方便学习。</p>
<p>在 Linux 中安装 Kibana 很方便。解压，启动即可。Kibana 要求的环境配置是小于ElasticSearch 的要求的。</p>
<p>tar -zxf kibana-6.3.1-linux-x86_64.tar.gz</p>
<p>修改 config/kibana.yml</p>
<p>vi config/kibana.yml</p>
<p>新增内容： server.host: &quot;0.0.0.0&quot;</p>
<p>bin/kibana</p>
<p>访问时，使用浏览器访问 http://192.168.2.119:5601/</p>
<h2 id="3-常用-elasticsearch-管理操作">3、常用 ElasticSearch 管理操作</h2>
<h3 id="31-查看健康状态">3.1 查看健康状态</h3>
<p>GET _cat/health?v</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721170056.png" alt="" loading="lazy"></figure>
<p>status：green、yellow、red</p>
<p>green：每个索引的 primary shard 和 replica shard 都是 active 的</p>
<p>yellow：每个索引的 primary shard 都是 active 的，但部分的 replica shard 不是 active的</p>
<p>red：不是所有的索引的 primary shard 都是 active 状态的。</p>
<h3 id="32-创建索引">3.2 创建索引</h3>
<p>命令语法：PUT 索引名{索引配置参数}</p>
<p>index 名称必须是小写的，且不能以下划线'_'，'-'，'+'开头。</p>
<p>在 ElasticSearch 中，默认的创建索引的时候，会分配 5 个 primary shard，并为每个primary shard 分配一个 replica shard（在 ES7 版本后，默认创建 1 个 primary shard）。在 ElasticSearch 中，默认的限制是：如果磁盘空间不足 15%的时候，不分配 replica shard。如果磁盘空间不足 5%的时候，不再分配任何的 primary shard。ElasticSearch 中对 shard的分布是有要求的。ElasticSearch 尽可能保证 primary shard 平均分布在多个节点上。Replica shard 会保证不和他备份的那个 primary shard 分配在同一个节点上。</p>
<p>创建默认索引</p>
<p>PUT test_index1</p>
<p>创建索引时指定分片。</p>
<pre><code class="language-properties">PUT test_index2
{
	&quot;settings&quot;:{
		&quot;number_of_shards&quot; : 2,
		&quot;number_of_replicas&quot; : 1
	}
}
</code></pre>
<h3 id="33-修改索引">3.3 修改索引</h3>
<p>命令语法：PUT 索引名/<em>settings{索引配置参数}<br>
<strong>注意：索引一旦创建，primary shard 数量不可变化，可以改变 replica shard 数量。</strong></em></p>
<pre><code class="language-properties">PUT test_index2/_settings
{
	&quot;number_of_replicas&quot; : 2
}
</code></pre>
<h3 id="34-删除索引">3.4  删除索引</h3>
<p>命令语法：DELETE 索引名 1[, 索引名 2 ...]</p>
<p>DELETE test_index1</p>
<h3 id="35-查看索引信息">3.5  查看索引信息</h3>
<p>GET _cat/indices?v</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721171902.png" alt="" loading="lazy"></figure>
<h3 id="36-检查分片信息">3.6 检查分片信息</h3>
<p>查看索引的 shard 信息。</p>
<p>GET _cat/shards?v</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721171928.png" alt="" loading="lazy"></figure>
<h3 id="37-新增-document">3.7 新增 Document</h3>
<p>在索引中增加文档。在 index 中增加 document。</p>
<p>ElasticSearch 有自动识别机制。如果增加的 document 对应的 index 不存在，自动创建 index；如果 index 存在，type 不存在，则自动创建 type。如果 index 和 type 都存在，则使用现有的 index 和 type。</p>
<h4 id="371-put-语法">3.7.1 PUT 语法</h4>
<p>此操作为手工指定 id 的 Document 新增方式。</p>
<p>语法：PUT 索引名/类型名/唯一 ID{字段名:字段值}</p>
<p>如：</p>
<pre><code class="language-properties">PUT test_index/my_type/1
{
	&quot;name&quot;:&quot;test_doc_01&quot;,
	&quot;remark&quot;:&quot;first test elastic search&quot;,
	&quot;order_no&quot;:1
}

PUT test_index/my_type/2
{
	&quot;name&quot;:&quot;test_doc_02&quot;,
	&quot;remark&quot;:&quot;second test elastic search&quot;,
	&quot;order_no&quot;:2
}

PUT test_index/my_type/3
{
	&quot;name&quot;:&quot;test_doc_03&quot;,
	&quot;remark&quot;:&quot;third test elastic search&quot;,
	&quot;order_no&quot;:3
}
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721172149.png" alt="" loading="lazy"></figure>
<p>如果使用 PUT 语法对同 id 的 Document 执行多次操作。是一种覆盖操作。如果需要ElasticSearch 辅助检查 PUT 的 Document 是否已存在，可以使用强制新增语法。使用强制新增语法时，如果 Document 的 id 在 ElasticSearch 中已存在，则会报错。（version conflict, document already exists）<br>
语法：</p>
<p>PUT 索引名/类型名/唯一 ID/_create{字段名:字段值}</p>
<p>或</p>
<p>PUT 索引名/类型名/唯一 ID?op_type=create{字段名:字段值}。</p>
<p>如：</p>
<pre><code class="language-properties">PUT test_index/my_type/1/_create
{
	&quot;name&quot;:&quot;new_test_doc_01&quot;,
	&quot;remark&quot;:&quot;first test elastic search&quot;,
	&quot;order_no&quot;:1
}
</code></pre>
<h4 id="372-post-语法">3.7.2 POST 语法</h4>
<p>此操作为 ElasticSearch 自动生成 id 的新增 Document 方式。此语法格式和 PUT 请求的数据新增，只有唯一的区别，就是可以自动生成主键 id，其他的和 PUT 请求新增数据完全一致。</p>
<p>语法：POST 索引名/类型名{字段名:字段值}</p>
<p>如：</p>
<pre><code class="language-properties">POST test_index/my_type
{
	&quot;name&quot;:&quot;test_doc_04&quot;,
	&quot;remark&quot;:&quot;forth test elastic search&quot;,
	&quot;order_no&quot;:4
}
</code></pre>
<h3 id="38-查询-document">3.8 查询 Document</h3>
<h4 id="381-get-id-单数据查询">3.8.1 GET ID 单数据查询</h4>
<p>语法：GET 索引名/类型名/唯一 ID</p>
<p>如：</p>
<p>GET test_index/my_type/1</p>
<p>结果：</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721172429.png" alt="" loading="lazy"></figure>
<h4 id="382-get-_mget-批量查询">3.8.2 GET _mget 批量查询</h4>
<p><em><strong>批量查询可以提高查询效率。推荐使用（相对于单数据查询来说）。</strong></em><br>
语法如下：</p>
<pre><code class="language-properties">GET _mget
{
	&quot;docs&quot; : [
	{
		&quot;_index&quot; : &quot;索引名&quot;,
		&quot;_type&quot; : &quot;类型名&quot;,
		&quot;_id&quot; : &quot;唯一 ID 值&quot;
	}, {}, {}
	]
}
</code></pre>
<pre><code class="language-properties">GET 索引名/_mget:
{
	&quot;docs&quot; : [
	{
		&quot;_type&quot; : &quot;类型名&quot;,
		&quot;_id&quot; : &quot;唯一 ID 值&quot;
	}, {}, {}
	]
}
</code></pre>
<pre><code class="language-properties">GET 索引名/类型名/_mget
{
	&quot;docs&quot; : [
	{
		&quot;_id&quot; : &quot;唯一 ID 值&quot;
	},
	{
		&quot;_id&quot; : &quot;唯一 ID 值&quot;
	}
	]
}
</code></pre>
<h3 id="39-修改-document">3.9 修改 Document</h3>
<h4 id="391-替换-document全量替换">3.9.1  替换 Document（全量替换）</h4>
<p>和新增的 PUT|POST 语法是一致。</p>
<p>PUT|POST 索引名/类型名/唯一 ID{字段名:字段值}<br>
本操作相当于覆盖操作。全量替换的过程中，ElasticSearch 不会真的修改 Document中的数据，而是标记 ElasticSearch 中原有的 Document 为 deleted 状态，再创建一个新的 Document 来存储数据，当 ElasticSearch 中的数据量过大时，ElasticSearch 后台回收 deleted 状态的 Document。<br>
如：</p>
<pre><code class="language-properties">PUT test_index/my_type/1
{
	&quot;name&quot;:&quot;new_test_doc_01&quot;,
	&quot;remark&quot;:&quot;first test elastic search&quot;,
	&quot;order_no&quot;:1
}
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722093619.png" alt="" loading="lazy"></figure>
<h4 id="392-更新-documentpartial-update">3.9.2 更新 Document（partial update）</h4>
<p>语法：POST 索引名/类型名/唯一 ID/_update{doc:{字段名:字段值}}</p>
<p>只更新某 Document 中的部分字段。这种更新方式也是标记原有数据为 deleted 状态，创建一个新的 Document 数据，将新的字段和未更新的原有字段组成这个新的 Document，并创建。对比全量替换而言，只是操作上的方便，在底层执行上几乎没有区别。</p>
<p>如：</p>
<pre><code class="language-properties">POST test_index/my_type/1/_update
{
	&quot;doc&quot;:{
	&quot;name&quot;:&quot; test_doc_01_for_update&quot;
	}
}
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722093937.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722093949.png" alt="" loading="lazy"></figure>
<h3 id="310-删除-document">3.10 删除 Document</h3>
<p><em><strong>ElasticSearch 中执行删除操作时，ElasticSearch 先标记 Document 为 deleted 状态，而不是直接物理删除。当 ElasticSearch 存储空间不足或工作空闲时，才会执行物理删除操作。标记为 deleted 状态的数据不会被查询搜索到。</strong></em><br>
语法：DELETE 索引名/类型名/唯一 ID</p>
<p>如：</p>
<pre><code class="language-properties">DELETE test_index/my_type/1
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722094045.png" alt="" loading="lazy"></figure>
<h3 id="311-bulk-批量增删改">3.11 bulk 批量增删改</h3>
<p>使用 bulk 语法执行批量增删改。语法格式如下：</p>
<p>POST _bulk<br>
{ &quot;action_type&quot; : { &quot;metadata_name&quot; : &quot;metadata_value&quot; } }<br>
{ document datas | action datas }</p>
<p>语法中的 action_type 可选值为：<br>
create : 强制创建，相当于 PUT 索引名/类型名/唯一 ID/_create<br>
index: 普通的 PUT 操作，相当于创建 Document 或全量替换<br>
update: 更新操作（partial update）,相当于 POST 索引名/类型名/唯一 ID/_update<br>
delete: 删除操作</p>
<p>案例如下：</p>
<pre><code class="language-properties">新增数据：
POST _bulk
{ &quot;create&quot; : { &quot;_index&quot; : &quot;test_index&quot; , &quot;_type&quot; : &quot;my_type&quot;, &quot;_id&quot; : &quot;1&quot; } }
{ &quot;field_name&quot; : &quot;field value&quot; }

PUT 操作新增或全量替换
POST _bulk
{ &quot;index&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot; , &quot;_id&quot; : &quot;2&quot; } }
{ &quot;field_name&quot; : &quot;field value 2&quot; }

POST 更新数据
POST _bulk
{ &quot;update&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot; , &quot;_id&quot; : 2, &quot;_retry_on_conflict&quot; : 3 } }
{ &quot;doc&quot; : { &quot;field_name&quot; : &quot;partial update field value&quot; } }

DELETE 删除数据
POST _bulk
{ &quot;delete&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot;, &quot;_id&quot; : &quot;2&quot; } }

批量写操作
POST _bulk
{ &quot;create&quot; : { &quot;_index&quot; : &quot;test_index&quot; , &quot;_type&quot; : &quot;my_type&quot;, &quot;_id&quot; : &quot;10&quot; } }
{ &quot;field_name&quot; : &quot;field value&quot; }
{ &quot;index&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot; , &quot;_id&quot; : &quot;20&quot; } }
{ &quot;field_name&quot; : &quot;field value 2&quot; }
{ &quot;update&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot; , &quot;_id&quot; : 20, &quot;_retry_on_conflict&quot; : 3 } }
{ &quot;doc&quot; : { &quot;field_name&quot; : &quot;partial update field value&quot; } }
{ &quot;delete&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot;, &quot;_id&quot; : &quot;2&quot; } }
</code></pre>
<p><em><strong>注意：bulk 语法中要求一个完整的 json 串不能有换行。不同的 json 串必须使用换行分隔。多个操作中，如果有错误情况，不会影响到其他的操作，只会在批量操作返回结果中标记失败。bulk 语法批量操作时，bulk request 会一次性加载到内存中，如果请求数据量太大，性能反而下降（内存压力过高），需要反复尝试一个最佳的 bulk request size。一般从 1000~5000 条数据开始尝试，逐渐增加。如果查看 bulk request size 的话，一般是 5~15MB 之间为好。</strong></em><br>
<em><strong>bulk 语法要求 json 格式是为了对内存的方便管理，和尽可能降低内存的压力。如果json 格式没有特殊的限制，ElasticSearch 在解释 bulk 请求时，需要对任意格式的 json进行解释处理，需要对 bulk 请求数据做 json 对象会 json array 对象的转化，那么内存的占用量至少翻倍，当请求量过大的时候，对内存的压力会直线上升，且需要 jvm gc 进程对垃圾数据做频繁回收，影响 ElasticSearch 效率。</strong></em><br>
<em><strong>生成环境中，bulk api 常用。都是使用 java 代码实现循环操作。一般一次 bulk 请求，执行一种操作。如：批量新增 10000 条数据等。</strong></em></p>
<h2 id="4-分词器analyzer和标准化处理normalization">4、分词器（analyzer）和标准化处理（normalization）</h2>
<h3 id="41-什么是分词器">4.1 什么是分词器</h3>
<p>分词器是一个字符串解析拆分工具。其作用是分析写入的 Document 中的文本数据field，并将 field 数据拆分成一个个有完整含义的、不可拆分的单词。</p>
<p>如：I think dogs is human's best friend.在写入此数据的时候，ElasticSearch 会使用分词器分析并拆分数据，将上述的语句切分成若干的单词，分别是：I、 think、 dogs、human's、 best、 friend。</p>
<h3 id="42-什么是标准化处理">4.2 什么是标准化处理</h3>
<p>标准化处理是用于完善分词器结果的。</p>
<p>分词器处理的文本结果，通常会有一些不需要的、有异议的、包含时态转化等情况的数据。在上述案例中的分词结果是：i、 think、 dogs、 human's、 best、 friend。其中i 是很少应用在搜索条件中的单词；dogs 是 dog 单词的复数形式，通常在搜索过程中使用dog 作为搜索条件更频繁一些；human's 是特殊的标记方式，通常不会在搜索中作为条件出现。那么 ElasticSearch 维护这些单词是没有太大必要的。这个时候就需要标准化处理了。</p>
<p>如：china 搜索时，如果条件为 cn 是否可搜索到。如：dogs，搜索时，条件为 dog是否可搜索到数据。如果可以使用简写（cn）或者单复数（dog&amp;dogs）搜索到想要的结果，那么称为搜索引擎人性化。</p>
<p>normalization 是为了提升召回率的（recall），就是提升搜索能力的。</p>
<p>normalization 是配合分词器(analyzer)完成其功能的。</p>
<h3 id="43-elasticsearch-默认提供的常见分词器">4.3 ElasticSearch 默认提供的常见分词器</h3>
<p>要切分的语句：Set the shape to semi-transparent by calling set_trans(5)<br>
standard analyzer - 是 ElasticSearch 中的默认分词器。标准分词器，处理英语语法的分词器。切分后的 key_words：set, the, shape, to, semi, transparent, by, calling,set_trans, 5。这种分词器也是 ElasticSearch 中默认的分词器。切分过程中不会忽略停止词（如：the、a、an 等）。会进行单词的大小写转换、过滤连接符（-）或括号等常见符号。</p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot;: &quot;Set the shape to semi-transparent by calling set_trans(5)&quot;,
	&quot;analyzer&quot;: &quot;standard&quot;
}
</code></pre>
<p>simple analyzer - 简单分词器。切分后的 key_words：set, the, shape, to, semi,transparent, by, calling, set, trans。就是将数据切分成一个个的单词。使用较少，经常会破坏英语语法。</p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot;: &quot;Set the shape to semi-transparent by calling 	set_trans(5)&quot;,
	&quot;analyzer&quot;: &quot;simple&quot;
}
</code></pre>
<p>whitespace analyzer - 空白符分词器。切分后的 key_words：Set, the, shape, to,semi-transparent, by, calling, set_trans(5)。就是根据空白符号切分数据。如：空格、制表符等。使用较少，经常会破坏英语语法。</p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot;: &quot;Set the shape to semi-transparent by calling set_trans(5)&quot;,
	&quot;analyzer&quot;: &quot;whitespace&quot;
}
</code></pre>
<p>language analyzer - 语言分词器，如英语分词器（english）等。切分后的 key_words：set, shape, semi, transpar, call, set_tran, 5。根据英语语法分词，会忽略停止词、转换大小写、单复数转换、时态转换等，应用分词器分词功能类似 standard analyzer。</p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot;: &quot;Set the shape to semi-transparent by calling set_trans(5)&quot;,
	&quot;analyzer&quot;: &quot;english&quot;
}
</code></pre>
<p><em><strong>注意：ElasticSearch 中提供的常用分词器都是英语相关的分词器，对中文的分词都是一字一词。</strong></em></p>
<h3 id="44-安装中文分词器">4.4  安装中文分词器</h3>
<p>IK 中文分词器，很少有直接下载使用的，都需要通过 github 下载源码，本地编译打包。</p>
<p>就是 maven 工程中的 package 能力。</p>
<p>github 上提供的源码不是伴随 ES 的每个版本提供，一般只有分词器无效后，才提供新的版本。通常都是伴随 ES 的次版本号提供 IK 分词器版本。下载对应的 IK 分词器源码，本地 package 打包，生成 zip 压缩包，既是 IK 在 ES 中的分词器安装包。</p>
<p>git clone https://github.com/medcl/elasticsearch-analysis-ik.git</p>
<p>git checkout tags/v6.5.0</p>
<ol>
<li>
<p>安装 IK 分词器<br>
ElasticSearch 是一个开箱即用的工具。插件安装方式也非常简单。</p>
<p>将 IK 分词器的 zip 压缩文件上传到 Linux，并在 ElasticSearch 安装目录的 plugins 目录中手工创建子目录，目录命名为 ik。将 zip 压缩文件解压缩到新建目录 ik 中。重新启动ElasticSearch 即可。</p>
<p>复制中文分词器 zip 压缩文件到 ElasticSearch 应用目录中：</p>
<p>cp elasticsearch-analysis-ik-6.8.4.zip /opt/es/plugins/</p>
<p>创建 IK 中文分词器的插件子目录：</p>
<p>mkdir /opt/es/plugins/ik/</p>
<p>移动压缩文件到 ik 插件目录中：</p>
<p>mv /opt/es/plugins/elasticsearch-analysis-ik-6.8.4.zip /usr/local/es/plugins/ik/</p>
<p>解压缩：</p>
<p>unzip /opt/es/plugins/ik/elasticsearch-analysis-ik-6.8.4.zip<br>
<em><strong>所有的分词器，都是针对词语的，不是语句的。拆分单元是词语，不是语句。</strong></em></p>
</li>
<li>
<p>测试 IK 分词器<br>
IK 分词器提供了两种 analyzer，分别是 ik_max_word 和 ik_smart。<br>
<em><strong>ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,国,国歌”，会穷尽各种可能的组合；</strong></em><br>
<em><strong>ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”。</strong></em></p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot; : &quot;中华人民共和国国歌&quot;,
	&quot;analyzer&quot;: &quot;ik_max_word&quot;
}


GET _analyze
{
	&quot;text&quot; : &quot;中华人民共和国国歌&quot;,
	&quot;analyzer&quot;: &quot;ik_smart&quot;
}
</code></pre>
</li>
<li>
<p>IK 配置文件<br>
IK 的配置文件在 ElasticSearch 安装目录/plugins/ik/config/中。</p>
</li>
</ol>
<p>配置文件有：</p>
<p>main.dic ： IK 中内置的词典。 main dictionary。记录了 IK 统计的所有中文单词。一行一词。文件中未记录的单词，IK 无法实现有效分词。如：雨女无瓜。不建议修改当前文件中的单词。这个是最核心的中文单词库。就好像，很多的网络词不会收集到辞海中一样。</p>
<p>quantifier.dic ： IK 内置的数据单位词典</p>
<p>suffix.dic ：IK 内置的后缀词典</p>
<p>surname.dic ：IK 内置的姓氏词典</p>
<p>stopword.dic ：IK 内置的英文停用词</p>
<p>preposition.dic ：IK 内置的中文停用词（介词）<br>
<em><strong>IKAnalyzer.cfg.xml</strong></em> ： 用于配置自定义词库的<br>
自定义词库是用户手工提供的特殊词典，类似网络热词，特定业务用词等。<br>
<em><strong>ext_dict - 自定义词库，配置方式为相对于 IKAnalyzer.cfg.xml 文件所在位置的相对路径寻址方式。相当于是用户自定义的一个 main.dic 文件。是对 main.dic 文件的扩展。</strong></em><br>
<em><strong>ext_stopwords - 自定义停用词，配置方式为相对于 IKAnalyzer.cfg.xml 文件所在位置的相对路径寻址方式。相当于是 preposition.dic 的扩展。</strong></em><br>
<em><strong>注意：IK 的所有的 dic 词库文件，必须使用 UTF-8 字符集。不建议使用 windows 自带的文本编辑器编辑。Windows 中自带的文本编辑器是使用 GBK 字符集。IK 不识别，是乱码。</strong></em></p>
<h2 id="5-elasticsearch-中的-mapping-问题">5、 ElasticSearch 中的 mapping 问题</h2>
<p>Mapping 在 ElasticSearch 中是非常重要的一个概念。决定了一个 index 中的 field 使用什么数据格式存储，使用什么分词器解析，是否有子字段等。</p>
<p>Mapping 决定了 index 中的 field 的特征。</p>
<h3 id="51-mapping-核心数据类型">5.1  mapping 核心数据类型</h3>
<p>ElasticSearch 中的数据类型有很多，在这里只介绍常用的数据类型。</p>
<p>文本（字符串）：text<br>
整数：byte、short、integer、long<br>
浮点型：float、double<br>
布尔类型：boolean<br>
日期类型：date<br>
数组类型：array {a:[]}<br>
对象类型：object {a:{}}<br>
不分词的字符串（关键字）： keyword</p>
<h3 id="52-dynamic-mapping-对字段的类型分配">5.2 dynamic mapping 对字段的类型分配</h3>
<p>true or false -&gt; boolean<br>
123 -&gt; long<br>
123.123 -&gt; double<br>
2018-01-01 -&gt; date<br>
hello world -&gt; text<br>
[] -&gt; array<br>
{} -&gt; object<br>
在上述的自动 mapping 字段类型分配的时候，只有 text 类型的字段需要分词器。默认分词器是 standard 分词器。</p>
<h3 id="53-查看索引-mapping">5.3 查看索引 mapping</h3>
<p>可以通过命令查看已有 index 的 mapping 具体信息，语法如下：</p>
<p>GET 索引名/_mapping</p>
<p>如：</p>
<pre><code class="language-properties">GET test_index/_mapping
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722105155.png" alt="" loading="lazy"></figure>
<h3 id="54-custom-mapping">5.4 custom mapping</h3>
<p>可以通过命令，在创建 index 和 type 的时候来定制 mapping 映射，也就是指定字段的类型和字段数据使用的分词器。<br>
手工定制 mapping 时，只能***新增 mapping 设置，不能对已有的 mapping 进行修改。***<br>
如：有索引 a，其中有类型 b，增加字段 f1 的 mapping 定义。后续可以增加字段 f2的 mapping 定义，但是不能修改 f1 字段的 mapping 定义。</p>
<p>通常都是手工创建 index，并进行各种定义。如：settings,mapping 等。</p>
<h4 id="541-创建索引时指定-mapping">5.4.1 创建索引时指定 mapping</h4>
<p>语法：</p>
<pre><code class="language-properties">PUT 索引名称
{
	&quot;mappings&quot;:{
		&quot;类型名称&quot;:{
			&quot;properties&quot;:{
				&quot;字段名&quot;:{
					&quot;type&quot;:类型,
					[&quot;analyer&quot;:字段的分词器,]
					[&quot;fields&quot;:{
						&quot;子字段名称&quot;:{
							&quot;type&quot;:类型,
							&quot;ignore_above&quot;:长度限制
							}
					}]
				}
			}
		}
	}
}
</code></pre>
<p>如：</p>
<pre><code class="language-properties">PUT /test_index
{
	&quot;settings&quot;: {
		&quot;number_of_shards&quot;: 2,
		&quot;number_of_replicas&quot;: 1
},
	&quot;mappings&quot;: {
		&quot;test_type&quot;:{
			&quot;properties&quot;: {
				&quot;author_id&quot; : {
					&quot;type&quot;: &quot;byte&quot;,
					&quot;index&quot;: false
				},
			&quot;title&quot; : {
				&quot;type&quot;: &quot;text&quot;,
				&quot;analyzer&quot;: &quot;ik_max_word&quot;,
				&quot;fields&quot;: {
					&quot;keyword&quot; : {
					&quot;type&quot;: &quot;keyword&quot;,
					&quot;ignore_above&quot;: 256
					}
				}
			},
			&quot;content&quot; : {
				&quot;type&quot;: &quot;text&quot;,
                  &quot;analyzer&quot;: &quot;ik_max_word&quot;
			},
			&quot;post_date&quot; : {
				&quot;type&quot;: &quot;date&quot;
			}
		}
	}
}
}
</code></pre>
<p>&quot;index&quot; - 是否可以作为搜索索引。可选值：true | false</p>
<p>&quot;analyzer&quot; - 指定分词器。</p>
<p>&quot;type&quot; - 指定字段类型</p>
<h4 id="542-为已有索引添加新的字段-mapping">5.4.2 为已有索引添加新的字段 mapping</h4>
<p>语法：</p>
<pre><code class="language-properties">PUT 索引名/_mapping/类型名
{
	&quot;properties&quot;:{
		&quot;新字段名&quot;:{
			&quot;type&quot;:类型,
			&quot;analyer&quot;:字段的分词器,
			&quot;fields&quot;:{
				&quot;子字段名&quot;:{
					&quot;type&quot;:类型,
					&quot;ignore_above&quot;:长度
				}
			}
		}
	}
}
</code></pre>
<p>如：</p>
<pre><code class="language-properties">PUT /test_index/_mapping/test_type
{
	&quot;properties&quot; : {
		&quot;new_field&quot; : { &quot;type&quot; : &quot;text&quot; , &quot;analyzer&quot; : &quot;standard&quot; }
	}
}
</code></pre>
<h4 id="543-测试不同的字段的分词器">5.4.3 测试不同的字段的分词器</h4>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名称/_analyze
{
	&quot;field&quot;:&quot;索引中的 text 类型的字段名&quot;,
	&quot;text&quot;:&quot;要分词处理的文本数据&quot;
}
</code></pre>
<p>使用索引中的字段对应的分词器，对文本数据做分词处理。</p>
<p>如：</p>
<pre><code class="language-properties">GET /test_index/_analyze
{
	&quot;field&quot;: &quot;new_field&quot;,
	&quot;text&quot;: &quot;中华人民共和国国歌&quot;
}

GET /test_index/_analyze
{
	&quot;field&quot;: &quot;content&quot;,
	&quot;text&quot;: &quot;中华人民共和国国歌&quot;
}
</code></pre>
<h2 id="6-search-搜索详解">6、 Search 搜索详解</h2>
<h3 id="61-搜索学习测试数据">6.1 搜索学习测试数据</h3>
<pre><code class="language-properties">PUT test_search
{
	&quot;mappings&quot;: {
		&quot;test_type&quot; : {
			&quot;properties&quot;: {
				&quot;dname&quot; : {
					&quot;type&quot; : &quot;text&quot;,
					&quot;analyzer&quot;: &quot;standard&quot;
				},
				&quot;ename&quot; : {
					&quot;type&quot; : &quot;text&quot;,
					&quot;analyzer&quot;: &quot;standard&quot;
				},
				&quot;eage&quot; : {
					&quot;type&quot;: &quot;long&quot;
				},
				&quot;hiredate&quot; : {
					&quot;type&quot;: &quot;date&quot;
				},
				&quot;gender&quot; : {
					&quot;type&quot; : &quot;keyword&quot;
				}
			}
		}
	}
}


POST test_search/test_type/_bulk
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Sales Department&quot;, &quot;ename&quot; : &quot; 张 三 &quot;, &quot;eage&quot;:20, &quot;hiredate&quot; : &quot;2019-01-01&quot;,&quot;gender&quot; : &quot;男性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Sales Department&quot;, &quot;ename&quot; : &quot; 李 四 &quot;, &quot;eage&quot;:21, &quot;hiredate&quot; : &quot;2019-02-01&quot;,&quot;gender&quot; : &quot;男性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Development Department&quot;, &quot;ename&quot; : &quot; 王 五 &quot;, &quot;eage&quot;:23, &quot;hiredate&quot; :&quot;2019-01-03&quot;, &quot;gender&quot; : &quot;男性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Development Department&quot;, &quot;ename&quot; : &quot; 赵 六 &quot;, &quot;eage&quot;:26, &quot;hiredate&quot; :&quot;2018-01-01&quot;, &quot;gender&quot; : &quot;男性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Development Department&quot;, &quot;ename&quot; : &quot; 韩 梅 梅 &quot;, &quot;eage&quot;:24, &quot;hiredate&quot; :&quot;2019-03-01&quot;, &quot;gender&quot; : &quot;女性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Development Department&quot;, &quot;ename&quot; : &quot; 钱 虹 &quot;, &quot;eage&quot;:29, &quot;hiredate&quot; :&quot;2018-03-01&quot;, &quot;gender&quot; : &quot;女性&quot; }
</code></pre>
<h3 id="62-query-string-search">6.2 query string search</h3>
<p>search 的参数都是类似 http 请求头中的字符串参数提供搜索条件的。</p>
<p>GET<br>
[/index_name/type_name/]_search[?parameter_name=parameter_value&amp;...]</p>
<h4 id="621-全搜索">6.2.1 全搜索</h4>
<p>timeout 参数：是超时时长定义。代表每个节点上的每个 shard 执行搜索时最多耗时多久。不会影响响应的正常返回。只会影响返回响应中的数据数量。<br>
如：索引 a 中，有 10 亿数据。存储在 5 个 shard 中，假设每个 shard 中 2 亿数据，执行全数据搜索的时候，需要耗时 1000 毫秒。定义 timeout 为 10 毫秒，代表的是 shard执行 10 毫秒，搜索出多少数据，直接返回。<br>
在商业项目中，是禁止全数据搜索的。必须指定搜索的索引，类型和关键字。如果没有指定索引或类型，则代表开发目的不明确，需要重新做用例分析。如果没有关键字，称为索引内全搜索，也叫魔鬼搜索。</p>
<p>语法：<br>
GET [索引名/类型名/]_search?timeout=10ms</p>
<p>结果：</p>
<pre><code class="language-properties">{
	&quot;took&quot;: 144, #请求耗时多少毫秒
	&quot;timed_out&quot;: false, #是否超时。默认情况下没有超时机制，也就是客户端等待 ElasticSearch 搜索结束（无论执行多久），提供超时机制的话，ElasticSearch 则在指定时长内处理搜索，在指定时长结束的时候，将搜索的结果直接返回（无论是否搜索结束）。指定超时的方式是传递参数，参数单位是：毫秒-ms。秒-s。分钟-m。
	&quot;_shards&quot;: {
		&quot;total&quot;: 1, #请求发送到多少个 shard 上
		&quot;successful&quot;: 1,#成功返回搜索结果的 shard
		&quot;skipped&quot;: 0, #停止服务的 shard
		&quot;failed&quot;: 0 #失败的 shard
	},
	&quot;hits&quot;: {
		&quot;total&quot;: 1, #返回了多少结果
		&quot;max_score&quot;: 1, #搜索结果中，最大的相关度分数，相关度越大分数越高，_score 越大，排位越靠前。
		&quot;hits&quot;: [ #搜索到的结果集合，默认查询前 10 条数据。
		{
			&quot;_index&quot;: &quot;test_index&quot;, #数据所在索引
			&quot;_type&quot;: &quot;my_type&quot;, #数据所在类型
			&quot;_id&quot;: &quot;1&quot;, #数据的 id
			&quot;_score&quot;: 1, #数据的搜索相关度分数
			&quot;_source&quot;: { # 数据的具体内容。
				&quot;field&quot;: &quot;value&quot;
			}
		}
	]
	}
}
</code></pre>
<h4 id="622-multi-index-搜索">6.2.2 multi index 搜索</h4>
<p>所谓的 multi-index 就是从多个 index 中搜索数据。相对使用较少，只有在复合数据搜索的时候，可能出现。一般来说，如果真使用复合数据搜索，都会使用_all。<br>
如：搜索引擎中的无条件搜索。（现在的应用中都被屏蔽了。使用的是默认搜索条件，执行数据搜索。 如： 电商中的搜索框默认值， 搜索引擎中的类别）<br>
无条件搜索，在搜索应用中称为“魔鬼搜索”，代表的是，搜索引擎会执行全数据检索，效率极低，且对资源有非常高的压力。</p>
<p>语法：</p>
<pre><code class="language-properties">GET _search
GET 索引名 1,索引名 2/_search # 搜索多个 index 中的数据
GET 索引名/类型名/_search # 所属一个 index 中 type 的数据
GET prefix_*/_search # 通配符搜索
GET *_suffix/_search
GET 索引名 1,索引名 2/类型名/_search # 搜索多个 index 中 type 的数据
GET _all/_search # _all 代表所有的索引
</code></pre>
<h4 id="623-条件搜索">6.2.3 条件搜索</h4>
<p>query string search 搜索是通过 HTTP 请求的请求头传递参数的，默认的 HTTP 请求头字符集是 ISO-8859-1，请求头传递中文会有乱码。</p>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名/_search?q=字段名:搜索条件
</code></pre>
<h4 id="624-分页搜索">6.2.4  分页搜索</h4>
<p>默认情况下，ElasticSearch 搜索返回结果是 10 条数据。从第 0 条开始查询。</p>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名/_search?size=10 # size 查询数据的行数

GET 索引名/_search?from=0&amp;size=10 # from 从第几行开始查询，行号从 0 开始。
</code></pre>
<h4 id="625-搜索">6.2.5 +/-搜索</h4>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名/_search?q=字段名:条件

GET 索引名/_search?q=+字段名:条件

GET 索引名/_search?q=-字段名:条件
</code></pre>
<p><code>+ ：和不定义符号含义一样，就是搜索指定的字段中包含 key words 的数据</code></p>
<p><code>- ： 与+符号含义相反，就是搜索指定的字段中不包含 key words 的数据</code></p>
<h4 id="626-排序">6.2.6 排序</h4>
<p>语法：GET 索引名/_search?sort=字段名:排序规则<br>
排序规则： asc(升序) | desc(降序)</p>
<pre><code class="language-properties">GET test_search/_search?sort=eage:asc
GET test_search/_search?sort=eage:desc
</code></pre>
<h3 id="63-query-dsl">6.3  query DSL</h3>
<p>DSL - Domain Specified Language ， 特殊领域的语言。</p>
<p>请求参数是请求体传递的。在 ElasticSearch 中，请求体的字符集默认为 UTF-8。</p>
<p>语法格式：</p>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;command&quot;:{ &quot;parameter_name&quot; : &quot;parameter_value&quot;}
}
</code></pre>
<h4 id="631-查询所有数据">6.3.1 查询所有数据</h4>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;query&quot; : { &quot;match_all&quot; : {} }
}
</code></pre>
<h4 id="632-match-search">6.3.2  match search</h4>
<p>全文检索。要求查询条件拆分后的任意词条与具体数据匹配就算搜索结果。</p>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;query&quot;: {
		&quot;match&quot;: {
			&quot;字段名&quot;: &quot;搜索条件&quot;
		}
	}
}
</code></pre>
<h4 id="633-phrase-search">6.3.3 phrase search</h4>
<p>短语检索。要求查询条件必须和具体数据完全匹配才算搜索结果。其特征是：1-搜索条件不做任何分词解析；2-在搜索字段对应的倒排索引(正排索引)中进行精确匹配，不再是简单的全文检索。</p>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;query&quot;: {
		&quot;match_phrase&quot;: {
			&quot;字段名&quot;: &quot;搜索条件&quot;
		}
	}
}
</code></pre>
<h4 id="634-range">6.3.4 range</h4>
<p>范围比较搜索</p>
<pre><code class="language-properties">GET 索引名/类型名/_search
{
	&quot;query&quot; : {
		&quot;range&quot; : {
			&quot;字段名&quot; : {
				&quot;gt&quot; : 搜索条件 1,
				&quot;lte&quot; : 搜索条件 2
			}
		}
	}
}
</code></pre>
<h4 id="635-term">6.3.5 term</h4>
<p>词组比较，词组搜索。</p>
<p>忽略搜索条件分词，在 ElasticSearch 倒排索引中进行精确匹配。</p>
<pre><code class="language-properties">GET 索引名/类型名/_search
{
	&quot;query&quot; : {
		&quot;term&quot; : {
			&quot;字段名&quot;: &quot;搜索条件&quot;
		}
	}
}

GET 索引名/类型名/_search
{
	&quot;query&quot; : {
		&quot;terms&quot; : {
			&quot;字段名&quot;: [&quot;搜索条件 1&quot;, &quot;搜索条件 2&quot;]
		}
	}
}
</code></pre>
<h4 id="636-多条件复合搜索">6.3.6  多条件复合搜索</h4>
<p>在一个请求体中，有多个搜索条件，就是复合搜索。如：搜索数据，条件为部门名称是Sales Department，员工年龄在 20 到 26 之间，部门员工姓名叫张三。上述条件中，部门名称为可选条件，员工年龄必须满足要求，部门员工姓名为可选要求。这种多条件搜索就是符合搜索。</p>
<pre><code class="language-properties">GET 索引名/类型名/_search
{
	&quot;query&quot;: {
		&quot;bool&quot;: {
			&quot;must&quot;: [ #数组中的多个条件必须同时满足
				{
					&quot;range&quot;: {
						&quot;字段名&quot;: {
						&quot;lt&quot;: 条件
						}
					}
				}
				],
			&quot;must_not&quot;:[ #数组中的多个条件必须都不满足
				{
					&quot;match&quot;: {
						&quot;字段名&quot;: &quot;条件&quot;
					}
				},
				{
					&quot;range&quot;: {
						&quot;字段名&quot;: {
							&quot;gte&quot;: &quot;搜索条件&quot;
						}
					}
				}
				]
			&quot;should&quot;: [# 数组中的多个条件有任意一个满足即可。
				{
					&quot;match&quot;: {
						&quot;字段名&quot;: &quot;条件&quot;
					}
				},
				{
					&quot;range&quot;: {
						&quot;字段名&quot;: {
							&quot;gte&quot;: &quot;搜索条件&quot;
       					 }
					}
				}
				]
			}
		}
	}
</code></pre>
<h4 id="637-排序">6.3.7  排序</h4>
<p>在 ElasticSearch 的搜索中，默认是使用相关度分数实现排序的。可以通过搜索语法实现定制化排序。</p>
<pre><code class="language-properties">GET 索引名/类型名/_search
{
	&quot;query&quot;: {
		[搜索条件]
	},
	&quot;sort&quot;: [
		{
			&quot;字段名 1&quot;: {
				&quot;order&quot;: &quot;asc&quot;
			}
		},
		{
			&quot;字段名 2&quot;: {
				&quot;order&quot;: &quot;desc&quot;
			}
		}
	]
}
</code></pre>
<p><em><strong>注意：在 ElasticSearch 中，如果使用 text 类型的字段作为排序依据，会有问题。ElasticSearch 需要对 text 类型字段数据做分词处理。如果使用 text 类型字段做排序，ElasticSearch 给出的排序结果未必友好，毕竟分词后，先使用哪一个单词做排序都是不合理的。所以 ElasticSearch 中默认情况下不允许使用 text 类型的字段做排序，如果需要使用字符串做结果排序，则可使用 keyword 类型字段作为排序依据，因为 keyword 字段不做分词处理。</strong></em></p>
<h4 id="638-分页">6.3.8 分页</h4>
<p>DSL 分页也是使用 from 和 size 实现的。</p>
<pre><code class="language-properties">GET 索引名称/_search
{
	&quot;query&quot;:{
		&quot;match_all&quot;:{}
	},
	&quot;from&quot;: 起始下标,
	&quot;size&quot;: 查询记录数
}
</code></pre>
<h4 id="639-highlight-display">6.3.9  highlight display</h4>
<p>在搜索中，经常需要对搜索关键字做高亮显示，这个时候就可以使用 highlight 语法。</p>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;query&quot;: {
		&quot;match&quot;: {
			&quot;字段名&quot;: &quot;条件&quot;
		}
	},
	&quot;highlight&quot;: {
		&quot;fields&quot;: {
			&quot;要高亮显示的字段名&quot;: {
				&quot;fragment_size&quot;: 5, #每个分段长度，默认 20
				&quot;number_of_fragments&quot;: 1 #返回多少个分段，默认 3
			}
		},
		&quot;pre_tags&quot;: [&quot;前缀&quot;],
		&quot;post_tags&quot;: [&quot;后缀&quot;]
	}
}
</code></pre>
<p>演示案例：</p>
<pre><code class="language-properties">GET test_search/_search
{
	&quot;query&quot;: {
		&quot;bool&quot;: {
			&quot;should&quot;: [
				{
					&quot;match&quot;: {
						&quot;dname&quot;: &quot;Development department&quot;
					}
				},
				{
					&quot;match&quot;: {
					&quot;gender&quot;: &quot;男性&quot;
				}
			}
		]
		}
	},
	&quot;highlight&quot;: {
		&quot;fields&quot;: {
			&quot;dname&quot;: {
				&quot;fragment_size&quot;: 20,
				&quot;number_of_fragments&quot;: 1
			},
			&quot;gender&quot;: {
				&quot;fragment_size&quot;: 20,
				&quot;number_of_fragments&quot;: 1
			}
		},
		&quot;pre_tags&quot;:[&quot;&lt;span style='color:red'&gt;&quot;],
		&quot;post_tags&quot;:[&quot;&lt;/span&gt;&quot;]
	},
	&quot;from&quot;: 2,
	&quot;size&quot;: 2
}
</code></pre>
<p>fragment_size：代表字段数据如果过长，则分段，每个片段数据长度为多少。长度不是字符数量，是 ElasticSearch 内部的数据长度计算方式。默认不对字段做分段。number_of_fragments：代表搜索返回的高亮片段数量，默认情况下会将拆分后的所有片段都返回。</p>
<p>pre_tags：高亮前缀</p>
<p>post_tags：高亮后缀</p>
<p>很多搜索结果显示页面中都不会显示完整的数据，这样在数据过长的时候会导致页面效果 不 佳 ， 都 会 按 照 某 一 个 固 定 长 度 来 显 示 搜 索 结 果 ， 所 以 fragment_size 和number_of_fragments 参数还是很常用的。</p>
<h2 id="7-spring-data-elasticsearch">7、Spring Data ElasticSearch</h2>
<p>使用 Spring Data 下二级子项目 Spring Data Elasticsearch 进行操作。支持 POJO 方法操作 Elasticsearch。相比 Elasticsearch 提供的 API 更加简单更加方便。</p>
<h3 id="71-修改-pom-文件添加依赖">7.1 修改 POM 文件添加依赖</h3>
<pre><code class="language-xml">&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="72-修改配置文件">7.2 修改配置文件</h3>
<p>集群版多地址之间使用逗号分隔。</p>
<p>在 ElasticSearch5.x 以前的版本中，客户端使用的是 Transport 客户端，通过 TCP 协议和 9300 端口访问 ES。在 6.x 及之后的版本中，官方推荐使用 Rest 客户端，通过 Http协议和 9200 端口访问 ES。且在新版的 Spring Data Elasticsearch 框架中，Transport 客户端配置已经设置为过时配置，推荐使用 Rest 客户端。</p>
<ol>
<li>
<p>高版本新客户端</p>
<pre><code class="language-yaml">elasticsearch:
    rest: # 配置ElasticsearchRestTemplate客户端的属性，是现在推荐使用的。
      uris:
        - http://124.70.181.124:9200
        - http://124.70.181.124:9201
</code></pre>
</li>
<li>
<p>低版本常用客户端</p>
<pre><code class="language-yaml">spring:
  data:
    elasticsearch:
      cluster-name: elasticsearch # 必须提供的配置，集群的名称。
      cluster-nodes: 124.70.181.124:9300,124.70.181.124:9301 # transport客户端的端口是9300
</code></pre>
</li>
</ol>
<h3 id="73-创建实体">7.3 创建实体</h3>
<p>@Document 指定实体类和索引对应关系<br>
indexName：索引名称<br>
type: 索引类型<br>
shards: 主分片数量<br>
replicas：复制分片数量<br>
@Id 指定主键<br>
@Field 指定普通属性<br>
type： 对应 Elasticsearch 中属性类型。使用 FiledType 枚举可以快速获取。测试发现没有 type 属性可能出现无法自动创建类型问题，所以一定要有 type 属性。<br>
text 类型能被分词<br>
keywords 不能被分词<br>
index： 是否创建索引。作为搜索条件时 index 必须为 true<br>
analyzer：指定分词器类型。<br>
fielddata：指定是否为 text 类型字段创建正向索引。默认为 false，设置为 true则可以使用此字段排序。</p>
<pre><code class="language-java">/**
 * 自定义类型，商品。
 * 让自定义的类型和ElasticSearch中的一个索引产生关联。
 *
 * Document - spring data elasticsearch提供的注解， 描述类型，说明类型和索引的关系。
 *  indexName - 对应的索引的名称。 必要属性。
 *  shards - 创建索引时，设置的主分片数量。 默认5
 *  replicas - 创建索引时，设置的副本分片数量。 默认1
 *  type - 对应的类型的名称。
 */
@Document(indexName = &quot;ego_item2&quot;,shards = 2,replicas = 1,type = &quot;item&quot;)
public class Item implements Serializable {
    /**
     * Id注解是Spring Data核心工程提供的，是所有的Spring Data二级子工程通用的。
     * 代表主键字段。
     */
    @Id
    private String id;
    /**
     * Field注解，描述实体类型中属性和ES索引中字段的关系。
     * 且可以为这个字段配置自定义映射mapping
     * 这个自定义映射必须通过代码逻辑调用设置映射的API才能生效。
     *  name - 索引中对应的字段名称，默认和属性同名。
     *  type - 索引中字段的类型，默认是FieldType.Auto，代表ES自动映射类型。
     *  analyzer - 字段的分词器名称，默认是standard。
     *  fielddata - 是否开启正向索引。默认关闭。
     *   默认只为文本类型的字段创建反向索引，提供快速搜索逻辑。
     *   fielddata设置为true，则会额外创建一个正向索引，支持排序。
     *  index - 是否创建默认的反向索引或正向索引。 text文本类型字段默认创建反向索引，其他创建正向索引。
     *   没有索引，就不能作为搜索条件。
     */
    @Field(name = &quot;title&quot;,type = FieldType.Text,analyzer = &quot;ik_max_word&quot;,fielddata = true)
    private String title; // 商品名称，需要中文分词，且偶尔需要排序， 常用搜索条件之一
    @Field(name = &quot;sellPoint&quot;,type = FieldType.Text,analyzer = &quot;ik_max_word&quot;)
    private String sellPoint; // 卖点， 需要中文分词， 常用搜索条件之一
    @Field(type = FieldType.Long)
    private Long price; // 单价
    @Field(type = FieldType.Integer,index = false)
    private int num; // 库存

    public Item() {
    }

    @Override
    public String toString() {
        return &quot;Item{&quot; +
                &quot;Id='&quot; + id + '\'' +
                &quot;, title='&quot; + title + '\'' +
                &quot;, sellPoint='&quot; + sellPoint + '\'' +
                &quot;, price=&quot; + price +
                &quot;, num=&quot; + num +
                '}';
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        Item item = (Item) o;
        return num == item.num &amp;&amp;
                Objects.equals(id, item.id) &amp;&amp;
                Objects.equals(title, item.title) &amp;&amp;
                Objects.equals(sellPoint, item.sellPoint) &amp;&amp;
                Objects.equals(price, item.price);
    }

    @Override
    public int hashCode() {
        return Objects.hash(id, title, sellPoint, price, num);
    }

    public String getId() {
        return id;
    }

    public void setId(String id) {
        this.id = id;
    }

    public String getTitle() {
        return title;
    }

    public void setTitle(String title) {
        this.title = title;
    }

    public String getSellPoint() {
        return sellPoint;
    }

    public void setSellPoint(String sellPoint) {
        this.sellPoint = sellPoint;
    }

    public Long getPrice() {
        return price;
    }

    public void setPrice(Long price) {
        this.price = price;
    }

    public int getNum() {
        return num;
    }

    public void setNum(int num) {
        this.num = num;
    }
}

</code></pre>
<h3 id="74-初始化索引">7.4 初始化索引</h3>
<p>首先注入客户端对象</p>
<pre><code class="language-java">/**
     * ES5.x以前，使用的客户端一般都是Transport客户端，数据交换客户端，通过端口9300，
     * 借助协议TCP，实现数据的交换访问。
     * Spring Data Elasticsearch 提供的客户端Template对象类型是 ElasticsearchTemplate
     * 配置是：
     * spring.data.elasticsearch.cluster-name = 集群名称
     * spring.data.elasticsearch.cluster-nodes = 集群每个节点的地址， ip:port,ip:port
     * &lt;p&gt;
     * ES6.x以后，官方推荐使用Rest客户端，通过端口9200，借助协议HTTP，实现数据访问控制
     * Spring Data Elasticsearch 提供的客户端Template对象类型是 ElasticsearchRestTemplate
     */
    // @Autowired
    //  private ElasticsearchTemplate elasticsearchTemplate;

    @Autowired
    private ElasticsearchRestTemplate elasticsearchRestTemplate;
</code></pre>
<p>createIndex(): 创建索引，创建出来的索引是不带有 mapping 信息的。返回值表示是否创建成功</p>
<p>putMapping():为已有的索引添加 mapping 信息。不具备创建索引的能力。返回值表示是否创建成功</p>
<pre><code class="language-java">    /**
     * 创建索引
     * 创建索引，不包括映射信息，因为只扫描类型上的Document注解。
     */
    @Test
    public void createIndexWithElasticsearchTemplate(){
        boolean isCreated = elasticsearchTemplate.createIndex(Item.class);
        System.out.println(&quot;创建索引是否成功:&quot;+isCreated);
    }
}

    /**
     * 创建索引，并设置映射。
     * 需要通过两次访问实现，1、创建索引；2、设置映射。
     */
    @Test
    public void testInitIndex() {
        // 创建索引，根据类型上的Document注解创建
        boolean isCreated = elasticsearchRestTemplate.createIndex(Item.class);
        // 设置映射，根据属性上的Field注解设置
        boolean isMapped = elasticsearchRestTemplate.putMapping(Item.class);
        System.out.println(&quot;创建索引是否成功&quot; + isCreated);
        System.out.println(&quot;设置映射是否成功&quot; + isMapped);
    }
</code></pre>
<h3 id="75-删除索引">7.5 删除索引</h3>
<pre><code class="language-java">/**
 * 删除索引
 */
@Test
public void deleteIndex() {
    // 扫描Item类型上的Document注解，删除对应的索引。
    boolean isDeleted = elasticsearchRestTemplate.deleteIndex(Item.class);
    System.out.println(&quot;删除Item对应索引是否成功&quot; + isDeleted);
    // 直接删除对应名称的索引。
    isDeleted = elasticsearchRestTemplate.deleteIndex(&quot;default_index&quot;);
    System.out.println(&quot;删除default_index索引是否成功&quot; + isDeleted);

}
</code></pre>
<h3 id="76-添加文档">7.6 添加文档</h3>
<p>如果索引和类型不存在，也可以执行进行新增，新增后自动创建索引和类型。但是 field通过动态 mapping 进行映射，elaticsearch 根据值类型进行判断每个属性类型，默认每个属性都是 standard 分词器，ik 分词器是不生效的。<em><strong>所以一定要先通过代码进行初始化或直接在 elasticsearch 中通过命令创建所有 field 的 mapping</strong></em></p>
<h4 id="761-新增单个文档">7.6.1 新增单个文档</h4>
<p>如果对象的 id 属性没有赋值，让 ES 自动生成主键，存储时 id 属性没有值，_id 存储document 的主键值。</p>
<p>如果对象的 id 属性明确设置值，存储时 id 属性为设置的值，ES 中 document 对象的_id 也是设置的值。</p>
<pre><code class="language-java">    /**
     * 新增数据到ES
     */
    @Test
    public void testInsert() {
        Item item = new Item();
        item.setId(&quot;111222333&quot;);
        item.setTitle(&quot;Spring In Action VI&quot;);
        item.setSellPoint(&quot;Spring系列书籍，非常好的一本Spring框架学习手册。唯一缺点没有中文版。&quot;);
        item.setPrice(9900L);
        item.setNum(999);

        IndexQuery indexQuery =
                new IndexQueryBuilder() // 创建一个IndexQuery的构建器
                        .withObject(item) // 设置要新增的Java对象
                        .build(); // 构建IndexQuery类型的对象

//        IndexQuery query = new IndexQuery();
//        query.setObject(item); //效果同上
        // index逻辑，相当于使用PUT请求，实现数据的新增。
        String result = elasticsearchRestTemplate.index(indexQuery);
        System.out.println(result);
    }
</code></pre>
<h4 id="762-批量新增">7.6.2 批量新增</h4>
<p>下面代码中使用的 IndexQueryBuilder()进行构建，可以一行代码完成。也可以使用上面的 IndexQuery()。效果是完全相同的，只是需要写多行。</p>
<pre><code class="language-java">/**
 * 批量新增
 * bulk操作
 */
@Test
public void testBatchInsert() {
    List&lt;IndexQuery&gt; queries = new ArrayList&lt;&gt;();
    for (int i = 0; i &lt; 3; i++) {
        Item item = new Item();
        item.setId(&quot;2000&quot; + i);
        item.setTitle(&quot;测试新增商品&quot; + i);
        item.setSellPoint(&quot;测试新增商品卖点&quot; + i);
        item.setPrice(new Random().nextLong());
        item.setNum(9999 - i);
        queries.add(
                new IndexQueryBuilder().withObject(item).build()
        );
    }
    // 批量新增，使用的是bulk操作。
    elasticsearchRestTemplate.bulkIndex(queries);
}
</code></pre>
<h3 id="77-删除操作">7.7.  删除操作</h3>
<p>根据主键删除</p>
<p>delete(String indexName,String typeName,String id); 通过字符串指定索引，类型和 id 值</p>
<p>delete(Class,String id) 第一个参数传递实体类类类型，建议使用此方法，减少索引名和类型名由于手动编写出现错误的概率。</p>
<p>返回值为 delete 方法第二个参数值（删除文档的主键值）</p>
<pre><code class="language-java">/**
 * 删除数据
 */
@Test
public void testDelete() {
    //根据主键删除
    String result = elasticsearchRestTemplate.delete(Item.class, &quot;epYDynEBHt6IU1hpAxvL&quot;);
    System.out.println(result);

    // 根据查询结果，删除查到的数据。 应用较少。
    DeleteQuery deleteQuery = new DeleteQuery();
    //deleteQuery.setIndex(&quot;ego_item&quot;);
    //deleteQuery.setType(&quot;item&quot;);
    deleteQuery.setQuery(
            QueryBuilders.matchQuery(&quot;title&quot;, &quot;Spring In Action VI&quot;)
    );
    elasticsearchRestTemplate.delete(deleteQuery, Item.class);
}
</code></pre>
<h3 id="78-修改操作">7.8 修改操作</h3>
<p>修改操作就是新增代码，只要保证主键 id 已经存在，新增就是修改。</p>
<p>如果使用部分更新，则需要通过 update 方法实现。具体如下：</p>
<pre><code class="language-java">    /**
     * 修改数据
     * 如果是全量替换，可以使用index方法实现，只要主键在索引中存在，就是全量替换。
     * 如果是部分修改，则可以使用update实现。
     */
    @Test
    public void testUpdate() throws IOException {
        UpdateRequest request = new UpdateRequest();
        request.doc(
                XContentFactory.jsonBuilder()
                        .startObject()
                        .field(&quot;name&quot;, &quot;测试update更新数据，商品名称&quot;)
                        .endObject()
        );
        UpdateQuery updateQuery =
                new UpdateQueryBuilder()
                        .withUpdateRequest(request)
                        .withClass(Item.class)
                        .withId(&quot;20200&quot;)
                        .build();
        elasticsearchRestTemplate.update(updateQuery);
    }
</code></pre>
<h3 id="79-搜索操作">7.9 搜索操作</h3>
<h4 id="791-模糊搜索">7.9.1  模糊搜索</h4>
<p>去所有 field 中搜索指定条件。</p>
<pre><code class="language-java">@Test
void query(){
	// NativeSearchQuery 构造方法参数。
	// 北京去和所有 field 进行匹配，只要出现了北京就可以进行查询
	QueryStringQueryBuilder queryStringQueryBuilder = QueryBuilders.queryStringQuery(&quot;北京&quot;);
// 查询条件 SearchQuery 是接口，只能实例化实现类。
	SearchQuery searchQuery = new NativeSearchQuery(queryStringQueryBuilder);
	List&lt;People&gt; list = elasticsearchRestTemplate.queryForList(searchQuery,People.class);
	for(People people : list){
		System.out.println(people);
	}
}
</code></pre>
<h4 id="792-使用-match_all-搜索所有文档">7.9.2 使用 match_all 搜索所有文档</h4>
<pre><code class="language-java">    /**
     * 搜素所有数据
     */
    @Test
    public void testMatchAll() {
        /**
         * SearchQuery - 是Spring Data Elasticsearch中定义的一个搜索接口
         * NativeSearchQuery - 是SearchQuery接口的实现类。
         *  构造的时候，需要提供一个QueryBuilder类型的对象，
         *  QueryBuilder是Elasticsearch的java客户端中定义的搜索条件类型。
         *
         * QueryBuilders - 是QueryBuilder类型的工具类，可以快速实现QueryBuilder类型对象的创建
         *  工具类中，提供了大量的静态方法，方法命名和DSL搜索中的条件关键字相关。
         *  如：match_all 对应 matchAllQuery()
         *  如：match 对应 matchQuery()
         *  如：range 对应 rangeQuery()
         */
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.matchAllQuery()
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }

</code></pre>
<h4 id="793-使用-match-搜索文档">7.9.3  使用 match 搜索文档</h4>
<pre><code class="language-java">    /**
     * 条件搜索
     */
    @Test
    public void testMatch() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.matchQuery(&quot;title&quot;, &quot;华为荣耀&quot;)
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<h4 id="794-使用-match_phrase-搜索文档">7.9.4 使用 match_phrase 搜索文档</h4>
<p>短语搜索是对条件不分词，但是文档中属性根据配置实体类时指定的分词类型进行分词。</p>
<p>如果属性使用 ik 分词器，从分词后的索引数据中进行匹配。</p>
<pre><code class="language-java">    /**
     * 短语搜索
     */
    @Test
    public void testMatchPhrase() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.matchPhraseQuery(&quot;title&quot;, &quot;华为荣耀&quot;)
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<h4 id="795-使用-term词组-搜索文档">7.9.5 使用 Term词组 搜索文档</h4>
<pre><code class="language-java">    /**
     * 词组搜索
     */
    @Test
    public void testTerm() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.termQuery(&quot;title&quot;, &quot;华为荣耀&quot;)
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<h4 id="796-使用-range-搜索文档">7.9.6 使用 range 搜索文档</h4>
<pre><code class="language-java">    /**
     * 范围搜索 range
     */
    @Test
    public void testRange() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.rangeQuery(&quot;price&quot;).lte(800000L).gte(200000L)
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<h4 id="797-多条件搜索">7.9.7 多条件搜索</h4>
<pre><code class="language-java">/**
 * 复合条件搜索
 */
@Test
public void testBool() {
    // 创建一个Bool搜索条件。 相当于定义 bool:{ must:[], should:[], must_not:[] }
    BoolQueryBuilder builder = QueryBuilders.boolQuery();
    List&lt;QueryBuilder&gt; mustList = builder.must();
    mustList.add(QueryBuilders.matchQuery(&quot;title&quot;, &quot;华为&quot;));
    mustList.add(QueryBuilders.rangeQuery(&quot;price&quot;).gte(300000L));
    SearchQuery query = new NativeSearchQuery(builder);
    List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
    for (Item item : items) {
        System.out.println(item);
    }
}
</code></pre>
<h4 id="798-分页与排序">7.9.8 分页与排序</h4>
<pre><code class="language-java">    /**
     * 分页和排序
     * 所有的Spring Data子工程中的分页和排序逻辑使用的都是相似的方式。
     * 根据PageRequest和Sort实现分页或排序。
     */
    @Test
    public void testPageable() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.matchAllQuery()
        );
        // 设置分页 ，从第0页开始的两条
        query.setPageable(PageRequest.of(0, 2));
        // 设置排序
        query.addSort(Sort.by(Sort.Direction.DESC, &quot;price&quot;));
        // 设置分页的同时设置排序
        // query.setPageable(PageRequest.of(0,2,Sort.by(Sort.Direction.DESC,&quot;price&quot;)));
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<p>如果实体类中主键只有@Id 注解，String id 对应 ES 中是 text 类型，text 类型是不允许被排序，所以如果必须按照主键进行排序时需要在实体类中设置主键类型</p>
<pre><code class="language-java">@Id
@Field(type = FieldType.Keyword)
private String id;
</code></pre>
<h4 id="799-高亮搜索">7.9.9 高亮搜索</h4>
<pre><code class="language-java">
    /**
     * 高亮
     */
    @Test
    public void testHighlight(){
        HighlightBuilder.Field field = new HighlightBuilder.Field(&quot;title&quot;);
        field.preTags(&quot;&lt;em&gt;&quot;);
        field.postTags(&quot;&lt;/em&gt;&quot;);

        NativeSearchQuery query =
                new NativeSearchQueryBuilder()
                        // 排序
                        .withSort(SortBuilders.fieldSort(&quot;price&quot;).order(SortOrder.ASC))
                        // 分页
                        .withPageable(PageRequest.of(0, 2))
                        // 搜索条件
                        .withQuery(QueryBuilders.matchQuery(&quot;title&quot;, &quot;华为&quot;))
                        // 设置高亮字段
                        .withHighlightFields(field)
                        .build();

        AggregatedPage&lt;? extends Item&gt; pageResult =
                elasticsearchRestTemplate.queryForPage(query, Item.class, new SearchResultMapper() {
                    // 处理搜索结果，搜索的完整结果，也就是那个集合。
                    // response - 就是搜索的结果，相当于在Kibana中执行搜索的结果内容。
                    // clazz - 就是返回结果的具体类型
                    // pageable - 分页处理，就是queryForPage方法参数query中的pageable对象。
                    @Override
                    public &lt;T&gt; AggregatedPage&lt;T&gt; mapResults(SearchResponse response,
                                                            Class&lt;T&gt; clazz,
                                                            Pageable pageable) {
                        // 获取搜索的结果数据
                        SearchHit[] hits = response.getHits().getHits();
                        List&lt;T&gt; resultList = new ArrayList&lt;&gt;();
                        for(SearchHit hit : hits){
                            // 搜索的source源
                            Map&lt;String, Object&gt; map = hit.getSourceAsMap();
                            Item item = new Item();
                            item.setId(map.get(&quot;id&quot;).toString());
                            item.setSellPoint(map.get(&quot;sellPoint&quot;).toString());
                            item.setPrice(Long.parseLong(map.get(&quot;price&quot;).toString()));
                            item.setNum(Integer.parseInt(map.get(&quot;num&quot;).toString()));
                            // 高亮数据处理。key - 字段名， value - 是高亮数据结果
                            Map&lt;String, HighlightField&gt; highlightFieldMap = hit.getHighlightFields();
                            HighlightField highlightField = highlightFieldMap.get(&quot;title&quot;);
                            if (highlightField == null){ // 没有高亮的title
                                item.setTitle(map.get(&quot;title&quot;).toString());
                            }else{ // 有高亮的title
                                item.setTitle(highlightField.getFragments()[0].toString());
                            }
                            resultList.add((T)item);
                        }
                        // 返回处理后的结果

                        return new AggregatedPageImpl&lt;&gt;(
                                resultList, pageable, response.getHits().getTotalHits()
                        );
                    }

                    // 不提供实现，这个是处理每个搜索结果的方法
                    @Override
                    public &lt;T&gt; T mapSearchHit(SearchHit searchHit, Class&lt;T&gt; type) {
                        return null;
                    }
                });

        for(Item item : pageResult.getContent()){
            System.out.println(item);
        }
    }

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Solr]]></title>
        <id>https://jonchan1013.github.io/post/solr/</id>
        <link href="https://jonchan1013.github.io/post/solr/">
        </link>
        <updated>2020-07-16T09:16:14.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716171735.png" alt="" loading="lazy"></figure>
<h2 id="1-solr-简介">1、Solr 简介</h2>
<h3 id="11-为什么使用-solr">1.1 为什么使用 Solr</h3>
<p>在海量数据下，对 MySQL 或 Oracle 进行模糊查询或条件查询的效率是很低的。而搜索功能在绝大多数项目中都是必须的，如何提升搜索效率是很多互联网项目必须要考虑的问题。<br>
既然使用关系型数据库进行搜索效率比较低，最直接的解决方案就是使用专用搜索工具进行搜索，从而提升搜索效率。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716171735.png" alt="" loading="lazy"></figure>
<h2 id="1-solr-简介">1、Solr 简介</h2>
<h3 id="11-为什么使用-solr">1.1 为什么使用 Solr</h3>
<p>在海量数据下，对 MySQL 或 Oracle 进行模糊查询或条件查询的效率是很低的。而搜索功能在绝大多数项目中都是必须的，如何提升搜索效率是很多互联网项目必须要考虑的问题。<br>
既然使用关系型数据库进行搜索效率比较低，最直接的解决方案就是使用专用搜索工具进行搜索，从而提升搜索效率。</p>
<!-- more -->
<h3 id="12-常见搜索解决方案">1.2 常见搜索解决方案</h3>
<p>基于 Apache Lucene（全文检索工具库）实现搜索。但是 Lucene 的使用对于绝大多数的程序员都是“噩梦级”的。</p>
<p>基于谷歌 API 实现搜索。</p>
<p>基于百度 API 实现搜索。</p>
<h3 id="13-solr-简介">1.3 Solr 简介</h3>
<p>Solr 是基于 Apache Lucene 构建的用于搜索和分析的开源解决方案。可提供可扩展索引、搜索功能、高亮显示和文字解析功能。</p>
<p>Solr 本质就是一个 Java web 项目，且内嵌了 Jetty 服务器，所以安装起来非常方便。客户端操作 Solr 的过程和平时我们所写项目一样，就是请求 Solr 中控制器，处理完数据后把结果响应给客户端。</p>
<h3 id="14-正向索引和反向索引">1.4 正向索引和反向索引</h3>
<p>只要讨论搜索就不得不提的两个概念：正向索引（forward index）和反向索引(invertedindex)。</p>
<p>正向索引：从文档内容到词组的过程。每次搜索的时候需要搜索所有文档，每个文档比较搜索条件和词组。</p>
<table>
<thead>
<tr>
<th style="text-align:center">文档</th>
<th style="text-align:center">词组</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">I am a chinese</td>
<td style="text-align:center">I,am,a,chinses</td>
</tr>
</tbody>
</table>
<p>反向索引：是正向索引的逆向。建立词组和文档的映射关系。通过找到词组就能找到文档内容。（和新华字典找字很像）</p>
<table>
<thead>
<tr>
<th style="text-align:center">词组</th>
<th style="text-align:center">文档</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">I,am,a,chinses</td>
<td style="text-align:center">I am a chinese</td>
</tr>
</tbody>
</table>
<h2 id="2-solr-搜索原理">2、Solr 搜索原理</h2>
<h3 id="21-搜索原理">2.1 搜索原理</h3>
<p>Solr 能够提升检索效率的主要原因就是<strong>分词和索引（反向索引）</strong>。</p>
<p>分词：会对搜索条件/存储内容进行分词，分成日常所使用的词语。</p>
<p>索引：存储在 Solr 中内容会按照程序员的要求来是否建立索引。如果要求建立索引会把存储内容中关键字（分词）建立索引。</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718221615.png" alt="" loading="lazy"></figure>
<h3 id="22-solr-中数据存储说明">2.2 Solr 中数据存储说明</h3>
<p>Solr 为了给内容建立索引，所以 Solr 就必须具备数据存储能力。所有需要被搜索的内容都需要存储在 Solr 中，在开发中需要把数据库中数据添加到 Solr 中进行初始化，每次修改数据库中数据还需要同步 Solr 中的数据。</p>
<p>Solr 中数据存储是存储在 Document 对象中，对象中可以包含的属性和属性类型都定义在 schema.xml 中。如果需要自定义属性或自定义属性类型都需要修改 schema.xml 配置文件。从 Solr5 开始 schema.xml 更改名称为 managed-schema(没有扩展名)</p>
<h2 id="3-solr-单机版安装">3、 Solr 单机版安装</h2>
<p>Solr 是使用 Java 编写，所以必选先安装 JDK。</p>
<ol>
<li>
<p>上传并解压<br>
上传压缩包 solr-8.2.0.tgz 到/usr/local/tmp 中。</p>
<p>解压</p>
<p>cd /usr/local/tmp</p>
<p>tar zxf solr-8.2.0.tgz</p>
</li>
<li>
<p>复制到/usr/local 中</p>
<p>cp -r solr-8.2.0 ../solr</p>
</li>
<li>
<p>修改启动参数<br>
修改启动参数，否则启动时报警告。提示设置 SOLR_ULIMIT_CHECKS=false</p>
</li>
</ol>
<p>cd /usr/local/solr/bin</p>
<p>vim solr.in.sh</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718221843.png" alt="" loading="lazy"></figure>
<ol start="4">
<li>启动 Solr<br>
Solr 内嵌 Jetty，直接启动即可。默认监听 <strong>8983 端口。</strong></li>
</ol>
<p>Solr 默认不推荐 root 账户启动，如果是 root 账户启动需要添加-force 参数。</p>
<p>./solr start -force</p>
<h2 id="4-可视化管理界面">4、可视化管理界面</h2>
<p>在关闭防火墙的前提下，可以在 windows 的浏览器中访问 Solr。</p>
<p>输入: http://124.70.181.124:8983 就可以访问 Solr 的可视化管理界面。</p>
<p>左侧有 5 个菜单。分别是：</p>
<p>（1）Dashboard：面板显示 Solr 的总体信息。</p>
<p>（2）Logging：日志</p>
<p>（3）Core Admin：Solr 的核心。类似于数据的 Database</p>
<p>（4）Java Perperties：所有 Java 相关属性。</p>
<p>（5）Thread Dump：线程相关信息。</p>
<p>（6）如果有 Core，将显示在此处。</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222009.png" alt="" loading="lazy"></figure>
<h2 id="5-新建核心">5、新建核心</h2>
<p>Solr 安装完成后默认是没有核心的。需要手动配置。</p>
<p>需要在 solr/server/solr 下新建文件夹，并给定配置文件，否则无法建立。</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222032.png" alt="" loading="lazy"></figure>
<ol>
<li>
<p>新建目录<br>
在/usr/local/solr/server/solr 中新建自定义名称目录。此处示例名称为 testcore。</p>
<p>cd /usr/local/solr/server/solr</p>
<p>mkdir testcore</p>
</li>
<li>
<p>复制配置文件<br>
在 configsets 里面包含了_default 和 sample_techproducts_configs。里面都是配置文件示例。_default 属于默认配置，较纯净。sample_techproducts_configs 是带有了一些配置示例。</p>
</li>
</ol>
<p>cp -r configsets/_default/conf/ testcore/</p>
<ol start="3">
<li>
<p>填写 Core 信息<br>
在可视化管理界面中 Core Admin 中编写信息后点击 Add Core 后，短暂延迟后testcore 就会创建成功。schema 处不用更改。</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222147.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>出现 testcore<br>
在客户端管理界面中，选择新建的 Core 后，就可以按照自己项目的需求进行操作了。</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222200.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h2 id="6-分词-analysis">6、 分词 Analysis</h2>
<p>在 Solr 可 视 化 管 理 界 面 中 ， Core 的 管 理 菜 单 项 中 都 会 有 Analysis 。 表 示 根 据Scheme.xml(managed-schema)中配置要求进行解析。</p>
<p>对英文解析就比较简单了，只要按照空格把英文语句拆分成英文单词即可。</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222225.png" alt="" loading="lazy"></figure>
<p>但是如果条件是中文时，把一句话按照字进行拆分就不是很合理了。正确的方式是按照合理的词组进行拆分。</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222236.png" alt="" loading="lazy"></figure>
<h3 id="61-中文分词器安装及配置步骤">6.1 中文分词器安装及配置步骤</h3>
<p>上传 ik-analyzer.jar 到 webapps 中。</p>
<p>去 https://search.maven.org/search?q=com.github.magese 下 载 对 应 版 本 的ik-analyzer。可以在&quot;软件/Analyzer&quot;中直接获取。</p>
<ol>
<li>
<p>上传 jar 到指定目录<br>
上传 ik-analyzer-8.2.0.jar 到</p>
<p>/usr/local/solr/server/solr-webapp/webapp/WEB-INF/lib 目录中</p>
</li>
<li>
<p>修改配置文件<br>
修改/usr/local/solr/server/solr/testcore/conf/managed-schema</p>
<p>vim /usr/local/solr/server/solr/testcore/conf/managed-schema</p>
<p>添加下面内容。</p>
<p>排版：Esc 退出编辑状态下：gg=G</p>
<pre><code class="language-xml">    &lt;field name=&quot;myfield&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; /&gt;

    &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt;
      &lt;analyzer type=&quot;index&quot;&gt;
        &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot; 
          useSmart=&quot;false&quot; conf=&quot;ik.conf&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
      &lt;/analyzer&gt;
      &lt;analyzer type=&quot;query&quot;&gt;
        &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot; 
          useSmart=&quot;true&quot; conf=&quot;ik.conf&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
      &lt;/analyzer&gt;
    &lt;/fieldType&gt;

</code></pre>
</li>
<li>
<p>重启</p>
<p>cd /usr/local/solr/bin</p>
<p>./solr stop -all</p>
<p>./solr start -force</p>
</li>
<li>
<p>验证<br>
可以在可视化管理界面中找到 myfield 属性进行验证。</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222452.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="62-managed-schema-配置说明">6.2 managed-schema 配置说明</h3>
<ol>
<li>
<fieldType/>
表 示 定 义 一 个 属 性 类 型 。 在 Solr 中 属 性 类 型 都 是 自 定 义 的 。 在 上 面 配 置 中name="text_ik"为自定义类型。当某个属性取值为 text_ik 时 IK Analyzer 才能生效。
</li>
<li>
<field/>
表示向 Document 中添加一个属性。
<p>常用属性：</p>
<p>name: 属性名</p>
<p>type:属性类型。所有类型都是 solr 使用<fieldType>配置的</p>
<p>indexed: 是否建立索引</p>
<p>stored: solr 是否把该属性值响应给搜索用户。</p>
<p>required：该属性是否是必须的。默认 id 是必须的。</p>
<p>multiValued：如果为 true，表示该属性为复合属性，此属性中包含了多个其他的属性。常用在多个列作为搜索条件时，把这些列定义定义成一个新的复合属性，通过搜索一个复合属性就可以实现搜索多个列。当设置为 true 时与<copyField source="" dest=""/>结合使用</p>
</li>
<li>
<uniqueKey>
唯一主键，Solr 中默认定义 id 属性为唯一主键。ID 的值是不允许重复的。
</li>
<li>
<dynamicField>
名称中允许*进行通配。代表满足特定名称要求的一组属性。
</li>
</ol>
<h2 id="7-dataimport">7、 Dataimport</h2>
<p>可以使用 Solr 自带的 Dataimport 功能把数据库中数据快速导入到 solr 中.</p>
<p>必须保证 managed-schema 和数据库中表的列对应。</p>
<ol>
<li>
<p>修改配置文件<br>
修改 solrconfig.xml，添加下面内容</p>
<pre><code class="language-xml">&lt;!-- 配置数据导入的处理器 --&gt;

 &lt;requestHandler name=&quot;/dataimport&quot; class=&quot;org.apache.solr.handler.dataimport.DataImportHandler&quot;&gt;

	&lt;lst name=&quot;defaults&quot;&gt;

		&lt;!-- 加载 data-config.xml --&gt;

		&lt;str name=&quot;config&quot;&gt;data-config.xml&lt;/str&gt;

	&lt;/lst&gt;

 &lt;/requestHandler&gt;
</code></pre>
</li>
<li>
<p>新建 data-config.xml</p>
<p>和 solrconfig.xml 同一目录下新建 data-config.xml</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;dataConfig&gt;
	&lt;dataSource 
		type=&quot;JdbcDataSource&quot;  
		driver=&quot;com.mysql.jdbc.Driver&quot;
		url=&quot;jdbc:mysql://124.70.181.124:3306/ego2&quot;
		user=&quot;root&quot;
		password=&quot;Chenyong.123&quot;/&gt;&lt;/dataSource&gt;

&lt;document&gt;

	&lt;entity name=&quot;product&quot; query=&quot;SELECT id,title from tb_item&quot;&gt;

	&lt;!--实现数据库的列和索引库的字段的映射
		column 指定数据库的列表
		name 指定索引库的字段名字，必须和 schema.xml 中定义的一样
	--&gt;
	&lt;field column=&quot;id&quot; name=&quot;id&quot;/&gt;
	&lt;field column=&quot;title&quot; name=&quot;myfield&quot;/&gt;
&lt;/entity&gt;
&lt;/document&gt;

&lt;/dataConfig&gt;
</code></pre>
</li>
<li>
<p>添加 jar<br>
向 solr-webapp 中添加三个 jar。在 dist 中两个还有一个数据库驱动。</p>
</li>
</ol>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222810.png" alt="" loading="lazy"></figure>
<ol start="4">
<li>
<p>操作<br>
重启 solr 后，在可视化管理页面中进行数据导入。</p>
<p>注意：</p>
<p>点击导入按钮后，要记得点击刷新按钮。</p>
</li>
</ol>
<h2 id="8-菜单项目-documents-使用办法">8、菜单项目 Documents 使用办法</h2>
<p>以 XML 格式举例</p>
<h3 id="81-新增修改">8.1 新增/修改</h3>
<p>当 id 不存在时新增，当 id 存在修改。</p>
<pre><code class="language-xml">&lt;doc&gt;

&lt;field name=&quot;id&quot;&gt;8&lt;/field&gt;

&lt;field name=&quot;name&quot;&gt;明天更大卖&lt;/field&gt;

&lt;field name=&quot;price&quot;&gt;98&lt;/field&gt;

&lt;/doc&gt;
</code></pre>
<h3 id="82-删除">8.2  删除</h3>
<ol>
<li>
<p>根据主键删除</p>
<pre><code class="language-xml">&lt;delete&gt;

&lt;id&gt;8&lt;/id&gt;

&lt;/delete&gt;
</code></pre>
</li>
<li>
<p>根据条件删除</p>
<pre><code class="language-xml">&lt;delete&gt;

&lt;query&gt;*:*&lt;/query&gt;

&lt;/delete&gt;
</code></pre>
</li>
</ol>
<h2 id="9-菜单项目-query-查询使用办法">9、菜单项目 query 查询使用办法</h2>
<h3 id="91-查询全部">9.1  查询全部</h3>
<p>只要在 q 参数中写入*:*既是搜索全部数据。</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223217.png" alt="" loading="lazy"></figure>
<h3 id="92-条件查询">9.2 条件查询</h3>
<p>在 q 参数部分写入 字段名:搜索条件值， 既是条件搜索</p>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223236.png" alt="" loading="lazy"></figure>
<h3 id="93-分页查询">9.3 分页查询</h3>
<p>在条件 start,rows 中输入从第几条数据开始查询，查询多少条数据。下标从 0 开始。类似 MySQL 数据库中的 limit。</p>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223256.png" alt="" loading="lazy"></figure>
<h3 id="94-查询排序">9.4 查询排序</h3>
<p>在 sort 条件中输入 字段名 排序规则。 排序规则包括 asc 和 desc。</p>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223320.png" alt="" loading="lazy"></figure>
<h3 id="95-高亮查询">9.5 高亮查询</h3>
<p>选中 hl 高亮复选框，在 hl.fl 中输入高亮显示的字段名称，在 hl.simple.pre 中输入高亮前缀，在 hl.simple.post 中输入高亮后缀。</p>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223339.png" alt="" loading="lazy"></figure>
<h2 id="10-使用-solrj-操作-solr">10、使用 SolrJ 操作 Solr</h2>
<p>SolrJ 是 Solr 提供的 Java 客户端 API。通过 SolrJ 可以实现 Java 程序对 Solr 中数据的操作。</p>
<p>大前提：添加 SolrJ 依赖。依赖版本和 Solr 版本严格对应</p>
<pre><code class="language-xml"> &lt;dependencies&gt;
     &lt;dependency&gt;
         &lt;groupId&gt;org.apache.solr&lt;/groupId&gt;
         &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt;
         &lt;version&gt;8.2.0&lt;/version&gt;
     &lt;/dependency&gt;
 &lt;/dependencies&gt;
</code></pre>
<pre><code class="language-java">/**
 * 使用SolrJ访问Solr服务。
 */
public class FirstAccess {
    public static void main(String[] args) {
        search();
    }

    // 搜索数据
    public static void search(){
        HttpSolrClient client = null;
        try{
            String url = &quot;http://124.70.181.124:8983/solr/testcore&quot;;
            client = new HttpSolrClient.Builder(url).build();

            // 创建搜索条件对象。
            SolrQuery params = new SolrQuery();
            // 提供搜索关键字， q  *:*
            params.setQuery(&quot;title_zh_cn:管理&quot;);

            // 排序
            params.setSort(&quot;id&quot;, SolrQuery.ORDER.asc);

            // 分页
            params.setStart(0); // 第几行开始查询
            params.setRows(3); // 查询多少行

            // 高亮
            // 开启高亮
            params.setHighlight(true);
            // 设置高亮字段，如果有多个高亮字段，多次调用当前方法。
            params.addHighlightField(&quot;title_zh_cn&quot;);
            // 设置高亮前缀
            params.setHighlightSimplePre(&quot;&lt;span style='color:red'&gt;&quot;);
            // 设置高亮后缀
            params.setHighlightSimplePost(&quot;&lt;/span&gt;&quot;);

            // 搜索数据
            QueryResponse response = client.query(params);

            // 从响应中获取高亮结果数据集合 {主键:{字段名:[&quot;高亮数据&quot;, &quot;高亮数据&quot;]}}
            Map&lt;String, Map&lt;String, List&lt;String&gt;&gt;&gt; highlightMap = response.getHighlighting();

            // 获取搜索返回结果集合  SolrDocumentList 是List接口的实现。 固定泛型是 SolrDocument
            SolrDocumentList docList = response.getResults();
            System.out.println(&quot;本次查询返回数据行数&quot; + docList.size());
            System.out.println(&quot;本次搜索总计数据行数&quot; + docList.getNumFound());
            for(SolrDocument doc : docList){
                System.out.print(doc + &quot;【 id = &quot; + doc.getFieldValue(&quot;id&quot;)
                        + &quot;， title_zh_cn = &quot; + doc.getFieldValue(&quot;title_zh_cn&quot;) + &quot;】&quot;);

                // 输出高亮
                // 根据当前文档主键查询高亮数据
                Map&lt;String, List&lt;String&gt;&gt; entry = highlightMap.get(doc.getFieldValue(&quot;id&quot;));
                if(null != entry &amp;&amp; entry.size() &gt; 0){
                    // 有高亮数据
                    List&lt;String&gt; hlStrList = entry.get(&quot;title_zh_cn&quot;);
                    System.out.println(&quot; 高亮数据内容是：【&quot; + hlStrList + &quot;】&quot;);
                }

                System.out.println();
            }
        }catch(Exception e){
            e.printStackTrace();
        }finally {
            try {
                client.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    // 删除数据
    public static void delete(){
        HttpSolrClient client = null;
        try{
            String url = &quot;http://124.70.181.124:8983/solr/testcore&quot;;
            client = new HttpSolrClient.Builder(url).build();

            // 删除数据
            client.deleteById(&quot;2000&quot;);  // 删除单数据

            client.deleteById(Arrays.asList(&quot;100&quot;, &quot;101&quot;, &quot;102&quot;, &quot;103&quot;)); // 批量删除

            client.deleteByQuery(&quot;title_zh_cn:角色&quot;); // 条件删除， 条件格式 -  字段名:条件数据

            client.commit();
        }catch(Exception e){
            e.printStackTrace();
        }finally {
            try {
                client.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    // 保存数据到Solr，如果主键字段id值唯一就是新增，不唯一就是覆盖（更新）
    public static void save(){
        HttpSolrClient client = null;
        try {
            // 创建客户端
            String url = &quot;http://124.70.181.124:8983/solr/testcore&quot;;
            client = new HttpSolrClient.Builder(url).build();

            // 创建要保存的数据对象
            SolrInputDocument doc = new SolrInputDocument();
            doc.addField(&quot;id&quot;, &quot;2000&quot;);
            doc.addField(&quot;title_zh_cn&quot;, &quot;SolrJ保存数据-二次执行&quot;);

            // 执行数据保存
            client.add(doc);

            // 事务管理
            client.commit(); // 提交当前url指向的core collection
            // client.commit(&quot;testcore&quot;);  // 提供core collection名称，指定提交事务

        }catch(Exception e){
            e.printStackTrace();
        }finally{
            // 回收资源
            try {
                client.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}

</code></pre>
<h2 id="11-spring-data-for-apache-solr">11、 Spring Data for Apache Solr</h2>
<h3 id="111-spring-data-简介">11.1 Spring Data 简介</h3>
<p>Spring Data 是 Spring 的顶级项目。里面包含了 N 多个二级子项目，每个子项目对应一种技术或工具。其目的为了让数据访问更加简单，更加方便的和 Spring 进行整合。</p>
<p>Spring Data 项目如果单独使用是还需要配置 XML 配置文件的，当和 Spring Boot整合后使用起来非常方便。spring-boot-starter-data-xx 就是对应的启动器。</p>
<h3 id="112-实现步骤">11.2 实现步骤</h3>
<ol>
<li>添加依赖</li>
</ol>
<pre><code class="language-xml">    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
                &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-data-solr&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre>
<ol start="2">
<li>
<p>编写配置文件</p>
<pre><code class="language-yaml">spring:
  data:
    solr:
      host: http://124.70.181.124:8983/solr # 配置solr服务器所在地址
</code></pre>
</li>
<li>
<p>编写实体类</p>
<pre><code class="language-java">@SolrDocument(collection = &quot;testcore&quot;)
public class Menu implements Serializable {
    // @Id - 代表当前字段是唯一主键字段。 在高亮查询的时候，需要检查。
    @Field(value = &quot;id&quot;)
    @Id
    private Long id;
    @Field(value = &quot;myfield&quot;)
    private String title;

    public Long getId() {
        return id;
    }

    public void setId(Long id) {
        this.id = id;
    }

    public String getTitle() {
        return title;
    }

    public void setTitle(String title) {
        this.title = title;
    }

    public Menu(Long id, String title) {
        this.id = id;
        this.title = title;
    }

    public Menu() {
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        Menu menu = (Menu) o;
        return Objects.equals(id, menu.id) &amp;&amp;
                Objects.equals(title, menu.title);
    }

    @Override
    public int hashCode() {
        return Objects.hash(id, title);
    }

    @Override
    public String toString() {
        return &quot;Menu{&quot; +
                &quot;id=&quot; + id +
                &quot;, title=&quot; + title +
                '}';
    }
}

</code></pre>
</li>
<li>
<p>编写测试类</p>
<pre><code class="language-java">/**
 * SpringBootTest测试类型
 */
@SpringBootTest(classes = {FirstSolrApp.class})
@RunWith(SpringRunner.class)
public class TestSolr {
    /**
     * SpringData的所有子工程，几乎都会提供一个XxxTemplate类型，
     * 这个Template是用来实现客户端服务器数据交互的对象。
     */
    @Autowired
    private SolrTemplate template;

    /**
     * 保存数据
     * 使用SpringData开发数据访问的时候，不要回收资源，因为SpringData会自动维护数据源连接池
     */
    @Test
    public void testSave() {
        //创建要保存的对象
        SolrInputDocument doc = new SolrInputDocument();
        doc.addField(&quot;id&quot;, &quot;2000&quot;);
        doc.addField(&quot;myfield&quot;, &quot;使用SpringDataForApacheSolr实现数据保存&quot;);
        //数据保存。主键唯一是新增，不是则为覆盖
        UpdateResponse response = template.saveBean(&quot;testcore&quot;, doc);

        System.out.println(response.getStatus() == 0 ? &quot;保存成功&quot; : &quot;保存失败&quot;);

        //提交事务
        template.commit(&quot;testcore&quot;);
    }

    /**
     * 输出数据
     */
    @Test
    public void testDelete() {
        //主键删除唯一数据
        UpdateResponse response = template.deleteByIds(&quot;testcore&quot;, &quot;2000&quot;);
        System.out.println(response.getStatus() == 0 ? &quot;删除成功&quot; : &quot;删除失败&quot;);

        //根据主键批量删除数据
        response = template.deleteByIds(&quot;testcore&quot;, Arrays.asList(&quot;20001&quot;, &quot;2002&quot;));
        System.out.println(response.getStatus() == 0 ? &quot;批量删除成功&quot; : &quot;批量删除失败&quot;);

        //根据查询条件删除
        SimpleQuery query = new SimpleQuery();
        // Criteria.where(&quot;title_zh_cn&quot;) - 提供一个搜索条件，对应的字段名是什么
        // criteria.is(&quot;参数&quot;) - 为这个搜索条件绑定具体的参数值
        query.addCriteria(Criteria.where(&quot;myfield&quot;).is(&quot;Spring&quot;));
        response = template.delete(&quot;testcore&quot;, query);
        System.out.println(response.getStatus() == 0 ? &quot;条件删除成功&quot; : &quot;条件删除失败&quot;);

        //提交事务
        template.commit(&quot;testcore&quot;);

    }

    /**
     * 搜索数据
     */
    @Test
    public void testSearch(){
        //创建搜索条件
        SimpleQuery query = new SimpleQuery();
        query.addCriteria(Criteria.where(&quot;myfield&quot;).is(&quot;数据&quot;));

        //分页
        query.setOffset(0L); //第几行开始查询
        query.setRows(3); //查询多少数据
        //排序
        query.addSort(Sort.by(Sort.Direction.DESC,&quot;id&quot;));

        //执行搜索
        // 参数 ：collection - 索引库名称， query - 搜索条件， Class - 实体类对象
        ScoredPage&lt;Menu&gt; scoredPage = template.queryForPage(&quot;testcore&quot;, query, Menu.class);

        //处理结果
        System.out.println(&quot;总计数据行数:&quot;+scoredPage.getTotalElements());
        System.out.println(&quot;总计页码数:&quot;+scoredPage.getTotalPages());
        //搜索的结果集合
        List&lt;Menu&gt; list = scoredPage.getContent();
        System.out.println(list);
    }

    /**
     * 高亮搜索
     */
    @Test
    public void testHighlightSearch(){
        SimpleHighlightQuery query = new SimpleHighlightQuery();
        query.addCriteria(Criteria.where(&quot;myfield&quot;).is(&quot;数据&quot;));
        // 设置高亮
        // 创建高亮设置对象
        HighlightOptions options = new HighlightOptions();
        // 设置高亮字段名
        options.addField(&quot;myfield&quot;);
        // 设置高亮前后缀
        options.setSimplePrefix(&quot;&lt;span&gt;&quot;);
        options.setSimplePostfix(&quot;&lt;/span&gt;&quot;);
        query.setHighlightOptions(options);

        // 搜索
        HighlightPage&lt;Menu&gt; page = template.queryForHighlightPage(&quot;testcore&quot;, query, Menu.class);
        List&lt;Menu&gt; result = new ArrayList&lt;&gt;();
        // 获取搜索结果中高亮处理过的结果。
        List&lt;HighlightEntry&lt;Menu&gt;&gt; list = page.getHighlighted();
        for(HighlightEntry&lt;Menu&gt; entry: list){
            // 获取entry中的高亮数据集合
            List&lt;HighlightEntry.Highlight&gt; highlights = entry.getHighlights();
            // 获取没有经过高亮处理的结果对象
            Menu menu = entry.getEntity();
            for (HighlightEntry.Highlight highlight : highlights){
                // 判断高亮数据的字段是否是自己需要的。
                if(highlight.getField().getName().equals(&quot;myfield&quot;)) {
                    // 获取高亮处理的字符串
                    String highlightString = highlight.getSnipplets().get(0);
                    // 把高亮处理的字符串赋值给对象。
                    menu.setTitle(highlightString);
                }
            }
            result.add(menu);
        }
        System.out.println(result);
    }
}

</code></pre>
</li>
</ol>
<h2 id="12-solrcloud">12、SolrCloud</h2>
<p>Solr 可以搭建具备容错能力和高可用的 Solr 集群。集群中集群配置、自动负载均衡和查询故障转移、Zookeeper 集群实现集群协调管理，这些全部功能统称为 SolrCloud。</p>
<p>SolrCloud 是基于 Zookeeper 进行管理的。在 Solr 中已经内置了 Zookeeper 相关内容，当执行集群创建命令会自动创建 Zookeeper 相关内容。这个使用的是 Zookeeper 的集群管理功能实现的。</p>
<ol>
<li>
<p>创建<br>
SolrCloud 已经包含在了 Solr 中，可以直接启动 Solr 集群。</p>
<p>./solr -e cloud -noprompt -force</p>
<p>此命令等同于# ./solr -e cloud -force 全部参数为默认值。</p>
<p>运行成功后会在 example 文件夹多出 cloud 文件夹。</p>
</li>
<li>
<p>停止</p>
<p>./solr stop -all</p>
</li>
<li>
<p>重新运行</p>
</li>
</ol>
<p>./solr start -c -p 8983 -s ../example/cloud/node1/solr/ -force</p>
<p>./solr start -c -p 7574 -z localhost:9983 -s ../example/cloud/node2/solr/ -force</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MyCat]]></title>
        <id>https://jonchan1013.github.io/post/mycat/</id>
        <link href="https://jonchan1013.github.io/post/mycat/">
        </link>
        <updated>2020-07-15T09:23:05.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715172709.png" alt="" loading="lazy"></figure>
<h2 id="1-mycat-简介">1、MyCat 简介</h2>
<h3 id="11-什么是-mycat">1.1 什么是 MyCat</h3>
<p>MyCat 是目前最流行的基于 java 语言编写的数据库中间件，是一个实现了 MySQL 协议的服务器，前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问，而其后端可以用 MySQL 原生协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分库分表。配合数据库的主从模式还可实现读写分离。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715172709.png" alt="" loading="lazy"></figure>
<h2 id="1-mycat-简介">1、MyCat 简介</h2>
<h3 id="11-什么是-mycat">1.1 什么是 MyCat</h3>
<p>MyCat 是目前最流行的基于 java 语言编写的数据库中间件，是一个实现了 MySQL 协议的服务器，前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问，而其后端可以用 MySQL 原生协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分库分表。配合数据库的主从模式还可实现读写分离。</p>
<!-- more -->
<p>MyCat 是基于阿里开源的 Cobar 产品而研发，Cobar 的稳定性、可靠性、优秀的架构和性能以及众多成熟的使用案例使得 MyCat 变得非常的强大。<br>
MyCat 发展到目前的版本，已经不是一个单纯的 MySQL 代理了，它的后端可以支持MySQL、SQL Server、Oracle、DB2、PostgreSQL 等主流数据库，也支持 MongoDB 这种新型NoSQL 方式的存储，未来还会支持更多类型的存储。而在最终用户看来，无论是那种存储方式，在 MyCat 里，都是一个传统的数据库表，支持标准的 SQL 语句进行数据的操作，这样一来，对前端业务系统来说，可以大幅降低开发难度，提升开发速度。<br>
MyCat 官网：http://www.mycat.io/</p>
<h3 id="12-使用-mycat-后的结构图">1.2 使用 Mycat 后的结构图</h3>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716163049.png" alt="" loading="lazy"></figure>
<h3 id="13-使用-mycat-的优势">1.3 使用 Mycat 的优势</h3>
<ol>
<li>
<p>数据量级</p>
<p>单一的 MySQL 其数据存储量级和操作量级有限.<br>
Mycat 可以管理若干 MySQL 数据库,同时实现数据的存储和操作.</p>
</li>
<li>
<p>开源性质<br>
Mycat 是 java 编写的中间件. 开源,免费.<br>
有非常多的人和组织对 Mycat 实行开发,维护,管理,更新.<br>
Mycat 版本提升较快,可以跟随环境发展.如果有问题,可以快速解决.<br>
Mycat 有开源网站和开源社区.且有官方发布的电子书籍.<br>
Mycat 是阿里原应用 corba 转型而来的.</p>
</li>
<li>
<p>市场应用<br>
2015 年左右,Mycat 在互联网应用中占比非常高.</p>
</li>
</ol>
<h2 id="2-mycat-中的概念">2、 MyCat 中的概念</h2>
<h3 id="21-切分">2.1 切分</h3>
<p>逻辑上的切分. 在物理层面,是使用多库[database],多表[table]实现的切分.</p>
<h4 id="211-纵向切分垂直切分">2.1.1 纵向切分/垂直切分</h4>
<p>就是把原本存储于一个库的数据存储到多个库上。<br>
由于对数据库的读写都是对同一个库进行操作，所以单库并不能解决大规模并发写入的问题。<br>
例如，我们会建立定义数据库 workDB、商品数据库 payDB、用户数据库 userDB、日志数据库 logDB 等，分别用于存储项目数据定义表、商品定义表、用户数据表、日志数据表等。<br>
优点<br>
1）减少增量数据写入时的锁对查询的影响。<br>
2）由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘 IO，时延变短。<br>
缺点：无法解决单表数据量太大的问题。</p>
<h4 id="212-横向切分水平切分">2.1.2 横向切分/水平切分</h4>
<p>把原本存储于一个表的数据分块存储到多个表上。当一个表中的数据量过大时，我们可以把该表的数据按照某种规则，进行划分，然后存储到多个结构相同的表，和不同的库上。<br>
例如，我们 userDB 中的 userTable 中数据量很大，那么可以把 userDB 切分为结构相同的多个 userDB：part0DB、part1DB 等，再将 userDB 上的 userTable，切分为很多 userTable：userTable0、userTable1 等，然后将这些表按照一定的规则存储到多个 userDB 上。<br>
优点<br>
1）单表的并发能力提高了，磁盘 I/O 性能也提高了。<br>
2）如果出现高并发的话，总表可以根据不同的查询，将并发压力分到不同的小表里面。<br>
缺点：无法实现表连接查询。</p>
<h3 id="22-逻辑库-schema">2.2 逻辑库-Schema</h3>
<p>Mycat 中定义的 database.是逻辑上存在的.但是物理上是不存在的.<br>
主要是针对纵向切分提供的概念.</p>
<h3 id="23-逻辑表-table">2.3 逻辑表-table</h3>
<p>Mycat 中定义的 table.是逻辑上存在,物理上是不存在的.<br>
主要是针对横向切分提供的概念.</p>
<h3 id="24-默认端口">2.4  默认端口</h3>
<p>MySQL 默认端口是 3306<br>
<strong>Mycat 默认端口是 8066</strong><br>
tomcat 默认端口是 8080<br>
Oracle 默认端口是 1521<br>
nginx 默认端口是 80<br>
http 协议默认端口 80<br>
redis 默认端口 6379</p>
<h3 id="25-数据主机-datahost">2.5  数据主机 - dataHost</h3>
<p>物理 MySQL 存放的主机地址.可以使用主机名,IP,域名定义.</p>
<h3 id="26-数据节点-datanode">2.6 数据节点 - dataNode</h3>
<p>配置物理的 database. 数据保存的物理节点.就是 database.</p>
<h3 id="27-分片规则">2.7 分片规则</h3>
<p>当控制数据的时候,如何访问物理 database 和 table.<br>
就是访问 dataHost 和 dataNode 的算法.<br>
在 Mycat 处理具体的数据 CRUD 的时候,如何访问 dataHost 和 dataNode 的算法.如:哈希算法,crc32 算法等</p>
<h2 id="3-mycat-的使用">3、 MyCat 的使用</h2>
<h3 id="31-读写分离">3.1 读写分离</h3>
<p>原理：需要搭建主从模式，让主数据库（master）处理事务性增、改、删操作（INSERT、UPDATE、DELETE），而从数据库（slave）处理 SELECT 查询操作。<br>
Mycat 配合数据库本身的复制功能，可以解决读写分离的问题。</p>
<h3 id="32-主从备份概念">3.2 主从备份概念</h3>
<p>什么是主从备份: 就是一种主备模式的数据库应用.<br>
主库(Master)数据与备库(Slave)数据完全一致.<br>
实现数据的多重备份, 保证数据的安全.<br>
可以在 Master[InnoDB]和 Slave[MyISAM]中使用不同的数据库引擎,实现读写的分离</p>
<p><strong>MySQL5.5, 5.6 版本后本身支持主从备份</strong></p>
<p>在老旧版本的 MySQL 数据库系统中,不支持主从备份,需要安装额外的 RPM 包.<br>
如果需要安装 RPM,只能在一个位置节点安装.</p>
<h4 id="321-主从备份目的">3.2.1 主从备份目的</h4>
<ol>
<li>
<p>实现主备模式</p>
<p>保证数据的安全. 尽量避免数据丢失的可能.</p>
</li>
<li>
<p>实现读写分离</p>
<p>使用不同的数据库引擎,实现读写分离.提高所有的操作效率.<br>
InnoDB 使用 DML 语法操作. MyISAM 使用 DQL 语法操作.</p>
</li>
</ol>
<h4 id="322-主从备份效果">3.2.2 主从备份效果</h4>
<ul>
<li>
<p>主库操作同步到备库：</p>
<p>所有对 Master 的操作,都会同步到 Slave 中.<br>
<strong>如果 Master 和 Salve 天生上环境不同,那么对 Master 的操作,可能会在 Slave 中出现错误如: 在创建主从模式之前,Master 有 database : db1, db2, db3. Slave 有 database: db1,db2.</strong><br>
<strong>创建主从模式.现在的情况 Master 和 Slave 天生不同.</strong><br>
<strong>主从模式创建成功后,在 Master 中 drop database db3. Slave 中抛出数据库 SQL 异常.后续所有的命令不能同步.</strong><br>
<strong>一旦出现错误. 只能重新实现主从模式.</strong></p>
</li>
</ul>
<h3 id="323-主从模式下的逻辑图">3.2.3  主从模式下的逻辑图</h3>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164034.png" alt="" loading="lazy"></figure>
<h3 id="33-mysql-的主从模式搭建">3.3  MySql 的主从模式搭建</h3>
<ol>
<li>
<p>安装 MySQL<br>
已安装<br>
主库：192.168.70.148<br>
从库：192.168.70.149</p>
</li>
<li>
<p>主从备份配置</p>
</li>
<li>
<p>Master[主库]配置</p>
<ol>
<li>
<p>修改 Master 配置文件<br>
路径：/etc/my.cnf<br>
命令：vim /etc/my.cnf</p>
</li>
<li>
<p>server_id<br>
本环境中 server_id 是 1<br>
MySQL 服务唯一标识</p>
</li>
</ol>
<p>配置要求：<br>
server_id 任意配置,只要是数字即可<br>
server_id Master 唯一标识数字必须小于 Slave 唯一标识数字.</p>
<ol start="3">
<li>
<p>log_bin<br>
本环境中 log_bin 值 : master_log<br>
开启日志功能以及日志文件命名,log_bin=master_log<br>
变量的值就是日志文件名称.是日志文件名称的主体.<br>
MySQL 数据库自动增加文件名后缀和文件类型.</p>
</li>
<li>
<p>重启 MySQL<br>
service mysqld restart</p>
</li>
<li>
<p>配置 Master</p>
<ol>
<li>
<p>访问 MySQL<br>
mysql -uusername -ppassword</p>
</li>
<li>
<p>创建用户<br>
在 MySQL 数据库中,为不存在的用户授权,就是同步创建用户并授权.<br>
此用户是从库访问主库使用的用户<br>
ip 地址不能写为%. 因为主从备份中,当前创建的用户,是给从库 Slave 访问主库 Master使用的.用户必须有指定的访问地址.不能是通用地址.<br>
grant all privileges on <em>.</em> to ‘username’@’ip’ identified by ‘password’ with grant option;<br>
flush privileges;</p>
<pre><code>grant all privileges on *.* to 'myslave'@'192.168.70.149' identified by 'myslave' with grant option;
flush privileges;
</code></pre>
</li>
<li>
<p>查看用户</p>
<p>use mysql;<br>
select host, name from user;</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164332.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>查看 Master 信息<br>
show master status;</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164351.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>关闭防火墙或在防火墙中开放 3306 端口</p>
</li>
</ol>
</li>
</ol>
</li>
<li>
<p>Slave[从库]配置</p>
<ol>
<li>
<p>修改 Slave 配置文件<br>
/etc/my.cnf</p>
</li>
<li>
<p>server_id<br>
唯一标识, 本环境中配置为 : 2</p>
</li>
<li>
<p>重启 MySQL 服务<br>
service mysqld restart</p>
</li>
<li>
<p>配置 Slave</p>
<ol>
<li>
<p>访问 mysql<br>
mysql -uusername -ppassword</p>
</li>
<li>
<p>停止 Slave 功能</p>
<p>stop slave</p>
</li>
<li>
<p>配置主库信息<br>
需要修改的数据是依据 Master 信息修改的. ip 是 Master 所在物理机 IP. 用户名和密码是Master 提供的 Slave 访问用户名和密码. 日志文件是在 Master 中查看的主库信息提供的.在Master 中使用命令 show master status 查看日志文件名称.<br>
change master to master_host=’ip’, master_user=’username’, master_password=’password’,master_log_file=’log_file_name’;</p>
<pre><code>change master to master_host='192.168.70.148',master_user='myslave',master_password='myslave',master_log_file='master_log.000001';
</code></pre>
</li>
<li>
<p>启动 Slave 功能</p>
<p>start slave;</p>
</li>
<li>
<p>查看 Slave 配置<br>
show slave status \G;</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164648.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164709.png" alt="" loading="lazy"></figure>
</li>
</ol>
</li>
</ol>
</li>
<li>
<p>测试主从</p>
<p>新建库</p>
<p>create database demo1 default character set utf8;</p>
<p>新建表</p>
<p>CREATE TABLE <code>t_users</code> (<br>
<code>id</code> int(11) NOT NULL,<br>
<code>name</code> varchar(30) DEFAULT NULL,<br>
PRIMARY KEY (<code>id</code>)<br>
) ENGINE=InnoDB DEFAULT CHARSET=utf8;</p>
<p>添加数据</p>
<p>insert into users values(1,‘admin’)</p>
</li>
</ol>
<h2 id="4-安装-mycat">4、安装 MyCat</h2>
<ol>
<li>
<p>安装环境<br>
192.168.70.150</p>
</li>
<li>
<p>需要配置 JDK<br>
已安装</p>
</li>
<li>
<p>在主数据库和从数据库都需要完成</p>
<ol>
<li>
<p>放开 3306 端口</p>
</li>
<li>
<p>保证 root 用户可以被 mycat 访问<br>
在 Mycat 中通过 Master 数据库的 root 用户访问 Master 数据库.</p>
<p>grant all privileges on <em>.</em> to 'root'@'%' identified by 'root' with grant option;</p>
<p>flush privileges;</p>
</li>
</ol>
</li>
<li>
<p>解压上传的 Mycat 压缩包<br>
tar -zxf Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gz</p>
</li>
<li>
<p>将解压后的文件夹复制到/usr/local/mycat</p>
</li>
<li>
<p>MyCat 目录介绍<br>
bin 目录里是启动脚本<br>
conf 目录里是配置文件<br>
catlet 为 Mycat 的一个扩展功能</p>
<p>lib 目录里是 Mycat 和它的依赖 jar<br>
logs 目录里是 console.log 用来保存控制台日志，和 mycat.log 用来保存 mycat 的 log4j日志</p>
</li>
</ol>
<h2 id="5-mycat-配置文件">5、MyCat 配置文件</h2>
<p>Mycat 的架构其实很好理解，Mycat 是代理，Mycat 后面就是物理数据库。和 Web 服务器的 Nginx 类似。对于使用者来说，访问的都是 Mycat，不会接触到后端的数据库。我们现在做一个主从、读写分离。结构如下图：</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716165236.png" alt="" loading="lazy"></figure>
<p>Mycat 的配置文件都在 conf 目录里面，这里介绍几个常用的文件</p>
<table>
<thead>
<tr>
<th style="text-align:center">文件</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">server.xml</td>
<td style="text-align:center">MyCat 的配置文件，设置账号、参数等</td>
</tr>
<tr>
<td style="text-align:center">schema.xml</td>
<td style="text-align:center">MyCat 对应的物理数据库和数据库表的配置</td>
</tr>
<tr>
<td style="text-align:center">rule.xml</td>
<td style="text-align:center">MyCat 分片（分库分表）规则</td>
</tr>
</tbody>
</table>
<h3 id="51-serverxml">5.1 server.xml</h3>
<p>常见修改内容:</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716165355.png" alt="" loading="lazy"></figure>
<ol>
<li>配置 Mycat 服务信息</li>
</ol>
<p>如: Mycat 中的用户,用户可以访问的逻辑库,可以访问的逻辑表,服务的端口号等</p>
<table>
<thead>
<tr>
<th style="text-align:center">user</th>
<th style="text-align:center">用户配置节点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">--name</td>
<td style="text-align:center">登录的用户名，也就是连接 Mycat 的用户名</td>
</tr>
<tr>
<td style="text-align:center">--password</td>
<td style="text-align:center">登录的密码，也就是连接 Mycat 的密码</td>
</tr>
<tr>
<td style="text-align:center">--schemas</td>
<td style="text-align:center">逻辑库名，这里会和 schema.xml 中的配置关联，多个用逗号分开，例如需要这个用户管理两个数据库 db1,db2，则配置 db1,db2</td>
</tr>
<tr>
<td style="text-align:center">--privileges</td>
<td style="text-align:center">配置用户针对表的增删改查的权限</td>
</tr>
</tbody>
</table>
<p>默认配置了一个账号 root 密码也是 123456,针对数据库 TESTDB,读写权限都有，没有针对表做任何特殊的权限。</p>
<ol start="2">
<li>配置权限</li>
</ol>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716165607.png" alt="" loading="lazy"></figure>
<p>dml 权限顺序为：insert(新增),update(修改),select(查询),delete(删除),0000--&gt; 1111,0 为禁止权限，1 为开启权限。</p>
<h3 id="52-schemaxml">5.2  schema.xml</h3>
<p>schema.xml 是最主要的配置文件，首先看默认的配置文件</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716165647.png" alt="" loading="lazy"></figure>
<h4 id="521-用于定义逻辑库和逻辑表的配置文件">5.2.1 用于定义逻辑库和逻辑表的配置文件</h4>
<p>在配置文件中可以定义读写分离,逻辑库,逻辑表,dataHost,dataNode 等信息.</p>
<table>
<thead>
<tr>
<th style="text-align:center">schema</th>
<th style="text-align:center">配置逻辑库，name 与 server.xml 中 schema 对应</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">dataNode</td>
<td style="text-align:center">定义数据节点的标签，也就是分库相关配置</td>
</tr>
<tr>
<td style="text-align:center">dataHost</td>
<td style="text-align:center">物理数据库，真正存储数据的数据库</td>
</tr>
</tbody>
</table>
<h4 id="522-节点与属性介绍">5.2.2 节点与属性介绍</h4>
<ol>
<li>
<p>标签 schema</p>
<p>配置逻辑库的标签</p>
<ol>
<li>属性 name<br>
逻辑库名称</li>
<li>属性 checkSQLschema<br>
是否检测 SQL 语法中的 schema 信息.<br>
如: Mycat 逻辑库名称 A, dataNode 名称 B<br>
SQL : select * from A.table;<br>
checkSQLschema 值是 true, Mycat 发送到数据库的 SQL 是 select * from table;<br>
checkSQLschema 只是 false,Mycat 发送的数据库的 SQL 是 select * from A.table;</li>
<li>sqlMaxLimit<br>
Mycat 在执行 SQL 的时候,如果 SQL 语句中没有 limit 子句.自动增加 limit 子句. 避免一次<br>
性得到过多的数据,影响效率. limit 子句的限制数量默认配置为 100.如果 SQL 中有具体的 limit<br>
子句,当前属性失效.<br>
SQL : select * from table . mycat 解析后: select * from table limit 100<br>
SQL : select * from table limit 10 . mycat 不做任何操作修改.</li>
</ol>
</li>
<li>
<p>标签 table<br>
定义逻辑表的标签</p>
<ol>
<li>属性 name<br>
逻辑表名</li>
<li>属性 dataNode<br>
数据节点名称. 即物理数据库中的 database 名称.多个名称使用逗号分隔.</li>
<li>属性 rule<br>
分片规则名称.具体的规则名称参考 rule.xml 配置文件.</li>
</ol>
</li>
<li>
<p>标签 dataNode<br>
定义数据节点的标签</p>
<ol>
<li>属性 name<br>
数据节点名称, 是定义的逻辑名称,对应具体的物理数据库 database</li>
<li>属性 dataHost<br>
引用 dataHost 标签的 name 值,代表使用的物理数据库所在位置和配置信息.</li>
<li>属性 database<br>
在 dataHost 物理机中,具体的物理数据库 database 名称.</li>
</ol>
</li>
<li>
<p>dataHost 标签<br>
定义数据主机的标签</p>
<ol>
<li>属性 name<br>
定义逻辑上的数据主机名称</li>
<li>属性 maxCon/minCon<br>
最大连接数, max connections<br>
最小连接数, min connections</li>
<li>属性 dbType<br>
数据库类型 : mysql 数据库</li>
<li>属性 dbDriver<br>
数据库驱动类型, native,使用 mycat 提供的本地驱动.</li>
</ol>
</li>
<li>
<p>dataHost 子标签 writeHost<br>
写数据的数据库定义标签. 实现读写分离操作.</p>
<ol>
<li>属性 host<br>
数据库命名</li>
<li>属性 url<br>
数据库访问路径</li>
<li>属性 user<br>
数据库访问用户名</li>
<li>属性 password<br>
访问用户密码</li>
</ol>
</li>
<li>
<p>writeHost 子标签 readHost</p>
<ol>
<li>属性 host<br>
数据库命名</li>
<li>属性 url<br>
数据库访问路径</li>
<li>属性 user<br>
数据库访问用户名</li>
<li>属性 password</li>
</ol>
</li>
</ol>
<h3 id="53-rulexml">5.3  rule.xml</h3>
<p>用于定义分片规则的配置文件.<br>
mycat 默认的分片规则: 以 500 万为单位,实现分片规则.<br>
逻辑库 A 对应 dataNode - db1 和 db2. 1-500 万保存在 db1 中, 500 万零 1 到 1000 万保存在 db2 中,1000 万零 1 到 1500 万保存在 db1 中.依次类推.</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170524.png" alt="" loading="lazy"></figure>
<ol>
<li>tableRule</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:center">name</th>
<th style="text-align:center">属性指定唯一的名字，用于标识不同的分片规则。内嵌的 rule 标签则指定对物理表中的哪一列进行拆分和使用什么分片算法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">columns</td>
<td style="text-align:center">指定要拆分的列名字</td>
</tr>
<tr>
<td style="text-align:center">algorithm</td>
<td style="text-align:center">使用 function 标签中的 name 属性。连接表规则和具体分片算法。 table 标签内使用。让逻辑表使用这个规则进行分片</td>
</tr>
</tbody>
</table>
<ol start="2">
<li>function</li>
</ol>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170718.png" alt="" loading="lazy"></figure>
<table>
<thead>
<tr>
<th style="text-align:center">name</th>
<th style="text-align:center">指定算法的名字</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">class</td>
<td style="text-align:center">制定分片算法具体的类名字</td>
</tr>
<tr>
<td style="text-align:center">property</td>
<td style="text-align:center">为具体算法需要用到的一些属性</td>
</tr>
</tbody>
</table>
<h2 id="6-实现读写分离">6、 实现读写分离</h2>
<h3 id="61-配置读写分离">6.1 配置读写分离</h3>
<ol>
<li>Schema.xml</li>
</ol>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170859.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>
<p>Server.xml</p>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170917.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170947.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>测试读写分离</p>
<ol>
<li>
<p>启动 Mycat 命令<br>
bin/mycat start</p>
</li>
<li>
<p>停止命令<br>
bin/mycat stop</p>
</li>
<li>
<p>重启命令<br>
bin/mycat restart</p>
</li>
<li>
<p>查看 MyCat 状态<br>
bin/mycat status</p>
</li>
<li>
<p>访问方式<br>
可以使用命令行访问或客户端软件访问.</p>
</li>
<li>
<p>命令行访问方式<br>
mysql -u 用户名 -p 密码 -hmycat 主机 IP -P8066<br>
链接成功后,可以当做 MySQL 数据库使用.<br>
访问约束</p>
</li>
<li>
<p>查看 Mycat 日志<br>
logs/wrapper.log<br>
日志中记录的是所有的 mycat 操作. 查看的时候主要看异常信息 caused by 信息</p>
</li>
<li>
<p>balance<br>
balance=”0”, 不开启读写分离机制，所有读操作都发送到当前可用的 writeHost 上<br>
balance=”1”，全部的 readHost 与 stand by writeHost 参与 select 语句的负载均衡<br>
balance=”2”，所有读操作都随机的在 writeHost、 readhost 上分发。</p>
</li>
</ol>
<p>balance=”3”， 所有读请求随机的分发到 writeHost 对应的 readhost 执行,writerHost不负担读压力</p>
</li>
</ol>
<p>7、MyCat 分库</p>
<h3 id="71-分片规则">7.1 分片规则</h3>
<ol>
<li>
<p>auto-sharding-long 范围约定</p>
<p>以 500 万为单位,实现分片规则.<br>
逻辑库 A 对应 dataNode - db1 和 db2. 1-500 万保存在 db1 中, 500 万零 1 到 1000 万保存在 db2 中,1000 万零 1 到 1500 万保存在 db1 中.依次类推.</p>
</li>
<li>
<p>crc32slot 规则<br>
在 CRUD 操作时,根据具体数据的 crc32 算法计算,数据应该保存在哪一个 dataNode 中</p>
</li>
</ol>
<h3 id="72-配置分片规则需要注意的地方">7.2 配置分片规则需要注意的地方</h3>
<p><em>1）<columns>id</columns>中推荐配置主键列</em><br>
<em>2）所有的 tableRule 只能使用一次。如果需要为多个表配置相同的分片规则，那么需要在此重新定义该规则。</em><br>
<em>3）在 crc32Slot 算法中的分片数量一旦给定，MyCat 会将该分片数量和 slor 的取值范围保存到文件中。在次修改分片数量时是不会生效的，需要将该文件删除。文件位置位于 conf目录中的 ruledata 目录中。</em></p>
<h3 id="73-配置分库">7.3 配置分库</h3>
<ol>
<li>
<p>需求：<br>
1）在 master 中创建 3 个数据库<br>
2）在 MyCat 中配置分库</p>
</li>
<li>
<p>创建数据库</p>
<p>create database demo1 default character set utf8;<br>
create database demo2 default character set utf8;<br>
create database demo3 default character set utf8;</p>
<p>创建 t_users 表：</p>
<p>CREATE TABLE <code>t_users</code> (</p>
<p><code>id</code> int(11) NOT NULL,<br>
<code>name</code> varchar(30) DEFAULT NULL,<br>
PRIMARY KEY (<code>id</code>)<br>
) ENGINE=InnoDB DEFAULT CHARSET=utf8;</p>
</li>
<li>
<p>修改 Schema.xml</p>
<figure data-type="image" tabindex="17"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716171350.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>测试</p>
<figure data-type="image" tabindex="18"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716171412.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="74-注意">7.4 注意：</h3>
<p>1）使用 MyCat 实现分库时，先在 MyCat 中定义逻辑库与逻辑表，然后在 MyCat 的链接中执行创建表的命令必须要在 MyCat 中运行。因为 MyCat 在创建表时，会在表中添加一个新的列，列名为_slot。<br>
2）使用 MyCat 插入数据时，语句中必须要指定所有的列。即便是一个完全项插入也不允许省略列名。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[后台管理系统（单体应用+前后端分离）]]></title>
        <id>https://jonchan1013.github.io/post/spring-bootlayui-kuai-su-da-jian-hou-tai-guan-li-xi-tong-dan-ti-ying-yong-qian-hou-duan-fen-chi/</id>
        <link href="https://jonchan1013.github.io/post/spring-bootlayui-kuai-su-da-jian-hou-tai-guan-li-xi-tong-dan-ti-ying-yong-qian-hou-duan-fen-chi/">
        </link>
        <updated>2020-07-10T07:10:29.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-layui">1、Layui</h2>
<p><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200710151802.png" alt="" loading="lazy"><br>
<img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200710151954.png" alt="" loading="lazy"></p>
<p>table.html</p>
<pre><code class="language-html">
</code></pre>
]]></content>
    </entry>
</feed>