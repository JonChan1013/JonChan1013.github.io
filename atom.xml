<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://jonchan1013.github.io</id>
    <title>CY的学习博客</title>
    <updated>2020-08-04T06:21:55.757Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://jonchan1013.github.io"/>
    <link rel="self" href="https://jonchan1013.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://jonchan1013.github.io/images/avatar.png</logo>
    <icon>https://jonchan1013.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, CY的学习博客</rights>
    <entry>
        <title type="html"><![CDATA[综合性 B2C 电子商务平台项目]]></title>
        <id>https://jonchan1013.github.io/post/zong-he-xing-b2c-dian-zi-shang-wu-ping-tai-xiang-mu/</id>
        <link href="https://jonchan1013.github.io/post/zong-he-xing-b2c-dian-zi-shang-wu-ping-tai-xiang-mu/">
        </link>
        <updated>2020-08-03T17:02:00.000Z</updated>
        <summary type="html"><![CDATA[<h2 id="1-项目介绍">1、项目介绍</h2>
<h3 id="11-电商行业发展">1.1 电商行业发展</h3>
<p>商务部统计数据显示，2012 年到 2016 年，我国网络购物用户人数从 2.42 亿人增长至4.67 亿人，增长近一倍。电子商务交易额从 8.1 万亿元增长至 26.1 万亿元，年均增长 34%。其中，网络零售交易额从 1.31 万亿元增长至 5.16 万亿元，年均增长 40%，对社会消费品零售总额增加值的贡献率从 17%增长至 30%。电子商务发展直接和间接带动的就业人数从1500 万人增长至 3700 万人。</p>
]]></summary>
        <content type="html"><![CDATA[<h2 id="1-项目介绍">1、项目介绍</h2>
<h3 id="11-电商行业发展">1.1 电商行业发展</h3>
<p>商务部统计数据显示，2012 年到 2016 年，我国网络购物用户人数从 2.42 亿人增长至4.67 亿人，增长近一倍。电子商务交易额从 8.1 万亿元增长至 26.1 万亿元，年均增长 34%。其中，网络零售交易额从 1.31 万亿元增长至 5.16 万亿元，年均增长 40%，对社会消费品零售总额增加值的贡献率从 17%增长至 30%。电子商务发展直接和间接带动的就业人数从1500 万人增长至 3700 万人。</p>
<!-- more -->
<p>经过多年发展，目前规模较大电子商务平台企业纷纷开始构建生态系统，平台为商家和消费者提供交易、支付、物流等各方面全周期支持与服务，各大平台与平台商家之间依存越来越紧密，阿里系、腾讯系、百度系、京东系等主体均取得了显著规模效益。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[SpringCloud]]></title>
        <id>https://jonchan1013.github.io/post/springcloud/</id>
        <link href="https://jonchan1013.github.io/post/springcloud/">
        </link>
        <updated>2020-08-03T16:28:58.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200730014043.png" alt="" loading="lazy"></figure>
<h2 id="1-系统架构演变">1、系统架构演变</h2>
<p>随着互联网的发展，网站应用的规模不断扩大。需求的激增，带来的是技术上的压力。系统架构也因此也不断的演进、升级、迭代。从单一应用，到垂直拆分，到分布式服务，到SOA，以及现在火热的微服务架构，还有在Google带领下来势汹涌的Service Mesh。我们到底是该乘坐微服务的船只驶向远方，还是偏安逸得过且过？</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200730014043.png" alt="" loading="lazy"></figure>
<h2 id="1-系统架构演变">1、系统架构演变</h2>
<p>随着互联网的发展，网站应用的规模不断扩大。需求的激增，带来的是技术上的压力。系统架构也因此也不断的演进、升级、迭代。从单一应用，到垂直拆分，到分布式服务，到SOA，以及现在火热的微服务架构，还有在Google带领下来势汹涌的Service Mesh。我们到底是该乘坐微服务的船只驶向远方，还是偏安逸得过且过？</p>
<!-- more -->
<h3 id="11-集中式架构">1.1 集中式架构</h3>
<p>当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731105554.png" alt="" loading="lazy"></figure>
<ul>
<li>优点：<br>
系统开发速度快<br>
维护成本低<br>
适用于并发要求较低的系统</li>
<li>缺点：<br>
代码耦合度高，后期维护困难<br>
无法针对不同模块进行针对性优化<br>
无法水平扩展<br>
单点容错率低，并发能力差</li>
</ul>
<h3 id="12-垂直拆分">1.2 垂直拆分</h3>
<p>当访问量逐渐增大，单一应用无法满足需求，此时为了应对更高的并发和业务需求，我们根据业务功能对系统进行拆分：</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731105826.png" alt="" loading="lazy"></figure>
<ul>
<li>优点：<br>
系统拆分实现了流量分担，解决了并发问题<br>
可以针对不同模块进行优化<br>
方便水平扩展，负载均衡，容错率提高</li>
<li>缺点：<br>
系统间相互独立，会有很多重复开发工作，影响开发效率</li>
</ul>
<h3 id="13-分布式服务">1.3 分布式服务</h3>
<p>当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731110007.png" alt="" loading="lazy"></figure>
<ul>
<li>优点：<br>
将基础服务进行了抽取，系统间相互调用，提高了代码复用和开发效率</li>
<li>缺点：<br>
系统间耦合度变高，调用关系错综复杂，难以维护</li>
</ul>
<h3 id="14-面向服务架构soa">1.4 面向服务架构（SOA）</h3>
<p>SOA（Service Oriented Architecture）面向服务的架构：它是一种设计方法，其中包含多个服务， 服务之间通过相互依赖最终提供一系列的功能。一个服务 通常以独立的形式存在与操作系统进程中。各个服务之间 通过网络调用。<br>
SOA结构图：</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731110053.png" alt="" loading="lazy"></figure>
<p><code>ESB（企业服务总线），简单 来说 ESB 就是一根管道，用来连接各个服务节点。为了集 成不同系统，不同协议的服务，ESB 做了消息的转化解释和路由工作，让不同的服务互联互通。</code></p>
<p><strong>SOA缺点</strong>：每个供应商提供的ESB产品有偏差，自身实现较为复杂；应用服务粒度较大，ESB集成整合所有服务和协议、数据转换使得运维、测试部署困难。所有服务都通过一个通路通信，直接降低了通信速度。</p>
<h3 id="15-微服务架构">1.5 微服务架构</h3>
<p><strong>微服务架构是使用一套小服务来开发单个应用的方式或途径</strong>，每个服务基于单一业务能力构建，运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API，并能够通过自动化部署机制来独立部署。这些服务可以使用不同的编程语言实现，以及不同数据存储技术，并保持最低限度的集中式管理。<br>
微服务结构图：</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731110312.png" alt="" loading="lazy"></figure>
<p><code>API Gateway网关是一个服务器，是系统的唯一入口。为每个客户端提供一个定制的API。API网关核心是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。如它还可以具有其它职责，如身份验证、监控、负载均衡、缓存、请求分片与管理、静态响应处理。通常，网关提供RESTful/HTTP的方式访问服务。而服务端通过服务注册中心进行服务注册和管理。</code></p>
<ul>
<li>微服务的特点：<br>
单一职责：微服务中每一个服务都对应唯一的业务能力，做到单一职责<br>
微：微服务的服务拆分粒度很小，例如一个用户管理就可以作为一个服务。每个服务虽小，但“五脏俱全”。<br>
面向服务：面向服务是说每个服务都要对外暴露Rest风格服务接口API。并不关心服务的技术实现，做到与平台和语言无关，也不限定用什么技术实现，只要提供Rest的接口即可。<br>
自治：自治是说服务间互相独立，互不干扰
<ul>
<li>团队独立：每个服务都是一个独立的开发团队，人数不能过多。</li>
<li>技术独立：因为是面向服务，提供Rest接口，使用什么技术没有别人干涉</li>
<li>前后端分离：采用前后端分离开发，提供统一Rest接口，后端不用再为PC、移动端开发不同接口</li>
<li>数据库分离：每个服务都使用自己的数据源</li>
<li>部署独立，服务间虽然有调用，但要做到服务重启不影响其它服务。有利于持续集成和持续交付。每个服务都是独立的组件，可复用，可替换，降低耦合，易维护</li>
</ul>
</li>
</ul>
<p>微服务架构与SOA都是对系统进行拆分；微服务架构基于SOA思想，可以把微服务当做去除了ESB的SOA。ESB是SOA架构中的中心总线，设计图形应该是星形的，而微服务是去中心化的分布式软件架构。两者比较类似，但其实也有一些差别：</p>
<table>
<thead>
<tr>
<th style="text-align:center">功能</th>
<th style="text-align:center">SOA</th>
<th style="text-align:center">微服务</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">组件大小</td>
<td style="text-align:center">大块业务逻辑</td>
<td style="text-align:center">单独任务或小块业务逻辑</td>
</tr>
<tr>
<td style="text-align:center">耦合</td>
<td style="text-align:center">通常松耦合</td>
<td style="text-align:center">总是松耦合</td>
</tr>
<tr>
<td style="text-align:center">管理</td>
<td style="text-align:center">着重中央管理</td>
<td style="text-align:center">着重分散管理</td>
</tr>
<tr>
<td style="text-align:center">目标</td>
<td style="text-align:center">确保应用能够交互操作</td>
<td style="text-align:center">易维护、易扩展、更轻量级的交互</td>
</tr>
</tbody>
</table>
<h2 id="2-服务调用方式">2、服务调用方式</h2>
<h3 id="21-rpc和http">2.1 RPC和HTTP</h3>
<p>无论是微服务还是SOA，都面临着服务间的远程调用。那么服务间的远程调用方式有哪些呢？<br>
常见的远程调用方式有以下2种：</p>
<ul>
<li><strong>RPC</strong>：Remote Produce Call远程过程调用，<strong>RPC基于Socket，工作在会话层。自定义数据格式</strong>，速度快，效率高。早期的webservice，现在热门的dubbo，都是RPC的典型代表</li>
<li><strong>Http</strong>：http其实是**一种网络传输协议，基于TCP，工作在应用层，规定了数据传输的格式。**现在客户端浏览器与服务端通信基本都是采用Http协议，也可以用来进行远程服务调用。缺点是消息封装臃肿，优势是对服务的提供和调用方没有任何技术限定，自由灵活，更符合微服务理念。</li>
</ul>
<p>现在热门的Rest风格，就可以通过http协议来实现。<br>
<strong>区别</strong>：RPC的机制是根据语言的API（language API）来定义的，而不是根据基于网络的应用来定义的。<br>
如果你们公司全部采用Java技术栈，那么使用Dubbo作为微服务架构是一个不错的选择。<br>
相反，如果公司的技术栈多样化，而且你更青睐Spring家族，那么Spring Cloud搭建微服务是不二之选。在我们的项目中，会选择Spring Cloud套件，因此会使用Http方式来实现服务间调用。</p>
<h3 id="22-http客户端工具">2.2 Http客户端工具</h3>
<p>既然微服务选择了Http，那么我们就需要考虑自己来实现对请求和响应的处理。不过开源世界已经有很多的http客户端工具，能够帮助我们做这些事情，例如：</p>
<ul>
<li>HttpClient</li>
<li>OKHttp</li>
<li>URLConnection<br>
不过这些不同的客户端，API各不相同。而Spring也有对http的客户端进行封装，提供了工具类叫RestTemplate。</li>
</ul>
<h3 id="23-spring的resttemplate">2.3 Spring的RestTemplate</h3>
<p>Spring提供了一个RestTemplate模板工具类，对基于Http的客户端进行了封装，并且实现了对象与json的序列化和反序列化，非常方便。RestTemplate并没有限定Http的客户端类型，而是进行了抽象，目前常用的3种都有支持：</p>
<ul>
<li>HttpClient</li>
<li>OkHttp</li>
<li>JDK原生的URLConnection（默认的）</li>
</ul>
<p>在项目中的 HttpDemoApplication 注册一个RestTemplate 对象，可以在启动类位置注册：</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.web.client.RestTemplate;

@SpringBootApplication
public class HttpDemoApplication {
    public static void main(String[] args) {
        SpringApplication.run(HttpDemoApplication.class, args);
    }

    @Bean
    public RestTemplate restTemplate(){
         return new RestTemplate();
    }
}
</code></pre>
<p>启动springboot项目，在项目中的测试类中直接@Autowired 注入：</p>
<pre><code class="language-java">@RunWith(SpringRunner.class)
@SpringBootTest
public class RestTemplateTest {

    @Autowired
    private RestTemplate restTemplate;

    @Test
    public void test(){
        //如果要测试需要启动spring boot项目，以便获取数据
        String url = &quot;http://localhost/user/8&quot;;
        User user = restTemplate.getForObject(url, User.class);
        System.out.println(user);
    }
}
</code></pre>
<p>通过RestTemplate的getForObject()方法，传递url地址及实体类的字节码，RestTemplate会自动发起请求，接收响应，并且帮我们对响应结果进行反序列化。</p>
<p>了解完Http客户端工具，接下来就可以正式学习微服务了。</p>
<h2 id="3-初识spring-cloud">3、 初识Spring Cloud</h2>
<p>微服务是一种架构方式，最终肯定需要技术架构去实施。<br>
微服务的实现方式很多，但是最火的莫过于Spring Cloud了。为什么？</p>
<ul>
<li>后台硬：作为Spring家族的一员，有整个Spring全家桶靠山，背景十分强大。</li>
<li>技术强：Spring作为Java领域的前辈，可以说是功力深厚。有强力的技术团队支撑，一般人还真比不了</li>
<li>群众基础好：可以说大多数程序员的成长都伴随着Spring框架，试问：现在有几家公司开发不用Spring？</li>
<li>Spring Cloud与Spring的各个框架无缝整合，对大家来说一切都是熟悉的配方，熟悉的味道。</li>
<li>使用方便：相信大家都体会到了SpringBoot给我们开发带来的便利，而Spring Cloud完全支持Spring Boot的开发，用很少的配置就能完成微服务框架的搭建</li>
</ul>
<h3 id="31-简介">3.1 简介</h3>
<p>Spring Cloud是Spring旗下的项目之一，官网地址：http://projects.spring.io/spring-cloud/Spring最擅长的就是集成，把世界上最好的框架拿过来，集成到自己的项目中。<br>
Spring Cloud也是一样，它将现在非常流行的一些技术整合到一起，实现了诸如：配置管理，服务发现，智能路由，负载均衡，熔断器，控制总线，集群状态等功能；协调分布式环境中各个系统，为各类服务提供模板性配置。其主要<br>
涉及的组件包括：</p>
<ul>
<li>Eureka：注册中心</li>
<li>Zuul、Gateway：服务网关</li>
<li>Ribbon：负载均衡</li>
<li>Feign：服务调用</li>
<li>Hystrix或Resilience4j：熔断器<br>
以上只是其中一部分，架构图：</li>
</ul>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731111940.png" alt="" loading="lazy"></figure>
<h3 id="32-版本">3.2 版本</h3>
<p>Spring Cloud不是一个组件，而是许多组件的集合；它的版本命名比较特殊，是以A到Z的为首字母的一些单词（其实是伦敦地铁站的名字）组成：</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731111959.png" alt="" loading="lazy"></figure>
<p>我们在项目中，使用最新稳定的Greenwich版本。</p>
<h2 id="4-微服务场景模拟">4、 微服务场景模拟</h2>
<p>首先，我们需要模拟一个服务调用的场景。方便后面学习微服务架构</p>
<h3 id="41-创建父工程">4.1 创建父工程</h3>
<p>微服务中需要同时创建多个项目，为了方便课堂演示，先创建一个父工程，然后后续的工程都以这个工程为父，实现maven的聚合。这样可以在一个窗口看到所有工程，方便讲解。<strong>在实际开发中，每个微服务可独立一个工程。</strong></p>
<p>修改pom文件：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;groupId&gt;com.cy&lt;/groupId&gt;
    &lt;artifactId&gt;heima-springcloud&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;
        &lt;relativePath/&gt;
    &lt;/parent&gt;

    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt;
        &lt;mapper.starter.version&gt;2.1.5&lt;/mapper.starter.version&gt;
        &lt;mysql.version&gt;5.1.46&lt;/mysql.version&gt;
    &lt;/properties&gt;

    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;!-- springCloud --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
            &lt;!-- 通用Mapper启动器 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;tk.mybatis&lt;/groupId&gt;
                &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;
                &lt;version&gt;${mapper.starter.version}&lt;/version&gt;
            &lt;/dependency&gt;
            &lt;!-- mysql驱动 --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;mysql&lt;/groupId&gt;
                &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
                &lt;version&gt;${mysql.version}&lt;/version&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
</code></pre>
<p>这里已经对大部分要用到的依赖的版本进行了 管理，方便后续使用</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731112314.png" alt="" loading="lazy"></figure>
<h3 id="42-服务提供者">4.2 服务提供者</h3>
<p>新建一个项目user-service，对外提供查询用户的服务。</p>
<ol>
<li>
<p><strong>创建module</strong><br>
选中父工程：springclouddemo创建module</p>
</li>
<li>
<p><strong>添加依赖</strong><br>
pom.xml 文件中的内容如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;springcloud-demo&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;artifactId&gt;user-service&lt;/artifactId&gt;

&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;!-- 通用Mapper启动器 --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;tk.mybatis&lt;/groupId&gt;
        &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;!-- mysql驱动 --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;mysql&lt;/groupId&gt;
        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>
</li>
<li>
<p><strong>编写配置文件</strong></p>
<p>创建user-service\src\main\resources\application.yml 属性文件,这里我们采用了yaml语法，而不是properties：</p>
<pre><code class="language-yaml">server:
  port: 9091
spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/springcloud
    username: root
    password: root
mybatis:
  type-aliases-package: com.cy.user.pojo
</code></pre>
<p>使用mysql图形界面工具创建springcloud 数据库，将tb_user.sql 导入；</p>
</li>
<li>
<p><strong>编写代码</strong></p>
<p>编写启动类</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import tk.mybatis.spring.annotation.MapperScan;

@SpringBootApplication
@MapperScan(&quot;com.cy.user.mapper&quot;)
public class UserApplication {
    public static void main(String[] args) {
        SpringApplication.run(UserApplication.class, args);
    }
}
</code></pre>
<p>编写实体类</p>
<pre><code class="language-java">import lombok.Data;
import tk.mybatis.mapper.annotation.KeySql;

import javax.persistence.Id;
import javax.persistence.Table;
import java.util.Date;

@Table(name = &quot;tb_user&quot;)
@Data
public class User {

    @Id
    @KeySql(useGeneratedKeys = true)
    private Long id;

    private String userName; // 用户名

    private String password; // 密码

    private String name;// 姓名

    private Integer age;// 年龄

    private Integer sex;// 性别，1男性，2女性

    private Date birthday;// 出生日期

    private Date created;// 创建时间

    private Date updated;// 更新时间

    private String note;// 备注
}
</code></pre>
<p>编写UserMapper</p>
<pre><code class="language-java">import com.cy.user.pojo.User;
import tk.mybatis.mapper.common.Mapper;

public interface UserMapper extends Mapper&lt;User&gt; {
}
</code></pre>
<p>编写UserService</p>
<pre><code class="language-java">import com.cy.user.mapper.UserMapper;
import com.cy.user.pojo.User;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Service;

@Service
public class UserService {

    @Autowired
    private UserMapper userMapper;

    public User queryById(Long id){
        return userMapper.selectByPrimaryKey(id);
    }
}
</code></pre>
<p>添加一个对外查询的接口处理器</p>
<pre><code class="language-java">import com.cy.user.pojo.User;
import com.cy.user.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping(&quot;/user&quot;)
public class UserController {

    @Autowired
    private UserService userService;
     @GetMapping(&quot;/{id}&quot;)
    public User queryById(@PathVariable Long id){
        return userService.queryById(id);
    }
}
</code></pre>
<p>创建完上述代码后项目结构：</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731132923.png" alt="" loading="lazy"></figure>
</li>
<li>
<p><strong>启动并测试</strong></p>
<p>启动 user-service 项目，访问接口：http://localhost:9091/user/8</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731133358.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="43-服务调用者">4.3 服务调用者</h3>
<ol>
<li>
<p><strong>创建工程</strong><br>
与上面类似，这里不再赘述，需要注意的是，我们调用user-service 的功能，因此不需要mybatis相关依赖了。</p>
<p>修改pom文件</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;springclouddemo&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.cy&lt;/groupId&gt;
    &lt;artifactId&gt;consumer-demo&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>
</li>
<li>
<p><strong>编写代码</strong></p>
</li>
</ol>
<p>编写启动类 consumer-demo\src\main\java\com\cy\consumer\ConsumerApplication.java 并在其中注册RestTemplate 具体如下：</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.context.annotation.Bean;
import org.springframework.web.client.RestTemplate;

@SpringBootApplication
public class ConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
</code></pre>
<p>创建实体类 consumer-demo\src\main\java\com\cy\consumer\pojo\User.java</p>
<pre><code class="language-java">import lombok.Data;

import java.util.Date;

@Data
public class User {

    private Long id;

    private String userName; // 用户名

    private String password; // 密码

    private String name;// 姓名

    private Integer age;// 年龄

    private Integer sex;// 性别，1男性，2女性

    private Date birthday;// 出生日期

    private Date created;// 创建时间

    private Date updated;// 更新时间

    private String note;// 备注

}
</code></pre>
<p>编写consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java ，在controller中直接调用RestTemplate，远程访问user-service 的服务接口：</p>
<pre><code class="language-java">import com.cy.consumer.pojo.User;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

@RestController
@RequestMapping(&quot;/consumer&quot;)
public class ConsumerController {

    @Autowired
    private RestTemplate restTemplate;

    @GetMapping(&quot;{id}&quot;)
    public User queryById(@PathVariable Long id){
        String url = &quot;http://localhost:9091/user/&quot; + id;
        return restTemplate.getForObject(url, User.class);
    }

}
</code></pre>
<p>服务调用者项目结构：</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731133845.png" alt="" loading="lazy"></figure>
<ol start="3">
<li>
<p><strong>启动测试</strong><br>
启动 consumer-demo 引导启动类；因为 consumer-demo 项目没有配置端口，那么默认就是8080，</p>
<p>我们访问：http://localhost:8080/consumer/8</p>
<p>一个简单的远程服务调用案例就实现了。</p>
</li>
</ol>
<h3 id="44-思考问题">4.4 思考问题</h3>
<p>简单回顾一下，刚才我们写了什么：<br>
user-service：对外提供了查询用户的接口<br>
consumer-demo：通过RestTemplate访问http://locahost:9091/user/{id} 接口，查询用户数据<br>
存在什么问题？</p>
<ul>
<li>
<p>在consumer中，我们把url地址硬编码到了代码中，不方便后期维护</p>
</li>
<li>
<p>consumer需要记忆user-service的地址，如果出现变更，可能得不到通知，地址将失效</p>
</li>
<li>
<p>consumer不清楚user-service的状态，服务宕机也不知道</p>
</li>
<li>
<p>user-service只有1台服务，不具备高可用性</p>
</li>
<li>
<p>即便user-service形成集群，consumer还需自己实现负载均衡</p>
</li>
</ul>
<p>其实上面说的问题，概括一下就是分布式服务必然要面临的问题：</p>
<ul>
<li>
<p>服务管理</p>
</li>
<li>
<p>如何自动注册和发现</p>
</li>
<li>
<p>如何实现状态监管</p>
</li>
<li>
<p>如何实现动态路由</p>
</li>
<li>
<p>服务如何实现负载均衡</p>
</li>
<li>
<p>服务如何解决容灾问题</p>
</li>
<li>
<p>服务如何实现统一配置<br>
以上的问题，都将在SpringCloud中得到答案。</p>
</li>
</ul>
<h2 id="5-eureka注册中心">5、Eureka注册中心</h2>
<h3 id="51-认识eureka">5.1 认识Eureka</h3>
<p>首先我们来解决第一问题，服务的管理。<br>
<strong>问题分析</strong><br>
在刚才的案例中，user-service对外提供服务，需要对外暴露自己的地址。而consumer-demo（调用者）需要记录服务提供者的地址。将来地址出现变更，还需要及时更新。这在服务较少的时候并不觉得有什么，但是在现在日益复杂的互联网环境，一个项目可能会拆分出十几，甚至几十个微服务。此时如果还人为管理地址，不仅开发困难，将来测试、发布上线都会非常麻烦，这与DevOps的思想是背道而驰的。<br>
DevOps的思想是系统可以通过一组过程、方法或系统；提高应用发布和运维的效率,降低管理成本。<br>
<strong>网约车</strong><br>
这就好比是 网约车出现以前，人们出门叫车只能叫出租车。一些私家车想做出租却没有资格，被称为黑车。而很多人想要约车，但是无奈出租车太少，不方便。私家车很多却不敢拦，而且满大街的车，谁知道哪个才是愿意载人的。一个想要，一个愿意给，就是缺少引子，缺乏管理啊。<br>
此时滴滴这样的网约车平台出现了，所有想载客的私家车全部到滴滴注册，记录你的车型（服务类型），身份信息（联系方式）。这样提供服务的私家车，在滴滴那里都能找到，一目了然。<br>
此时要叫车的人，只需要打开APP，输入你的目的地，选择车型（服务类型），滴滴自动安排一个符合需求的车到你面前，为你服务，完美！<br>
<strong>Eureka做什么？</strong><br>
Eureka就好比是滴滴，负责管理、记录服务提供者的信息。服务调用者无需自己寻找服务，而是把自己的需求告诉Eureka，然后Eureka会把符合你需求的服务告诉你。<br>
同时，服务提供方与Eureka之间通过“心跳” 机制进行监控，当某个服务提供方出现问题，Eureka自然会把它从服务列表中剔除。<br>
这就实现了服务的自动注册、发现、状态监控。</p>
<h3 id="52-原理图">5.2 原理图</h3>
<p><strong>基本架构：</strong></p>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/1560439174201.png" alt="" loading="lazy"></figure>
<ul>
<li>Eureka：就是服务注册中心（可以是一个集群），对外暴露自己的地址</li>
<li>提供者：启动后向Eureka注册自己信息（地址，提供什么服务）</li>
<li>消费者：向Eureka订阅服务，Eureka会将对应服务的所有提供者地址列表发送给消费者，并且定期更新</li>
<li>心跳(续约)：提供者定期通过http方式向Eureka刷新自己的状态</li>
</ul>
<h3 id="53-入门案例">5.3  入门案例</h3>
<ol>
<li>
<p><strong>搭建eureka-server工程</strong><br>
接下来创建一个项目eureka-server ，启动一个Eureka Server Application服务注册中心。</p>
<p>项目中的pom.xml 文件如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;heima-springcloud&lt;/artifactId&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.cy&lt;/groupId&gt;
    &lt;artifactId&gt;eureka-server&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
<p>编写启动类</p>
<p>eureka-server\src\main\java\com\cy\EurekaServerApplication.java</p>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;

//声明当前应用为eureka服务
@EnableEurekaServer
@SpringBootApplication
public class EurekaServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(EurekaServerApplication.class);
    }
}
</code></pre>
</li>
<li>
<p><strong>编写配置文件</strong></p>
</li>
</ol>
<p>eureka-server\src\main\resources\application.yml</p>
<pre><code class="language-yaml">server:
  port: 10086
spring:
  application:
    name: eureka-server # 应用名称，会在Eureka中作为服务的id标识（serviceId）
eureka:
  client:
    service-url: # EurekaServer的地址，现在是自己的地址，如果是集群，需要写其它Server的地址。
      defaultZone: http://127.0.0.1:10086/eureka
    register-with-eureka: false # 不注册自己
    fetch-registry: false #不拉取
</code></pre>
<ol start="3">
<li>
<p><strong>启动服务</strong><br>
启动 eureka-server 访问：http://127.0.0.1:10086</p>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731134955.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731135002.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="54-服务注册">5.4 服务注册</h3>
<p>注册服务，就是在服务上添加Eureka的客户端依赖，客户端代码会自动把服务注册到EurekaServer中。</p>
<ol>
<li><strong>添加依赖</strong><br>
我们在user-service中添加Eureka客户端依赖：</li>
</ol>
<pre><code class="language-xml">&lt;!-- Eureka客户端 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ol start="2">
<li><strong>修改启动类</strong><br>
在启动类上开启Eureka客户端功能<br>
通过添加@EnableDiscoveryClient 来开启Eureka客户端功能</li>
</ol>
<pre><code class="language-java">@SpringBootApplication
@MapperScan(&quot;com.cy.user.mapper&quot;)
@EnableDiscoveryClient // 开启Eureka客户端发现功能
public class UserServiceDemoApplication {
    public static void main(String[] args) {
        SpringApplication.run(UserServiceDemoApplication.class, args);
    }
}
</code></pre>
<ol start="3">
<li>
<p><strong>修改配置文件</strong></p>
<p>编写user-service\src\main\resources\application.yml配置文件为如下：</p>
</li>
</ol>
<pre><code class="language-yaml">server:
  port: 9091
spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/springcloud
    username: root
    password: root
  application:
    #应用名
    name: user-service
mybatis:
  type-aliases-package: cn.itcast.user.pojo
eureka:
  client:
    service-url:
      defaultZone: http://localhost:10086/eureka
</code></pre>
<p>注意：</p>
<ul>
<li>这里我们添加了spring.application.name属性来指定应用名称，将来会作为服务的id使用。</li>
</ul>
<ol start="4">
<li><strong>测试</strong><br>
重启 user-service 项目，访问Eureka监控页面</li>
</ol>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731135225.png" alt="" loading="lazy"></figure>
<p>我们发现user-service服务已经注册成功了</p>
<h3 id="55-服务发现">5.5 服务发现</h3>
<p>接下来我们修改consumer-demo ，尝试从EurekaServer获取服务。<br>
方法与服务提供者类似，只需要在项目中添加EurekaClient依赖，就可以通过服务名称来获取信息了！</p>
<ol>
<li><strong>添加依赖</strong><br>
找到 consumer-demo\pom.xml 添加如下依赖</li>
</ol>
<pre><code class="language-xml">&lt;!-- Eureka客户端 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<ol start="2">
<li>
<p><strong>修改启动类</strong></p>
<p>修改 consumer-demo\src\main\java\com\cy\consumer\ConsumerApplication.java 开启Eureka客户端</p>
</li>
</ol>
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;
import org.springframework.context.annotation.Bean;
import org.springframework.web.client.RestTemplate;

@SpringBootApplication
@EnableDiscoveryClient
public class ConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
</code></pre>
<ol start="3">
<li><strong>新增配置文件</strong></li>
</ol>
<p>新增 consumer-demo\src\main\resources\application.yml 配置文件</p>
<pre><code class="language-yaml">server:
  port: 8080
spring:
  application:
    name: consumer-demo # 应用名称
eureka:
  client:
    service-url: # EurekaServer地址
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
<ol start="4">
<li><strong>修改处理器</strong><br>
修改 consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java 代码，用DiscoveryClient类的方法，根据服务名称，获取服务实例。</li>
</ol>
<pre><code class="language-java">import com.cy.consumer.pojo.User;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.client.ServiceInstance;
import org.springframework.cloud.client.discovery.DiscoveryClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

import java.util.List;

@RestController
@RequestMapping(&quot;/consumer&quot;)
public class ConsumerController {

    @Autowired
    private RestTemplate restTemplate;

    @Autowired
    private DiscoveryClient discoveryClient;

    @GetMapping(&quot;{id}&quot;)
    public User queryById(@PathVariable Long id){
        String url = &quot;http://localhost:9091/user/&quot; + id;

        //获取eureka中注册的user-service实例列表
        List&lt;ServiceInstance&gt; serviceInstanceList = 
discoveryClient.getInstances(&quot;user-service&quot;);
        ServiceInstance serviceInstance = serviceInstanceList.get(0);

        url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort() 
+ &quot;/user/&quot; + id;
        return restTemplate.getForObject(url, User.class);
    }

}
</code></pre>
<ol start="5">
<li><strong>Debug跟踪运行</strong></li>
</ol>
<p>重启 consumer-demo 项目；然后再浏览器中再次访问 http://localhost:8080/consumer/8 ；在代码中debug跟进查看最终拼接要访问的URL：</p>
<figure data-type="image" tabindex="17"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731135743.png" alt="" loading="lazy"></figure>
<h3 id="56-eureka详解">5.6 Eureka详解</h3>
<h4 id="561-基础架构">5.6.1 基础架构</h4>
<p>Eureka架构中的三个核心角色：</p>
<ul>
<li>服务注册中心<br>
Eureka的服务端应用，提供服务注册和发现功能，就是刚刚我们建立的eureka-server</li>
<li>服务提供者<br>
提供服务的应用，可以是SpringBoot应用，也可以是其它任意技术实现，只要对外提供的是Rest风格服务即可。本例中就是我们实现的user-service</li>
<li>服务消费者<br>
消费应用从注册中心获取服务列表，从而得知每个服务方的信息，知道去哪里调用服务方。本例中就是我们实现的consumer-demo</li>
</ul>
<h4 id="562-高可用的eureka-server">5.6.2 高可用的Eureka Server</h4>
<p>Eureka Server即服务的注册中心，在刚才的案例中，我们只有一个EurekaServer，事实上EurekaServer也可以是一个集群，形成高可用的Eureka中心。<br>
<strong>服务同步</strong><br>
多个Eureka Server之间也会互相注册为服务，当服务提供者注册到Eureka Server集群中的某个节点时，该节点会把服务的信息同步给集群中的每个节点，从而实现<strong>数据同步</strong>。因此，无论客户端访问到Eureka Server集群中的任意一个节点，都可以获取到完整的服务列表信息。<br>
而作为客户端，需要把信息注册到每个Eureka中：</p>
<figure data-type="image" tabindex="18"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140001.png" alt="" loading="lazy"></figure>
<p>如果有三个Eureka，则每一个EurekaServer都需要注册到其它几个Eureka服务中，例如：有三个分别为10086、10087、10088，则：<br>
10086要注册到10087和10088上<br>
10087要注册到10086和10088上<br>
10088要注册到10086和10087上<br>
<strong>动手搭建高可用的EurekaServer</strong><br>
我们假设要搭建两台EurekaServer的集群，端口分别为：10086和10087<br>
1）修改原来的EurekaServer配置；修改 eureka-server\src\main\resources\application.yml 如下：</p>
<pre><code class="language-yaml">server:
  port: ${port:10086}

spring:
  application:
    # 应用名称，会在eureka中作为服务的id(serviceId)
    name: eureka-server
eureka:
  client:
    service-url:
      # eureka服务地址；如果是集群则是其它服务器地址，后面要加/eureka
      defaultZone: ${defaultZone:http://127.0.0.1:10086/eureka}
    # 是否注册自己，自身不提供服务所以不注册
    #register-with-eureka: false
    # 是否拉取服务
    #fetch-registry: false
</code></pre>
<p>所谓的高可用注册中心，其实就是把EurekaServer自己也作为一个服务，注册到其它EurekaServer上，这样多个EurekaServer之间就能互相发现对方，从而形成集群。因此我们做了以下修改：</p>
<p>注意:</p>
<ul>
<li>把register-with-eureka和fetch-registry修改为true或者注释掉</li>
<li>在上述配置文件中的${}表示在jvm启动时候若能找到对应port或者defaultZone参数则使用，若无则使用后面的默认值</li>
<li>把service-url的值改成了另外一台EurekaServer的地址，而不是自己</li>
</ul>
<p>2）另外一台在启动的时候可以指定端口port和defaultZone配置：</p>
<figure data-type="image" tabindex="19"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140210.png" alt="" loading="lazy"></figure>
<p>修改原来的启动配置组件；在如下界面中的 VM options 中<br>
设置 -DdefaultZone=http:127.0.0.1:10087/eureka</p>
<figure data-type="image" tabindex="20"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140228.png" alt="" loading="lazy"></figure>
<p>复制一份并修改；在如下界面中的 VM options 中<br>
设置 -Dport=10087 -DdefaultZone=http:127.0.0.1:10086/eureka</p>
<figure data-type="image" tabindex="21"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140239.png" alt="" loading="lazy"></figure>
<p>3）启动测试；同时启动两台eureka server</p>
<figure data-type="image" tabindex="22"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140248.png" alt="" loading="lazy"></figure>
<p>4）客户端注册服务到集群<br>
因为EurekaServer不止一个，因此user-service 项目注册服务或者consumer-demo 获取服务的时候，service-url参数需要修改为如下：</p>
<pre><code class="language-yaml">eureka:
  client:
    service-url: # EurekaServer地址,多个地址以','隔开
      defaultZone: http://127.0.0.1:10086/eureka,http://127.0.0.1:10087/eureka
</code></pre>
<p>为了方便后面内容的修改，在测试完上述配置后可以再次改回单个eureka server的方式。</p>
<h4 id="563-eureka客户端">5.6.3 Eureka客户端</h4>
<p>服务提供者要向EurekaServer注册服务，并且完成服务续约等工作。<br>
<strong>服务注册</strong><br>
服务提供者在启动时，会检测配置属性中的：eureka.client.register-with-erueka=true 参数是否正确，事实上默认就是true。如果值确实为true，则会向EurekaServer发起一个Rest请求，并携带自己的元数据信息，Eureka<br>
Server会把这些信息保存到一个双层Map结构中。</p>
<ul>
<li>
<p>第一层Map的Key就是服务id，一般是配置中的spring.application.name 属性</p>
</li>
<li>
<p>第二层Map的key是服务的实例id。一般host+ serviceId + port，例如：localhost:user-service:8081</p>
</li>
<li>
<p>值则是服务的实例对象，也就是说一个服务，可以同时启动多个不同实例，形成集群。</p>
</li>
</ul>
<p>默认注册时使用的是主机名或者localhost，如果想用ip进行注册，可以在user-service 中添加配置如下：</p>
<pre><code class="language-yaml">eureka:
  instance:
    ip-address: 127.0.0.1 # ip地址
    prefer-ip-address: true # 更倾向于使用ip，而不是host名
</code></pre>
<p>修改完后先后重启user-service 和consumer-demo ；在调用服务的时候就已经变成ip地址；需要注意的是：不是在eureka中的控制台服务实例状态显示。</p>
<p><strong>服务续约</strong></p>
<p>在注册服务完成以后，服务提供者会维持一个心跳（定时向EurekaServer发起Rest请求），告诉EurekaServer：“我还活着”。这个我们称为服务的续约（renew）；<br>
有两个重要参数可以修改服务续约的行为；可以在 user-service 中添加如下配置项：</p>
<pre><code class="language-yaml">eureka:
  instance:
    lease-expiration-duration-in-seconds: 90
    lease-renewal-interval-in-seconds: 30
</code></pre>
<ul>
<li>lease-renewal-interval-in-seconds：服务续约(renew)的间隔，默认为30秒</li>
<li>lease-expiration-duration-in-seconds：服务失效时间，默认值90秒</li>
</ul>
<p>也就是说，默认情况下每隔30秒服务会向注册中心发送一次心跳，证明自己还活着。如果超过90秒没有发送心跳，EurekaServer就会认为该服务宕机，会定时（eureka.server.eviction-interval-timer-in-ms设定的时间）从服务列表中移除，这两个值在生产环境不要修改，默认即可。</p>
<p><strong>获取服务列表</strong><br>
当服务消费者启动时，会检测eureka.client.fetch-registry=true 参数的值，如果为true，则会从EurekaServer服务的列表拉取只读备份，然后缓存在本地。并且每隔30秒会重新拉取并更新数据。可以在consumer-demo项目中通过下面的参数来修改：</p>
<pre><code class="language-yaml">eureka:
  client:
    registry-fetch-interval-seconds: 30
</code></pre>
<h4 id="564-失效剔除和自我保护">5.6.4 失效剔除和自我保护</h4>
<p>如下的配置都是在Eureka Server服务端进行：<br>
<strong>服务下线</strong><br>
当服务进行正常关闭操作时，它会触发一个服务下线的REST请求给Eureka Server，告诉服务注册中心：“我要下线了”。服务中心接受到请求之后，将该服务置为下线状态。<br>
<strong>失效剔除</strong><br>
有时我们的服务可能由于内存溢出或网络故障等原因使得服务不能正常的工作，而服务注册中心并未收到“服务下线”的请求。相对于服务提供者的“服务续约”操作，服务注册中心在启动时会创建一个定时任务，默认每隔一段时间（默认为60秒）将当前清单中超时（默认为90秒）没有续约的服务剔除，这个操作被称为失效剔除。<br>
可以通过eureka.server.eviction-interval-timer-in-ms 参数对其进行修改，单位是毫秒。<br>
<strong>自我保护</strong><br>
我们关停一个服务，很可能会在Eureka面板看到一条警告：</p>
<figure data-type="image" tabindex="23"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731140915.png" alt="" loading="lazy"></figure>
<p>这是触发了Eureka的自我保护机制。当服务未按时进行心跳续约时，Eureka会统计服务实例最近15分钟心跳续约的比例是否低于了85%。在生产环境下，因为网络延迟等原因，心跳失败实例的比例很有可能超标，但是此时就把服务剔除列表并不妥当，因为服务可能没有宕机。Eureka在这段时间内不会剔除任何服务实例，直到网络恢复正常。生产环境下这很有效，保证了大多数服务依然可用，不过也有可能获取到失败的服务实例，因此服务调用者必须做好服务的失败容错。<br>
可以通过下面的配置来关停自我保护：</p>
<pre><code class="language-yaml">eureka:
  server:
    enable-self-preservation: false # 关闭自我保护模式（缺省为打开）
</code></pre>
<h2 id="6-负载均衡ribbon">6、负载均衡Ribbon</h2>
<p>在刚才的案例中，我们启动了一个user-service ，然后通过DiscoveryClient来获取服务实例信息，然后获取ip和端口来访问。</p>
<p>但是实际环境中，往往会开启很多个user-service 的集群。此时获取的服务列表中就会有多个，到底该访问哪一个呢？<br>
一般这种情况下就需要编写负载均衡算法，在多个实例列表中进行选择。<br>
不过Eureka中已经集成了负载均衡组件：Ribbon，简单修改代码即可使用。<br>
什么是Ribbon：</p>
<figure data-type="image" tabindex="24"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731141223.png" alt="" loading="lazy"></figure>
<p>接下来，我们就来使用Ribbon实现负载均衡。</p>
<h3 id="61-启动两个服务实例">6.1 启动两个服务实例</h3>
<p>首先我们配置启动两个user-service 实例，一个9091，一个9092。</p>
<figure data-type="image" tabindex="25"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731141249.png" alt="" loading="lazy"></figure>
<p>Eureka监控面板：</p>
<figure data-type="image" tabindex="26"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731141259.png" alt="" loading="lazy"></figure>
<h3 id="62-开启负载均衡">6.2 开启负载均衡</h3>
<p>因为Eureka中已经集成了Ribbon，所以我们无需引入新的依赖。<br>
直接修改 consumer-demo\src\main\java\com\cy\consumer\ConsumerApplication.java<br>
在RestTemplate的配置方法上添加@LoadBalanced 注解：</p>
<pre><code class="language-java">@SpringBootApplication
@EnableEurekaClient //开启eureka客户端发现
public class ConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class,args);
    }

    @Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
</code></pre>
<p>修改consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java 调用方式，不再手动获取ip和端口，而是直接通过服务名称调用；</p>
<pre><code class="language-java">@GetMapping(&quot;{id}&quot;)
public User queryById(@PathVariable(&quot;id&quot;) Long id){
    String url = &quot;http://user-service/user/&quot; + id;
    User user = restTemplate.getForObject(url, User.class);
    return user;
}
</code></pre>
<p>访问页面，查看结果；并可以在9091和9092的控制台查看执行情况：</p>
<p>了解：Ribbon默认的负载均衡策略是轮询。SpringBoot也帮提供了修改负载均衡规则的配置入口在consumer-demo的配置文件中添加如下，就变成随机的了：</p>
<pre><code class="language-yaml">user-service:
  ribbon:
    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule
</code></pre>
<p>格式是：{服务名称}.ribbon.NFLoadBalancerRuleClassName</p>
<h3 id="63-源码跟踪">6.3 源码跟踪</h3>
<p>为什么只输入了service名称就可以访问了呢？之前还要获取ip和端口。<br>
显然是有组件根据service名称，获取到了服务实例的ip和端口。因为consumer-demo 使用的是RestTemplate，spring的负载均衡自动配置类 LoadBalancerAutoConfiguration.LoadBalancerInterceptorConfig 会自动配置负载均衡拦截器（在spring-cloud-commons-**.jar包中的spring.factories中定义的自动配置类）， 它就是LoadBalancerInterceptor ，这个类会在对RestTemplate的请求进行拦截，然后从Eureka根据服务id获取服务列表，随后利用负载均衡算法得到真实的服务地址信息，替换服务id。<br>
我们进行源码跟踪：</p>
<figure data-type="image" tabindex="27"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731142533.png" alt="" loading="lazy"></figure>
<p>继续跟入execute方法：发现获取了9092端口的服务</p>
<figure data-type="image" tabindex="28"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731142740.png" alt="" loading="lazy"></figure>
<p>再跟下一次，发现获取的是9091、9092之间切换：</p>
<figure data-type="image" tabindex="29"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143101.png" alt="" loading="lazy"></figure>
<p>多次访问consumer-demo 的请求地址；然后跟进代码，发现其果然实现了负载均衡。</p>
<h2 id="7-熔断器hystrix">7、熔断器Hystrix</h2>
<h3 id="71-简介">7.1 简介</h3>
<p>Hystrix 在英文里面的意思是 豪猪，它的logo 看下面的图是一头豪猪，它在微服务系统中是一款提供保护机制的组件，和eureka一样也是由netﬂix公司开发。<br>
主页：https://github.com/Netﬂix/Hystrix/</p>
<figure data-type="image" tabindex="30"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143149.png" alt="" loading="lazy"></figure>
<p>那么Hystrix的作用是什么呢？具体要保护什么呢？<br>
Hystrix是Netﬂix开源的一个延迟和容错库，用于隔离访问远程服务、第三方库，防止出现级联失败。</p>
<h3 id="72-雪崩问题">7.2 雪崩问题</h3>
<p>微服务中，服务间调用关系错综复杂，一个请求，可能需要调用多个微服务接口才能实现，会形成非常复杂的调用链路：</p>
<figure data-type="image" tabindex="31"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143246.png" alt="" loading="lazy"></figure>
<p>如图，一次业务请求，需要调用A、P、H、I四个服务，这四个服务又可能调用其它服务。<br>
如果此时，某个服务出现异常：</p>
<figure data-type="image" tabindex="32"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143314.png" alt="" loading="lazy"></figure>
<p>例如：微服务I 发生异常，请求阻塞，用户请求就不会得到响应，则tomcat的这个线程不会释放，于是越来越多的用户请求到来，越来越多的线程会阻塞：</p>
<figure data-type="image" tabindex="33"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143344.png" alt="" loading="lazy"></figure>
<p>服务器支持的线程和并发数有限，请求一直阻塞，会导致服务器资源耗尽，从而导致所有其它服务都不可用，形成雪崩效应。<br>
这就好比，一个汽车生产线，生产不同的汽车，需要使用不同的零件，如果某个零件因为种种原因无法使用，那么就会造成整台车无法装配，陷入等待零件的状态，直到零件到位，才能继续组装。  此时如果有很多个车型都需要这个零件，那么整个工厂都将陷入等待的状态，导致所有生产都陷入瘫痪。一个零件的波及范围不断扩大。</p>
<p>Hystrix解决雪崩问题的手段主要是服务降级，包括：</p>
<ul>
<li>线程隔离</li>
<li>服务熔断</li>
</ul>
<h3 id="73-线程隔离服务降级">7.3 线程隔离&amp;服务降级</h3>
<h4 id="731-原理">7.3.1 原理</h4>
<p>线程隔离示意图：</p>
<figure data-type="image" tabindex="34"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731143445.png" alt="" loading="lazy"></figure>
<p>解读：</p>
<ul>
<li>Hystrix为每个依赖服务调用分配一个小的线程池，如果线程池已满调用将被立即拒绝，默认不采用排队，<strong>加速失败判定时间。</strong></li>
<li>用户的请求将不再直接访问服务，而是通过线程池中的空闲线程来访问服务，如果线程池已满，或者请求超时，则会进行降级处理，什么是服务降级？<br>
<strong>服务降级：优先保证核心服务，而非核心服务不可用或弱可用。</strong><br>
用户的请求故障时，不会被阻塞，更不会无休止的等待或者看到系统崩溃，至少可以看到一个执行结果（例如返回友好的提示信息） 。<br>
<strong>服务降级虽然会导致请求失败，但是不会导致阻塞，而且最多会影响这个依赖服务对应的线程池中的资源，对其它服务没有响应。</strong><br>
<strong>触发Hystrix服务降级的情况：</strong>
<ul>
<li>线程池已满</li>
<li>请求超时</li>
</ul>
</li>
</ul>
<h4 id="732-动手实践">7.3.2 动手实践</h4>
<p>1）引入依赖<br>
在consumer-demo 消费端系统的pom.xml文件添加如下依赖：</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<p>2）开启熔断<br>
在启动类ConsumerApplication 上添加注解：@EnableCircuitBreaker</p>
<pre><code class="language-java">@SpringBootApplication
@EnableDiscoveryClient
@EnableCircuitBreaker
public class ConsumerApplication {
    // ...
}
</code></pre>
<p>可以看到，我们类上的注解越来越多，在微服务中，经常会引入上面的三个注解，于是Spring就提供了一个组合注解：@SpringCloudApplication</p>
<figure data-type="image" tabindex="35"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731145640.png" alt="" loading="lazy"></figure>
<p>因此，我们可以使用这个组合注解来代替之前的3个注解。</p>
<pre><code class="language-java">@SpringCloudApplication
public class ConsumerApplication {
    // ...
}
</code></pre>
<p>3）编写降级逻辑<br>
当目标服务的调用出现故障，我们希望快速失败，给用户一个友好提示。因此需要提前编写好失败时的降级处理逻辑，要使用HystrixCommand来完成。<br>
改造consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java 处理器类，如下：</p>
<pre><code class="language-java">import com.cy.consumer.pojo.User;
import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.client.ServiceInstance;
import org.springframework.cloud.client.discovery.DiscoveryClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

import java.util.List;

@RestController
@RequestMapping(&quot;/consumer&quot;)
@Slf4j
public class ConsumerController {

    @Autowired
    private RestTemplate restTemplate;

    @Autowired
    private DiscoveryClient discoveryClient;

    @GetMapping(&quot;{id}&quot;)
    @HystrixCommand(fallbackMethod = &quot;queryByIdFallback&quot;)
    public String queryById(@PathVariable Long id){
        String url = &quot;http://localhost:9091/user/&quot; + id;

        //获取eureka中注册的user-service实例列表
        /*List&lt;ServiceInstance&gt; serviceInstanceList = 
discoveryClient.getInstances(&quot;user-service&quot;);
        ServiceInstance serviceInstance = serviceInstanceList.get(0);
    url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort() 
+ &quot;/user/&quot; + id;*/
        url = &quot;http://user-service/user/&quot; + id;

        return restTemplate.getForObject(url, String.class);
    }

    public String queryByIdFallback(Long id){
        log.error(&quot;查询用户信息失败。id：{}&quot;, id);
        return &quot;对不起，网络太拥挤了！&quot;;
    }

}     
</code></pre>
<p><code>要注意；因为熔断的降级逻辑方法必须跟正常逻辑方法保证：相同的参数列表和返回值声明。 失败逻辑中返回User对象没有太大意义，一般会返回友好提示。所以把queryById的方法改造为返回String，反正也是Json数据。这样失败逻辑中返回一个错误说明，会比较方便。</code></p>
<p>说明：</p>
<ul>
<li>@HystrixCommand(fallbackMethod = &quot;queryByIdFallBack&quot;)：用来声明一个降级逻辑的方法<br>
测试：<br>
当user-service 正常提供服务时，访问与以前一致。但是当将user-service 停机时，会发现页面返回了降级处理信息：</li>
</ul>
<figure data-type="image" tabindex="36"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731150137.png" alt="" loading="lazy"></figure>
<p>4）默认的Fallback<br>
刚才把fallback写在了某个业务方法上，如果这样的方法很多，那岂不是要写很多。所以可以把Fallback配置加在类上，实现默认fallback；<br>
再次改造 consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java</p>
<pre><code class="language-java">import com.cy.consumer.pojo.User;
import com.netflix.hystrix.contrib.javanica.annotation.DefaultProperties;
import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.client.ServiceInstance;
import org.springframework.cloud.client.discovery.DiscoveryClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.client.RestTemplate;

import java.util.List;

@RestController
@RequestMapping(&quot;/consumer&quot;)
@Slf4j
@DefaultProperties(defaultFallback = &quot;defaultFallback&quot;)
public class ConsumerController {

    @Autowired
    private RestTemplate restTemplate;

    @Autowired
    private DiscoveryClient discoveryClient;

    @GetMapping(&quot;{id}&quot;)
    //@HystrixCommand(fallbackMethod = &quot;queryByIdFallback&quot;)
    @HystrixCommand
    public String queryById(@PathVariable Long id){
        String url = &quot;http://localhost:9091/user/&quot; + id;

        //获取eureka中注册的user-service实例列表
        /*List&lt;ServiceInstance&gt; serviceInstanceList = 
discoveryClient.getInstances(&quot;user-service&quot;);
        ServiceInstance serviceInstance = serviceInstanceList.get(0);

        url = &quot;http://&quot; + serviceInstance.getHost() + &quot;:&quot; + serviceInstance.getPort() 
+ &quot;/user/&quot; + id;*/
        url = &quot;http://user-service/user/&quot; + id;

        return restTemplate.getForObject(url, String.class);
    }

    public String queryByIdFallback(Long id){
        log.error(&quot;查询用户信息失败。id：{}&quot;, id);
        return &quot;对不起，网络太拥挤了！&quot;;
    }

    public String defaultFallback(){
        return &quot;默认提示：对不起，网络太拥挤了！&quot;;
    }

}
</code></pre>
<ul>
<li>@DefaultProperties(defaultFallback = &quot;defaultFallBack&quot;)：在类上指明统一的失败降级方法；该类中所有方法返回类型要与处理失败的方法的返回类型一致。</li>
</ul>
<figure data-type="image" tabindex="37"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731150351.png" alt="" loading="lazy"></figure>
<p>5）超时设置<br>
在之前的案例中，请求在超过1秒后都会返回错误信息，这是因为Hystrix的默认超时时长为1，我们可以通过配置修改这个值；修改 consumer-demo\src\main\resources\application.yml 添加如下配置：</p>
<pre><code class="language-yaml">hystrix:
  command:
    default:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 2000
</code></pre>
<p>这个配置会作用于全局所有方法。为了方便复制到yml配置文件中，可以复制<br>
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=2000 到yml文件中会自动格式化后再进行修改。</p>
<p>为了触发超时，可以在user-service\src\main\java\com\cy\user\service\UserService.java 的方法中休眠2秒；</p>
<pre><code class="language-java">@Service
public class UserService {

    @Autowired
    private UserMapper userMapper;

    public User queryById(Long id) {
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return userMapper.selectByPrimaryKey(id);
    }
}
</code></pre>
<p>测试：</p>
<figure data-type="image" tabindex="38"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200731150557.png" alt="" loading="lazy"></figure>
<p>可以发现，请求的时长已经到了2s+，证明配置生效了。如果把修改时间修改到2秒以下，又可以正常访问。</p>
<h3 id="74-服务熔断">7.4 服务熔断</h3>
<h4 id="741-熔断原理">7.4.1  熔断原理</h4>
<p>在服务熔断中，使用的熔断器，也叫断路器，其英文单词为：Circuit Breaker<br>
熔断机制与家里使用的电路熔断原理类似；当如果电路发生短路的时候能立刻熔断电路，避免发生灾难。在分布式系统中应用服务熔断后；服务调用方可以自己进行判断哪些服务反应慢或存在大量超时，可以针对这些服务进行主动熔断，防止整个系统被拖垮。<br>
Hystrix的服务熔断机制，可以实现弹性容错；当服务请求情况好转之后，可以自动重连。通过断路的方式，将后续请求直接拒绝，一段时间（默认5秒）之后允许部分请求通过，如果调用成功则回到断路器关闭状态，否则继续打<br>
开，拒绝请求的服务。<br>
Hystrix的熔断状态机模型：</p>
<figure data-type="image" tabindex="39"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/1560682028169.png" alt="" loading="lazy"></figure>
<p>状态机有3个状态：</p>
<ul>
<li>Closed：关闭状态（断路器关闭），所有请求都正常访问。</li>
<li>Open：打开状态（断路器打开），所有请求都会被降级。Hystrix会对请求情况计数，当一定时间内失败请求百分比达到阈值，则触发熔断，断路器会完全打开。默认失败比例的阈值是50%，请求次数最少不低于20次。</li>
<li>Half Open：半开状态，不是永久的，断路器打开后会进入休眠时间（默认是5S）。随后断路器会自动进入半开状态。此时会释放部分请求通过，若这些请求都是健康的，则会关闭断路器，否则继续保持打开，再次进行休眠计时</li>
</ul>
<h4 id="742-动手实践">7.4.2 动手实践</h4>
<p>为了能够精确控制请求的成功或失败，在consumer-demo 的处理器业务方法中加入一段逻辑；<br>
修改 consumer-demo\src\main\java\com\cy\consumer\controller\ConsumerController.java</p>
<pre><code class="language-java">@GetMapping(&quot;{id}&quot;)
@HystrixCommand
public String queryById(@PathVariable(&quot;id&quot;) Long id){
    if(id == 1){
        throw new RuntimeException(&quot;太忙了&quot;);
    }
    String url = &quot;http://user-service/user/&quot; + id;
    String user = restTemplate.getForObject(url, String.class);
    return user;
}
</code></pre>
<p>这样如果参数是id为1，一定失败，其它情况都成功。（不要忘了清空user-service中的休眠逻辑）<br>
我们准备两个请求窗口：</p>
<ul>
<li>一个请求：http://localhost:8080/consumer/1，注定失败</li>
<li>一个请求：http://localhost:8080/consumer/2，肯定成功<br>
当我们疯狂访问id为1的请求时（超过20次），就会触发熔断。断路器会打开，一切请求都会被降级处理。<br>
此时你访问id为2的请求，会发现返回的也是失败，而且失败时间很短，只有20毫秒左右；因进入半开状态之后2是可以的。</li>
</ul>
<figure data-type="image" tabindex="40"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803023239.png" alt="" loading="lazy"></figure>
<p>不过，默认的熔断触发要求较高，休眠时间窗较短，为了测试方便，我们可以通过配置修改熔断策略：</p>
<pre><code class="language-yaml"># 配置熔断策略：
hystrix:
  command:
    default:
      circuitBreaker:
        errorThresholdPercentage: 50 # 触发熔断错误比例阈值，默认值50%
        sleepWindowInMilliseconds: 10000 # 熔断后休眠时长，默认值5秒
        requestVolumeThreshold: 10 # 熔断触发最小请求次数，默认值是20
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 2000 # 熔断超时设置，默认为1秒
</code></pre>
<p>为了方便复制上述配置，可以使用如下格式复制到yml文件中会自动格式化：</p>
<pre><code class="language-properties">hystrix.command.default.circuitBreaker.requestVolumeThreshold=10
hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds=10000
hystrix.command.default.circuitBreaker.errorThresholdPercentage=50
hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=2000
</code></pre>
<p>上述的配置项可以参考 HystrixCommandProperties 类中。</p>
<h2 id="8-feign">8、Feign</h2>
<p>在前面的学习中，使用了Ribbon的负载均衡功能，大大简化了远程调用时的代码：</p>
<pre><code class="language-java">String url = &quot;http://user-service/user/&quot; + id;
User user = this.restTemplate.getForObject(url, User.class)
</code></pre>
<p>如果就学到这里，可能以后需要编写类似的大量重复代码，格式基本相同，无非参数不一样。有没有更优雅的方式，来对这些代码再次优化呢？<br>
这就是接下来要学的Feign的功能了。</p>
<h3 id="81-简介">8.1 简介</h3>
<p>Feign也叫伪装：<br>
Feign可以把Rest的请求进行隐藏，伪装成类似SpringMVC的Controller一样。你不用再自己拼接url，拼接参数等等操作，一切都交给Feign去做。</p>
<p>项目主页：https://github.com/OpenFeign/feign</p>
<h3 id="82-快速入门">8.2 快速入门</h3>
<ol>
<li>
<p>导入依赖<br>
在consumer-demo 项目的pom.xml 文件中添加如下依赖</p>
<pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li>
<p>Feign的客户端</p>
<p>在consumer-demo 中编写如下Feign客户端接口类：</p>
<pre><code class="language-java">package com.itheima.consumer.client;

import com.itheima.consumer.pojo.User;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;

@FeignClient(&quot;user-service&quot;)
public interface UserClient {

    @GetMapping(&quot;/user/{id}&quot;)
    User queryById(@PathVariable(&quot;id&quot;) Long id);
}
</code></pre>
<ul>
<li>首先这是一个接口，Feign会通过动态代理，帮我们生成实现类。这点跟mybatis的mapper很像</li>
<li>@FeignClient ，声明这是一个Feign客户端，同时通过value 属性指定服务名称</li>
<li>接口中的定义方法，完全采用SpringMVC的注解，Feign会根据注解帮我们生成URL，并访问获取结果</li>
<li>@GetMapping中的/user，请不要忘记；因为Feign需要拼接可访问的地址</li>
</ul>
<p>编写新的控制器类ConsumerFeignController ，使用UserClient访问：</p>
<pre><code class="language-java">package com.itheima.consumer.controller;

import com.itheima.consumer.client.UserClient;
import com.itheima.consumer.pojo.User;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping(&quot;/cf&quot;)
public class ConsumerFeignController {

    @Autowired
    private UserClient userClient;

    @GetMapping(&quot;/{id}&quot;)
    public User queryById(@PathVariable Long id){
        return userClient.queryById(id);
    }
}
</code></pre>
</li>
<li>
<p>开启Feign功能<br>
在ConsumerApplication 启动类上，添加注解，开启Feign功能</p>
<pre><code class="language-java">package com.itheima.consumer;

import org.springframework.boot.SpringApplication;
import org.springframework.cloud.client.SpringCloudApplication;
import org.springframework.cloud.client.loadbalancer.LoadBalanced;
import org.springframework.cloud.openfeign.EnableFeignClients;
import org.springframework.context.annotation.Bean;
import org.springframework.web.client.RestTemplate;

/*@SpringBootApplication
@EnableDiscoveryClient
@EnableCircuitBreaker*/
@SpringCloudApplication
@EnableFeignClients//开启Feign功能
public class ConsumerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

    @Bean
    @LoadBalanced
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
}
</code></pre>
<p>Feign中已经自动集成了Ribbon负载均衡，因此不需要自己定义RestTemplate进行负载均衡的配置。</p>
</li>
<li>
<p>启动测试</p>
<p>访问接口：http://localhost:8080/cf/2</p>
<figure data-type="image" tabindex="41"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803023919.png" alt="" loading="lazy"></figure>
<p>正常获取到了结果。</p>
</li>
</ol>
<h3 id="83-负载均衡">8.3 负载均衡</h3>
<p>Feign中本身已经集成了Ribbon依赖和自动配置：</p>
<figure data-type="image" tabindex="42"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024003.png" alt="" loading="lazy"></figure>
<p>因此不需要额外引入依赖，也不需要再注册RestTemplate 对象。</p>
<p>Fegin内置的ribbon默认设置了请求超时时长，默认是1000，我们可以通过手动配置来修改这个超时时长：</p>
<pre><code class="language-yaml">ribbon:
  ReadTimeout: 2000 # 读取超时时长
  ConnectTimeout: 1000 # 建立链接的超时时长
</code></pre>
<p>因为ribbon内部有重试机制，一旦超时，会自动重新发起请求。如果不希望重试，可以添加配置：<br>
修改 consumer-demo\src\main\resources\application.yml 添加如下配置：</p>
<pre><code class="language-yaml">ribbon:
  ConnectTimeout: 1000 # 连接超时时长
  ReadTimeout: 2000 # 数据通信超时时长
  MaxAutoRetries: 0 # 当前服务器的重试次数
  MaxAutoRetriesNextServer: 0 # 重试多少次服务
  OkToRetryOnAllOperations: false # 是否对所有的请求方式都重试
</code></pre>
<p>重新给UserService的方法设置上线程沉睡时间2秒可以测试上述配置</p>
<h3 id="84-hystrix支持了解">8.4 Hystrix支持(了解)</h3>
<p>Feign默认也有对Hystrix的集成：</p>
<figure data-type="image" tabindex="43"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024124.png" alt="" loading="lazy"></figure>
<p>只不过，默认情况下是关闭的。需要通过下面的参数来开启；<br>
修改 consumer-demo\src\main\resources\application.yml 添加如下配置：</p>
<pre><code class="language-yaml">feign:
  hystrix:
    enabled: true # 开启Feign的熔断功能
</code></pre>
<p>但是，Feign中的Fallback配置不像Ribbon中那样简单了。<br>
1）首先，要定义一个类，实现刚才编写的UserFeignClient，作为fallback的处理类</p>
<pre><code class="language-java">package com.itheima.consumer.client.fallback;

import com.itheima.consumer.client.UserClient;
import com.itheima.consumer.pojo.User;
import org.springframework.stereotype.Component;

@Component
public class UserClientFallback implements UserClient {
    @Override
    public User queryById(Long id) {
        User user = new User();
        user.setId(id);
        user.setName(&quot;用户异常&quot;);
        return user;
    }
}
</code></pre>
<p>2）然后在UserFeignClient中，指定刚才编写的实现类</p>
<pre><code class="language-java">@FeignClient(value = &quot;user-service&quot;, fallback = UserClientFallback.class)
public interface UserClient {

    @GetMapping(&quot;/user/{id}&quot;)
    User queryById(@PathVariable(&quot;id&quot;) Long id);
}
</code></pre>
<p>3）重启测试<br>
重启启动 consumer-demo 并关闭user-service 服务，然后在页面访问：http://localhost:8080/cf/8</p>
<figure data-type="image" tabindex="44"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024404.png" alt="" loading="lazy"></figure>
<h3 id="85-请求压缩了解">8.5 请求压缩(了解)</h3>
<p>Spring Cloud Feign 支持对请求和响应进行GZIP压缩，以减少通信过程中的性能损耗。通过下面的参数即可开启请求与响应的压缩功能：</p>
<pre><code class="language-yaml">feign:
  compression:
    request:
      enabled: true # 开启请求压缩
    response:
      enabled: true # 开启响应压缩
</code></pre>
<p>同时，我们也可以对请求的数据类型，以及触发压缩的大小下限进行设置：</p>
<pre><code class="language-yaml">feign:
  compression:
    request:
      enabled: true # 开启请求压缩
      mime-types: text/html,application/xml,application/json # 设置压缩的数据类型
      min-request-size: 2048 # 设置触发压缩的大小下限
</code></pre>
<p>注：上面的数据类型、压缩大小下限均为默认值。</p>
<h3 id="86-日志级别了解">8.6  日志级别(了解)</h3>
<p>前面讲过，通过logging.level.xx=debug 来设置日志级别。然而这个对Fegin客户端而言不会产生效果。因为@FeignClient 注解修改的客户端在被代理时，都会创建一个新的Fegin.Logger实例。我们需要额外指定这个日志的<br>
级别才可以。<br>
1）在consumer-demo 的配置文件中设置com.itheima包下的日志级别都为 debug<br>
修改 consumer-demo\src\main\resources\application.yml 添加如下配置：</p>
<pre><code class="language-yaml">logging:
  level:
    com.itheima: debug
</code></pre>
<p>2）在consumer-demo 编写FeignConﬁg配置类，定义日志级别</p>
<pre><code class="language-java">package com.itheima.consumer.config;

import feign.Logger;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class FeignConfig {

    @Bean
    Logger.Level feignLoggerLevel(){
        //记录所有请求和响应的明细，包括头信息、请求体、元数据
        return Logger.Level.FULL;
    }
}
</code></pre>
<p>这里指定的Level级别是FULL，Feign支持4种级别：<br>
NONE：不记录任何日志信息，这是默认值。<br>
BASIC：仅记录请求的方法，URL以及响应状态码和执行时间<br>
HEADERS：在BASIC的基础上，额外记录了请求和响应的头信息<br>
FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。</p>
<p>3）在consumer-demo 的UserClient 接口类上的@FeignClient注解中指定配置类：</p>
<pre><code class="language-java">package com.itheima.consumer.client;

import com.itheima.consumer.client.fallback.UserClientFallback;
import com.itheima.consumer.config.FeignConfig;
import com.itheima.consumer.pojo.User;
import org.springframework.cloud.openfeign.FeignClient;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;

@FeignClient(value = &quot;user-service&quot;, fallback = UserClientFallback.class,
configuration = FeignConfig.class)
public interface UserClient {

    @GetMapping(&quot;/user/{id}&quot;)
    User queryById(@PathVariable Long id);
}
</code></pre>
<p>4）重启项目，访问：http://localhost:8080/cf/8 ；即可看到每次访问的日志：</p>
<figure data-type="image" tabindex="45"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024710.png" alt="" loading="lazy"></figure>
<h2 id="9-spring-cloud-gateway网关">9、Spring Cloud Gateway网关</h2>
<h3 id="91-简介">9.1 简介</h3>
<ul>
<li>Spring Cloud Gateway是Spring官网基于Spring 5.0、 Spring Boot 2.0、Project Reactor等技术开发的网关服务。</li>
<li>Spring Cloud Gateway基于Filter链提供网关基本功能：安全、监控／埋点、限流等。</li>
<li>Spring Cloud Gateway为微服务架构提供简单、有效且统一的API路由管理方式。</li>
<li>Spring Cloud Gateway是替代Netﬂix Zuul的一套解决方案。<br>
Spring Cloud Gateway组件的核心是一系列的过滤器，通过这些过滤器可以将客户端发送的请求转发（路由）到对应的微服务。 Spring Cloud Gateway是加在整个微服务最前沿的防火墙和代理器，隐藏微服务结点IP端口信息，从而加强安全保护。Spring Cloud Gateway本身也是一个微服务，需要注册到Eureka服务注册中心。<br>
网关的核心功能是：<strong>过滤和路由</strong></li>
</ul>
<h3 id="92-gateway加入后的架构">9.2 Gateway加入后的架构</h3>
<figure data-type="image" tabindex="46"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803024952.png" alt="" loading="lazy"></figure>
<ul>
<li>不管是来自于客户端（PC或移动端）的请求，还是服务内部调用。一切对服务的请求都可经过网关，然后再由网关来实现 鉴权、动态路由等等操作。Gateway就是我们服务的统一入口。</li>
</ul>
<h3 id="93-核心概念">9.3 核心概念</h3>
<ul>
<li><strong>路由（route）</strong> 路由信息的组成：由一个ID、一个目的URL、一组断言工厂、一组Filter组成。如果路由断言为真，说明请求URL和配置路由匹配。</li>
<li><strong>断言（Predicate）</strong> Spring Cloud Gateway中的断言函数输入类型是Spring 5.0框架中的ServerWebExchange。Spring Cloud Gateway的断言函数允许开发者去定义匹配来自于Http Request中的任何信息比如请求头和参数。</li>
<li><strong>过滤器（Filter）</strong> 一个标准的Spring WebFilter。 Spring Cloud Gateway中的Filter分为两种类型的Filter，分别是Gateway Filter和Global Filter。过滤器Filter将会对请求和响应进行修改处理。</li>
</ul>
<h3 id="94-快速入门">9.4 快速入门</h3>
<ol>
<li>
<p><strong>新建工程</strong></p>
<p>打开 heima-springcloud\heima-gateway\pom.xml 文件修改为如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;heima-springcloud&lt;/artifactId&gt;
        &lt;groupId&gt;com.itheima&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.itheima&lt;/groupId&gt;
    &lt;artifactId&gt;heima-gateway&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
</li>
<li>
<p><strong>编写启动类</strong><br>
在heima-gateway中创建com.itheima.gateway.GatewayApplication 启动类</p>
<pre><code class="language-java">package com.itheima.gateway;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.client.discovery.EnableDiscoveryClient;

@SpringBootApplication
@EnableDiscoveryClient
public class GatewayApplication {
    public static void main(String[] args) {
        SpringApplication.run(GatewayApplication.class, args);
    }
}
</code></pre>
</li>
<li>
<p><strong>创建heima-gateway\src\main\resources\application.yml 文件，内容如下：</strong></p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway

eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
</li>
<li>
<p><strong>编写路由规则</strong><br>
需要用网关来代理user-service 服务，先看一下控制面板中的服务状态：</p>
<figure data-type="image" tabindex="47"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803154326.png" alt="" loading="lazy"></figure>
<ul>
<li>ip为：127.0.0.1</li>
<li>端口为：9091<br>
修改heima-gateway\src\main\resources\application.yml 文件为：</li>
</ul>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址
          uri: http://127.0.0.1:9091
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/user/**
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>将符合Path 规则的一切请求，都代理到 uri 参数指定的地址<br>
本例中，我们将路径中包含有 /user/** 开头的请求，代理到http://127.0.0.1:9091</p>
</li>
<li>
<p><strong>启动测试</strong><br>
访问的路径中需要加上配置规则的映射路径，我们访问：http://localhost:10010/user/8</p>
<figure data-type="image" tabindex="48"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803154523.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="95-面向服务的路由">9.5 面向服务的路由</h3>
<p>在刚才的路由规则中，把路径对应的服务地址写死了！如果同一服务有多个实例的话，这样做显然不合理。应该根据服务的名称，去Eureka注册中心查找服务对应的所有实例列表，然后进行动态路由！</p>
<ol>
<li>
<p><strong>修改映射配置，通过服务名称获取</strong><br>
因为已经配置了Eureka客户端，可以从Eureka获取服务的地址信息。<br>
修改heima-gateway\src\main\resources\application.yml 文件如下：</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/user/**
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>路由配置中uri所用的协议为lb时（以uri: lb://user-service为例），gateway将使用 LoadBalancerClient把user-service通过eureka解析为实际的主机和端口，并进行ribbon负载均衡。</p>
</li>
<li>
<p><strong>启动测试</strong><br>
再次启动 heima-gateway ，这次gateway进行代理时，会利用Ribbon进行负载均衡访问：<br>
http://localhost:10010/user/8<br>
日志中可以看到使用了负载均衡器：</p>
<figure data-type="image" tabindex="49"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155238.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="96-路由前缀">9.6 路由前缀</h3>
<h4 id="961-添加前缀">9.6.1 添加前缀</h4>
<p>在gateway中可以通过配置路由的过滤器PreﬁxPath，实现映射路径中地址的添加；<br>
修改heima-gateway\src\main\resources\application.yml 文件：</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
    cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/**
          filters:
            # 添加请求路径的前缀
            - PrefixPath=/user
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>通过PrefixPath=/xxx 来指定了路由要添加的前缀。<br>
也就是：<br>
PrefixPath=/user http://localhost:10010/8 --》http://localhost:9091/user/8<br>
PrefixPath=/user/abc http://localhost:10010/8 --》http://localhost:9091/user/abc/8<br>
以此类推。</p>
<figure data-type="image" tabindex="50"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155358.png" alt="" loading="lazy"></figure>
<h4 id="962-去除前缀">9.6.2 去除前缀</h4>
<p>在gateway中可以通过配置路由的过滤器StripPreﬁx，实现映射路径中地址的去除；</p>
<p>修改heima-gateway\src\main\resources\application.yml 文件：</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/api/user/**
          filters:
            # 表示过滤1个路径，2表示两个路径，以此类推
            - StripPrefix=1
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>通过StripPrefix=1 来指定了路由要去掉的前缀个数。如：路径/api/user/1 将会被代理到/user/1 。<br>
也就是：<br>
StripPrefix=1 http://localhost:10010/api/user/8 --》http://localhost:9091/user/8<br>
StripPrefix=2 http://localhost:10010/api/user/8 --》http://localhost:9091/8<br>
以此类推。</p>
<figure data-type="image" tabindex="51"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155500.png" alt="" loading="lazy"></figure>
<h3 id="97-过滤器">9.7  过滤器</h3>
<h4 id="971-简介">9.7.1 简介</h4>
<p>Gateway作为网关的其中一个重要功能，就是实现请求的鉴权。而这个动作往往是通过网关提供的过滤器来实现的。<br>
前面的 路由前缀 章节中的功能也是使用过滤器实现的。</p>
<p>Gateway自带过滤器有几十个，常见自带过滤器有：</p>
<table>
<thead>
<tr>
<th style="text-align:center">过滤器名称</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">AddRequestHeader</td>
<td style="text-align:center">对匹配上的请求加上Header</td>
</tr>
<tr>
<td style="text-align:center">AddRequestParameters</td>
<td style="text-align:center">对匹配上的请求路由添加参数</td>
</tr>
<tr>
<td style="text-align:center">AddResponseHeader</td>
<td style="text-align:center">对从网关返回的响应添加Header</td>
</tr>
<tr>
<td style="text-align:center">StripPreﬁx</td>
<td style="text-align:center">对匹配上的请求路径去除前缀</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="52"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155639.png" alt="" loading="lazy"></figure>
<p>详细的说明在官网链接</p>
<p><strong>配置全局默认过滤器</strong><br>
这些自带的过滤器可以和使用 路由前缀 章节中的用法类似，也可以将这些过滤器配置成不只是针对某个路由；而是可以对所有路由生效，也就是配置默认过滤器：<br>
了解如下：</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      # 默认过滤器，对所有路由生效
       default-filters:
        # 响应头过滤器，对输出的响应设置其头部属性名称为X-Response-Default-MyName，值为itcast；
如果有多个参数多则重写一行设置不同的参数
        - AddResponseHeader=X-Response-Default-MyName, itcast
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/api/user/**
          filters:
            # 表示过滤1个路径，2表示两个路径，以此类推
            - StripPrefix=1
</code></pre>
<p>上述配置后，再访问 http://localhost:10010/api/user/8 的话；那么可以从其响应中查看到如下信息：</p>
<figure data-type="image" tabindex="53"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155843.png" alt="" loading="lazy"></figure>
<p><strong>过滤器类型</strong>：Gateway实现方式上，有两种过滤器；</p>
<ol>
<li><strong>局部</strong>过滤器：通过spring.cloud.gateway.routes.filters 配置在具体路由下，只作用在当前路由上；自带的过滤器都可以配置或者自定义按照自带过滤器的方式。如果配置spring.cloud.gateway.default-filters 上会对所有路由生效也算是全局的过滤器；但是这些过滤器的实现上都是要实现GatewayFilterFactory接口。</li>
<li><strong>全局</strong>过滤器：不需要在配置文件中配置，作用在所有的路由上；实现 GlobalFilter 接口即可。</li>
</ol>
<h4 id="972-执行生命周期">9.7.2 执行生命周期</h4>
<p>Spring Cloud Gateway 的 Filter 的生命周期也类似Spring MVC的拦截器有两个：“pre” 和 “post”。“pre”和 “post” 分别会在请求被执行前调用和被执行后调用。</p>
<figure data-type="image" tabindex="54"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803155949.png" alt="" loading="lazy"></figure>
<p>这里的 pre 和 post 可以通过过滤器的GatewayFilterChain 执行ﬁlter方法前后来实现。</p>
<h4 id="973-使用场景">9.7.3 使用场景</h4>
<p>常见的应用场景如下：</p>
<ul>
<li>请求鉴权：一般GatewayFilterChain 执行ﬁlter方法前，如果发现没有访问权限，直接就返回空。</li>
<li>异常处理：一般GatewayFilterChain 执行ﬁlter方法后，记录异常并返回。</li>
<li>服务调用时长统计：GatewayFilterChain 执行ﬁlter方法前后根据时间统计。</li>
</ul>
<h3 id="98-自定义过滤器">9.8 自定义过滤器</h3>
<h4 id="981-自定义局部过滤器">9.8.1 自定义局部过滤器</h4>
<p>需求：在application.yml中对某个路由配置过滤器，该过滤器可以在控制台输出配置文件中指定名称的请求参数的值。</p>
<p><strong>1）编写过滤器</strong><br>
在heima-gateway工程编写过滤器工厂类MyParamGatewayFilterFactory</p>
<pre><code class="language-java">package com.itheima.gateway.filter;

import org.springframework.cloud.gateway.filter.GatewayFilter;
import org.springframework.cloud.gateway.filter.factory.AbstractGatewayFilterFactory;
import org.springframework.http.server.reactive.ServerHttpRequest;
import org.springframework.stereotype.Component;

import java.util.Arrays;
import java.util.List;

@Component
public class MyParamGatewayFilterFactory extends 
AbstractGatewayFilterFactory&lt;MyParamGatewayFilterFactory.Config&gt; {

    public static final String PARAM_NAME = &quot;param&quot;;

    public MyParamGatewayFilterFactory() {
        super(Config.class);
    }

    @Override
    public List&lt;String&gt; shortcutFieldOrder() {
        return Arrays.asList(PARAM_NAME);
    }

    @Override
    public GatewayFilter apply(Config config) {
        return (exchange, chain) -&gt; {
            ServerHttpRequest request = exchange.getRequest();

            if (request.getQueryParams().containsKey(config.param)) {
                request.getQueryParams().get(config.param)
                        .forEach(value -&gt; System.out.printf(&quot;----------局部过滤器-----%s 
= %s-----&quot;,
                                config.param, value));
            }

            return chain.filter(exchange);
        };
    }

    public static class Config {
        private String param;

        public String getParam() {
            return param;
        }

        public void setParam(String param) {
            this.param = param;
        }
    }

}
</code></pre>
<p>2）修改配置文件<br>
在heima-gateway工程修改heima-gateway\src\main\resources\application.yml 配置文件</p>
<pre><code class="language-yaml">server:
  port: 10010
spring:
  application:
    name: api-gateway
  cloud:
    gateway:
      routes:
        # 路由id，可以随意写
        - id: user-service-route
          # 代理的服务地址；lb表示从eureka中获取具体服务
          uri: lb://user-service
          # 路由断言，可以配置映射路径
          predicates:
            - Path=/api/user/**
          filters:
            # 表示过滤1个路径，2表示两个路径，以此类推
            - StripPrefix=1
            # 自定义过滤器
            - MyParam=name
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
    prefer-ip-address: true
</code></pre>
<p>注意：自定义过滤器的命名应该为：***GatewayFilterFactory</p>
<p>测试访问：http://localhost:10010/api/user/8?name=itcast 检查后台是否输出name和itcast；但是若访问http://localhost:10010/api/user/8?name2=itcast 则是不会输出的。</p>
<h4 id="982-自定义全局过滤器">9.8.2 自定义全局过滤器</h4>
<p><strong>需求</strong>：模拟一个登录的校验。基本逻辑：如果请求中有token参数，则认为请求有效，放行。</p>
<p>在heima-gateway工程编写全局过滤器类MyGlobalFilter</p>
<pre><code class="language-java">package com.itheima.gateway.filter;

import org.apache.commons.lang.StringUtils;
import org.springframework.cloud.gateway.filter.GatewayFilterChain;
import org.springframework.cloud.gateway.filter.GlobalFilter;
import org.springframework.core.Ordered;
import org.springframework.http.HttpStatus;
import org.springframework.stereotype.Component;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Mono;

@Component
public class MyGlobalFilter implements GlobalFilter, Ordered {
    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        System.out.println(&quot;-----------------全局过滤器MyGlobalFilter-------------------
--&quot;);
        String token = exchange.getRequest().getQueryParams().getFirst(&quot;token&quot;);
        if (StringUtils.isBlank(token)) {
            exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED);
            return exchange.getResponse().setComplete();
        }
        return chain.filter(exchange);
    }

    @Override
    public int getOrder() {
        //值越小越先执行
        return 1;
    }
}
</code></pre>
<p>访问 http://localhost:10010/api/user/8</p>
<figure data-type="image" tabindex="55"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803170715.png" alt="" loading="lazy"></figure>
<p>访问 http://localhost:10010/api/user/8?token=abc</p>
<figure data-type="image" tabindex="56"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803170749.png" alt="" loading="lazy"></figure>
<h3 id="99-负载均衡和熔断了解">9.9 负载均衡和熔断（了解）</h3>
<p>Gateway中默认就已经集成了Ribbon负载均衡和Hystrix熔断机制。但是所有的超时策略都是走的默认值，比如熔断超时时间只有1S，很容易就触发了。因此建议手动进行配置：</p>
<pre><code class="language-yaml">hystrix:
  command:
    default:
      execution:
        isolation:
          thread:
            timeoutInMilliseconds: 6000
ribbon:
  ConnectTimeout: 1000
  ReadTimeout: 2000
  MaxAutoRetries: 0
  MaxAutoRetriesNextServer: 0
</code></pre>
<h3 id="910-gateway跨域配置">9.10 Gateway跨域配置</h3>
<p>一般网关都是所有微服务的统一入口，必然在被调用的时候会出现跨域问题。<br>
<strong>跨域</strong>：在js请求访问中，如果访问的地址与当前服务器的域名、ip或者端口号不一致则称为跨域请求。若不解决则不能获取到对应地址的返回结果。<br>
如：从在http://localhost:9090中的js访问 http://localhost:9000的数据，因为端口不同，所以也是跨域请求。</p>
<p>在访问Spring Cloud Gateway网关服务器的时候，出现跨域问题的话；可以在网关服务器中通过配置解决，允许哪些服务是可以跨域请求的；具体配置如下：</p>
<pre><code class="language-yaml">spring:
  cloud:
    gateway:
      globalcors:
        corsConfigurations:
          '[/**]':
            #allowedOrigins: * # 这种写法或者下面的都可以，*表示全部
            allowedOrigins:
            - &quot;http://docs.spring.io&quot;
            allowedMethods:
            - GET
</code></pre>
<p>上述配置表示：可以允许来自 http://docs.spring.io 的get请求方式获取服务数据。<br>
allowedOrigins 指定允许访问的服务器地址，如：http://localhost:10000 也是可以的。<br>
'[/**]' 表示对所有访问到网关服务器的请求地址<br>
官网具体说明：https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.1.1.RELEASE/multi/multi__cors_conﬁguration.html</p>
<h3 id="911-gateway的高可用了解">9.11 Gateway的高可用（了解）</h3>
<p>启动多个Gateway服务，自动注册到Eureka，形成集群。如果是服务内部访问，访问Gateway，自动负载均衡，没问题。<br>
但是，Gateway更多是外部访问，PC端、移动端等。它们无法通过Eureka进行负载均衡，那么该怎么办？<br>
此时，可以使用其它的服务网关，来对Gateway进行代理。比如：Nginx</p>
<h3 id="912-gateway与feign的区别">9.12 Gateway与Feign的区别</h3>
<ul>
<li>Gateway 作为整个应用的流量入口，接收所有的请求，如PC、移动端等，并且将不同的请求转发至不同的处理微服务模块，其作用可视为nginx；大部分情况下用作权限鉴定、服务端流量控制</li>
<li>Feign 则是将当前微服务的部分服务接口暴露出来，并且主要用于各个微服务之间的服务调用</li>
</ul>
<h2 id="10-spring-cloud-config分布式配置中心">10、Spring Cloud Conﬁg分布式配置中心</h2>
<h3 id="101-简介">10.1 简介</h3>
<p>在分布式系统中，由于服务数量非常多，配置文件分散在不同的微服务项目中，管理不方便。为了方便配置文件集中管理，需要分布式配置中心组件。在Spring Cloud中，提供了Spring Cloud Conﬁg，它支持配置文件放在配置服务的本地，也支持放在远程Git仓库（GitHub、码云）。<br>
使用Spring Cloud Conﬁg配置中心后的架构如下图：</p>
<figure data-type="image" tabindex="57"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171244.png" alt="" loading="lazy"></figure>
<p>配置中心本质上也是一个微服务，同样需要注册到Eureka服务注册中心！</p>
<h3 id="102-git配置管理">10.2 Git配置管理</h3>
<ol>
<li>
<p><strong>远程Git仓库</strong></p>
<p>知名的Git远程仓库有国外的GitHub和国内的码云（gitee）；但是使用GitHub时，国内的用户经常遇到的问题是访问速度太慢，有时候还会出现无法连接的情况。如果希望体验更好一些，可以使用国内的Git托管服务——码云（gitee.com）。<br>
与GitHub相比，码云也提供免费的Git仓库。此外，还集成了代码质量检测、项目演示等功能。对于团队协作开发，码云还提供了项目管理、代码托管、文档管理的服务。本章中使用的远程Git仓库是码云。<br>
码云访问地址：https://gitee.com/</p>
</li>
<li>
<p><strong>创建远程仓库</strong></p>
<p>首先要使用码云上的私有远程git仓库需要先注册帐号；请先自行访问网站并注册帐号，然后使用帐号登录码云控制台并创建公开仓库。</p>
</li>
<li>
<p><strong>创建配置文件</strong></p>
<p>在新建的仓库中创建需要被统一配置管理的配置文件。<br>
配置文件的命名方式：{application}-{proﬁle}.yml 或 {application}-{proﬁle}.properties<br>
application为应用名称<br>
proﬁle用于区分开发环境，测试环境、生产环境等<br>
如user-dev.yml，表示用户微服务开发环境下使用的配置文件。<br>
这里将user-service工程的配置文件application.yml文件的内容复制作为user-dev.yml文件的内容，具体配置如下：</p>
<figure data-type="image" tabindex="58"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171438.png" alt="" loading="lazy"></figure>
<p>创建 user-dev.yml ；内容来自 user-service\src\main\resources\application.yml （方便后面测试user-service项目的配置），可以如下：</p>
<pre><code class="language-yaml">server:
  port: ${port:9091}
spring:
  datasource:
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/springcloud
    username: root
    password: root
  application:
    #应用名
    name: user-service
mybatis:
  type-aliases-package: com.itheima.user.pojo
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
  instance:
  	ip-address: 127.0.0.1
    	prefer-ip-address: true
    	lease-expiration-duration-in-seconds: 90
    	lease-renewal-interval-in-seconds: 30
</code></pre>
<figure data-type="image" tabindex="59"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171549.png" alt="" loading="lazy"></figure>
<p>创建完user-dev.yml配置文件之后，gitee中的仓库如下：</p>
<figure data-type="image" tabindex="60"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171601.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="103-搭建配置中心微服务">10.3 搭建配置中心微服务</h3>
<ol>
<li>
<p><strong>创建工程</strong></p>
<p>创建配置中心微服务工程 config-server：</p>
<p>添加依赖，修改config-server\pom.xml 如下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 
http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;parent&gt;
        &lt;artifactId&gt;heima-springcloud&lt;/artifactId&gt;
        &lt;groupId&gt;com.itheima&lt;/groupId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.itheima&lt;/groupId&gt;
    &lt;artifactId&gt;config-server&lt;/artifactId&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>
</li>
<li>
<p><strong>启动类</strong></p>
<p>创建配置中心工程config-server 的启动类；<br>
config-server\src\main\java\com\itheima\config\ConfigServerApplication.java 如下：</p>
<pre><code class="language-java">package com.itheima.config;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;
import org.springframework.cloud.config.server.EnableConfigServer;

@SpringBootApplication
@EnableConfigServer
public class ConfigServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConfigServerApplication.class, args);
    }
}
</code></pre>
</li>
<li>
<p><strong>配置文件</strong><br>
创建配置中心工程config-server 的配置文件；<br>
config-server\src\main\resources\application.yml 如下：</p>
<pre><code class="language-yaml">server:
  port: 12000
spring:
  application:
    name: config-server
  cloud:
    config:
      server:
        git:
          uri: https://gitee.com/liaojianbin/heima-config.git
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
<p>注意上述的 spring.cloud.conﬁg.server.git.uri 则是在码云创建的仓库地址；可修改为自己创建的仓库地址</p>
</li>
<li>
<p><strong>启动测试</strong><br>
启动eureka注册中心和配置中心；然后访问http://localhost:12000/user-dev.yml ，查看能否输出在码云存储管理的user-dev.yml文件。并且可以在gitee上修改user-dev.yml然后刷新上述测试地址也能及时到最新数据。</p>
</li>
</ol>
<figure data-type="image" tabindex="61"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803171928.png" alt="" loading="lazy"></figure>
<h3 id="104-获取配置中心配置">10.4 获取配置中心配置</h3>
<p>前面已经完成了配置中心微服务的搭建，下面我们就需要改造一下用户微服务user-service ，配置文件信息不再由微服务项目提供，而是从配置中心获取。如下对user-service 工程进行改造。</p>
<ol>
<li>
<p><strong>添加依赖</strong></p>
<p>在user-service 工程中的pom.xml文件中添加如下依赖：</p>
<pre><code class="language-xml">		&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;
            &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
</li>
<li>
<p><strong>修改配置</strong></p>
<ol>
<li>删除user-service 工程的user-service\src\main\resources\application.yml 文件（因为该文件从配置中心获取）</li>
<li>创建user-service 工程user-service\src\main\resources\bootstrap.yml 配置文件</li>
</ol>
<pre><code class="language-yaml">spring:
  cloud:
    config:
      # 与远程仓库中的配置文件的application保持一致
      name: user
      # 远程仓库中的配置文件的profile保持一致
      profile: dev
      # 远程仓库中的版本保持一致
      label: master
      discovery:
        # 使用配置中心
        enabled: true
        # 配置中心服务id
        service-id: config-server
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
<p>bootstrap.yml文件也是Spring Boot的默认配置文件，而且其加载的时间相比于application.yml更早。<br>
application.yml和bootstrap.yml虽然都是Spring Boot的默认配置文件，但是定位却不相同。bootstrap.yml可以理解成系统级别的一些参数配置，这些参数一般是不会变动的。application.yml 可以用来定义应用级别的参数，如果搭配 spring cloud conﬁg 使用，application.yml 里面定义的文件可以实现动态替换。</p>
<p>总结就是，bootstrap.yml文件相当于项目启动时的引导文件，内容相对固定。application.yml文件是微服务的一些常规配置参数，变化比较频繁。</p>
</li>
<li>
<p><strong>启动测试</strong><br>
启动注册中心eureka-server 、配置中心config-server 、用户服务user-service ，如果启动没有报错其实已经使用上配置中心内容，可以到注册中心查看，也可以检验user-service 的服务。</p>
<figure data-type="image" tabindex="62"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803172413.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h2 id="11-spring-cloud-bus服务总线">11、Spring Cloud Bus服务总线</h2>
<h3 id="111-问题">11.1 问题</h3>
<p>前面已经完成了将微服务中的配置文件集中存储在远程Git仓库，并且通过配置中心微服务从Git仓库拉取配置文件，当用户微服务启动时会连接配置中心获取配置信息从而启动用户微服务。<br>
如果我们更新Git仓库中的配置文件，那用户微服务是否可以及时接收到新的配置信息并更新呢？</p>
<ol>
<li>
<p><strong>修改远程Git配置</strong><br>
修改在码云上的user-dev.yml文件，添加一个属性test.name。</p>
<figure data-type="image" tabindex="63"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803172557.png" alt="" loading="lazy"></figure>
</li>
<li>
<p><strong>修改UserController</strong><br>
修改user-service 工程中的处理器类；<br>
user-service\src\main\java\com\itheima\user\controller\UserController.java 如下：</p>
<pre><code class="language-java">package com.itheima.user.controller;

import com.itheima.user.pojo.User;
import com.itheima.user.service.UserService;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@RequestMapping(&quot;/user&quot;)
public class UserController {
        @Autowired
    private UserService userService;

    @Value(&quot;${test.name}&quot;)
    private String name;

    @GetMapping(&quot;/{id}&quot;)
    public User queryById(@PathVariable Long id){
        System.out.println(&quot;配置文件中的test.name = &quot; + name);
        return userService.queryById(id);
    }
}
</code></pre>
</li>
<li>
<p><strong>测试</strong><br>
依次启动注册中心eureka-server 、配置中心config-server 、用户服务user-service ；然后修改Git仓库中的配置信息，访问用户微服务，查看输出内容。</p>
<p>**结论：**通过查看用户微服务控制台的输出结果可以发现，我们对于Git仓库中配置文件的修改并没有及时更新到用户微服务，只有重启用户微服务才能生效。<br>
如果想在不重启微服务的情况下更新配置该如何实现呢? <strong>可以使用Spring Cloud Bus来实现配置的自动更新。</strong></p>
<p>需要注意的是Spring Cloud Bus底层是基于RabbitMQ实现的，默认使用本地的消息队列服务，所以需要提前启动本地RabbitMQ服务（安装RabbitMQ以后才有），如下：</p>
<figure data-type="image" tabindex="64"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803172726.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="112-spring-cloud-bus简介">11.2 Spring Cloud Bus简介</h3>
<p>Spring Cloud Bus是用轻量的消息代理将分布式的节点连接起来，可以用于广播配置文件的更改或者服务的监控管理。也就是消息总线可以为微服务做监控，也可以实现应用程序之间相互通信。 Spring Cloud Bus可选的消息代理<br>
有RabbitMQ和Kafka。</p>
<p>使用了Bus之后：</p>
<figure data-type="image" tabindex="65"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803172800.png" alt="" loading="lazy"></figure>
<h3 id="113-改造配置中心">11.3 改造配置中心</h3>
<ol>
<li>
<p>在config-server 项目的pom.xml文件中加入Spring Cloud Bus相关依赖</p>
<pre><code class="language-xml">        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
</li>
<li>
<p>在config-server 项目修改application.yml文件如下：</p>
<pre><code class="language-yaml">server:
  port: 12000
spring:
  application:
    name: config-server
  cloud:
    config:
      server:
        git:
          uri: https://gitee.com/liaojianbin/heima-config.git
  # rabbitmq的配置信息；如下配置的rabbit都是默认值，其实可以完全不配置
  rabbitmq:
    host: localhost
    port: 5672
    username: guest
    password: guest
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
management:
  endpoints:
    web:
      exposure:
        # 暴露触发消息总线的地址
        include: bus-refresh
</code></pre>
</li>
</ol>
<h3 id="114-改造用户服务">11.4  改造用户服务</h3>
<ol>
<li>
<p>在用户微服务user-service 项目的pom.xml中加入Spring Cloud Bus相关依赖</p>
<pre><code class="language-xml">        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
        &lt;/dependency&gt;
</code></pre>
</li>
<li>
<p>修改user-service 项目的bootstrap.yml如下：</p>
<pre><code class="language-yaml">spring:
  cloud:
    config:
      # 与远程仓库中的配置文件的application保持一致
      name: user
      # 远程仓库中的配置文件的profile保持一致
      profile: dev
      # 远程仓库中的版本保持一致
      label: master
      discovery:
        # 使用配置中心
        enabled: true
        # 配置中心服务id
        service-id: config-server
  # rabbitmq的配置信息；如下配置的rabbit都是默认值，其实可以完全不配置
  rabbitmq:
    host: localhost
    port: 5672
    username: guest
    password: guest
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
</code></pre>
</li>
<li>
<p>改造用户微服务user-service 项目的UserController</p>
<figure data-type="image" tabindex="66"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803173237.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="115-测试">11.5 测试</h3>
<p>前面已经完成了配置中心微服务和用户微服务的改造，下面来测试一下，当我们修改了Git仓库中的配置文件，用户微服务是否能够在不重启的情况下自动更新配置信息。<br>
<strong>测试步骤：</strong><br>
第一步：依次启动注册中心eureka-server 、配置中心config-server 、用户服务user-service<br>
第二步：访问用户微服务http://localhost:9091/user/8；查看IDEA控制台输出结果</p>
<p>第三步：修改Git仓库中配置文件user-dev.yml 的test.name 内容<br>
第四步：使用Postman或者RESTClient工具发送POST方式请求访问地址http://127.0.0.1:12000/actuator/bus-refresh</p>
<figure data-type="image" tabindex="67"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803173322.png" alt="" loading="lazy"></figure>
<p>第五步：访问用户微服务系统控制台查看输出结果</p>
<p>说明：<br>
1、Postman或者RESTClient是一个可以模拟浏览器发送各种请求（POST、GET、PUT、DELETE等）的工具<br>
2、请求地址http://127.0.0.1:12000/actuator/bus-refresh中 /actuator是固定的，/bus-refresh对应的是配置中心conﬁg-server中的application.yml文件的配置项include的内容<br>
3、请求http://127.0.0.1:12000/actuator/bus-refresh地址的作用是访问配置中心的消息总线服务，消息总线服务接收到请求后会向消息队列中发送消息，各个微服务会监听消息队列。当微服务接收到队列中的消息后，会重新从配置中心获取最新的配置信息。</p>
<h3 id="116-spring-cloud-体系技术综合应用概览">11.6 Spring Cloud 体系技术综合应用概览</h3>
<figure data-type="image" tabindex="68"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803173833.png" alt="" loading="lazy"></figure>
<h2 id="12-思维导图">12、思维导图</h2>
<figure data-type="image" tabindex="69"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200803174547.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Session]]></title>
        <id>https://jonchan1013.github.io/post/spring-session/</id>
        <link href="https://jonchan1013.github.io/post/spring-session/">
        </link>
        <updated>2020-07-24T02:12:46.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724102425.png" alt="" loading="lazy"></figure>
<h2 id="1-httpsession-回顾">1、HttpSession 回顾</h2>
<h3 id="11-什么是-httpsession">1.1  什么是 HttpSession</h3>
<p>是JavaWeb 服务端提供的用来建立与客户端会话状态的对象。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724102425.png" alt="" loading="lazy"></figure>
<h2 id="1-httpsession-回顾">1、HttpSession 回顾</h2>
<h3 id="11-什么是-httpsession">1.1  什么是 HttpSession</h3>
<p>是JavaWeb 服务端提供的用来建立与客户端会话状态的对象。</p>
<!-- more -->
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Logstash_Kibana]]></title>
        <id>https://jonchan1013.github.io/post/logstash_kibana/</id>
        <link href="https://jonchan1013.github.io/post/logstash_kibana/">
        </link>
        <updated>2020-07-22T19:02:44.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200723030527.png" alt="" loading="lazy"></figure>
<h2 id="1-logstash-简介">1、LogStash 简介</h2>
<h3 id="11-什么是logstash">1.1 什么是LogStash</h3>
<p>官方文字说明：Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。<br>
通俗说明：Logstash 是一款强大的数据处理工具，常用作日志处理。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200723030527.png" alt="" loading="lazy"></figure>
<h2 id="1-logstash-简介">1、LogStash 简介</h2>
<h3 id="11-什么是logstash">1.1 什么是LogStash</h3>
<p>官方文字说明：Logstash 是开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。<br>
通俗说明：Logstash 是一款强大的数据处理工具，常用作日志处理。</p>
<!-- more -->
<p><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200723030716.png" alt="" loading="lazy"><br>
到目前为止，Logstash 已经有超过 200 个可用的插件，以及创建和贡献自己的灵活性。社区生态非常完善，对于我们可以放心的使用。</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724091204.png" alt="" loading="lazy"></figure>
<h3 id="12-为什么使用logstash">1.2 为什么使用Logstash</h3>
<p>通常当系统发生故障时，工程师需要登录到各个服务器上，使用 grep / sed / awk 等Linux 脚本工具去日志里查找故障原因。在没有日志系统的情况下，首先需要定位处理请求的服务器，如果这台服务器部署了多个实例，则需要去每个应用实例的日志目录下去找日志文件。每个应用实例还会设置日志滚动策略（如：每天生成一个文件），还有日志压缩归档策略等。</p>
<p>这样一系列流程下来，对于我们排查故障以及及时找到故障原因，造成了比较大的麻烦。因此，如果我们能***把这些日志集中管理***，并提供集中检索功能，不仅可以提高诊断的效率，同时对系统情况有个全面的理解，避免事后救火的被动。<br>
所以日志集中管理功能就可以使用 ELK 技术栈进行实现。Elasticsearch 只有数据存储和分析的能力，Kibana 就是可视化管理平台。还缺少数据收集和整理的角色，这个功能就是Logstash 负责的。</p>
<h3 id="13-logstash-工作原理">1.3  Logstash 工作原理</h3>
<h4 id="131-data-source">1.3.1 Data Source</h4>
<p>Logstash 支持的数据源有很多。例如对于日志功能来说只能能有日志记录和日志传递功能的日志都支持，Spring Boot 中默认推荐 logback 支持日志输出功能（输出到数据库、数据出到文件）。<br>
我们就使用 logback 进行日志输出给 Logstash。</p>
<h4 id="132-logstash-pipeline">1.3.2 Logstash Pipeline</h4>
<p>整个整体就是 Logstash 的功能。<br>
在 Logstash 中包含非常重要的三个功能：<br>
a) Input<br>
输入源，一般配置为自己监听的主机及端口。DataSource 向指定的 ip 及端口输出日志，Input 输入源监听到数据信息就可以进行收集。<br>
b) Filter<br>
过滤功能，对收集到的信息进行过滤（额外处理），也可以省略这个配置（不做处理）<br>
c) Output<br>
把收集到的信息发送给谁。在 ELK 技术栈中都是输出给 Elasticsearch，后面数据检索和数据分析的过程就给 Elasticsearch 了。</p>
<p><strong>最终效果：通过整体步骤就可以把原来一行日志信息转换为 Elasticsearch 支持的Document 形式（键值对形式）的数据进行存储。</strong></p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724091938.png" alt="" loading="lazy"></figure>
<h2 id="2-安装logstash">2、安装Logstash</h2>
<p>前面已经安装好了 Elasticsearch 和 Kibana。下面是安装 Logstash 的步骤<br>
Logstash 是不需要必须和 Elasticsearch 安装到一起，如果独立安装到一台服务器，需要在服务器中先配置好 JDK 环境变量。在课堂中把 ELK 三个软件都装到一台服务器中。</p>
<h3 id="21-安装logstash">2.1 安装Logstash</h3>
<ol>
<li>
<p>上传 Logstash 并解压</p>
<p>上传压缩包到/usr/local/tmp 中后，解压压缩包。</p>
<p>tar zxf logstash-6.8.4.tar.gz</p>
<p>剪切到/usr/local 中并命名为 logstash</p>
<p>mv logstash-6.8.4 ../logstash</p>
</li>
<li>
<p>进入到 logstash 配置文件夹中</p>
<p>cd /usr/local/logstash/config/</p>
<p>创建配置文件，名称自定义。</p>
<p>vim mylogstash.conf</p>
<p>配置解释说明：<br>
input:接收日志输入配置<br>
tcp: 协议<br>
mode: logstash 服务<br>
host:logstash 主机 ip<br>
port：端口，自己指定。默认 4560<br>
output：日志处理输出<br>
elasticsearch: 交给 es 处理<br>
action：es 中 index 命令。也就是新增命令。<br>
hosts：es 的主机<br>
index:存储日志的索引。如果不存在可以自动创建。默认的 type 名称为 doc<br>
一定要先启动编辑状态（点击键盘i 键）在粘贴，如果没启用第一行是nput{少个i。</p>
<pre><code class="language-xml">input {
		tcp {
			mode =&gt; &quot;server&quot;
			host =&gt; &quot;192.168.8.140&quot;
			port =&gt; 4560
		}
}
filter {
}
output {
		elasticsearch {
			action =&gt; &quot;index&quot;
			hosts =&gt; &quot;192.168.8.140:9200&quot;
			index =&gt; &quot;test_log&quot;
		}
}
</code></pre>
</li>
<li>
<p>启动 Logstash<br>
进入到 bin 目录</p>
<p>cd /usr/local/logstash/bin</p>
<p>需要先启动 Elasticsearch 否则会频繁提示无法连接到 Elasticsearch</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724092726.png" alt="" loading="lazy"></figure>
<p>启动 logstash</p>
<p>./logstash -f /usr/local/logstash/config/mylogstash.conf</p>
<p>如果启动完成没有出异常，提示 Successfully 说明安装成功。</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724092738.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h2 id="3-使用logback-向logstash-中输出日志">3、使用Logback 向Logstash 中输出日志</h2>
<p>需求：随意新建一个项目把输出到控制台的日志信息也输出到 Logstash 中。</p>
<ol>
<li>
<p>修改pom.xml<br>
logstash-logback-encoder 就是转码后向 logstash 中输入的依赖。<br>
注意：</p>
<p>如果导入的是 6.x 版本不会在控制台看见任何额外日志信息。<br>
如果导入的是 5.x 版本会在控制台看见 logback.xml 加载的信息。</p>
<pre><code class="language-xml">&lt;parent&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
	&lt;version&gt;2.2.6.RELEASE&lt;/version&gt;
&lt;/parent&gt;
&lt;dependencies&gt;
	&lt;dependency&gt;
		&lt;groupId&gt;net.logstash.logback&lt;/groupId&gt;
		&lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;
		&lt;version&gt;6.3&lt;/version&gt;
	&lt;/dependency&gt;
	&lt;dependency&gt;
		&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
		&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
	&lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
</li>
<li>
<p>导入logback.xml<br>
将logback.xml文件粘贴到 resources 中。</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724093405.png" alt="" loading="lazy"></figure>
<p>logback.xml 文件内容如下，红色部分表示向 logstash 中输出日志信息。<br>
红色中<destination>配置的是 logstash 配置文件中 input 里面 host 和 post 的信息。</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!--该日志将日志级别不同的 log 信息保存到不同的文件中 --&gt;
&lt;configuration&gt;
    &lt;include resource=&quot;org/springframework/boot/logging/logback/defaults.xml&quot;&gt;&lt;/include&gt;
    &lt;springProperty scope=&quot;context&quot; name=&quot;egoSearchLogback&quot; source=&quot;spring.application.name&quot;/&gt;

    &lt;!-- 日志在工程中的输出位置 --&gt;
    &lt;property name=&quot;EGO-LOG-APPENDER&quot; value=&quot;%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}&quot;&gt;&lt;/property&gt;
    &lt;!-- 控制台的日志输出样式 --&gt;
    &lt;appender name=&quot;consoleAppender&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;filter class=&quot;ch.qos.logback.classic.filter.ThresholdFilter&quot;&gt;
            &lt;level&gt;INFO&lt;/level&gt;
        &lt;/filter&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;${EGO-LOG-APPENDER}&lt;/pattern&gt;
            &lt;charset&gt;utf8&lt;/charset&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;
    &lt;!-- logstash 输出 --&gt;
    &lt;appender name=&quot;logstashAppender&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt;
        &lt;destination&gt;192.168.89.141:5044&lt;/destination&gt;
        &lt;!-- 日志输出编码 --&gt;
        &lt;encoder charset=&quot;UTF-8&quot; class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot;&gt;&lt;/encoder&gt;
    &lt;/appender&gt;
    &lt;!-- logstash 远程日志配置--&gt;
&lt;appender name=&quot;logstash&quot;
class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt;
&lt;destination&gt;192.168.8.140:4560&lt;/destination&gt;
&lt;encoder charset=&quot;UTF-8&quot;
class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot; /&gt;
&lt;/appender&gt;
    &lt;root level=&quot;DEBUG&quot;&gt;
        &lt;appender-ref ref=&quot;consoleAppender&quot;/&gt;
        &lt;appender-ref ref=&quot;logstashAppender&quot;/&gt;
    &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>
</li>
<li>
<p>新建启动类</p>
</li>
</ol>
<p>新建 com.cy.DemoApplication</p>
<pre><code class="language-java">@SpringBootApplication
public class DemoApplication {
	public static void main(String[] args) {
		SpringApplication.run(DemoApplication.class,args);
	}
}
</code></pre>
<h2 id="4-在kibana-中查看日志信息">4、在Kibana 中查看日志信息</h2>
<h3 id="41-使用命令方式查看">4.1 使用命令方式查看</h3>
<p>可以直接在 Dev Tools 中输入命令查看日志信息。<br>
输入： GET test_log/_search 查看全部。</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094359.png" alt="" loading="lazy"></figure>
<h3 id="42-是kibana-界面查看">4.2  是Kibana 界面查看</h3>
<p>进入到 Kibana 后按图所示点击。创建索引表达式</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094419.png" alt="" loading="lazy"></figure>
<p>选择没有时间过滤后，点击“Create index pattern”按钮</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094434.png" alt="" loading="lazy"></figure>
<p>点击菜单中 Discover，选择右侧 test_log</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094507.png" alt="" loading="lazy"></figure>
<p>每条日志在 Elasticsearch 中存储形式</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094920.png" alt="" loading="lazy"></figure>
<p>IDEA 中控制台打印的原日志内容是下面内容。Logstash 作用就是把下面内容转换为上面Elasticsearch 存储的内容。在中间做了数据格式转换，收集数据放入 Elasticsearch 中的工作。</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724094935.png" alt="" loading="lazy"></figure>
<h2 id="5-搭建日志系统">5、搭建日志系统</h2>
<p>绝大多数项目在后台管理中都有日志管理。以前的日志信息是存储在 MySQL 中，日志随着项目运行时间会越来越多，一直存储在 MySQL 会导致查询降低。现在的日志信息通过ELK 技术栈进行操作。存储在 Elasticsearch 中，可以更好的分析日志内容及更快查询效率。</p>
<p>给定简单需求：<br>
搭建日志系统，提供查询 Elasticsearch 中日志信息的接口。</p>
<ol>
<li>
<p>新建项目<br>
名称为 ELK_Demo</p>
</li>
<li>
<p>修改pom.xml<br>
搭建最基本的环境，实现需求，没有考虑 Spring Cloud 相关环境，如果考虑 Spring Cloud还需要配置 Eureka 等信息。</p>
</li>
</ol>
<pre><code class="language-xml">&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
            &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;

&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;
</code></pre>
<ol start="3">
<li>
<p>创建配置文件<br>
在 resources 下新建 application.yml 配置文件。<br>
配置 Elasticsearch 相关配置信息。</p>
<pre><code class="language-yaml">elasticsearch:
  rest:  # 配置ElasticsearchRestTemplate客户端的属性，是现在推荐使用的。
    uris:
      - http://192.168.89.140:9200
      - http://192.168.89.141:9200
</code></pre>
</li>
<li>
<p>新建实体<br>
根据 kibana 中查看到日志信息可以得出看出，除了 message 是类类型，里面包含一些其他属性外，其他的属性都是简单类型属性。</p>
</li>
</ol>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724095948.png" alt="" loading="lazy"></figure>
<p>新建 com.cy.pojo.Log。</p>
<p>注意@version 和@timestamp 要使用@JsonProperty 进行接收。</p>
<pre><code class="language-java">@Data
@Document(indexName = &quot;test_log&quot;,type = &quot;doc&quot;)
public class Log {
	@Id
	private String id;
	@Field(type= FieldType.Text)
	private String host;
	@Field(type= FieldType.Text)
	private String message;
	@Field(type= FieldType.Long)
	private Long port;
	@Field(type = FieldType.Date)
	@JsonProperty(&quot;@timestamp&quot;)
	private Date timestamp;
	@Field(type = FieldType.Text)
	@JsonProperty(&quot;@version&quot;)
	private String version;
}
</code></pre>
<ol start="5">
<li>
<p>新建service 及实现类</p>
<p>新建 com.cy.service.LogService 及实现类</p>
<pre><code class="language-java">public interface LogService {
    List&lt;Log&gt; selectByPage(int page,int size);
}

------------------------------------------------
    @Service
public class LogServiceImpl implements LogService {
	@Autowired
	private ElasticsearchTemplate elasticsearchTemplate;
	@Override
	public List&lt;Log&gt; selectByPage(int page, int size) {
		SearchQuery sq = new NativeSearchQuery(QueryBuilders.matchAllQuery());
		sq.setPageable(PageRequest.of(page-1,size));
		return elasticsearchTemplate.queryForList(sq,Log.class);
	}
}
</code></pre>
</li>
<li>
<p>新建控制器</p>
</li>
</ol>
<p>新建 com.cy.controller.LogController</p>
<pre><code class="language-java">@Controller
public class LogController {
	@Autowired
	private LogService logService;
	@RequestMapping(&quot;/page&quot;)
	@ResponseBody
	public List&lt;Log&gt; showPage(int page,int size){
		return logService.selectByPage(page,size);
	}
}
</code></pre>
<ol start="7">
<li>
<p>测试结果</p>
<p>在浏览器输入: http://localhost:8080/page?page=1&amp;size=2</p>
<p>会看见下面的结果。</p>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200724100358.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h2 id="6-logstashmysqlelasticsearch-实现数据增量导入双写一致">6、LogStash+MySQL+Elasticsearch 实现数据增量导入（双写一致）</h2>
<p>原有系统中，如果使用了缓存应用，全文搜索服务等额外数据存储，则在代码实现中，要保证双写一致，即写数据库的同时，把数据的变量同步到其他存储中。<br>
如果使用 LogStash，则可以实现数据的增量导入。<br>
思路：写数据到数据库，LogStash 监听数据库中数据的变化，把增量数据读取，并保存到 ES 中。</p>
<h3 id="61-环境准备">6.1 环境准备</h3>
<ol>
<li>
<p>上传数据库驱动<br>
LogStash 本身不提供数据库驱动，需要使用者提供数据库的驱动包，且 LogStash 中的数据库 JDBC 插件就是 Java 开发的。需要上传数据库驱动到 LogStash 所在主机。<br>
Logstash5.x &amp; 6.3.*以下版本，上传驱动不需要固定位置，任意位置即可。<br>
Logstash6.8.4 版本的上传位置固定是：$LogStash_HOME/logstash_core/lib/jars/</p>
</li>
<li>
<p>准备数据库表格<br>
案例中使用电商项目中的商品表格，建表语句如下：</p>
<pre><code class="language-mysql">CREATE TABLE `tb_item` (
`id` bigint(20) NOT NULL COMMENT '商品 id，同时也是商品编号',
`title` varchar(100) NOT NULL COMMENT '商品标题',
`sell_point` varchar(500) DEFAULT NULL COMMENT '商品卖点',
`price` bigint(20) NOT NULL COMMENT '商品价格，单位为：分',
   `num` int(10) NOT NULL COMMENT '库存数量',
`barcode` varchar(30) DEFAULT NULL COMMENT '商品条形码',
`image` varchar(500) DEFAULT NULL COMMENT '商品图片',
`cid` bigint(10) NOT NULL COMMENT '所属类目，叶子类目',
`status` tinyint(4) NOT NULL DEFAULT '1' COMMENT '商品状态，1-正常，2-下架，3-删除',
`created` datetime NOT NULL COMMENT '创建时间',
`updated` datetime NOT NULL COMMENT '更新时间',
PRIMARY KEY (`id`),
KEY `cid` (`cid`),
KEY `status` (`status`),
KEY `updated` (`updated`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='商品表'; 
</code></pre>
<p>LogStash 实现增量导入，需要有一个定位字段，这个字段的数据，可以表示数据的新旧，代表这个数据是否是一个需要导入到 ES 中的数据。案例中使用表格的 updated 字段作为定位字段，每次读取数据的时候，都会记录一个最大的 updated 时间，每次读取数据的时候，都读取 updated 大于等于记录的定位字段数据。每次查询的就都是最新的，要导入到 ES 中的数据。</p>
</li>
</ol>
<h3 id="62-编写logstash-配置文件">6.2 编写LogStash 配置文件</h3>
<p>在$LogStash_home/config/目录中，编写配置文件 ego-items-db2es.conf<br>
vim config/ego-items-db2es.conf</p>
<pre><code class="language-xml">input {
  jdbc {
	# 连接地址
    jdbc_connection_string =&gt; &quot;jdbc:mysql://192.168.1.2:3306/ego?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=GMT%2B8&quot;
	
	# 数据库用户名和密码
    jdbc_user =&gt; &quot;root&quot;
    jdbc_password =&gt; &quot;root&quot;

	# 驱 动 类 ， 如 果 使 用 低 版 本 的 logstash ， 需 要 再 增 加 配 置jdbc_driver_library，配置驱动包所在位置
    jdbc_driver_class =&gt; &quot;com.mysql.cj.jdbc.Driver&quot;
	# 是否开启分页逻辑
    jdbc_paging_enabled =&gt; true
	# 分页的长度是多少
    jdbc_page_size =&gt; &quot;2000&quot;
	# 时区
    jdbc_default_timezone =&gt; &quot;Asia/Shanghai&quot;

	# 执行的 SQL
    statement =&gt; &quot;select id, title, sell_point, price, image, updated from tb_item where updated &gt;= :sql_last_value order by updated asc&quot;

	# 执行 SQL 的周期， [秒] 分钟 小时 天 月 年
    schedule =&gt; &quot;* * * * *&quot;
	# 是否使用字段的值作为比较策略
    use_column_value =&gt; true
	# 作为比较策略的字段名称
    tracking_column =&gt; &quot;updated&quot;
	# 作为比较策略的字段类型，可选为 numberic 和 timestamp
    tracking_column_type =&gt; &quot;timestamp&quot;
	# 记录最近的比较策略字段值的文件是什么，相对寻址路径是 logstash 的安装路径
    last_run_metadata_path =&gt; &quot;./ego-items-db2es-last-value&quot;
	# 是否每次执行 SQL 的时候，都删除 last_run_metadata_path 文件内容
    clean_run =&gt; false
	# 是否强制把 ES 中的字段名都定义为小写。
    lowercase_column_names =&gt; false
  }
}

output {
  elasticsearch {
    hosts =&gt; [&quot;http://192.168.89.140:9200&quot;, &quot;http://192.168.89.141:9200&quot;]
    index =&gt; &quot;ego-items-index&quot;
    action =&gt; &quot;index&quot;
    document_id =&gt; &quot;%{id}&quot;
  }
}

</code></pre>
<h3 id="63-安装logstash-input-jdbc-插件">6.3  安装logstash-input-jdbc 插件</h3>
<p>在 LogStash6.3.x 和 5.x 版本中，logstash-input-jdbc 插件是默认安装的。在 6.8.4 版本的LogStash 中是未安装的，需要手工安装。安装命令如下：<br>
$Logstash_HOME/bin/logstash-plugin install logstash-input-jdbc</p>
<h3 id="64-启动测试">6.4 启动测试</h3>
<p>启动 LogStash 命令不变：<br>
bin/logstash -f 配置文件</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ElasticSearch]]></title>
        <id>https://jonchan1013.github.io/post/elasticsearch/</id>
        <link href="https://jonchan1013.github.io/post/elasticsearch/">
        </link>
        <updated>2020-07-18T17:38:47.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200719014000.png" alt="" loading="lazy"></figure>
<h2 id="1-什么是-elastic-search">1、什么是 Elastic Search</h2>
<p>ElasticSearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式的全文搜索引擎，其对外服务是基于 RESTful web 接口发布的。Elasticsearch 是用 Java 开发的应用，并作为 Apache 许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到近实时搜索，稳定，可靠，快速，安装使用方便。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200719014000.png" alt="" loading="lazy"></figure>
<h2 id="1-什么是-elastic-search">1、什么是 Elastic Search</h2>
<p>ElasticSearch 是一个基于 Lucene 的搜索服务器。它提供了一个分布式的全文搜索引擎，其对外服务是基于 RESTful web 接口发布的。Elasticsearch 是用 Java 开发的应用，并作为 Apache 许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到近实时搜索，稳定，可靠，快速，安装使用方便。</p>
<!-- more -->
<h3 id="11-相关概念">1.1 相关概念</h3>
<h4 id="111-cluster">1.1.1  cluster</h4>
<p>集群。ElasticSearch 集群由一或多个节点组成，其中有一个主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。ElasticSearch 的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部看 ElasticSearch集群，在逻辑上是个整体，你与集群中的任何一个节点通信和与整个 ElasticSearch 集群通信是等价的。也就是说，主节点的存在不会产生单点安全隐患、并发访问瓶颈等问题。</p>
<h4 id="112-shards">1.1.2 shards</h4>
<p>primary shard：代表索引的主分片，ElasticSearch 可以把一个完整的索引分成多个primary shard，这样的好处是可以把一个大的索引拆分成多个分片，分布存储在不同的ElasticSearch 节点上，从而形成分布式存储，并为搜索访问提供分布式服务，提高并发处理能。primary shard 的数量只能在索引创建时指定，并且索引创建后不能再更改 primaryshard 数量。</p>
<h4 id="113-replicas">1.1.3 replicas</h4>
<p>replica shard：代表索引主分片的副本，ElasticSearch 可以设置多个 replica shard。replica shard 的作用：一是提高系统的容错性，当某个节点某个 primary shard 损坏或丢失时可以从副本中恢复。二是提高 ElasticSearch 的查询效率，ElasticSearch 会自动对搜索请求进行负载均衡，将并发的搜索请求发送给合适的节点，增强并发处理能力。</p>
<h4 id="114-index">1.1.4  Index</h4>
<p>索引。相当于关系型数据库中的表。其中存储若干相似结构的 Document 数据。如：客户索引，订单索引，商品索引等。ElasticSearch 中的索引不像数据库表格一样有强制的数据结构约束，在理论上，可以存储任意结构的数据。但了为更好的为业务提供搜索数据支撑，还是要设计合适的索引体系来存储不同的数据。</p>
<h4 id="115-type">1.1.5 Type</h4>
<p>类型。每个索引中都必须有唯一的一个 Type，Type 是 Index 中的一个逻辑分类。ElasticSearch 中的数据 Document 是存储在索引下的 Type 中的。</p>
<p><em><strong>注 意 ： ElasticSearch5.x 及 更 低 版 本 中 ， 一 个 Index 中 可 以 有 多 个 Type 。ElasticSearch6.x 版本之后，type 概念被弱化，一个 index 中只能有唯一的一个 type。且在 7.x 版本之后，删除 type 定义。</strong></em></p>
<h4 id="116-document">1.1.6  Document</h4>
<p>文档。ElasticSearch 中的最小数据单元。一个 Document 就是一条数据，一般使用JSON 数据结构表示。每个 Index 下的 Type 中都可以存储多个 Document。一个 Document中可定义多个 field，field 就是数据字段。如：学生数据（{&quot;name&quot;:&quot;张三&quot;, &quot;age&quot;:20,&quot;gender&quot;:&quot;男&quot;}）。</p>
<h4 id="117-反向索引倒排索引">1.1.7 反向索引|倒排索引</h4>
<p>对数据进行分析，抽取出数据中的词条，以词条作为 key，对应数据的存储位置作为value，实现索引的存储。这种索引称为倒排索引。倒排索引是 Document 写入 ElasticSearch时分析维护的。</p>
<p>如：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">数据</th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">商品主键</td>
<td style="text-align:center">商品名</td>
<td style="text-align:center">商品描述</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">荣耀 10</td>
<td style="text-align:center">更贵的手机</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">荣耀 8</td>
<td style="text-align:center">相对便宜的手机</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">IPHONE X</td>
<td style="text-align:center">要卖肾买的手机</td>
</tr>
</tbody>
</table>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200720091147.png" alt="" loading="lazy"></figure>
<h3 id="12-elasticsearch-常见使用场景">1.2 ElasticSearch 常见使用场景</h3>
<p>维基百科：全文检索，高亮显示，搜索推荐</p>
<p>The Guardian（国外的一个新闻网站），此平台可以对用户的行为（点击、浏览、收藏、评论）、社区网络数据（对新闻的评论等）进行数据分析，为新闻的发布者提供相关的公众反馈。</p>
<p>Stack Overflow（国外的程序异常讨论论坛）</p>
<p>Github（开源代码管理），在千亿级别的代码行中搜索信息</p>
<p>电子商务平台等。</p>
<h3 id="13-为什么不用数据库做搜索">1.3 为什么不用数据库做搜索？</h3>
<h4 id="131-查询语法复杂度高">1.3.1  查询语法复杂度高。</h4>
<p>如：电商系统中搜索商品数据 - select * from products where name like '%关键字%' and price bewteen xxx and yyy and ......。不同的用户提供的查询条件不同，需要提供的动态 SQL 过于复杂。</p>
<h4 id="132-关键字索引不全面搜索结果不符合要求">1.3.2 关键字索引不全面，搜索结果不符合要求</h4>
<p>如：电商系统中查询商品数据，条件为商品名包含'笔记本电脑'。那么对此关键字的分析结果为-笔记本、电脑、笔记等。对应的查询语法应该为 - select * from products where name like '%笔记本%' or name like '%电脑%' .......</p>
<h4 id="133-效率问题">1.3.3 效率问题</h4>
<p>数据量越大，查询反应效率越低。</p>
<h2 id="2-linux-安装-elasticsearch">2、Linux 安装 ElasticSearch</h2>
<p>使用的 ElasticSearch 的版本是 6.8.4。ElasticSearch6.x 要求 Linux 内核必须是 3.5+版本以上。</p>
<p>在 linux 操作系统中，查看内核版本的命令是： uname -a</p>
<p>课堂使用的 Linux 是 CentOS8。内核使用的是 4.4。</p>
<p>ElasticSearch6.X 版本要求 JDK 版本至少是 1.8.0_131。 提供 1.8.0_161JDK 安装包。</p>
<h3 id="21-为-elasticsearch-提供完善的系统配置">2.1  为 ElasticSearch 提供完善的系统配置</h3>
<p>ElasticSearch 在 Linux 中安装部署的时候，需要系统为其提供若干系统配置。如：应用可启动的线程数、应用可以在系统中划分的虚拟内存、应用可以最多创建多少文件等。</p>
<ol>
<li>
<p>修改限制信息<br>
vi /etc/security/limits.conf</p>
<p>是修改系统中允许应用最多创建多少文件等的限制权限。Linux 默认来说，一般限制应用最多创建的文件是 65535 个。但是 ElasticSearch 至少需要 65536 的文件创建权限。修改后的内容为：</p>
<p><code>* soft nofile 65536</code></p>
<p><code>* hard nofile 65536</code></p>
</li>
<li>
<p>修改线程开启限制<br>
在 CentOS6.5 版本中编辑下述的配置文件</p>
</li>
</ol>
<p>vi /etc/security/limits.d/90-nproc.conf</p>
<p>在 CentOS7+版本中编辑配置文件是：</p>
<p>vi /etc/security/limits.conf</p>
<p>是修改系统中允许用户启动的进程开启多少个线程。默认的 Linux 限制 root 用户开启的进程可以开启任意数量的线程，其他用户开启的进程可以开启 1024 个线程。必须修改限制数为 4096+。因为 ElasticSearch 至少需要 4096 的线程池预备。ElasticSearch 在 5.x版本之后，强制要求在 linux 中不能使用 root 用户启动 ElasticSearch 进程。所以必须使用其他用户启动 ElasticSearch 进程才可以。</p>
<p><code>* soft nproc 4096</code></p>
<p><code>root soft nproc unlimited</code></p>
<p>注意：Linux 低版本内核为线程分配的内存是 128K。4.x 版本的内核分配的内存更大。如果虚拟机的内存是 1G，最多只能开启 3000+个线程数。至少为虚拟机分配 1.5G 以上的内存。</p>
<ol start="3">
<li>
<p>修改系统控制权限<br>
CentOS6.5 中的配置文件为：</p>
<p>vi /etc/sysctl.conf</p>
<p>CentOS8 中的配置文件为：</p>
<p>vi /etc/sysctl.d/99-sysctl.conf</p>
<p>系统控制文件是管理系统中的各种资源控制的配置文件。ElasticSearch 需要开辟一个65536 字节以上空间的虚拟内存。Linux 默认不允许任何用户和应用直接开辟虚拟内存。</p>
<p>新增内容为：</p>
<p>vm.max_map_count=655360</p>
<p>使用命令： sysctl -p 。 让系统控制权限配置生效。</p>
</li>
</ol>
<h3 id="22-安装-elasticsearch">2.2 安装 ElasticSearch</h3>
<p>ElasticSearch 是 java 开发的应用。在 6.8.4 版本中，要求 JDK 至少是 1.8.0_131 版本以上。</p>
<p>ElasticSearch 的安装过程非常简单。解压立刻可以使用。</p>
<ol>
<li>
<p>解压缩安装压缩包<br>
tar -zxf elasticsearch-6.8.4.tar.gz</p>
</li>
<li>
<p>移动 ElasticSearch<br>
mv elasticsearch-6.8.4 /usr/local/elasticsearch/</p>
</li>
<li>
<p>修改 ElasticSearch 应用的所有者<br>
因为 ElasticSearch 不允许 root 用户启动，而课堂案例中，ElasticSearch 是 root 用户 解 压 缩 的 。 所 以 解 压 后 的 ElasticSearch 应 用 属 于 root 用 户 。 所 以 我 们 需 要 将ElasticSearch 应用的所有者修改为其他用户。</p>
</li>
</ol>
<p>chown -R user.user  /usr/local/elasticsearch</p>
<ol start="4">
<li>
<p>切换用户</p>
<p>su user</p>
</li>
<li>
<p>修改配置<br>
修改 config/elasticsearch 的配置文件，设置可访问的客户端。0.0.0.0 代表任意客户端访问。</p>
<p>vi config/elasticsearch.yml</p>
<p>增加下述内容：</p>
<p>network.host: 0.0.0.0</p>
</li>
<li>
<p>启动<br>
前台启动</p>
<p>/usr/local/elasticsearch/bin/elasticsearch</p>
<p>关闭： ctrl + c</p>
<p>后台启动</p>
<p>/usr/local/elasticsearch/bin/elasticsearch -d</p>
<p>关闭：</p>
<p>jps 命令查看 ElasticSearch 线程的编号</p>
<p>kill -9 ElasticSearch 线程编号</p>
</li>
<li>
<p>测试连接<br>
curl http://localhost:9200</p>
<p>返回如下结果：</p>
<p>{</p>
<p>&quot;name&quot; : &quot;L6WdN7y&quot;,</p>
<p>&quot;cluster_name&quot; : &quot;elasticsearch&quot;,</p>
<p>&quot;cluster_uuid&quot; : &quot;s7_GSd9YQnaH10VQBKCQ5w&quot;,</p>
<p>&quot;version&quot; : {</p>
<p>&quot;number&quot; : &quot;6.3.1&quot;,</p>
<p>&quot;build_flavor&quot; : &quot;default&quot;,</p>
<p>&quot;build_type&quot; : &quot;tar&quot;,</p>
<p>&quot;build_hash&quot; : &quot;eb782d0&quot;,</p>
<p>&quot;build_date&quot; : &quot;2019-06-29T21:59:26.107521Z&quot;,</p>
<p>&quot;build_snapshot&quot; : false,</p>
<p>&quot;lucene_version&quot; : &quot;7.3.1&quot;,****</p>
<p>&quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;,</p>
<p>&quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot;</p>
<p>},</p>
<p>&quot;tagline&quot; : &quot;You Know, for Search&quot;</p>
<p>}</p>
</li>
</ol>
<h3 id="23-搭建集群">2.3 搭建集群</h3>
<p>修改配置文件$elasticsearch_home/config/elasticsearch.yml</p>
<p>增加配置：</p>
<p>发现的节点 IP</p>
<p>discovery.zen.ping.unicast.hosts: [&quot;ip1&quot;, &quot;ip2&quot;]</p>
<p>最小集群数：常用计算公式 - 总数/2 + 1</p>
<p>discovery.zen.minimum_master_nodes: min_nodes_count</p>
<h3 id="24-安装-kibana">2.4 安装 Kibana</h3>
<p>Kibana 是一个基于 WEB 的 ElasticSearch 管理控制台。现阶段安装 Kibana 主要是为了方便学习。</p>
<p>在 Linux 中安装 Kibana 很方便。解压，启动即可。Kibana 要求的环境配置是小于ElasticSearch 的要求的。</p>
<p>tar -zxf kibana-6.3.1-linux-x86_64.tar.gz</p>
<p>修改 config/kibana.yml</p>
<p>vi config/kibana.yml</p>
<p>新增内容： server.host: &quot;0.0.0.0&quot;</p>
<p>bin/kibana</p>
<p>访问时，使用浏览器访问 http://192.168.2.119:5601/</p>
<h2 id="3-常用-elasticsearch-管理操作">3、常用 ElasticSearch 管理操作</h2>
<h3 id="31-查看健康状态">3.1 查看健康状态</h3>
<p>GET _cat/health?v</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721170056.png" alt="" loading="lazy"></figure>
<p>status：green、yellow、red</p>
<p>green：每个索引的 primary shard 和 replica shard 都是 active 的</p>
<p>yellow：每个索引的 primary shard 都是 active 的，但部分的 replica shard 不是 active的</p>
<p>red：不是所有的索引的 primary shard 都是 active 状态的。</p>
<h3 id="32-创建索引">3.2 创建索引</h3>
<p>命令语法：PUT 索引名{索引配置参数}</p>
<p>index 名称必须是小写的，且不能以下划线'_'，'-'，'+'开头。</p>
<p>在 ElasticSearch 中，默认的创建索引的时候，会分配 5 个 primary shard，并为每个primary shard 分配一个 replica shard（在 ES7 版本后，默认创建 1 个 primary shard）。在 ElasticSearch 中，默认的限制是：如果磁盘空间不足 15%的时候，不分配 replica shard。如果磁盘空间不足 5%的时候，不再分配任何的 primary shard。ElasticSearch 中对 shard的分布是有要求的。ElasticSearch 尽可能保证 primary shard 平均分布在多个节点上。Replica shard 会保证不和他备份的那个 primary shard 分配在同一个节点上。</p>
<p>创建默认索引</p>
<p>PUT test_index1</p>
<p>创建索引时指定分片。</p>
<pre><code class="language-properties">PUT test_index2
{
	&quot;settings&quot;:{
		&quot;number_of_shards&quot; : 2,
		&quot;number_of_replicas&quot; : 1
	}
}
</code></pre>
<h3 id="33-修改索引">3.3 修改索引</h3>
<p>命令语法：PUT 索引名/<em>settings{索引配置参数}<br>
<strong>注意：索引一旦创建，primary shard 数量不可变化，可以改变 replica shard 数量。</strong></em></p>
<pre><code class="language-properties">PUT test_index2/_settings
{
	&quot;number_of_replicas&quot; : 2
}
</code></pre>
<h3 id="34-删除索引">3.4  删除索引</h3>
<p>命令语法：DELETE 索引名 1[, 索引名 2 ...]</p>
<p>DELETE test_index1</p>
<h3 id="35-查看索引信息">3.5  查看索引信息</h3>
<p>GET _cat/indices?v</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721171902.png" alt="" loading="lazy"></figure>
<h3 id="36-检查分片信息">3.6 检查分片信息</h3>
<p>查看索引的 shard 信息。</p>
<p>GET _cat/shards?v</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721171928.png" alt="" loading="lazy"></figure>
<h3 id="37-新增-document">3.7 新增 Document</h3>
<p>在索引中增加文档。在 index 中增加 document。</p>
<p>ElasticSearch 有自动识别机制。如果增加的 document 对应的 index 不存在，自动创建 index；如果 index 存在，type 不存在，则自动创建 type。如果 index 和 type 都存在，则使用现有的 index 和 type。</p>
<h4 id="371-put-语法">3.7.1 PUT 语法</h4>
<p>此操作为手工指定 id 的 Document 新增方式。</p>
<p>语法：PUT 索引名/类型名/唯一 ID{字段名:字段值}</p>
<p>如：</p>
<pre><code class="language-properties">PUT test_index/my_type/1
{
	&quot;name&quot;:&quot;test_doc_01&quot;,
	&quot;remark&quot;:&quot;first test elastic search&quot;,
	&quot;order_no&quot;:1
}

PUT test_index/my_type/2
{
	&quot;name&quot;:&quot;test_doc_02&quot;,
	&quot;remark&quot;:&quot;second test elastic search&quot;,
	&quot;order_no&quot;:2
}

PUT test_index/my_type/3
{
	&quot;name&quot;:&quot;test_doc_03&quot;,
	&quot;remark&quot;:&quot;third test elastic search&quot;,
	&quot;order_no&quot;:3
}
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721172149.png" alt="" loading="lazy"></figure>
<p>如果使用 PUT 语法对同 id 的 Document 执行多次操作。是一种覆盖操作。如果需要ElasticSearch 辅助检查 PUT 的 Document 是否已存在，可以使用强制新增语法。使用强制新增语法时，如果 Document 的 id 在 ElasticSearch 中已存在，则会报错。（version conflict, document already exists）<br>
语法：</p>
<p>PUT 索引名/类型名/唯一 ID/_create{字段名:字段值}</p>
<p>或</p>
<p>PUT 索引名/类型名/唯一 ID?op_type=create{字段名:字段值}。</p>
<p>如：</p>
<pre><code class="language-properties">PUT test_index/my_type/1/_create
{
	&quot;name&quot;:&quot;new_test_doc_01&quot;,
	&quot;remark&quot;:&quot;first test elastic search&quot;,
	&quot;order_no&quot;:1
}
</code></pre>
<h4 id="372-post-语法">3.7.2 POST 语法</h4>
<p>此操作为 ElasticSearch 自动生成 id 的新增 Document 方式。此语法格式和 PUT 请求的数据新增，只有唯一的区别，就是可以自动生成主键 id，其他的和 PUT 请求新增数据完全一致。</p>
<p>语法：POST 索引名/类型名{字段名:字段值}</p>
<p>如：</p>
<pre><code class="language-properties">POST test_index/my_type
{
	&quot;name&quot;:&quot;test_doc_04&quot;,
	&quot;remark&quot;:&quot;forth test elastic search&quot;,
	&quot;order_no&quot;:4
}
</code></pre>
<h3 id="38-查询-document">3.8 查询 Document</h3>
<h4 id="381-get-id-单数据查询">3.8.1 GET ID 单数据查询</h4>
<p>语法：GET 索引名/类型名/唯一 ID</p>
<p>如：</p>
<p>GET test_index/my_type/1</p>
<p>结果：</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200721172429.png" alt="" loading="lazy"></figure>
<h4 id="382-get-_mget-批量查询">3.8.2 GET _mget 批量查询</h4>
<p><em><strong>批量查询可以提高查询效率。推荐使用（相对于单数据查询来说）。</strong></em><br>
语法如下：</p>
<pre><code class="language-properties">GET _mget
{
	&quot;docs&quot; : [
	{
		&quot;_index&quot; : &quot;索引名&quot;,
		&quot;_type&quot; : &quot;类型名&quot;,
		&quot;_id&quot; : &quot;唯一 ID 值&quot;
	}, {}, {}
	]
}
</code></pre>
<pre><code class="language-properties">GET 索引名/_mget:
{
	&quot;docs&quot; : [
	{
		&quot;_type&quot; : &quot;类型名&quot;,
		&quot;_id&quot; : &quot;唯一 ID 值&quot;
	}, {}, {}
	]
}
</code></pre>
<pre><code class="language-properties">GET 索引名/类型名/_mget
{
	&quot;docs&quot; : [
	{
		&quot;_id&quot; : &quot;唯一 ID 值&quot;
	},
	{
		&quot;_id&quot; : &quot;唯一 ID 值&quot;
	}
	]
}
</code></pre>
<h3 id="39-修改-document">3.9 修改 Document</h3>
<h4 id="391-替换-document全量替换">3.9.1  替换 Document（全量替换）</h4>
<p>和新增的 PUT|POST 语法是一致。</p>
<p>PUT|POST 索引名/类型名/唯一 ID{字段名:字段值}<br>
本操作相当于覆盖操作。全量替换的过程中，ElasticSearch 不会真的修改 Document中的数据，而是标记 ElasticSearch 中原有的 Document 为 deleted 状态，再创建一个新的 Document 来存储数据，当 ElasticSearch 中的数据量过大时，ElasticSearch 后台回收 deleted 状态的 Document。<br>
如：</p>
<pre><code class="language-properties">PUT test_index/my_type/1
{
	&quot;name&quot;:&quot;new_test_doc_01&quot;,
	&quot;remark&quot;:&quot;first test elastic search&quot;,
	&quot;order_no&quot;:1
}
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722093619.png" alt="" loading="lazy"></figure>
<h4 id="392-更新-documentpartial-update">3.9.2 更新 Document（partial update）</h4>
<p>语法：POST 索引名/类型名/唯一 ID/_update{doc:{字段名:字段值}}</p>
<p>只更新某 Document 中的部分字段。这种更新方式也是标记原有数据为 deleted 状态，创建一个新的 Document 数据，将新的字段和未更新的原有字段组成这个新的 Document，并创建。对比全量替换而言，只是操作上的方便，在底层执行上几乎没有区别。</p>
<p>如：</p>
<pre><code class="language-properties">POST test_index/my_type/1/_update
{
	&quot;doc&quot;:{
	&quot;name&quot;:&quot; test_doc_01_for_update&quot;
	}
}
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722093937.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722093949.png" alt="" loading="lazy"></figure>
<h3 id="310-删除-document">3.10 删除 Document</h3>
<p><em><strong>ElasticSearch 中执行删除操作时，ElasticSearch 先标记 Document 为 deleted 状态，而不是直接物理删除。当 ElasticSearch 存储空间不足或工作空闲时，才会执行物理删除操作。标记为 deleted 状态的数据不会被查询搜索到。</strong></em><br>
语法：DELETE 索引名/类型名/唯一 ID</p>
<p>如：</p>
<pre><code class="language-properties">DELETE test_index/my_type/1
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722094045.png" alt="" loading="lazy"></figure>
<h3 id="311-bulk-批量增删改">3.11 bulk 批量增删改</h3>
<p>使用 bulk 语法执行批量增删改。语法格式如下：</p>
<p>POST _bulk<br>
{ &quot;action_type&quot; : { &quot;metadata_name&quot; : &quot;metadata_value&quot; } }<br>
{ document datas | action datas }</p>
<p>语法中的 action_type 可选值为：<br>
create : 强制创建，相当于 PUT 索引名/类型名/唯一 ID/_create<br>
index: 普通的 PUT 操作，相当于创建 Document 或全量替换<br>
update: 更新操作（partial update）,相当于 POST 索引名/类型名/唯一 ID/_update<br>
delete: 删除操作</p>
<p>案例如下：</p>
<pre><code class="language-properties">新增数据：
POST _bulk
{ &quot;create&quot; : { &quot;_index&quot; : &quot;test_index&quot; , &quot;_type&quot; : &quot;my_type&quot;, &quot;_id&quot; : &quot;1&quot; } }
{ &quot;field_name&quot; : &quot;field value&quot; }

PUT 操作新增或全量替换
POST _bulk
{ &quot;index&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot; , &quot;_id&quot; : &quot;2&quot; } }
{ &quot;field_name&quot; : &quot;field value 2&quot; }

POST 更新数据
POST _bulk
{ &quot;update&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot; , &quot;_id&quot; : 2, &quot;_retry_on_conflict&quot; : 3 } }
{ &quot;doc&quot; : { &quot;field_name&quot; : &quot;partial update field value&quot; } }

DELETE 删除数据
POST _bulk
{ &quot;delete&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot;, &quot;_id&quot; : &quot;2&quot; } }

批量写操作
POST _bulk
{ &quot;create&quot; : { &quot;_index&quot; : &quot;test_index&quot; , &quot;_type&quot; : &quot;my_type&quot;, &quot;_id&quot; : &quot;10&quot; } }
{ &quot;field_name&quot; : &quot;field value&quot; }
{ &quot;index&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot; , &quot;_id&quot; : &quot;20&quot; } }
{ &quot;field_name&quot; : &quot;field value 2&quot; }
{ &quot;update&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot; , &quot;_id&quot; : 20, &quot;_retry_on_conflict&quot; : 3 } }
{ &quot;doc&quot; : { &quot;field_name&quot; : &quot;partial update field value&quot; } }
{ &quot;delete&quot; : { &quot;_index&quot; : &quot;test_index&quot;, &quot;_type&quot; : &quot;my_type&quot;, &quot;_id&quot; : &quot;2&quot; } }
</code></pre>
<p><em><strong>注意：bulk 语法中要求一个完整的 json 串不能有换行。不同的 json 串必须使用换行分隔。多个操作中，如果有错误情况，不会影响到其他的操作，只会在批量操作返回结果中标记失败。bulk 语法批量操作时，bulk request 会一次性加载到内存中，如果请求数据量太大，性能反而下降（内存压力过高），需要反复尝试一个最佳的 bulk request size。一般从 1000~5000 条数据开始尝试，逐渐增加。如果查看 bulk request size 的话，一般是 5~15MB 之间为好。</strong></em><br>
<em><strong>bulk 语法要求 json 格式是为了对内存的方便管理，和尽可能降低内存的压力。如果json 格式没有特殊的限制，ElasticSearch 在解释 bulk 请求时，需要对任意格式的 json进行解释处理，需要对 bulk 请求数据做 json 对象会 json array 对象的转化，那么内存的占用量至少翻倍，当请求量过大的时候，对内存的压力会直线上升，且需要 jvm gc 进程对垃圾数据做频繁回收，影响 ElasticSearch 效率。</strong></em><br>
<em><strong>生成环境中，bulk api 常用。都是使用 java 代码实现循环操作。一般一次 bulk 请求，执行一种操作。如：批量新增 10000 条数据等。</strong></em></p>
<h2 id="4-分词器analyzer和标准化处理normalization">4、分词器（analyzer）和标准化处理（normalization）</h2>
<h3 id="41-什么是分词器">4.1 什么是分词器</h3>
<p>分词器是一个字符串解析拆分工具。其作用是分析写入的 Document 中的文本数据field，并将 field 数据拆分成一个个有完整含义的、不可拆分的单词。</p>
<p>如：I think dogs is human's best friend.在写入此数据的时候，ElasticSearch 会使用分词器分析并拆分数据，将上述的语句切分成若干的单词，分别是：I、 think、 dogs、human's、 best、 friend。</p>
<h3 id="42-什么是标准化处理">4.2 什么是标准化处理</h3>
<p>标准化处理是用于完善分词器结果的。</p>
<p>分词器处理的文本结果，通常会有一些不需要的、有异议的、包含时态转化等情况的数据。在上述案例中的分词结果是：i、 think、 dogs、 human's、 best、 friend。其中i 是很少应用在搜索条件中的单词；dogs 是 dog 单词的复数形式，通常在搜索过程中使用dog 作为搜索条件更频繁一些；human's 是特殊的标记方式，通常不会在搜索中作为条件出现。那么 ElasticSearch 维护这些单词是没有太大必要的。这个时候就需要标准化处理了。</p>
<p>如：china 搜索时，如果条件为 cn 是否可搜索到。如：dogs，搜索时，条件为 dog是否可搜索到数据。如果可以使用简写（cn）或者单复数（dog&amp;dogs）搜索到想要的结果，那么称为搜索引擎人性化。</p>
<p>normalization 是为了提升召回率的（recall），就是提升搜索能力的。</p>
<p>normalization 是配合分词器(analyzer)完成其功能的。</p>
<h3 id="43-elasticsearch-默认提供的常见分词器">4.3 ElasticSearch 默认提供的常见分词器</h3>
<p>要切分的语句：Set the shape to semi-transparent by calling set_trans(5)<br>
standard analyzer - 是 ElasticSearch 中的默认分词器。标准分词器，处理英语语法的分词器。切分后的 key_words：set, the, shape, to, semi, transparent, by, calling,set_trans, 5。这种分词器也是 ElasticSearch 中默认的分词器。切分过程中不会忽略停止词（如：the、a、an 等）。会进行单词的大小写转换、过滤连接符（-）或括号等常见符号。</p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot;: &quot;Set the shape to semi-transparent by calling set_trans(5)&quot;,
	&quot;analyzer&quot;: &quot;standard&quot;
}
</code></pre>
<p>simple analyzer - 简单分词器。切分后的 key_words：set, the, shape, to, semi,transparent, by, calling, set, trans。就是将数据切分成一个个的单词。使用较少，经常会破坏英语语法。</p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot;: &quot;Set the shape to semi-transparent by calling 	set_trans(5)&quot;,
	&quot;analyzer&quot;: &quot;simple&quot;
}
</code></pre>
<p>whitespace analyzer - 空白符分词器。切分后的 key_words：Set, the, shape, to,semi-transparent, by, calling, set_trans(5)。就是根据空白符号切分数据。如：空格、制表符等。使用较少，经常会破坏英语语法。</p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot;: &quot;Set the shape to semi-transparent by calling set_trans(5)&quot;,
	&quot;analyzer&quot;: &quot;whitespace&quot;
}
</code></pre>
<p>language analyzer - 语言分词器，如英语分词器（english）等。切分后的 key_words：set, shape, semi, transpar, call, set_tran, 5。根据英语语法分词，会忽略停止词、转换大小写、单复数转换、时态转换等，应用分词器分词功能类似 standard analyzer。</p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot;: &quot;Set the shape to semi-transparent by calling set_trans(5)&quot;,
	&quot;analyzer&quot;: &quot;english&quot;
}
</code></pre>
<p><em><strong>注意：ElasticSearch 中提供的常用分词器都是英语相关的分词器，对中文的分词都是一字一词。</strong></em></p>
<h3 id="44-安装中文分词器">4.4  安装中文分词器</h3>
<p>IK 中文分词器，很少有直接下载使用的，都需要通过 github 下载源码，本地编译打包。</p>
<p>就是 maven 工程中的 package 能力。</p>
<p>github 上提供的源码不是伴随 ES 的每个版本提供，一般只有分词器无效后，才提供新的版本。通常都是伴随 ES 的次版本号提供 IK 分词器版本。下载对应的 IK 分词器源码，本地 package 打包，生成 zip 压缩包，既是 IK 在 ES 中的分词器安装包。</p>
<p>git clone https://github.com/medcl/elasticsearch-analysis-ik.git</p>
<p>git checkout tags/v6.5.0</p>
<ol>
<li>
<p>安装 IK 分词器<br>
ElasticSearch 是一个开箱即用的工具。插件安装方式也非常简单。</p>
<p>将 IK 分词器的 zip 压缩文件上传到 Linux，并在 ElasticSearch 安装目录的 plugins 目录中手工创建子目录，目录命名为 ik。将 zip 压缩文件解压缩到新建目录 ik 中。重新启动ElasticSearch 即可。</p>
<p>复制中文分词器 zip 压缩文件到 ElasticSearch 应用目录中：</p>
<p>cp elasticsearch-analysis-ik-6.8.4.zip /opt/es/plugins/</p>
<p>创建 IK 中文分词器的插件子目录：</p>
<p>mkdir /opt/es/plugins/ik/</p>
<p>移动压缩文件到 ik 插件目录中：</p>
<p>mv /opt/es/plugins/elasticsearch-analysis-ik-6.8.4.zip /usr/local/es/plugins/ik/</p>
<p>解压缩：</p>
<p>unzip /opt/es/plugins/ik/elasticsearch-analysis-ik-6.8.4.zip<br>
<em><strong>所有的分词器，都是针对词语的，不是语句的。拆分单元是词语，不是语句。</strong></em></p>
</li>
<li>
<p>测试 IK 分词器<br>
IK 分词器提供了两种 analyzer，分别是 ik_max_word 和 ik_smart。<br>
<em><strong>ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,国,国歌”，会穷尽各种可能的组合；</strong></em><br>
<em><strong>ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”。</strong></em></p>
<pre><code class="language-properties">GET _analyze
{
	&quot;text&quot; : &quot;中华人民共和国国歌&quot;,
	&quot;analyzer&quot;: &quot;ik_max_word&quot;
}


GET _analyze
{
	&quot;text&quot; : &quot;中华人民共和国国歌&quot;,
	&quot;analyzer&quot;: &quot;ik_smart&quot;
}
</code></pre>
</li>
<li>
<p>IK 配置文件<br>
IK 的配置文件在 ElasticSearch 安装目录/plugins/ik/config/中。</p>
</li>
</ol>
<p>配置文件有：</p>
<p>main.dic ： IK 中内置的词典。 main dictionary。记录了 IK 统计的所有中文单词。一行一词。文件中未记录的单词，IK 无法实现有效分词。如：雨女无瓜。不建议修改当前文件中的单词。这个是最核心的中文单词库。就好像，很多的网络词不会收集到辞海中一样。</p>
<p>quantifier.dic ： IK 内置的数据单位词典</p>
<p>suffix.dic ：IK 内置的后缀词典</p>
<p>surname.dic ：IK 内置的姓氏词典</p>
<p>stopword.dic ：IK 内置的英文停用词</p>
<p>preposition.dic ：IK 内置的中文停用词（介词）<br>
<em><strong>IKAnalyzer.cfg.xml</strong></em> ： 用于配置自定义词库的<br>
自定义词库是用户手工提供的特殊词典，类似网络热词，特定业务用词等。<br>
<em><strong>ext_dict - 自定义词库，配置方式为相对于 IKAnalyzer.cfg.xml 文件所在位置的相对路径寻址方式。相当于是用户自定义的一个 main.dic 文件。是对 main.dic 文件的扩展。</strong></em><br>
<em><strong>ext_stopwords - 自定义停用词，配置方式为相对于 IKAnalyzer.cfg.xml 文件所在位置的相对路径寻址方式。相当于是 preposition.dic 的扩展。</strong></em><br>
<em><strong>注意：IK 的所有的 dic 词库文件，必须使用 UTF-8 字符集。不建议使用 windows 自带的文本编辑器编辑。Windows 中自带的文本编辑器是使用 GBK 字符集。IK 不识别，是乱码。</strong></em></p>
<h2 id="5-elasticsearch-中的-mapping-问题">5、 ElasticSearch 中的 mapping 问题</h2>
<p>Mapping 在 ElasticSearch 中是非常重要的一个概念。决定了一个 index 中的 field 使用什么数据格式存储，使用什么分词器解析，是否有子字段等。</p>
<p>Mapping 决定了 index 中的 field 的特征。</p>
<h3 id="51-mapping-核心数据类型">5.1  mapping 核心数据类型</h3>
<p>ElasticSearch 中的数据类型有很多，在这里只介绍常用的数据类型。</p>
<p>文本（字符串）：text<br>
整数：byte、short、integer、long<br>
浮点型：float、double<br>
布尔类型：boolean<br>
日期类型：date<br>
数组类型：array {a:[]}<br>
对象类型：object {a:{}}<br>
不分词的字符串（关键字）： keyword</p>
<h3 id="52-dynamic-mapping-对字段的类型分配">5.2 dynamic mapping 对字段的类型分配</h3>
<p>true or false -&gt; boolean<br>
123 -&gt; long<br>
123.123 -&gt; double<br>
2018-01-01 -&gt; date<br>
hello world -&gt; text<br>
[] -&gt; array<br>
{} -&gt; object<br>
在上述的自动 mapping 字段类型分配的时候，只有 text 类型的字段需要分词器。默认分词器是 standard 分词器。</p>
<h3 id="53-查看索引-mapping">5.3 查看索引 mapping</h3>
<p>可以通过命令查看已有 index 的 mapping 具体信息，语法如下：</p>
<p>GET 索引名/_mapping</p>
<p>如：</p>
<pre><code class="language-properties">GET test_index/_mapping
</code></pre>
<p>结果：</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200722105155.png" alt="" loading="lazy"></figure>
<h3 id="54-custom-mapping">5.4 custom mapping</h3>
<p>可以通过命令，在创建 index 和 type 的时候来定制 mapping 映射，也就是指定字段的类型和字段数据使用的分词器。<br>
手工定制 mapping 时，只能***新增 mapping 设置，不能对已有的 mapping 进行修改。***<br>
如：有索引 a，其中有类型 b，增加字段 f1 的 mapping 定义。后续可以增加字段 f2的 mapping 定义，但是不能修改 f1 字段的 mapping 定义。</p>
<p>通常都是手工创建 index，并进行各种定义。如：settings,mapping 等。</p>
<h4 id="541-创建索引时指定-mapping">5.4.1 创建索引时指定 mapping</h4>
<p>语法：</p>
<pre><code class="language-properties">PUT 索引名称
{
	&quot;mappings&quot;:{
		&quot;类型名称&quot;:{
			&quot;properties&quot;:{
				&quot;字段名&quot;:{
					&quot;type&quot;:类型,
					[&quot;analyer&quot;:字段的分词器,]
					[&quot;fields&quot;:{
						&quot;子字段名称&quot;:{
							&quot;type&quot;:类型,
							&quot;ignore_above&quot;:长度限制
							}
					}]
				}
			}
		}
	}
}
</code></pre>
<p>如：</p>
<pre><code class="language-properties">PUT /test_index
{
	&quot;settings&quot;: {
		&quot;number_of_shards&quot;: 2,
		&quot;number_of_replicas&quot;: 1
},
	&quot;mappings&quot;: {
		&quot;test_type&quot;:{
			&quot;properties&quot;: {
				&quot;author_id&quot; : {
					&quot;type&quot;: &quot;byte&quot;,
					&quot;index&quot;: false
				},
			&quot;title&quot; : {
				&quot;type&quot;: &quot;text&quot;,
				&quot;analyzer&quot;: &quot;ik_max_word&quot;,
				&quot;fields&quot;: {
					&quot;keyword&quot; : {
					&quot;type&quot;: &quot;keyword&quot;,
					&quot;ignore_above&quot;: 256
					}
				}
			},
			&quot;content&quot; : {
				&quot;type&quot;: &quot;text&quot;,
                  &quot;analyzer&quot;: &quot;ik_max_word&quot;
			},
			&quot;post_date&quot; : {
				&quot;type&quot;: &quot;date&quot;
			}
		}
	}
}
}
</code></pre>
<p>&quot;index&quot; - 是否可以作为搜索索引。可选值：true | false</p>
<p>&quot;analyzer&quot; - 指定分词器。</p>
<p>&quot;type&quot; - 指定字段类型</p>
<h4 id="542-为已有索引添加新的字段-mapping">5.4.2 为已有索引添加新的字段 mapping</h4>
<p>语法：</p>
<pre><code class="language-properties">PUT 索引名/_mapping/类型名
{
	&quot;properties&quot;:{
		&quot;新字段名&quot;:{
			&quot;type&quot;:类型,
			&quot;analyer&quot;:字段的分词器,
			&quot;fields&quot;:{
				&quot;子字段名&quot;:{
					&quot;type&quot;:类型,
					&quot;ignore_above&quot;:长度
				}
			}
		}
	}
}
</code></pre>
<p>如：</p>
<pre><code class="language-properties">PUT /test_index/_mapping/test_type
{
	&quot;properties&quot; : {
		&quot;new_field&quot; : { &quot;type&quot; : &quot;text&quot; , &quot;analyzer&quot; : &quot;standard&quot; }
	}
}
</code></pre>
<h4 id="543-测试不同的字段的分词器">5.4.3 测试不同的字段的分词器</h4>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名称/_analyze
{
	&quot;field&quot;:&quot;索引中的 text 类型的字段名&quot;,
	&quot;text&quot;:&quot;要分词处理的文本数据&quot;
}
</code></pre>
<p>使用索引中的字段对应的分词器，对文本数据做分词处理。</p>
<p>如：</p>
<pre><code class="language-properties">GET /test_index/_analyze
{
	&quot;field&quot;: &quot;new_field&quot;,
	&quot;text&quot;: &quot;中华人民共和国国歌&quot;
}

GET /test_index/_analyze
{
	&quot;field&quot;: &quot;content&quot;,
	&quot;text&quot;: &quot;中华人民共和国国歌&quot;
}
</code></pre>
<h2 id="6-search-搜索详解">6、 Search 搜索详解</h2>
<h3 id="61-搜索学习测试数据">6.1 搜索学习测试数据</h3>
<pre><code class="language-properties">PUT test_search
{
	&quot;mappings&quot;: {
		&quot;test_type&quot; : {
			&quot;properties&quot;: {
				&quot;dname&quot; : {
					&quot;type&quot; : &quot;text&quot;,
					&quot;analyzer&quot;: &quot;standard&quot;
				},
				&quot;ename&quot; : {
					&quot;type&quot; : &quot;text&quot;,
					&quot;analyzer&quot;: &quot;standard&quot;
				},
				&quot;eage&quot; : {
					&quot;type&quot;: &quot;long&quot;
				},
				&quot;hiredate&quot; : {
					&quot;type&quot;: &quot;date&quot;
				},
				&quot;gender&quot; : {
					&quot;type&quot; : &quot;keyword&quot;
				}
			}
		}
	}
}


POST test_search/test_type/_bulk
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Sales Department&quot;, &quot;ename&quot; : &quot; 张 三 &quot;, &quot;eage&quot;:20, &quot;hiredate&quot; : &quot;2019-01-01&quot;,&quot;gender&quot; : &quot;男性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Sales Department&quot;, &quot;ename&quot; : &quot; 李 四 &quot;, &quot;eage&quot;:21, &quot;hiredate&quot; : &quot;2019-02-01&quot;,&quot;gender&quot; : &quot;男性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Development Department&quot;, &quot;ename&quot; : &quot; 王 五 &quot;, &quot;eage&quot;:23, &quot;hiredate&quot; :&quot;2019-01-03&quot;, &quot;gender&quot; : &quot;男性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Development Department&quot;, &quot;ename&quot; : &quot; 赵 六 &quot;, &quot;eage&quot;:26, &quot;hiredate&quot; :&quot;2018-01-01&quot;, &quot;gender&quot; : &quot;男性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Development Department&quot;, &quot;ename&quot; : &quot; 韩 梅 梅 &quot;, &quot;eage&quot;:24, &quot;hiredate&quot; :&quot;2019-03-01&quot;, &quot;gender&quot; : &quot;女性&quot; }
{ &quot;index&quot;: {}}
{ &quot;dname&quot; : &quot;Development Department&quot;, &quot;ename&quot; : &quot; 钱 虹 &quot;, &quot;eage&quot;:29, &quot;hiredate&quot; :&quot;2018-03-01&quot;, &quot;gender&quot; : &quot;女性&quot; }
</code></pre>
<h3 id="62-query-string-search">6.2 query string search</h3>
<p>search 的参数都是类似 http 请求头中的字符串参数提供搜索条件的。</p>
<p>GET<br>
[/index_name/type_name/]_search[?parameter_name=parameter_value&amp;...]</p>
<h4 id="621-全搜索">6.2.1 全搜索</h4>
<p>timeout 参数：是超时时长定义。代表每个节点上的每个 shard 执行搜索时最多耗时多久。不会影响响应的正常返回。只会影响返回响应中的数据数量。<br>
如：索引 a 中，有 10 亿数据。存储在 5 个 shard 中，假设每个 shard 中 2 亿数据，执行全数据搜索的时候，需要耗时 1000 毫秒。定义 timeout 为 10 毫秒，代表的是 shard执行 10 毫秒，搜索出多少数据，直接返回。<br>
在商业项目中，是禁止全数据搜索的。必须指定搜索的索引，类型和关键字。如果没有指定索引或类型，则代表开发目的不明确，需要重新做用例分析。如果没有关键字，称为索引内全搜索，也叫魔鬼搜索。</p>
<p>语法：<br>
GET [索引名/类型名/]_search?timeout=10ms</p>
<p>结果：</p>
<pre><code class="language-properties">{
	&quot;took&quot;: 144, #请求耗时多少毫秒
	&quot;timed_out&quot;: false, #是否超时。默认情况下没有超时机制，也就是客户端等待 ElasticSearch 搜索结束（无论执行多久），提供超时机制的话，ElasticSearch 则在指定时长内处理搜索，在指定时长结束的时候，将搜索的结果直接返回（无论是否搜索结束）。指定超时的方式是传递参数，参数单位是：毫秒-ms。秒-s。分钟-m。
	&quot;_shards&quot;: {
		&quot;total&quot;: 1, #请求发送到多少个 shard 上
		&quot;successful&quot;: 1,#成功返回搜索结果的 shard
		&quot;skipped&quot;: 0, #停止服务的 shard
		&quot;failed&quot;: 0 #失败的 shard
	},
	&quot;hits&quot;: {
		&quot;total&quot;: 1, #返回了多少结果
		&quot;max_score&quot;: 1, #搜索结果中，最大的相关度分数，相关度越大分数越高，_score 越大，排位越靠前。
		&quot;hits&quot;: [ #搜索到的结果集合，默认查询前 10 条数据。
		{
			&quot;_index&quot;: &quot;test_index&quot;, #数据所在索引
			&quot;_type&quot;: &quot;my_type&quot;, #数据所在类型
			&quot;_id&quot;: &quot;1&quot;, #数据的 id
			&quot;_score&quot;: 1, #数据的搜索相关度分数
			&quot;_source&quot;: { # 数据的具体内容。
				&quot;field&quot;: &quot;value&quot;
			}
		}
	]
	}
}
</code></pre>
<h4 id="622-multi-index-搜索">6.2.2 multi index 搜索</h4>
<p>所谓的 multi-index 就是从多个 index 中搜索数据。相对使用较少，只有在复合数据搜索的时候，可能出现。一般来说，如果真使用复合数据搜索，都会使用_all。<br>
如：搜索引擎中的无条件搜索。（现在的应用中都被屏蔽了。使用的是默认搜索条件，执行数据搜索。 如： 电商中的搜索框默认值， 搜索引擎中的类别）<br>
无条件搜索，在搜索应用中称为“魔鬼搜索”，代表的是，搜索引擎会执行全数据检索，效率极低，且对资源有非常高的压力。</p>
<p>语法：</p>
<pre><code class="language-properties">GET _search
GET 索引名 1,索引名 2/_search # 搜索多个 index 中的数据
GET 索引名/类型名/_search # 所属一个 index 中 type 的数据
GET prefix_*/_search # 通配符搜索
GET *_suffix/_search
GET 索引名 1,索引名 2/类型名/_search # 搜索多个 index 中 type 的数据
GET _all/_search # _all 代表所有的索引
</code></pre>
<h4 id="623-条件搜索">6.2.3 条件搜索</h4>
<p>query string search 搜索是通过 HTTP 请求的请求头传递参数的，默认的 HTTP 请求头字符集是 ISO-8859-1，请求头传递中文会有乱码。</p>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名/_search?q=字段名:搜索条件
</code></pre>
<h4 id="624-分页搜索">6.2.4  分页搜索</h4>
<p>默认情况下，ElasticSearch 搜索返回结果是 10 条数据。从第 0 条开始查询。</p>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名/_search?size=10 # size 查询数据的行数

GET 索引名/_search?from=0&amp;size=10 # from 从第几行开始查询，行号从 0 开始。
</code></pre>
<h4 id="625-搜索">6.2.5 +/-搜索</h4>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名/_search?q=字段名:条件

GET 索引名/_search?q=+字段名:条件

GET 索引名/_search?q=-字段名:条件
</code></pre>
<p><code>+ ：和不定义符号含义一样，就是搜索指定的字段中包含 key words 的数据</code></p>
<p><code>- ： 与+符号含义相反，就是搜索指定的字段中不包含 key words 的数据</code></p>
<h4 id="626-排序">6.2.6 排序</h4>
<p>语法：GET 索引名/_search?sort=字段名:排序规则<br>
排序规则： asc(升序) | desc(降序)</p>
<pre><code class="language-properties">GET test_search/_search?sort=eage:asc
GET test_search/_search?sort=eage:desc
</code></pre>
<h3 id="63-query-dsl">6.3  query DSL</h3>
<p>DSL - Domain Specified Language ， 特殊领域的语言。</p>
<p>请求参数是请求体传递的。在 ElasticSearch 中，请求体的字符集默认为 UTF-8。</p>
<p>语法格式：</p>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;command&quot;:{ &quot;parameter_name&quot; : &quot;parameter_value&quot;}
}
</code></pre>
<h4 id="631-查询所有数据">6.3.1 查询所有数据</h4>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;query&quot; : { &quot;match_all&quot; : {} }
}
</code></pre>
<h4 id="632-match-search">6.3.2  match search</h4>
<p>全文检索。要求查询条件拆分后的任意词条与具体数据匹配就算搜索结果。</p>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;query&quot;: {
		&quot;match&quot;: {
			&quot;字段名&quot;: &quot;搜索条件&quot;
		}
	}
}
</code></pre>
<h4 id="633-phrase-search">6.3.3 phrase search</h4>
<p>短语检索。要求查询条件必须和具体数据完全匹配才算搜索结果。其特征是：1-搜索条件不做任何分词解析；2-在搜索字段对应的倒排索引(正排索引)中进行精确匹配，不再是简单的全文检索。</p>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;query&quot;: {
		&quot;match_phrase&quot;: {
			&quot;字段名&quot;: &quot;搜索条件&quot;
		}
	}
}
</code></pre>
<h4 id="634-range">6.3.4 range</h4>
<p>范围比较搜索</p>
<pre><code class="language-properties">GET 索引名/类型名/_search
{
	&quot;query&quot; : {
		&quot;range&quot; : {
			&quot;字段名&quot; : {
				&quot;gt&quot; : 搜索条件 1,
				&quot;lte&quot; : 搜索条件 2
			}
		}
	}
}
</code></pre>
<h4 id="635-term">6.3.5 term</h4>
<p>词组比较，词组搜索。</p>
<p>忽略搜索条件分词，在 ElasticSearch 倒排索引中进行精确匹配。</p>
<pre><code class="language-properties">GET 索引名/类型名/_search
{
	&quot;query&quot; : {
		&quot;term&quot; : {
			&quot;字段名&quot;: &quot;搜索条件&quot;
		}
	}
}

GET 索引名/类型名/_search
{
	&quot;query&quot; : {
		&quot;terms&quot; : {
			&quot;字段名&quot;: [&quot;搜索条件 1&quot;, &quot;搜索条件 2&quot;]
		}
	}
}
</code></pre>
<h4 id="636-多条件复合搜索">6.3.6  多条件复合搜索</h4>
<p>在一个请求体中，有多个搜索条件，就是复合搜索。如：搜索数据，条件为部门名称是Sales Department，员工年龄在 20 到 26 之间，部门员工姓名叫张三。上述条件中，部门名称为可选条件，员工年龄必须满足要求，部门员工姓名为可选要求。这种多条件搜索就是符合搜索。</p>
<pre><code class="language-properties">GET 索引名/类型名/_search
{
	&quot;query&quot;: {
		&quot;bool&quot;: {
			&quot;must&quot;: [ #数组中的多个条件必须同时满足
				{
					&quot;range&quot;: {
						&quot;字段名&quot;: {
						&quot;lt&quot;: 条件
						}
					}
				}
				],
			&quot;must_not&quot;:[ #数组中的多个条件必须都不满足
				{
					&quot;match&quot;: {
						&quot;字段名&quot;: &quot;条件&quot;
					}
				},
				{
					&quot;range&quot;: {
						&quot;字段名&quot;: {
							&quot;gte&quot;: &quot;搜索条件&quot;
						}
					}
				}
				]
			&quot;should&quot;: [# 数组中的多个条件有任意一个满足即可。
				{
					&quot;match&quot;: {
						&quot;字段名&quot;: &quot;条件&quot;
					}
				},
				{
					&quot;range&quot;: {
						&quot;字段名&quot;: {
							&quot;gte&quot;: &quot;搜索条件&quot;
       					 }
					}
				}
				]
			}
		}
	}
</code></pre>
<h4 id="637-排序">6.3.7  排序</h4>
<p>在 ElasticSearch 的搜索中，默认是使用相关度分数实现排序的。可以通过搜索语法实现定制化排序。</p>
<pre><code class="language-properties">GET 索引名/类型名/_search
{
	&quot;query&quot;: {
		[搜索条件]
	},
	&quot;sort&quot;: [
		{
			&quot;字段名 1&quot;: {
				&quot;order&quot;: &quot;asc&quot;
			}
		},
		{
			&quot;字段名 2&quot;: {
				&quot;order&quot;: &quot;desc&quot;
			}
		}
	]
}
</code></pre>
<p><em><strong>注意：在 ElasticSearch 中，如果使用 text 类型的字段作为排序依据，会有问题。ElasticSearch 需要对 text 类型字段数据做分词处理。如果使用 text 类型字段做排序，ElasticSearch 给出的排序结果未必友好，毕竟分词后，先使用哪一个单词做排序都是不合理的。所以 ElasticSearch 中默认情况下不允许使用 text 类型的字段做排序，如果需要使用字符串做结果排序，则可使用 keyword 类型字段作为排序依据，因为 keyword 字段不做分词处理。</strong></em></p>
<h4 id="638-分页">6.3.8 分页</h4>
<p>DSL 分页也是使用 from 和 size 实现的。</p>
<pre><code class="language-properties">GET 索引名称/_search
{
	&quot;query&quot;:{
		&quot;match_all&quot;:{}
	},
	&quot;from&quot;: 起始下标,
	&quot;size&quot;: 查询记录数
}
</code></pre>
<h4 id="639-highlight-display">6.3.9  highlight display</h4>
<p>在搜索中，经常需要对搜索关键字做高亮显示，这个时候就可以使用 highlight 语法。</p>
<p>语法：</p>
<pre><code class="language-properties">GET 索引名/_search
{
	&quot;query&quot;: {
		&quot;match&quot;: {
			&quot;字段名&quot;: &quot;条件&quot;
		}
	},
	&quot;highlight&quot;: {
		&quot;fields&quot;: {
			&quot;要高亮显示的字段名&quot;: {
				&quot;fragment_size&quot;: 5, #每个分段长度，默认 20
				&quot;number_of_fragments&quot;: 1 #返回多少个分段，默认 3
			}
		},
		&quot;pre_tags&quot;: [&quot;前缀&quot;],
		&quot;post_tags&quot;: [&quot;后缀&quot;]
	}
}
</code></pre>
<p>演示案例：</p>
<pre><code class="language-properties">GET test_search/_search
{
	&quot;query&quot;: {
		&quot;bool&quot;: {
			&quot;should&quot;: [
				{
					&quot;match&quot;: {
						&quot;dname&quot;: &quot;Development department&quot;
					}
				},
				{
					&quot;match&quot;: {
					&quot;gender&quot;: &quot;男性&quot;
				}
			}
		]
		}
	},
	&quot;highlight&quot;: {
		&quot;fields&quot;: {
			&quot;dname&quot;: {
				&quot;fragment_size&quot;: 20,
				&quot;number_of_fragments&quot;: 1
			},
			&quot;gender&quot;: {
				&quot;fragment_size&quot;: 20,
				&quot;number_of_fragments&quot;: 1
			}
		},
		&quot;pre_tags&quot;:[&quot;&lt;span style='color:red'&gt;&quot;],
		&quot;post_tags&quot;:[&quot;&lt;/span&gt;&quot;]
	},
	&quot;from&quot;: 2,
	&quot;size&quot;: 2
}
</code></pre>
<p>fragment_size：代表字段数据如果过长，则分段，每个片段数据长度为多少。长度不是字符数量，是 ElasticSearch 内部的数据长度计算方式。默认不对字段做分段。number_of_fragments：代表搜索返回的高亮片段数量，默认情况下会将拆分后的所有片段都返回。</p>
<p>pre_tags：高亮前缀</p>
<p>post_tags：高亮后缀</p>
<p>很多搜索结果显示页面中都不会显示完整的数据，这样在数据过长的时候会导致页面效果 不 佳 ， 都 会 按 照 某 一 个 固 定 长 度 来 显 示 搜 索 结 果 ， 所 以 fragment_size 和number_of_fragments 参数还是很常用的。</p>
<h2 id="7-spring-data-elasticsearch">7、Spring Data ElasticSearch</h2>
<p>使用 Spring Data 下二级子项目 Spring Data Elasticsearch 进行操作。支持 POJO 方法操作 Elasticsearch。相比 Elasticsearch 提供的 API 更加简单更加方便。</p>
<h3 id="71-修改-pom-文件添加依赖">7.1 修改 POM 文件添加依赖</h3>
<pre><code class="language-xml">&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>
<h3 id="72-修改配置文件">7.2 修改配置文件</h3>
<p>集群版多地址之间使用逗号分隔。</p>
<p>在 ElasticSearch5.x 以前的版本中，客户端使用的是 Transport 客户端，通过 TCP 协议和 9300 端口访问 ES。在 6.x 及之后的版本中，官方推荐使用 Rest 客户端，通过 Http协议和 9200 端口访问 ES。且在新版的 Spring Data Elasticsearch 框架中，Transport 客户端配置已经设置为过时配置，推荐使用 Rest 客户端。</p>
<ol>
<li>
<p>高版本新客户端</p>
<pre><code class="language-yaml">elasticsearch:
    rest: # 配置ElasticsearchRestTemplate客户端的属性，是现在推荐使用的。
      uris:
        - http://124.70.181.124:9200
        - http://124.70.181.124:9201
</code></pre>
</li>
<li>
<p>低版本常用客户端</p>
<pre><code class="language-yaml">spring:
  data:
    elasticsearch:
      cluster-name: elasticsearch # 必须提供的配置，集群的名称。
      cluster-nodes: 124.70.181.124:9300,124.70.181.124:9301 # transport客户端的端口是9300
</code></pre>
</li>
</ol>
<h3 id="73-创建实体">7.3 创建实体</h3>
<p>@Document 指定实体类和索引对应关系<br>
indexName：索引名称<br>
type: 索引类型<br>
shards: 主分片数量<br>
replicas：复制分片数量<br>
@Id 指定主键<br>
@Field 指定普通属性<br>
type： 对应 Elasticsearch 中属性类型。使用 FiledType 枚举可以快速获取。测试发现没有 type 属性可能出现无法自动创建类型问题，所以一定要有 type 属性。<br>
text 类型能被分词<br>
keywords 不能被分词<br>
index： 是否创建索引。作为搜索条件时 index 必须为 true<br>
analyzer：指定分词器类型。<br>
fielddata：指定是否为 text 类型字段创建正向索引。默认为 false，设置为 true则可以使用此字段排序。</p>
<pre><code class="language-java">/**
 * 自定义类型，商品。
 * 让自定义的类型和ElasticSearch中的一个索引产生关联。
 *
 * Document - spring data elasticsearch提供的注解， 描述类型，说明类型和索引的关系。
 *  indexName - 对应的索引的名称。 必要属性。
 *  shards - 创建索引时，设置的主分片数量。 默认5
 *  replicas - 创建索引时，设置的副本分片数量。 默认1
 *  type - 对应的类型的名称。
 */
@Document(indexName = &quot;ego_item2&quot;,shards = 2,replicas = 1,type = &quot;item&quot;)
public class Item implements Serializable {
    /**
     * Id注解是Spring Data核心工程提供的，是所有的Spring Data二级子工程通用的。
     * 代表主键字段。
     */
    @Id
    private String id;
    /**
     * Field注解，描述实体类型中属性和ES索引中字段的关系。
     * 且可以为这个字段配置自定义映射mapping
     * 这个自定义映射必须通过代码逻辑调用设置映射的API才能生效。
     *  name - 索引中对应的字段名称，默认和属性同名。
     *  type - 索引中字段的类型，默认是FieldType.Auto，代表ES自动映射类型。
     *  analyzer - 字段的分词器名称，默认是standard。
     *  fielddata - 是否开启正向索引。默认关闭。
     *   默认只为文本类型的字段创建反向索引，提供快速搜索逻辑。
     *   fielddata设置为true，则会额外创建一个正向索引，支持排序。
     *  index - 是否创建默认的反向索引或正向索引。 text文本类型字段默认创建反向索引，其他创建正向索引。
     *   没有索引，就不能作为搜索条件。
     */
    @Field(name = &quot;title&quot;,type = FieldType.Text,analyzer = &quot;ik_max_word&quot;,fielddata = true)
    private String title; // 商品名称，需要中文分词，且偶尔需要排序， 常用搜索条件之一
    @Field(name = &quot;sellPoint&quot;,type = FieldType.Text,analyzer = &quot;ik_max_word&quot;)
    private String sellPoint; // 卖点， 需要中文分词， 常用搜索条件之一
    @Field(type = FieldType.Long)
    private Long price; // 单价
    @Field(type = FieldType.Integer,index = false)
    private int num; // 库存

    public Item() {
    }

    @Override
    public String toString() {
        return &quot;Item{&quot; +
                &quot;Id='&quot; + id + '\'' +
                &quot;, title='&quot; + title + '\'' +
                &quot;, sellPoint='&quot; + sellPoint + '\'' +
                &quot;, price=&quot; + price +
                &quot;, num=&quot; + num +
                '}';
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        Item item = (Item) o;
        return num == item.num &amp;&amp;
                Objects.equals(id, item.id) &amp;&amp;
                Objects.equals(title, item.title) &amp;&amp;
                Objects.equals(sellPoint, item.sellPoint) &amp;&amp;
                Objects.equals(price, item.price);
    }

    @Override
    public int hashCode() {
        return Objects.hash(id, title, sellPoint, price, num);
    }

    public String getId() {
        return id;
    }

    public void setId(String id) {
        this.id = id;
    }

    public String getTitle() {
        return title;
    }

    public void setTitle(String title) {
        this.title = title;
    }

    public String getSellPoint() {
        return sellPoint;
    }

    public void setSellPoint(String sellPoint) {
        this.sellPoint = sellPoint;
    }

    public Long getPrice() {
        return price;
    }

    public void setPrice(Long price) {
        this.price = price;
    }

    public int getNum() {
        return num;
    }

    public void setNum(int num) {
        this.num = num;
    }
}

</code></pre>
<h3 id="74-初始化索引">7.4 初始化索引</h3>
<p>首先注入客户端对象</p>
<pre><code class="language-java">/**
     * ES5.x以前，使用的客户端一般都是Transport客户端，数据交换客户端，通过端口9300，
     * 借助协议TCP，实现数据的交换访问。
     * Spring Data Elasticsearch 提供的客户端Template对象类型是 ElasticsearchTemplate
     * 配置是：
     * spring.data.elasticsearch.cluster-name = 集群名称
     * spring.data.elasticsearch.cluster-nodes = 集群每个节点的地址， ip:port,ip:port
     * &lt;p&gt;
     * ES6.x以后，官方推荐使用Rest客户端，通过端口9200，借助协议HTTP，实现数据访问控制
     * Spring Data Elasticsearch 提供的客户端Template对象类型是 ElasticsearchRestTemplate
     */
    // @Autowired
    //  private ElasticsearchTemplate elasticsearchTemplate;

    @Autowired
    private ElasticsearchRestTemplate elasticsearchRestTemplate;
</code></pre>
<p>createIndex(): 创建索引，创建出来的索引是不带有 mapping 信息的。返回值表示是否创建成功</p>
<p>putMapping():为已有的索引添加 mapping 信息。不具备创建索引的能力。返回值表示是否创建成功</p>
<pre><code class="language-java">    /**
     * 创建索引
     * 创建索引，不包括映射信息，因为只扫描类型上的Document注解。
     */
    @Test
    public void createIndexWithElasticsearchTemplate(){
        boolean isCreated = elasticsearchTemplate.createIndex(Item.class);
        System.out.println(&quot;创建索引是否成功:&quot;+isCreated);
    }
}

    /**
     * 创建索引，并设置映射。
     * 需要通过两次访问实现，1、创建索引；2、设置映射。
     */
    @Test
    public void testInitIndex() {
        // 创建索引，根据类型上的Document注解创建
        boolean isCreated = elasticsearchRestTemplate.createIndex(Item.class);
        // 设置映射，根据属性上的Field注解设置
        boolean isMapped = elasticsearchRestTemplate.putMapping(Item.class);
        System.out.println(&quot;创建索引是否成功&quot; + isCreated);
        System.out.println(&quot;设置映射是否成功&quot; + isMapped);
    }
</code></pre>
<h3 id="75-删除索引">7.5 删除索引</h3>
<pre><code class="language-java">/**
 * 删除索引
 */
@Test
public void deleteIndex() {
    // 扫描Item类型上的Document注解，删除对应的索引。
    boolean isDeleted = elasticsearchRestTemplate.deleteIndex(Item.class);
    System.out.println(&quot;删除Item对应索引是否成功&quot; + isDeleted);
    // 直接删除对应名称的索引。
    isDeleted = elasticsearchRestTemplate.deleteIndex(&quot;default_index&quot;);
    System.out.println(&quot;删除default_index索引是否成功&quot; + isDeleted);

}
</code></pre>
<h3 id="76-添加文档">7.6 添加文档</h3>
<p>如果索引和类型不存在，也可以执行进行新增，新增后自动创建索引和类型。但是 field通过动态 mapping 进行映射，elaticsearch 根据值类型进行判断每个属性类型，默认每个属性都是 standard 分词器，ik 分词器是不生效的。<em><strong>所以一定要先通过代码进行初始化或直接在 elasticsearch 中通过命令创建所有 field 的 mapping</strong></em></p>
<h4 id="761-新增单个文档">7.6.1 新增单个文档</h4>
<p>如果对象的 id 属性没有赋值，让 ES 自动生成主键，存储时 id 属性没有值，_id 存储document 的主键值。</p>
<p>如果对象的 id 属性明确设置值，存储时 id 属性为设置的值，ES 中 document 对象的_id 也是设置的值。</p>
<pre><code class="language-java">    /**
     * 新增数据到ES
     */
    @Test
    public void testInsert() {
        Item item = new Item();
        item.setId(&quot;111222333&quot;);
        item.setTitle(&quot;Spring In Action VI&quot;);
        item.setSellPoint(&quot;Spring系列书籍，非常好的一本Spring框架学习手册。唯一缺点没有中文版。&quot;);
        item.setPrice(9900L);
        item.setNum(999);

        IndexQuery indexQuery =
                new IndexQueryBuilder() // 创建一个IndexQuery的构建器
                        .withObject(item) // 设置要新增的Java对象
                        .build(); // 构建IndexQuery类型的对象

//        IndexQuery query = new IndexQuery();
//        query.setObject(item); //效果同上
        // index逻辑，相当于使用PUT请求，实现数据的新增。
        String result = elasticsearchRestTemplate.index(indexQuery);
        System.out.println(result);
    }
</code></pre>
<h4 id="762-批量新增">7.6.2 批量新增</h4>
<p>下面代码中使用的 IndexQueryBuilder()进行构建，可以一行代码完成。也可以使用上面的 IndexQuery()。效果是完全相同的，只是需要写多行。</p>
<pre><code class="language-java">/**
 * 批量新增
 * bulk操作
 */
@Test
public void testBatchInsert() {
    List&lt;IndexQuery&gt; queries = new ArrayList&lt;&gt;();
    for (int i = 0; i &lt; 3; i++) {
        Item item = new Item();
        item.setId(&quot;2000&quot; + i);
        item.setTitle(&quot;测试新增商品&quot; + i);
        item.setSellPoint(&quot;测试新增商品卖点&quot; + i);
        item.setPrice(new Random().nextLong());
        item.setNum(9999 - i);
        queries.add(
                new IndexQueryBuilder().withObject(item).build()
        );
    }
    // 批量新增，使用的是bulk操作。
    elasticsearchRestTemplate.bulkIndex(queries);
}
</code></pre>
<h3 id="77-删除操作">7.7.  删除操作</h3>
<p>根据主键删除</p>
<p>delete(String indexName,String typeName,String id); 通过字符串指定索引，类型和 id 值</p>
<p>delete(Class,String id) 第一个参数传递实体类类类型，建议使用此方法，减少索引名和类型名由于手动编写出现错误的概率。</p>
<p>返回值为 delete 方法第二个参数值（删除文档的主键值）</p>
<pre><code class="language-java">/**
 * 删除数据
 */
@Test
public void testDelete() {
    //根据主键删除
    String result = elasticsearchRestTemplate.delete(Item.class, &quot;epYDynEBHt6IU1hpAxvL&quot;);
    System.out.println(result);

    // 根据查询结果，删除查到的数据。 应用较少。
    DeleteQuery deleteQuery = new DeleteQuery();
    //deleteQuery.setIndex(&quot;ego_item&quot;);
    //deleteQuery.setType(&quot;item&quot;);
    deleteQuery.setQuery(
            QueryBuilders.matchQuery(&quot;title&quot;, &quot;Spring In Action VI&quot;)
    );
    elasticsearchRestTemplate.delete(deleteQuery, Item.class);
}
</code></pre>
<h3 id="78-修改操作">7.8 修改操作</h3>
<p>修改操作就是新增代码，只要保证主键 id 已经存在，新增就是修改。</p>
<p>如果使用部分更新，则需要通过 update 方法实现。具体如下：</p>
<pre><code class="language-java">    /**
     * 修改数据
     * 如果是全量替换，可以使用index方法实现，只要主键在索引中存在，就是全量替换。
     * 如果是部分修改，则可以使用update实现。
     */
    @Test
    public void testUpdate() throws IOException {
        UpdateRequest request = new UpdateRequest();
        request.doc(
                XContentFactory.jsonBuilder()
                        .startObject()
                        .field(&quot;name&quot;, &quot;测试update更新数据，商品名称&quot;)
                        .endObject()
        );
        UpdateQuery updateQuery =
                new UpdateQueryBuilder()
                        .withUpdateRequest(request)
                        .withClass(Item.class)
                        .withId(&quot;20200&quot;)
                        .build();
        elasticsearchRestTemplate.update(updateQuery);
    }
</code></pre>
<h3 id="79-搜索操作">7.9 搜索操作</h3>
<h4 id="791-模糊搜索">7.9.1  模糊搜索</h4>
<p>去所有 field 中搜索指定条件。</p>
<pre><code class="language-java">@Test
void query(){
	// NativeSearchQuery 构造方法参数。
	// 北京去和所有 field 进行匹配，只要出现了北京就可以进行查询
	QueryStringQueryBuilder queryStringQueryBuilder = QueryBuilders.queryStringQuery(&quot;北京&quot;);
// 查询条件 SearchQuery 是接口，只能实例化实现类。
	SearchQuery searchQuery = new NativeSearchQuery(queryStringQueryBuilder);
	List&lt;People&gt; list = elasticsearchRestTemplate.queryForList(searchQuery,People.class);
	for(People people : list){
		System.out.println(people);
	}
}
</code></pre>
<h4 id="792-使用-match_all-搜索所有文档">7.9.2 使用 match_all 搜索所有文档</h4>
<pre><code class="language-java">    /**
     * 搜素所有数据
     */
    @Test
    public void testMatchAll() {
        /**
         * SearchQuery - 是Spring Data Elasticsearch中定义的一个搜索接口
         * NativeSearchQuery - 是SearchQuery接口的实现类。
         *  构造的时候，需要提供一个QueryBuilder类型的对象，
         *  QueryBuilder是Elasticsearch的java客户端中定义的搜索条件类型。
         *
         * QueryBuilders - 是QueryBuilder类型的工具类，可以快速实现QueryBuilder类型对象的创建
         *  工具类中，提供了大量的静态方法，方法命名和DSL搜索中的条件关键字相关。
         *  如：match_all 对应 matchAllQuery()
         *  如：match 对应 matchQuery()
         *  如：range 对应 rangeQuery()
         */
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.matchAllQuery()
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }

</code></pre>
<h4 id="793-使用-match-搜索文档">7.9.3  使用 match 搜索文档</h4>
<pre><code class="language-java">    /**
     * 条件搜索
     */
    @Test
    public void testMatch() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.matchQuery(&quot;title&quot;, &quot;华为荣耀&quot;)
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<h4 id="794-使用-match_phrase-搜索文档">7.9.4 使用 match_phrase 搜索文档</h4>
<p>短语搜索是对条件不分词，但是文档中属性根据配置实体类时指定的分词类型进行分词。</p>
<p>如果属性使用 ik 分词器，从分词后的索引数据中进行匹配。</p>
<pre><code class="language-java">    /**
     * 短语搜索
     */
    @Test
    public void testMatchPhrase() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.matchPhraseQuery(&quot;title&quot;, &quot;华为荣耀&quot;)
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<h4 id="795-使用-term词组-搜索文档">7.9.5 使用 Term词组 搜索文档</h4>
<pre><code class="language-java">    /**
     * 词组搜索
     */
    @Test
    public void testTerm() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.termQuery(&quot;title&quot;, &quot;华为荣耀&quot;)
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<h4 id="796-使用-range-搜索文档">7.9.6 使用 range 搜索文档</h4>
<pre><code class="language-java">    /**
     * 范围搜索 range
     */
    @Test
    public void testRange() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.rangeQuery(&quot;price&quot;).lte(800000L).gte(200000L)
        );
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<h4 id="797-多条件搜索">7.9.7 多条件搜索</h4>
<pre><code class="language-java">/**
 * 复合条件搜索
 */
@Test
public void testBool() {
    // 创建一个Bool搜索条件。 相当于定义 bool:{ must:[], should:[], must_not:[] }
    BoolQueryBuilder builder = QueryBuilders.boolQuery();
    List&lt;QueryBuilder&gt; mustList = builder.must();
    mustList.add(QueryBuilders.matchQuery(&quot;title&quot;, &quot;华为&quot;));
    mustList.add(QueryBuilders.rangeQuery(&quot;price&quot;).gte(300000L));
    SearchQuery query = new NativeSearchQuery(builder);
    List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
    for (Item item : items) {
        System.out.println(item);
    }
}
</code></pre>
<h4 id="798-分页与排序">7.9.8 分页与排序</h4>
<pre><code class="language-java">    /**
     * 分页和排序
     * 所有的Spring Data子工程中的分页和排序逻辑使用的都是相似的方式。
     * 根据PageRequest和Sort实现分页或排序。
     */
    @Test
    public void testPageable() {
        SearchQuery query = new NativeSearchQuery(
                QueryBuilders.matchAllQuery()
        );
        // 设置分页 ，从第0页开始的两条
        query.setPageable(PageRequest.of(0, 2));
        // 设置排序
        query.addSort(Sort.by(Sort.Direction.DESC, &quot;price&quot;));
        // 设置分页的同时设置排序
        // query.setPageable(PageRequest.of(0,2,Sort.by(Sort.Direction.DESC,&quot;price&quot;)));
        List&lt;Item&gt; items = elasticsearchRestTemplate.queryForList(query, Item.class);
        for (Item item : items) {
            System.out.println(item);
        }
    }
</code></pre>
<p>如果实体类中主键只有@Id 注解，String id 对应 ES 中是 text 类型，text 类型是不允许被排序，所以如果必须按照主键进行排序时需要在实体类中设置主键类型</p>
<pre><code class="language-java">@Id
@Field(type = FieldType.Keyword)
private String id;
</code></pre>
<h4 id="799-高亮搜索">7.9.9 高亮搜索</h4>
<pre><code class="language-java">
    /**
     * 高亮
     */
    @Test
    public void testHighlight(){
        HighlightBuilder.Field field = new HighlightBuilder.Field(&quot;title&quot;);
        field.preTags(&quot;&lt;em&gt;&quot;);
        field.postTags(&quot;&lt;/em&gt;&quot;);

        NativeSearchQuery query =
                new NativeSearchQueryBuilder()
                        // 排序
                        .withSort(SortBuilders.fieldSort(&quot;price&quot;).order(SortOrder.ASC))
                        // 分页
                        .withPageable(PageRequest.of(0, 2))
                        // 搜索条件
                        .withQuery(QueryBuilders.matchQuery(&quot;title&quot;, &quot;华为&quot;))
                        // 设置高亮字段
                        .withHighlightFields(field)
                        .build();

        AggregatedPage&lt;? extends Item&gt; pageResult =
                elasticsearchRestTemplate.queryForPage(query, Item.class, new SearchResultMapper() {
                    // 处理搜索结果，搜索的完整结果，也就是那个集合。
                    // response - 就是搜索的结果，相当于在Kibana中执行搜索的结果内容。
                    // clazz - 就是返回结果的具体类型
                    // pageable - 分页处理，就是queryForPage方法参数query中的pageable对象。
                    @Override
                    public &lt;T&gt; AggregatedPage&lt;T&gt; mapResults(SearchResponse response,
                                                            Class&lt;T&gt; clazz,
                                                            Pageable pageable) {
                        // 获取搜索的结果数据
                        SearchHit[] hits = response.getHits().getHits();
                        List&lt;T&gt; resultList = new ArrayList&lt;&gt;();
                        for(SearchHit hit : hits){
                            // 搜索的source源
                            Map&lt;String, Object&gt; map = hit.getSourceAsMap();
                            Item item = new Item();
                            item.setId(map.get(&quot;id&quot;).toString());
                            item.setSellPoint(map.get(&quot;sellPoint&quot;).toString());
                            item.setPrice(Long.parseLong(map.get(&quot;price&quot;).toString()));
                            item.setNum(Integer.parseInt(map.get(&quot;num&quot;).toString()));
                            // 高亮数据处理。key - 字段名， value - 是高亮数据结果
                            Map&lt;String, HighlightField&gt; highlightFieldMap = hit.getHighlightFields();
                            HighlightField highlightField = highlightFieldMap.get(&quot;title&quot;);
                            if (highlightField == null){ // 没有高亮的title
                                item.setTitle(map.get(&quot;title&quot;).toString());
                            }else{ // 有高亮的title
                                item.setTitle(highlightField.getFragments()[0].toString());
                            }
                            resultList.add((T)item);
                        }
                        // 返回处理后的结果

                        return new AggregatedPageImpl&lt;&gt;(
                                resultList, pageable, response.getHits().getTotalHits()
                        );
                    }

                    // 不提供实现，这个是处理每个搜索结果的方法
                    @Override
                    public &lt;T&gt; T mapSearchHit(SearchHit searchHit, Class&lt;T&gt; type) {
                        return null;
                    }
                });

        for(Item item : pageResult.getContent()){
            System.out.println(item);
        }
    }

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Solr]]></title>
        <id>https://jonchan1013.github.io/post/solr/</id>
        <link href="https://jonchan1013.github.io/post/solr/">
        </link>
        <updated>2020-07-16T09:16:14.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716171735.png" alt="" loading="lazy"></figure>
<h2 id="1-solr-简介">1、Solr 简介</h2>
<h3 id="11-为什么使用-solr">1.1 为什么使用 Solr</h3>
<p>在海量数据下，对 MySQL 或 Oracle 进行模糊查询或条件查询的效率是很低的。而搜索功能在绝大多数项目中都是必须的，如何提升搜索效率是很多互联网项目必须要考虑的问题。<br>
既然使用关系型数据库进行搜索效率比较低，最直接的解决方案就是使用专用搜索工具进行搜索，从而提升搜索效率。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716171735.png" alt="" loading="lazy"></figure>
<h2 id="1-solr-简介">1、Solr 简介</h2>
<h3 id="11-为什么使用-solr">1.1 为什么使用 Solr</h3>
<p>在海量数据下，对 MySQL 或 Oracle 进行模糊查询或条件查询的效率是很低的。而搜索功能在绝大多数项目中都是必须的，如何提升搜索效率是很多互联网项目必须要考虑的问题。<br>
既然使用关系型数据库进行搜索效率比较低，最直接的解决方案就是使用专用搜索工具进行搜索，从而提升搜索效率。</p>
<!-- more -->
<h3 id="12-常见搜索解决方案">1.2 常见搜索解决方案</h3>
<p>基于 Apache Lucene（全文检索工具库）实现搜索。但是 Lucene 的使用对于绝大多数的程序员都是“噩梦级”的。</p>
<p>基于谷歌 API 实现搜索。</p>
<p>基于百度 API 实现搜索。</p>
<h3 id="13-solr-简介">1.3 Solr 简介</h3>
<p>Solr 是基于 Apache Lucene 构建的用于搜索和分析的开源解决方案。可提供可扩展索引、搜索功能、高亮显示和文字解析功能。</p>
<p>Solr 本质就是一个 Java web 项目，且内嵌了 Jetty 服务器，所以安装起来非常方便。客户端操作 Solr 的过程和平时我们所写项目一样，就是请求 Solr 中控制器，处理完数据后把结果响应给客户端。</p>
<h3 id="14-正向索引和反向索引">1.4 正向索引和反向索引</h3>
<p>只要讨论搜索就不得不提的两个概念：正向索引（forward index）和反向索引(invertedindex)。</p>
<p>正向索引：从文档内容到词组的过程。每次搜索的时候需要搜索所有文档，每个文档比较搜索条件和词组。</p>
<table>
<thead>
<tr>
<th style="text-align:center">文档</th>
<th style="text-align:center">词组</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">I am a chinese</td>
<td style="text-align:center">I,am,a,chinses</td>
</tr>
</tbody>
</table>
<p>反向索引：是正向索引的逆向。建立词组和文档的映射关系。通过找到词组就能找到文档内容。（和新华字典找字很像）</p>
<table>
<thead>
<tr>
<th style="text-align:center">词组</th>
<th style="text-align:center">文档</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">I,am,a,chinses</td>
<td style="text-align:center">I am a chinese</td>
</tr>
</tbody>
</table>
<h2 id="2-solr-搜索原理">2、Solr 搜索原理</h2>
<h3 id="21-搜索原理">2.1 搜索原理</h3>
<p>Solr 能够提升检索效率的主要原因就是<strong>分词和索引（反向索引）</strong>。</p>
<p>分词：会对搜索条件/存储内容进行分词，分成日常所使用的词语。</p>
<p>索引：存储在 Solr 中内容会按照程序员的要求来是否建立索引。如果要求建立索引会把存储内容中关键字（分词）建立索引。</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718221615.png" alt="" loading="lazy"></figure>
<h3 id="22-solr-中数据存储说明">2.2 Solr 中数据存储说明</h3>
<p>Solr 为了给内容建立索引，所以 Solr 就必须具备数据存储能力。所有需要被搜索的内容都需要存储在 Solr 中，在开发中需要把数据库中数据添加到 Solr 中进行初始化，每次修改数据库中数据还需要同步 Solr 中的数据。</p>
<p>Solr 中数据存储是存储在 Document 对象中，对象中可以包含的属性和属性类型都定义在 schema.xml 中。如果需要自定义属性或自定义属性类型都需要修改 schema.xml 配置文件。从 Solr5 开始 schema.xml 更改名称为 managed-schema(没有扩展名)</p>
<h2 id="3-solr-单机版安装">3、 Solr 单机版安装</h2>
<p>Solr 是使用 Java 编写，所以必选先安装 JDK。</p>
<ol>
<li>
<p>上传并解压<br>
上传压缩包 solr-8.2.0.tgz 到/usr/local/tmp 中。</p>
<p>解压</p>
<p>cd /usr/local/tmp</p>
<p>tar zxf solr-8.2.0.tgz</p>
</li>
<li>
<p>复制到/usr/local 中</p>
<p>cp -r solr-8.2.0 ../solr</p>
</li>
<li>
<p>修改启动参数<br>
修改启动参数，否则启动时报警告。提示设置 SOLR_ULIMIT_CHECKS=false</p>
</li>
</ol>
<p>cd /usr/local/solr/bin</p>
<p>vim solr.in.sh</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718221843.png" alt="" loading="lazy"></figure>
<ol start="4">
<li>启动 Solr<br>
Solr 内嵌 Jetty，直接启动即可。默认监听 <strong>8983 端口。</strong></li>
</ol>
<p>Solr 默认不推荐 root 账户启动，如果是 root 账户启动需要添加-force 参数。</p>
<p>./solr start -force</p>
<h2 id="4-可视化管理界面">4、可视化管理界面</h2>
<p>在关闭防火墙的前提下，可以在 windows 的浏览器中访问 Solr。</p>
<p>输入: http://124.70.181.124:8983 就可以访问 Solr 的可视化管理界面。</p>
<p>左侧有 5 个菜单。分别是：</p>
<p>（1）Dashboard：面板显示 Solr 的总体信息。</p>
<p>（2）Logging：日志</p>
<p>（3）Core Admin：Solr 的核心。类似于数据的 Database</p>
<p>（4）Java Perperties：所有 Java 相关属性。</p>
<p>（5）Thread Dump：线程相关信息。</p>
<p>（6）如果有 Core，将显示在此处。</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222009.png" alt="" loading="lazy"></figure>
<h2 id="5-新建核心">5、新建核心</h2>
<p>Solr 安装完成后默认是没有核心的。需要手动配置。</p>
<p>需要在 solr/server/solr 下新建文件夹，并给定配置文件，否则无法建立。</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222032.png" alt="" loading="lazy"></figure>
<ol>
<li>
<p>新建目录<br>
在/usr/local/solr/server/solr 中新建自定义名称目录。此处示例名称为 testcore。</p>
<p>cd /usr/local/solr/server/solr</p>
<p>mkdir testcore</p>
</li>
<li>
<p>复制配置文件<br>
在 configsets 里面包含了_default 和 sample_techproducts_configs。里面都是配置文件示例。_default 属于默认配置，较纯净。sample_techproducts_configs 是带有了一些配置示例。</p>
</li>
</ol>
<p>cp -r configsets/_default/conf/ testcore/</p>
<ol start="3">
<li>
<p>填写 Core 信息<br>
在可视化管理界面中 Core Admin 中编写信息后点击 Add Core 后，短暂延迟后testcore 就会创建成功。schema 处不用更改。</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222147.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>出现 testcore<br>
在客户端管理界面中，选择新建的 Core 后，就可以按照自己项目的需求进行操作了。</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222200.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h2 id="6-分词-analysis">6、 分词 Analysis</h2>
<p>在 Solr 可 视 化 管 理 界 面 中 ， Core 的 管 理 菜 单 项 中 都 会 有 Analysis 。 表 示 根 据Scheme.xml(managed-schema)中配置要求进行解析。</p>
<p>对英文解析就比较简单了，只要按照空格把英文语句拆分成英文单词即可。</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222225.png" alt="" loading="lazy"></figure>
<p>但是如果条件是中文时，把一句话按照字进行拆分就不是很合理了。正确的方式是按照合理的词组进行拆分。</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222236.png" alt="" loading="lazy"></figure>
<h3 id="61-中文分词器安装及配置步骤">6.1 中文分词器安装及配置步骤</h3>
<p>上传 ik-analyzer.jar 到 webapps 中。</p>
<p>去 https://search.maven.org/search?q=com.github.magese 下 载 对 应 版 本 的ik-analyzer。可以在&quot;软件/Analyzer&quot;中直接获取。</p>
<ol>
<li>
<p>上传 jar 到指定目录<br>
上传 ik-analyzer-8.2.0.jar 到</p>
<p>/usr/local/solr/server/solr-webapp/webapp/WEB-INF/lib 目录中</p>
</li>
<li>
<p>修改配置文件<br>
修改/usr/local/solr/server/solr/testcore/conf/managed-schema</p>
<p>vim /usr/local/solr/server/solr/testcore/conf/managed-schema</p>
<p>添加下面内容。</p>
<p>排版：Esc 退出编辑状态下：gg=G</p>
<pre><code class="language-xml">    &lt;field name=&quot;myfield&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; /&gt;

    &lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt;
      &lt;analyzer type=&quot;index&quot;&gt;
        &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot; 
          useSmart=&quot;false&quot; conf=&quot;ik.conf&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
      &lt;/analyzer&gt;
      &lt;analyzer type=&quot;query&quot;&gt;
        &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot; 
          useSmart=&quot;true&quot; conf=&quot;ik.conf&quot;/&gt;
        &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt;
      &lt;/analyzer&gt;
    &lt;/fieldType&gt;

</code></pre>
</li>
<li>
<p>重启</p>
<p>cd /usr/local/solr/bin</p>
<p>./solr stop -all</p>
<p>./solr start -force</p>
</li>
<li>
<p>验证<br>
可以在可视化管理界面中找到 myfield 属性进行验证。</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222452.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="62-managed-schema-配置说明">6.2 managed-schema 配置说明</h3>
<ol>
<li>
<fieldType/>
表 示 定 义 一 个 属 性 类 型 。 在 Solr 中 属 性 类 型 都 是 自 定 义 的 。 在 上 面 配 置 中name="text_ik"为自定义类型。当某个属性取值为 text_ik 时 IK Analyzer 才能生效。
</li>
<li>
<field/>
表示向 Document 中添加一个属性。
<p>常用属性：</p>
<p>name: 属性名</p>
<p>type:属性类型。所有类型都是 solr 使用<fieldType>配置的</p>
<p>indexed: 是否建立索引</p>
<p>stored: solr 是否把该属性值响应给搜索用户。</p>
<p>required：该属性是否是必须的。默认 id 是必须的。</p>
<p>multiValued：如果为 true，表示该属性为复合属性，此属性中包含了多个其他的属性。常用在多个列作为搜索条件时，把这些列定义定义成一个新的复合属性，通过搜索一个复合属性就可以实现搜索多个列。当设置为 true 时与<copyField source="" dest=""/>结合使用</p>
</li>
<li>
<uniqueKey>
唯一主键，Solr 中默认定义 id 属性为唯一主键。ID 的值是不允许重复的。
</li>
<li>
<dynamicField>
名称中允许*进行通配。代表满足特定名称要求的一组属性。
</li>
</ol>
<h2 id="7-dataimport">7、 Dataimport</h2>
<p>可以使用 Solr 自带的 Dataimport 功能把数据库中数据快速导入到 solr 中.</p>
<p>必须保证 managed-schema 和数据库中表的列对应。</p>
<ol>
<li>
<p>修改配置文件<br>
修改 solrconfig.xml，添加下面内容</p>
<pre><code class="language-xml">&lt;!-- 配置数据导入的处理器 --&gt;

 &lt;requestHandler name=&quot;/dataimport&quot; class=&quot;org.apache.solr.handler.dataimport.DataImportHandler&quot;&gt;

	&lt;lst name=&quot;defaults&quot;&gt;

		&lt;!-- 加载 data-config.xml --&gt;

		&lt;str name=&quot;config&quot;&gt;data-config.xml&lt;/str&gt;

	&lt;/lst&gt;

 &lt;/requestHandler&gt;
</code></pre>
</li>
<li>
<p>新建 data-config.xml</p>
<p>和 solrconfig.xml 同一目录下新建 data-config.xml</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;dataConfig&gt;
	&lt;dataSource 
		type=&quot;JdbcDataSource&quot;  
		driver=&quot;com.mysql.jdbc.Driver&quot;
		url=&quot;jdbc:mysql://124.70.181.124:3306/ego2&quot;
		user=&quot;root&quot;
		password=&quot;Chenyong.123&quot;/&gt;&lt;/dataSource&gt;

&lt;document&gt;

	&lt;entity name=&quot;product&quot; query=&quot;SELECT id,title from tb_item&quot;&gt;

	&lt;!--实现数据库的列和索引库的字段的映射
		column 指定数据库的列表
		name 指定索引库的字段名字，必须和 schema.xml 中定义的一样
	--&gt;
	&lt;field column=&quot;id&quot; name=&quot;id&quot;/&gt;
	&lt;field column=&quot;title&quot; name=&quot;myfield&quot;/&gt;
&lt;/entity&gt;
&lt;/document&gt;

&lt;/dataConfig&gt;
</code></pre>
</li>
<li>
<p>添加 jar<br>
向 solr-webapp 中添加三个 jar。在 dist 中两个还有一个数据库驱动。</p>
</li>
</ol>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718222810.png" alt="" loading="lazy"></figure>
<ol start="4">
<li>
<p>操作<br>
重启 solr 后，在可视化管理页面中进行数据导入。</p>
<p>注意：</p>
<p>点击导入按钮后，要记得点击刷新按钮。</p>
</li>
</ol>
<h2 id="8-菜单项目-documents-使用办法">8、菜单项目 Documents 使用办法</h2>
<p>以 XML 格式举例</p>
<h3 id="81-新增修改">8.1 新增/修改</h3>
<p>当 id 不存在时新增，当 id 存在修改。</p>
<pre><code class="language-xml">&lt;doc&gt;

&lt;field name=&quot;id&quot;&gt;8&lt;/field&gt;

&lt;field name=&quot;name&quot;&gt;明天更大卖&lt;/field&gt;

&lt;field name=&quot;price&quot;&gt;98&lt;/field&gt;

&lt;/doc&gt;
</code></pre>
<h3 id="82-删除">8.2  删除</h3>
<ol>
<li>
<p>根据主键删除</p>
<pre><code class="language-xml">&lt;delete&gt;

&lt;id&gt;8&lt;/id&gt;

&lt;/delete&gt;
</code></pre>
</li>
<li>
<p>根据条件删除</p>
<pre><code class="language-xml">&lt;delete&gt;

&lt;query&gt;*:*&lt;/query&gt;

&lt;/delete&gt;
</code></pre>
</li>
</ol>
<h2 id="9-菜单项目-query-查询使用办法">9、菜单项目 query 查询使用办法</h2>
<h3 id="91-查询全部">9.1  查询全部</h3>
<p>只要在 q 参数中写入*:*既是搜索全部数据。</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223217.png" alt="" loading="lazy"></figure>
<h3 id="92-条件查询">9.2 条件查询</h3>
<p>在 q 参数部分写入 字段名:搜索条件值， 既是条件搜索</p>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223236.png" alt="" loading="lazy"></figure>
<h3 id="93-分页查询">9.3 分页查询</h3>
<p>在条件 start,rows 中输入从第几条数据开始查询，查询多少条数据。下标从 0 开始。类似 MySQL 数据库中的 limit。</p>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223256.png" alt="" loading="lazy"></figure>
<h3 id="94-查询排序">9.4 查询排序</h3>
<p>在 sort 条件中输入 字段名 排序规则。 排序规则包括 asc 和 desc。</p>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223320.png" alt="" loading="lazy"></figure>
<h3 id="95-高亮查询">9.5 高亮查询</h3>
<p>选中 hl 高亮复选框，在 hl.fl 中输入高亮显示的字段名称，在 hl.simple.pre 中输入高亮前缀，在 hl.simple.post 中输入高亮后缀。</p>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200718223339.png" alt="" loading="lazy"></figure>
<h2 id="10-使用-solrj-操作-solr">10、使用 SolrJ 操作 Solr</h2>
<p>SolrJ 是 Solr 提供的 Java 客户端 API。通过 SolrJ 可以实现 Java 程序对 Solr 中数据的操作。</p>
<p>大前提：添加 SolrJ 依赖。依赖版本和 Solr 版本严格对应</p>
<pre><code class="language-xml"> &lt;dependencies&gt;
     &lt;dependency&gt;
         &lt;groupId&gt;org.apache.solr&lt;/groupId&gt;
         &lt;artifactId&gt;solr-solrj&lt;/artifactId&gt;
         &lt;version&gt;8.2.0&lt;/version&gt;
     &lt;/dependency&gt;
 &lt;/dependencies&gt;
</code></pre>
<pre><code class="language-java">/**
 * 使用SolrJ访问Solr服务。
 */
public class FirstAccess {
    public static void main(String[] args) {
        search();
    }

    // 搜索数据
    public static void search(){
        HttpSolrClient client = null;
        try{
            String url = &quot;http://124.70.181.124:8983/solr/testcore&quot;;
            client = new HttpSolrClient.Builder(url).build();

            // 创建搜索条件对象。
            SolrQuery params = new SolrQuery();
            // 提供搜索关键字， q  *:*
            params.setQuery(&quot;title_zh_cn:管理&quot;);

            // 排序
            params.setSort(&quot;id&quot;, SolrQuery.ORDER.asc);

            // 分页
            params.setStart(0); // 第几行开始查询
            params.setRows(3); // 查询多少行

            // 高亮
            // 开启高亮
            params.setHighlight(true);
            // 设置高亮字段，如果有多个高亮字段，多次调用当前方法。
            params.addHighlightField(&quot;title_zh_cn&quot;);
            // 设置高亮前缀
            params.setHighlightSimplePre(&quot;&lt;span style='color:red'&gt;&quot;);
            // 设置高亮后缀
            params.setHighlightSimplePost(&quot;&lt;/span&gt;&quot;);

            // 搜索数据
            QueryResponse response = client.query(params);

            // 从响应中获取高亮结果数据集合 {主键:{字段名:[&quot;高亮数据&quot;, &quot;高亮数据&quot;]}}
            Map&lt;String, Map&lt;String, List&lt;String&gt;&gt;&gt; highlightMap = response.getHighlighting();

            // 获取搜索返回结果集合  SolrDocumentList 是List接口的实现。 固定泛型是 SolrDocument
            SolrDocumentList docList = response.getResults();
            System.out.println(&quot;本次查询返回数据行数&quot; + docList.size());
            System.out.println(&quot;本次搜索总计数据行数&quot; + docList.getNumFound());
            for(SolrDocument doc : docList){
                System.out.print(doc + &quot;【 id = &quot; + doc.getFieldValue(&quot;id&quot;)
                        + &quot;， title_zh_cn = &quot; + doc.getFieldValue(&quot;title_zh_cn&quot;) + &quot;】&quot;);

                // 输出高亮
                // 根据当前文档主键查询高亮数据
                Map&lt;String, List&lt;String&gt;&gt; entry = highlightMap.get(doc.getFieldValue(&quot;id&quot;));
                if(null != entry &amp;&amp; entry.size() &gt; 0){
                    // 有高亮数据
                    List&lt;String&gt; hlStrList = entry.get(&quot;title_zh_cn&quot;);
                    System.out.println(&quot; 高亮数据内容是：【&quot; + hlStrList + &quot;】&quot;);
                }

                System.out.println();
            }
        }catch(Exception e){
            e.printStackTrace();
        }finally {
            try {
                client.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    // 删除数据
    public static void delete(){
        HttpSolrClient client = null;
        try{
            String url = &quot;http://124.70.181.124:8983/solr/testcore&quot;;
            client = new HttpSolrClient.Builder(url).build();

            // 删除数据
            client.deleteById(&quot;2000&quot;);  // 删除单数据

            client.deleteById(Arrays.asList(&quot;100&quot;, &quot;101&quot;, &quot;102&quot;, &quot;103&quot;)); // 批量删除

            client.deleteByQuery(&quot;title_zh_cn:角色&quot;); // 条件删除， 条件格式 -  字段名:条件数据

            client.commit();
        }catch(Exception e){
            e.printStackTrace();
        }finally {
            try {
                client.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }

    // 保存数据到Solr，如果主键字段id值唯一就是新增，不唯一就是覆盖（更新）
    public static void save(){
        HttpSolrClient client = null;
        try {
            // 创建客户端
            String url = &quot;http://124.70.181.124:8983/solr/testcore&quot;;
            client = new HttpSolrClient.Builder(url).build();

            // 创建要保存的数据对象
            SolrInputDocument doc = new SolrInputDocument();
            doc.addField(&quot;id&quot;, &quot;2000&quot;);
            doc.addField(&quot;title_zh_cn&quot;, &quot;SolrJ保存数据-二次执行&quot;);

            // 执行数据保存
            client.add(doc);

            // 事务管理
            client.commit(); // 提交当前url指向的core collection
            // client.commit(&quot;testcore&quot;);  // 提供core collection名称，指定提交事务

        }catch(Exception e){
            e.printStackTrace();
        }finally{
            // 回收资源
            try {
                client.close();
            } catch (IOException e) {
                e.printStackTrace();
            }
        }
    }
}

</code></pre>
<h2 id="11-spring-data-for-apache-solr">11、 Spring Data for Apache Solr</h2>
<h3 id="111-spring-data-简介">11.1 Spring Data 简介</h3>
<p>Spring Data 是 Spring 的顶级项目。里面包含了 N 多个二级子项目，每个子项目对应一种技术或工具。其目的为了让数据访问更加简单，更加方便的和 Spring 进行整合。</p>
<p>Spring Data 项目如果单独使用是还需要配置 XML 配置文件的，当和 Spring Boot整合后使用起来非常方便。spring-boot-starter-data-xx 就是对应的启动器。</p>
<h3 id="112-实现步骤">11.2 实现步骤</h3>
<ol>
<li>添加依赖</li>
</ol>
<pre><code class="language-xml">    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt;
                &lt;version&gt;2.2.5.RELEASE&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-data-solr&lt;/artifactId&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre>
<ol start="2">
<li>
<p>编写配置文件</p>
<pre><code class="language-yaml">spring:
  data:
    solr:
      host: http://124.70.181.124:8983/solr # 配置solr服务器所在地址
</code></pre>
</li>
<li>
<p>编写实体类</p>
<pre><code class="language-java">@SolrDocument(collection = &quot;testcore&quot;)
public class Menu implements Serializable {
    // @Id - 代表当前字段是唯一主键字段。 在高亮查询的时候，需要检查。
    @Field(value = &quot;id&quot;)
    @Id
    private Long id;
    @Field(value = &quot;myfield&quot;)
    private String title;

    public Long getId() {
        return id;
    }

    public void setId(Long id) {
        this.id = id;
    }

    public String getTitle() {
        return title;
    }

    public void setTitle(String title) {
        this.title = title;
    }

    public Menu(Long id, String title) {
        this.id = id;
        this.title = title;
    }

    public Menu() {
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        Menu menu = (Menu) o;
        return Objects.equals(id, menu.id) &amp;&amp;
                Objects.equals(title, menu.title);
    }

    @Override
    public int hashCode() {
        return Objects.hash(id, title);
    }

    @Override
    public String toString() {
        return &quot;Menu{&quot; +
                &quot;id=&quot; + id +
                &quot;, title=&quot; + title +
                '}';
    }
}

</code></pre>
</li>
<li>
<p>编写测试类</p>
<pre><code class="language-java">/**
 * SpringBootTest测试类型
 */
@SpringBootTest(classes = {FirstSolrApp.class})
@RunWith(SpringRunner.class)
public class TestSolr {
    /**
     * SpringData的所有子工程，几乎都会提供一个XxxTemplate类型，
     * 这个Template是用来实现客户端服务器数据交互的对象。
     */
    @Autowired
    private SolrTemplate template;

    /**
     * 保存数据
     * 使用SpringData开发数据访问的时候，不要回收资源，因为SpringData会自动维护数据源连接池
     */
    @Test
    public void testSave() {
        //创建要保存的对象
        SolrInputDocument doc = new SolrInputDocument();
        doc.addField(&quot;id&quot;, &quot;2000&quot;);
        doc.addField(&quot;myfield&quot;, &quot;使用SpringDataForApacheSolr实现数据保存&quot;);
        //数据保存。主键唯一是新增，不是则为覆盖
        UpdateResponse response = template.saveBean(&quot;testcore&quot;, doc);

        System.out.println(response.getStatus() == 0 ? &quot;保存成功&quot; : &quot;保存失败&quot;);

        //提交事务
        template.commit(&quot;testcore&quot;);
    }

    /**
     * 输出数据
     */
    @Test
    public void testDelete() {
        //主键删除唯一数据
        UpdateResponse response = template.deleteByIds(&quot;testcore&quot;, &quot;2000&quot;);
        System.out.println(response.getStatus() == 0 ? &quot;删除成功&quot; : &quot;删除失败&quot;);

        //根据主键批量删除数据
        response = template.deleteByIds(&quot;testcore&quot;, Arrays.asList(&quot;20001&quot;, &quot;2002&quot;));
        System.out.println(response.getStatus() == 0 ? &quot;批量删除成功&quot; : &quot;批量删除失败&quot;);

        //根据查询条件删除
        SimpleQuery query = new SimpleQuery();
        // Criteria.where(&quot;title_zh_cn&quot;) - 提供一个搜索条件，对应的字段名是什么
        // criteria.is(&quot;参数&quot;) - 为这个搜索条件绑定具体的参数值
        query.addCriteria(Criteria.where(&quot;myfield&quot;).is(&quot;Spring&quot;));
        response = template.delete(&quot;testcore&quot;, query);
        System.out.println(response.getStatus() == 0 ? &quot;条件删除成功&quot; : &quot;条件删除失败&quot;);

        //提交事务
        template.commit(&quot;testcore&quot;);

    }

    /**
     * 搜索数据
     */
    @Test
    public void testSearch(){
        //创建搜索条件
        SimpleQuery query = new SimpleQuery();
        query.addCriteria(Criteria.where(&quot;myfield&quot;).is(&quot;数据&quot;));

        //分页
        query.setOffset(0L); //第几行开始查询
        query.setRows(3); //查询多少数据
        //排序
        query.addSort(Sort.by(Sort.Direction.DESC,&quot;id&quot;));

        //执行搜索
        // 参数 ：collection - 索引库名称， query - 搜索条件， Class - 实体类对象
        ScoredPage&lt;Menu&gt; scoredPage = template.queryForPage(&quot;testcore&quot;, query, Menu.class);

        //处理结果
        System.out.println(&quot;总计数据行数:&quot;+scoredPage.getTotalElements());
        System.out.println(&quot;总计页码数:&quot;+scoredPage.getTotalPages());
        //搜索的结果集合
        List&lt;Menu&gt; list = scoredPage.getContent();
        System.out.println(list);
    }

    /**
     * 高亮搜索
     */
    @Test
    public void testHighlightSearch(){
        SimpleHighlightQuery query = new SimpleHighlightQuery();
        query.addCriteria(Criteria.where(&quot;myfield&quot;).is(&quot;数据&quot;));
        // 设置高亮
        // 创建高亮设置对象
        HighlightOptions options = new HighlightOptions();
        // 设置高亮字段名
        options.addField(&quot;myfield&quot;);
        // 设置高亮前后缀
        options.setSimplePrefix(&quot;&lt;span&gt;&quot;);
        options.setSimplePostfix(&quot;&lt;/span&gt;&quot;);
        query.setHighlightOptions(options);

        // 搜索
        HighlightPage&lt;Menu&gt; page = template.queryForHighlightPage(&quot;testcore&quot;, query, Menu.class);
        List&lt;Menu&gt; result = new ArrayList&lt;&gt;();
        // 获取搜索结果中高亮处理过的结果。
        List&lt;HighlightEntry&lt;Menu&gt;&gt; list = page.getHighlighted();
        for(HighlightEntry&lt;Menu&gt; entry: list){
            // 获取entry中的高亮数据集合
            List&lt;HighlightEntry.Highlight&gt; highlights = entry.getHighlights();
            // 获取没有经过高亮处理的结果对象
            Menu menu = entry.getEntity();
            for (HighlightEntry.Highlight highlight : highlights){
                // 判断高亮数据的字段是否是自己需要的。
                if(highlight.getField().getName().equals(&quot;myfield&quot;)) {
                    // 获取高亮处理的字符串
                    String highlightString = highlight.getSnipplets().get(0);
                    // 把高亮处理的字符串赋值给对象。
                    menu.setTitle(highlightString);
                }
            }
            result.add(menu);
        }
        System.out.println(result);
    }
}

</code></pre>
</li>
</ol>
<h2 id="12-solrcloud">12、SolrCloud</h2>
<p>Solr 可以搭建具备容错能力和高可用的 Solr 集群。集群中集群配置、自动负载均衡和查询故障转移、Zookeeper 集群实现集群协调管理，这些全部功能统称为 SolrCloud。</p>
<p>SolrCloud 是基于 Zookeeper 进行管理的。在 Solr 中已经内置了 Zookeeper 相关内容，当执行集群创建命令会自动创建 Zookeeper 相关内容。这个使用的是 Zookeeper 的集群管理功能实现的。</p>
<ol>
<li>
<p>创建<br>
SolrCloud 已经包含在了 Solr 中，可以直接启动 Solr 集群。</p>
<p>./solr -e cloud -noprompt -force</p>
<p>此命令等同于# ./solr -e cloud -force 全部参数为默认值。</p>
<p>运行成功后会在 example 文件夹多出 cloud 文件夹。</p>
</li>
<li>
<p>停止</p>
<p>./solr stop -all</p>
</li>
<li>
<p>重新运行</p>
</li>
</ol>
<p>./solr start -c -p 8983 -s ../example/cloud/node1/solr/ -force</p>
<p>./solr start -c -p 7574 -z localhost:9983 -s ../example/cloud/node2/solr/ -force</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MyCat]]></title>
        <id>https://jonchan1013.github.io/post/mycat/</id>
        <link href="https://jonchan1013.github.io/post/mycat/">
        </link>
        <updated>2020-07-15T09:23:05.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715172709.png" alt="" loading="lazy"></figure>
<h2 id="1-mycat-简介">1、MyCat 简介</h2>
<h3 id="11-什么是-mycat">1.1 什么是 MyCat</h3>
<p>MyCat 是目前最流行的基于 java 语言编写的数据库中间件，是一个实现了 MySQL 协议的服务器，前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问，而其后端可以用 MySQL 原生协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分库分表。配合数据库的主从模式还可实现读写分离。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715172709.png" alt="" loading="lazy"></figure>
<h2 id="1-mycat-简介">1、MyCat 简介</h2>
<h3 id="11-什么是-mycat">1.1 什么是 MyCat</h3>
<p>MyCat 是目前最流行的基于 java 语言编写的数据库中间件，是一个实现了 MySQL 协议的服务器，前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问，而其后端可以用 MySQL 原生协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分库分表。配合数据库的主从模式还可实现读写分离。</p>
<!-- more -->
<p>MyCat 是基于阿里开源的 Cobar 产品而研发，Cobar 的稳定性、可靠性、优秀的架构和性能以及众多成熟的使用案例使得 MyCat 变得非常的强大。<br>
MyCat 发展到目前的版本，已经不是一个单纯的 MySQL 代理了，它的后端可以支持MySQL、SQL Server、Oracle、DB2、PostgreSQL 等主流数据库，也支持 MongoDB 这种新型NoSQL 方式的存储，未来还会支持更多类型的存储。而在最终用户看来，无论是那种存储方式，在 MyCat 里，都是一个传统的数据库表，支持标准的 SQL 语句进行数据的操作，这样一来，对前端业务系统来说，可以大幅降低开发难度，提升开发速度。<br>
MyCat 官网：http://www.mycat.io/</p>
<h3 id="12-使用-mycat-后的结构图">1.2 使用 Mycat 后的结构图</h3>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716163049.png" alt="" loading="lazy"></figure>
<h3 id="13-使用-mycat-的优势">1.3 使用 Mycat 的优势</h3>
<ol>
<li>
<p>数据量级</p>
<p>单一的 MySQL 其数据存储量级和操作量级有限.<br>
Mycat 可以管理若干 MySQL 数据库,同时实现数据的存储和操作.</p>
</li>
<li>
<p>开源性质<br>
Mycat 是 java 编写的中间件. 开源,免费.<br>
有非常多的人和组织对 Mycat 实行开发,维护,管理,更新.<br>
Mycat 版本提升较快,可以跟随环境发展.如果有问题,可以快速解决.<br>
Mycat 有开源网站和开源社区.且有官方发布的电子书籍.<br>
Mycat 是阿里原应用 corba 转型而来的.</p>
</li>
<li>
<p>市场应用<br>
2015 年左右,Mycat 在互联网应用中占比非常高.</p>
</li>
</ol>
<h2 id="2-mycat-中的概念">2、 MyCat 中的概念</h2>
<h3 id="21-切分">2.1 切分</h3>
<p>逻辑上的切分. 在物理层面,是使用多库[database],多表[table]实现的切分.</p>
<h4 id="211-纵向切分垂直切分">2.1.1 纵向切分/垂直切分</h4>
<p>就是把原本存储于一个库的数据存储到多个库上。<br>
由于对数据库的读写都是对同一个库进行操作，所以单库并不能解决大规模并发写入的问题。<br>
例如，我们会建立定义数据库 workDB、商品数据库 payDB、用户数据库 userDB、日志数据库 logDB 等，分别用于存储项目数据定义表、商品定义表、用户数据表、日志数据表等。<br>
优点<br>
1）减少增量数据写入时的锁对查询的影响。<br>
2）由于单表数量下降，常见的查询操作由于减少了需要扫描的记录，使得单表单次查询所需的检索行数变少，减少了磁盘 IO，时延变短。<br>
缺点：无法解决单表数据量太大的问题。</p>
<h4 id="212-横向切分水平切分">2.1.2 横向切分/水平切分</h4>
<p>把原本存储于一个表的数据分块存储到多个表上。当一个表中的数据量过大时，我们可以把该表的数据按照某种规则，进行划分，然后存储到多个结构相同的表，和不同的库上。<br>
例如，我们 userDB 中的 userTable 中数据量很大，那么可以把 userDB 切分为结构相同的多个 userDB：part0DB、part1DB 等，再将 userDB 上的 userTable，切分为很多 userTable：userTable0、userTable1 等，然后将这些表按照一定的规则存储到多个 userDB 上。<br>
优点<br>
1）单表的并发能力提高了，磁盘 I/O 性能也提高了。<br>
2）如果出现高并发的话，总表可以根据不同的查询，将并发压力分到不同的小表里面。<br>
缺点：无法实现表连接查询。</p>
<h3 id="22-逻辑库-schema">2.2 逻辑库-Schema</h3>
<p>Mycat 中定义的 database.是逻辑上存在的.但是物理上是不存在的.<br>
主要是针对纵向切分提供的概念.</p>
<h3 id="23-逻辑表-table">2.3 逻辑表-table</h3>
<p>Mycat 中定义的 table.是逻辑上存在,物理上是不存在的.<br>
主要是针对横向切分提供的概念.</p>
<h3 id="24-默认端口">2.4  默认端口</h3>
<p>MySQL 默认端口是 3306<br>
<strong>Mycat 默认端口是 8066</strong><br>
tomcat 默认端口是 8080<br>
Oracle 默认端口是 1521<br>
nginx 默认端口是 80<br>
http 协议默认端口 80<br>
redis 默认端口 6379</p>
<h3 id="25-数据主机-datahost">2.5  数据主机 - dataHost</h3>
<p>物理 MySQL 存放的主机地址.可以使用主机名,IP,域名定义.</p>
<h3 id="26-数据节点-datanode">2.6 数据节点 - dataNode</h3>
<p>配置物理的 database. 数据保存的物理节点.就是 database.</p>
<h3 id="27-分片规则">2.7 分片规则</h3>
<p>当控制数据的时候,如何访问物理 database 和 table.<br>
就是访问 dataHost 和 dataNode 的算法.<br>
在 Mycat 处理具体的数据 CRUD 的时候,如何访问 dataHost 和 dataNode 的算法.如:哈希算法,crc32 算法等</p>
<h2 id="3-mycat-的使用">3、 MyCat 的使用</h2>
<h3 id="31-读写分离">3.1 读写分离</h3>
<p>原理：需要搭建主从模式，让主数据库（master）处理事务性增、改、删操作（INSERT、UPDATE、DELETE），而从数据库（slave）处理 SELECT 查询操作。<br>
Mycat 配合数据库本身的复制功能，可以解决读写分离的问题。</p>
<h3 id="32-主从备份概念">3.2 主从备份概念</h3>
<p>什么是主从备份: 就是一种主备模式的数据库应用.<br>
主库(Master)数据与备库(Slave)数据完全一致.<br>
实现数据的多重备份, 保证数据的安全.<br>
可以在 Master[InnoDB]和 Slave[MyISAM]中使用不同的数据库引擎,实现读写的分离</p>
<p><strong>MySQL5.5, 5.6 版本后本身支持主从备份</strong></p>
<p>在老旧版本的 MySQL 数据库系统中,不支持主从备份,需要安装额外的 RPM 包.<br>
如果需要安装 RPM,只能在一个位置节点安装.</p>
<h4 id="321-主从备份目的">3.2.1 主从备份目的</h4>
<ol>
<li>
<p>实现主备模式</p>
<p>保证数据的安全. 尽量避免数据丢失的可能.</p>
</li>
<li>
<p>实现读写分离</p>
<p>使用不同的数据库引擎,实现读写分离.提高所有的操作效率.<br>
InnoDB 使用 DML 语法操作. MyISAM 使用 DQL 语法操作.</p>
</li>
</ol>
<h4 id="322-主从备份效果">3.2.2 主从备份效果</h4>
<ul>
<li>
<p>主库操作同步到备库：</p>
<p>所有对 Master 的操作,都会同步到 Slave 中.<br>
<strong>如果 Master 和 Salve 天生上环境不同,那么对 Master 的操作,可能会在 Slave 中出现错误如: 在创建主从模式之前,Master 有 database : db1, db2, db3. Slave 有 database: db1,db2.</strong><br>
<strong>创建主从模式.现在的情况 Master 和 Slave 天生不同.</strong><br>
<strong>主从模式创建成功后,在 Master 中 drop database db3. Slave 中抛出数据库 SQL 异常.后续所有的命令不能同步.</strong><br>
<strong>一旦出现错误. 只能重新实现主从模式.</strong></p>
</li>
</ul>
<h3 id="323-主从模式下的逻辑图">3.2.3  主从模式下的逻辑图</h3>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164034.png" alt="" loading="lazy"></figure>
<h3 id="33-mysql-的主从模式搭建">3.3  MySql 的主从模式搭建</h3>
<ol>
<li>
<p>安装 MySQL<br>
已安装<br>
主库：192.168.70.148<br>
从库：192.168.70.149</p>
</li>
<li>
<p>主从备份配置</p>
</li>
<li>
<p>Master[主库]配置</p>
<ol>
<li>
<p>修改 Master 配置文件<br>
路径：/etc/my.cnf<br>
命令：vim /etc/my.cnf</p>
</li>
<li>
<p>server_id<br>
本环境中 server_id 是 1<br>
MySQL 服务唯一标识</p>
</li>
</ol>
<p>配置要求：<br>
server_id 任意配置,只要是数字即可<br>
server_id Master 唯一标识数字必须小于 Slave 唯一标识数字.</p>
<ol start="3">
<li>
<p>log_bin<br>
本环境中 log_bin 值 : master_log<br>
开启日志功能以及日志文件命名,log_bin=master_log<br>
变量的值就是日志文件名称.是日志文件名称的主体.<br>
MySQL 数据库自动增加文件名后缀和文件类型.</p>
</li>
<li>
<p>重启 MySQL<br>
service mysqld restart</p>
</li>
<li>
<p>配置 Master</p>
<ol>
<li>
<p>访问 MySQL<br>
mysql -uusername -ppassword</p>
</li>
<li>
<p>创建用户<br>
在 MySQL 数据库中,为不存在的用户授权,就是同步创建用户并授权.<br>
此用户是从库访问主库使用的用户<br>
ip 地址不能写为%. 因为主从备份中,当前创建的用户,是给从库 Slave 访问主库 Master使用的.用户必须有指定的访问地址.不能是通用地址.<br>
grant all privileges on <em>.</em> to ‘username’@’ip’ identified by ‘password’ with grant option;<br>
flush privileges;</p>
<pre><code>grant all privileges on *.* to 'myslave'@'192.168.70.149' identified by 'myslave' with grant option;
flush privileges;
</code></pre>
</li>
<li>
<p>查看用户</p>
<p>use mysql;<br>
select host, name from user;</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164332.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>查看 Master 信息<br>
show master status;</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164351.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>关闭防火墙或在防火墙中开放 3306 端口</p>
</li>
</ol>
</li>
</ol>
</li>
<li>
<p>Slave[从库]配置</p>
<ol>
<li>
<p>修改 Slave 配置文件<br>
/etc/my.cnf</p>
</li>
<li>
<p>server_id<br>
唯一标识, 本环境中配置为 : 2</p>
</li>
<li>
<p>重启 MySQL 服务<br>
service mysqld restart</p>
</li>
<li>
<p>配置 Slave</p>
<ol>
<li>
<p>访问 mysql<br>
mysql -uusername -ppassword</p>
</li>
<li>
<p>停止 Slave 功能</p>
<p>stop slave</p>
</li>
<li>
<p>配置主库信息<br>
需要修改的数据是依据 Master 信息修改的. ip 是 Master 所在物理机 IP. 用户名和密码是Master 提供的 Slave 访问用户名和密码. 日志文件是在 Master 中查看的主库信息提供的.在Master 中使用命令 show master status 查看日志文件名称.<br>
change master to master_host=’ip’, master_user=’username’, master_password=’password’,master_log_file=’log_file_name’;</p>
<pre><code>change master to master_host='192.168.70.148',master_user='myslave',master_password='myslave',master_log_file='master_log.000001';
</code></pre>
</li>
<li>
<p>启动 Slave 功能</p>
<p>start slave;</p>
</li>
<li>
<p>查看 Slave 配置<br>
show slave status \G;</p>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164648.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716164709.png" alt="" loading="lazy"></figure>
</li>
</ol>
</li>
</ol>
</li>
<li>
<p>测试主从</p>
<p>新建库</p>
<p>create database demo1 default character set utf8;</p>
<p>新建表</p>
<p>CREATE TABLE <code>t_users</code> (<br>
<code>id</code> int(11) NOT NULL,<br>
<code>name</code> varchar(30) DEFAULT NULL,<br>
PRIMARY KEY (<code>id</code>)<br>
) ENGINE=InnoDB DEFAULT CHARSET=utf8;</p>
<p>添加数据</p>
<p>insert into users values(1,‘admin’)</p>
</li>
</ol>
<h2 id="4-安装-mycat">4、安装 MyCat</h2>
<ol>
<li>
<p>安装环境<br>
192.168.70.150</p>
</li>
<li>
<p>需要配置 JDK<br>
已安装</p>
</li>
<li>
<p>在主数据库和从数据库都需要完成</p>
<ol>
<li>
<p>放开 3306 端口</p>
</li>
<li>
<p>保证 root 用户可以被 mycat 访问<br>
在 Mycat 中通过 Master 数据库的 root 用户访问 Master 数据库.</p>
<p>grant all privileges on <em>.</em> to 'root'@'%' identified by 'root' with grant option;</p>
<p>flush privileges;</p>
</li>
</ol>
</li>
<li>
<p>解压上传的 Mycat 压缩包<br>
tar -zxf Mycat-server-1.6-RELEASE-20161028204710-linux.tar.gz</p>
</li>
<li>
<p>将解压后的文件夹复制到/usr/local/mycat</p>
</li>
<li>
<p>MyCat 目录介绍<br>
bin 目录里是启动脚本<br>
conf 目录里是配置文件<br>
catlet 为 Mycat 的一个扩展功能</p>
<p>lib 目录里是 Mycat 和它的依赖 jar<br>
logs 目录里是 console.log 用来保存控制台日志，和 mycat.log 用来保存 mycat 的 log4j日志</p>
</li>
</ol>
<h2 id="5-mycat-配置文件">5、MyCat 配置文件</h2>
<p>Mycat 的架构其实很好理解，Mycat 是代理，Mycat 后面就是物理数据库。和 Web 服务器的 Nginx 类似。对于使用者来说，访问的都是 Mycat，不会接触到后端的数据库。我们现在做一个主从、读写分离。结构如下图：</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716165236.png" alt="" loading="lazy"></figure>
<p>Mycat 的配置文件都在 conf 目录里面，这里介绍几个常用的文件</p>
<table>
<thead>
<tr>
<th style="text-align:center">文件</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">server.xml</td>
<td style="text-align:center">MyCat 的配置文件，设置账号、参数等</td>
</tr>
<tr>
<td style="text-align:center">schema.xml</td>
<td style="text-align:center">MyCat 对应的物理数据库和数据库表的配置</td>
</tr>
<tr>
<td style="text-align:center">rule.xml</td>
<td style="text-align:center">MyCat 分片（分库分表）规则</td>
</tr>
</tbody>
</table>
<h3 id="51-serverxml">5.1 server.xml</h3>
<p>常见修改内容:</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716165355.png" alt="" loading="lazy"></figure>
<ol>
<li>配置 Mycat 服务信息</li>
</ol>
<p>如: Mycat 中的用户,用户可以访问的逻辑库,可以访问的逻辑表,服务的端口号等</p>
<table>
<thead>
<tr>
<th style="text-align:center">user</th>
<th style="text-align:center">用户配置节点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">--name</td>
<td style="text-align:center">登录的用户名，也就是连接 Mycat 的用户名</td>
</tr>
<tr>
<td style="text-align:center">--password</td>
<td style="text-align:center">登录的密码，也就是连接 Mycat 的密码</td>
</tr>
<tr>
<td style="text-align:center">--schemas</td>
<td style="text-align:center">逻辑库名，这里会和 schema.xml 中的配置关联，多个用逗号分开，例如需要这个用户管理两个数据库 db1,db2，则配置 db1,db2</td>
</tr>
<tr>
<td style="text-align:center">--privileges</td>
<td style="text-align:center">配置用户针对表的增删改查的权限</td>
</tr>
</tbody>
</table>
<p>默认配置了一个账号 root 密码也是 123456,针对数据库 TESTDB,读写权限都有，没有针对表做任何特殊的权限。</p>
<ol start="2">
<li>配置权限</li>
</ol>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716165607.png" alt="" loading="lazy"></figure>
<p>dml 权限顺序为：insert(新增),update(修改),select(查询),delete(删除),0000--&gt; 1111,0 为禁止权限，1 为开启权限。</p>
<h3 id="52-schemaxml">5.2  schema.xml</h3>
<p>schema.xml 是最主要的配置文件，首先看默认的配置文件</p>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716165647.png" alt="" loading="lazy"></figure>
<h4 id="521-用于定义逻辑库和逻辑表的配置文件">5.2.1 用于定义逻辑库和逻辑表的配置文件</h4>
<p>在配置文件中可以定义读写分离,逻辑库,逻辑表,dataHost,dataNode 等信息.</p>
<table>
<thead>
<tr>
<th style="text-align:center">schema</th>
<th style="text-align:center">配置逻辑库，name 与 server.xml 中 schema 对应</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">dataNode</td>
<td style="text-align:center">定义数据节点的标签，也就是分库相关配置</td>
</tr>
<tr>
<td style="text-align:center">dataHost</td>
<td style="text-align:center">物理数据库，真正存储数据的数据库</td>
</tr>
</tbody>
</table>
<h4 id="522-节点与属性介绍">5.2.2 节点与属性介绍</h4>
<ol>
<li>
<p>标签 schema</p>
<p>配置逻辑库的标签</p>
<ol>
<li>属性 name<br>
逻辑库名称</li>
<li>属性 checkSQLschema<br>
是否检测 SQL 语法中的 schema 信息.<br>
如: Mycat 逻辑库名称 A, dataNode 名称 B<br>
SQL : select * from A.table;<br>
checkSQLschema 值是 true, Mycat 发送到数据库的 SQL 是 select * from table;<br>
checkSQLschema 只是 false,Mycat 发送的数据库的 SQL 是 select * from A.table;</li>
<li>sqlMaxLimit<br>
Mycat 在执行 SQL 的时候,如果 SQL 语句中没有 limit 子句.自动增加 limit 子句. 避免一次<br>
性得到过多的数据,影响效率. limit 子句的限制数量默认配置为 100.如果 SQL 中有具体的 limit<br>
子句,当前属性失效.<br>
SQL : select * from table . mycat 解析后: select * from table limit 100<br>
SQL : select * from table limit 10 . mycat 不做任何操作修改.</li>
</ol>
</li>
<li>
<p>标签 table<br>
定义逻辑表的标签</p>
<ol>
<li>属性 name<br>
逻辑表名</li>
<li>属性 dataNode<br>
数据节点名称. 即物理数据库中的 database 名称.多个名称使用逗号分隔.</li>
<li>属性 rule<br>
分片规则名称.具体的规则名称参考 rule.xml 配置文件.</li>
</ol>
</li>
<li>
<p>标签 dataNode<br>
定义数据节点的标签</p>
<ol>
<li>属性 name<br>
数据节点名称, 是定义的逻辑名称,对应具体的物理数据库 database</li>
<li>属性 dataHost<br>
引用 dataHost 标签的 name 值,代表使用的物理数据库所在位置和配置信息.</li>
<li>属性 database<br>
在 dataHost 物理机中,具体的物理数据库 database 名称.</li>
</ol>
</li>
<li>
<p>dataHost 标签<br>
定义数据主机的标签</p>
<ol>
<li>属性 name<br>
定义逻辑上的数据主机名称</li>
<li>属性 maxCon/minCon<br>
最大连接数, max connections<br>
最小连接数, min connections</li>
<li>属性 dbType<br>
数据库类型 : mysql 数据库</li>
<li>属性 dbDriver<br>
数据库驱动类型, native,使用 mycat 提供的本地驱动.</li>
</ol>
</li>
<li>
<p>dataHost 子标签 writeHost<br>
写数据的数据库定义标签. 实现读写分离操作.</p>
<ol>
<li>属性 host<br>
数据库命名</li>
<li>属性 url<br>
数据库访问路径</li>
<li>属性 user<br>
数据库访问用户名</li>
<li>属性 password<br>
访问用户密码</li>
</ol>
</li>
<li>
<p>writeHost 子标签 readHost</p>
<ol>
<li>属性 host<br>
数据库命名</li>
<li>属性 url<br>
数据库访问路径</li>
<li>属性 user<br>
数据库访问用户名</li>
<li>属性 password</li>
</ol>
</li>
</ol>
<h3 id="53-rulexml">5.3  rule.xml</h3>
<p>用于定义分片规则的配置文件.<br>
mycat 默认的分片规则: 以 500 万为单位,实现分片规则.<br>
逻辑库 A 对应 dataNode - db1 和 db2. 1-500 万保存在 db1 中, 500 万零 1 到 1000 万保存在 db2 中,1000 万零 1 到 1500 万保存在 db1 中.依次类推.</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170524.png" alt="" loading="lazy"></figure>
<ol>
<li>tableRule</li>
</ol>
<table>
<thead>
<tr>
<th style="text-align:center">name</th>
<th style="text-align:center">属性指定唯一的名字，用于标识不同的分片规则。内嵌的 rule 标签则指定对物理表中的哪一列进行拆分和使用什么分片算法</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">columns</td>
<td style="text-align:center">指定要拆分的列名字</td>
</tr>
<tr>
<td style="text-align:center">algorithm</td>
<td style="text-align:center">使用 function 标签中的 name 属性。连接表规则和具体分片算法。 table 标签内使用。让逻辑表使用这个规则进行分片</td>
</tr>
</tbody>
</table>
<ol start="2">
<li>function</li>
</ol>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170718.png" alt="" loading="lazy"></figure>
<table>
<thead>
<tr>
<th style="text-align:center">name</th>
<th style="text-align:center">指定算法的名字</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">class</td>
<td style="text-align:center">制定分片算法具体的类名字</td>
</tr>
<tr>
<td style="text-align:center">property</td>
<td style="text-align:center">为具体算法需要用到的一些属性</td>
</tr>
</tbody>
</table>
<h2 id="6-实现读写分离">6、 实现读写分离</h2>
<h3 id="61-配置读写分离">6.1 配置读写分离</h3>
<ol>
<li>Schema.xml</li>
</ol>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170859.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>
<p>Server.xml</p>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170917.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716170947.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>测试读写分离</p>
<ol>
<li>
<p>启动 Mycat 命令<br>
bin/mycat start</p>
</li>
<li>
<p>停止命令<br>
bin/mycat stop</p>
</li>
<li>
<p>重启命令<br>
bin/mycat restart</p>
</li>
<li>
<p>查看 MyCat 状态<br>
bin/mycat status</p>
</li>
<li>
<p>访问方式<br>
可以使用命令行访问或客户端软件访问.</p>
</li>
<li>
<p>命令行访问方式<br>
mysql -u 用户名 -p 密码 -hmycat 主机 IP -P8066<br>
链接成功后,可以当做 MySQL 数据库使用.<br>
访问约束</p>
</li>
<li>
<p>查看 Mycat 日志<br>
logs/wrapper.log<br>
日志中记录的是所有的 mycat 操作. 查看的时候主要看异常信息 caused by 信息</p>
</li>
<li>
<p>balance<br>
balance=”0”, 不开启读写分离机制，所有读操作都发送到当前可用的 writeHost 上<br>
balance=”1”，全部的 readHost 与 stand by writeHost 参与 select 语句的负载均衡<br>
balance=”2”，所有读操作都随机的在 writeHost、 readhost 上分发。</p>
</li>
</ol>
<p>balance=”3”， 所有读请求随机的分发到 writeHost 对应的 readhost 执行,writerHost不负担读压力</p>
</li>
</ol>
<p>7、MyCat 分库</p>
<h3 id="71-分片规则">7.1 分片规则</h3>
<ol>
<li>
<p>auto-sharding-long 范围约定</p>
<p>以 500 万为单位,实现分片规则.<br>
逻辑库 A 对应 dataNode - db1 和 db2. 1-500 万保存在 db1 中, 500 万零 1 到 1000 万保存在 db2 中,1000 万零 1 到 1500 万保存在 db1 中.依次类推.</p>
</li>
<li>
<p>crc32slot 规则<br>
在 CRUD 操作时,根据具体数据的 crc32 算法计算,数据应该保存在哪一个 dataNode 中</p>
</li>
</ol>
<h3 id="72-配置分片规则需要注意的地方">7.2 配置分片规则需要注意的地方</h3>
<p><em>1）<columns>id</columns>中推荐配置主键列</em><br>
<em>2）所有的 tableRule 只能使用一次。如果需要为多个表配置相同的分片规则，那么需要在此重新定义该规则。</em><br>
<em>3）在 crc32Slot 算法中的分片数量一旦给定，MyCat 会将该分片数量和 slor 的取值范围保存到文件中。在次修改分片数量时是不会生效的，需要将该文件删除。文件位置位于 conf目录中的 ruledata 目录中。</em></p>
<h3 id="73-配置分库">7.3 配置分库</h3>
<ol>
<li>
<p>需求：<br>
1）在 master 中创建 3 个数据库<br>
2）在 MyCat 中配置分库</p>
</li>
<li>
<p>创建数据库</p>
<p>create database demo1 default character set utf8;<br>
create database demo2 default character set utf8;<br>
create database demo3 default character set utf8;</p>
<p>创建 t_users 表：</p>
<p>CREATE TABLE <code>t_users</code> (</p>
<p><code>id</code> int(11) NOT NULL,<br>
<code>name</code> varchar(30) DEFAULT NULL,<br>
PRIMARY KEY (<code>id</code>)<br>
) ENGINE=InnoDB DEFAULT CHARSET=utf8;</p>
</li>
<li>
<p>修改 Schema.xml</p>
<figure data-type="image" tabindex="17"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716171350.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>测试</p>
<figure data-type="image" tabindex="18"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200716171412.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="74-注意">7.4 注意：</h3>
<p>1）使用 MyCat 实现分库时，先在 MyCat 中定义逻辑库与逻辑表，然后在 MyCat 的链接中执行创建表的命令必须要在 MyCat 中运行。因为 MyCat 在创建表时，会在表中添加一个新的列，列名为_slot。<br>
2）使用 MyCat 插入数据时，语句中必须要指定所有的列。即便是一个完全项插入也不允许省略列名。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[后台管理系统（单体应用+前后端分离）]]></title>
        <id>https://jonchan1013.github.io/post/spring-bootlayui-kuai-su-da-jian-hou-tai-guan-li-xi-tong-dan-ti-ying-yong-qian-hou-duan-fen-chi/</id>
        <link href="https://jonchan1013.github.io/post/spring-bootlayui-kuai-su-da-jian-hou-tai-guan-li-xi-tong-dan-ti-ying-yong-qian-hou-duan-fen-chi/">
        </link>
        <updated>2020-07-10T07:10:29.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-layui">1、Layui</h2>
<p><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200710151802.png" alt="" loading="lazy"><br>
<img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200710151954.png" alt="" loading="lazy"></p>
<p>table.html</p>
<pre><code class="language-html">
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MongoDB]]></title>
        <id>https://jonchan1013.github.io/post/mongodb/</id>
        <link href="https://jonchan1013.github.io/post/mongodb/">
        </link>
        <updated>2020-07-08T09:19:58.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708172130.png" alt="" loading="lazy"></figure>
<h2 id="1-mongodb-简介">1、MongoDB 简介</h2>
<h3 id="11-什么是-mongodb">1.1 什么是 MongoDB</h3>
<p>MongoDB 是一个基于分布式文件存储的数据库。由 C++语言编写。在为 WEB 应用提供可扩展的高性能数据存储解决方案。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708172130.png" alt="" loading="lazy"></figure>
<h2 id="1-mongodb-简介">1、MongoDB 简介</h2>
<h3 id="11-什么是-mongodb">1.1 什么是 MongoDB</h3>
<p>MongoDB 是一个基于分布式文件存储的数据库。由 C++语言编写。在为 WEB 应用提供可扩展的高性能数据存储解决方案。</p>
<!-- more -->
<p>MongoDB 是一个介于关系数据库和非 关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似json 的bson 格式，因此可以存储比较复杂的数据类型。Mongo 最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。</p>
<h3 id="12-什么是nosql">1.2 什么是NoSQL</h3>
<p>NoSQL(NoSQL = Not Only SQL )，意即“不仅仅是SQL”，是一项全新的数据库革命性运动，早期就有人提出，发展至 2009 年趋势越发高涨。NoSQL 的拥护者们提倡运用非关系型的数据存储，相对于铺天盖地的关系型数据库运用，这一概念无疑是一种全新的思维的注入。</p>
<h3 id="13-nosql-数据库的分类">1.3 NoSQL 数据库的分类</h3>
<ol>
<li>
<p>键值(Key-Value)存储数据库</p>
<p>这一类数据库主要会使用到一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。Key/value 模型对于 IT 系统来说的优势在于简单、易部署。但是如果 DBA 只对部分值进行查询或更新的时候，Key/value 就显得效率低下了。例如： Redis</p>
</li>
<li>
<p>列存储数据库<br>
这部分数据库通常是用来应对分布式存储的海量数据。键仍然存在，但是它们的特点是指向了多个列。这些列是由列家族来安排的。如：HBase。</p>
</li>
<li>
<p>文档型数据库<br>
文档型数据库的灵感是来自于 Lotus Notes 办公软件的，而且它同第一种键值存储相类似。该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可 以看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。如：CouchDB, MongoDB. 国内也有文档型数据库 SequoiaDB，已经开源。</p>
</li>
<li>
<p>图形(Graph)数据库<br>
图形结构的数据库同其他行列以及刚性结构的 SQL 数据库不同，它是使用灵活的图形模型，并且能够扩展到多个服务器上。NoSQL 数据库没有标准的查询语言(SQL)，因此进行数据库查询需要制定数据模型。许多 NoSQL 数据库都有REST 式的数据接口或者查询API。如：Neo4J, InfoGrid。</p>
</li>
</ol>
<h2 id="2-mongodb-与关系型数据库对比">2、MongoDB 与关系型数据库对比</h2>
<h3 id="21-与关系型数据库术语对比">2.1  与关系型数据库术语对比</h3>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708220755.png" alt="" loading="lazy"></figure>
<h3 id="22-存储数据对比">2.2 存储数据对比</h3>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708220819.png" alt="" loading="lazy"></figure>
<h3 id="23-rdbms-与-mongodb-对应的术语">2.3 RDBMS 与 MongoDB 对应的术语</h3>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708221436.png" alt="" loading="lazy"></figure>
<h2 id="3-mongodb-的数据类型">3、 MongoDB 的数据类型</h2>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708221500.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708221505.png" alt="" loading="lazy"></figure>
<h2 id="4-mongodb-的下载与安装">4、MongoDB 的下载与安装</h2>
<h3 id="41-下载-mongodb">4.1 下载 MongoDB</h3>
<p>下载地址：https://www.mongodb.com/download-center/community</p>
<h3 id="42-安装-mongodb">4.2 安装 MongoDB</h3>
<ol>
<li>
<p>下载 ForLinux 平台的 MongoDB</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708221632.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>Linux 安装<br>
在 Linux 平台的MongoDB 为解压版。我们只要解压 tgz 文件就可以使用。</p>
<ol>
<li>
<p>将下载的 tgz 包上传到Linux 环境中</p>
<p>我将 tgz 包上传到了自己创建的 temp 目录中。该目录位于/root 目录中。</p>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708221830.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>解压tgz 文件<br>
通过 tar 命令对tgz 文件做解压处理。</p>
</li>
<li>
<p>移动 MongoDB<br>
我们将解压完的MongoDB 目录移动到/usr/local 目录中并改名为mongodb。</p>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708221855.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>创建数据库目录<br>
MongoDB 的数据存储在 data 目录的 db 目录下，但是这个目录在安装过程不会自动创建，需要手动创建data 目录，并在data 目录中创建db 目录。data 目录可以创建在任何位置。我们将data 目录创建在mongodb 的根目录下。</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708234940.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708234949.png" alt="" loading="lazy"></figure>
</li>
</ol>
<p>至此 Linux 平台中的 MongoDB 就已经安装完毕。</p>
</li>
</ol>
<h3 id="43-mongodb-的启动与关闭">4.3 MongoDB 的启动与关闭</h3>
<h4 id="431-启动mongodb">4.3.1 启动MongoDB</h4>
<p>MongoDB 的启动方式分为两种<br>
1）前置启动<br>
2）后置启动<br>
无论哪种启动方式都需要执行 bin 目录中的 mongod 命令。MongoDB 在启动时默认的查找数据库的路径为/data/db。如果我们数据库路径有变化，需要在该命令中通过--dbpath 参数来指定db 目录的路径(该路径可以是绝对路径，也可是相对路径)。</p>
<ol>
<li>
<p>前置启动<br>
MongoDB 的默认启动方式为前置启动。所谓前置启动就是 MongoDB 启动进程后会占用当前终端窗口。<br>
进入到MongoDB 的bin 目录。</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235039.png" alt="" loading="lazy"></figure>
<p>执行 bin 目录中的 mongod 命令。</p>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235055.png" alt="" loading="lazy"></figure>
<p>由于我们的db 目录放在 mongodb 的根下，所以在执行该命令时需要通过 --dbpath 参数指定db 路径。</p>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235122.png" alt="" loading="lazy"></figure>
<p>启动后会在终端中输出一些启动信息。此时终端窗口已被启动进程所占用。我们通过启动信息可以看到MongoDB 默认的监听端口为27017</p>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235141.png" alt="" loading="lazy"></figure>
<p>按 Ctrl+C 可结束启动进程关闭 MongoDB</p>
</li>
<li>
<p>后置启动<br>
所谓后置启动就是以守护进程的方式启动 MongoDB。我们需要在执行 mongod 命令中添加 --fork 参数。需要注意的是，--fork 参数需要配合着--logpath 或者是--syslog 参数使用。--logpath 与--syslog 参数是指定 MongoDB 的日志文件。MongoDB 的日志文件可以在系统中的任意位置，本视频中我们在 mongodb 目录下创建 log 目录，在该目录中创建一个名为mongodb.log 的日志文件。</p>
<p>创建 log 目录</p>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235225.png" alt="" loading="lazy"></figure>
<p>在 log 目录中创建 mongodb.log 日志文件</p>
<figure data-type="image" tabindex="17"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235238.png" alt="" loading="lazy"></figure>
<p>后置启动MongoDB</p>
<figure data-type="image" tabindex="18"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235258.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>常见的启动参数</p>
<table>
<thead>
<tr>
<th style="text-align:center">--quiet</th>
<th style="text-align:center">安静输出</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">--port</td>
<td style="text-align:center">指定服务端口号，默认端口 27017</td>
</tr>
<tr>
<td style="text-align:center">--bind</td>
<td style="text-align:center">绑定服务IP，若绑定127.0.0.1，则只能本机访问</td>
</tr>
<tr>
<td style="text-align:center">--logpath</td>
<td style="text-align:center">指定 MongoDB 日志文件，注意是指定日志文件不是目录</td>
</tr>
<tr>
<td style="text-align:center">--logappend</td>
<td style="text-align:center">使用追加的方式写日志</td>
</tr>
<tr>
<td style="text-align:center">--fork</td>
<td style="text-align:center">守护进程的方式运行 MongoDB，创建服务器进程</td>
</tr>
<tr>
<td style="text-align:center">--auth</td>
<td style="text-align:center">启用验证</td>
</tr>
<tr>
<td style="text-align:center">--config</td>
<td style="text-align:center">指定配置文件的路径，注意是指定配置文件不是目录</td>
</tr>
<tr>
<td style="text-align:center">--journal</td>
<td style="text-align:center">启用日志选项，MongoDB 的数据操作将会写入到 journal 文件夹的文件里</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>通过配置文件加载启动参数<br>
如果觉得在启动MongoDB 时给定的参数项太多，那么我们也可以通过配置文件来配置启动参数，配置文件可以在任意目录中，配置文件的扩展名应为.conf，配置文件中使用key=value 结构。在执行 MongoDB 时通过--config 参数来指定需要加载的配置文件。</p>
<p>我们在 mongodb 目录下创建一个 etc 目录，在该目录中创建一个名为 mongodb.conf 的配置文件。</p>
<figure data-type="image" tabindex="19"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235523.png" alt="" loading="lazy"></figure>
<p>创建 mongodb.conf 配置文件</p>
<figure data-type="image" tabindex="20"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235533.png" alt="" loading="lazy"></figure>
<p>编辑配置文件，在配置文件中添加配置项：<br>
1）指定db 路径<br>
2）指定日志文件<br>
3）配置端口<br>
4）配置后端启动<br>
在配置文件中配置启动参数时需要注意的是，在参数前不在加--符号，直接以参数名作为 key 就可以。</p>
<figure data-type="image" tabindex="21"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235547.png" alt="" loading="lazy"></figure>
<p>通过加载配置文件启动 MongoDB</p>
<figure data-type="image" tabindex="22"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235601.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>配置环境变量<br>
为了能够在任何目录中执行 bin 目录中的命令，我们可以将 bin 目录添加到环境变量中。<br>
修 改 /etc/profile 文 件 ， 添 加 export PATH=/usr/local/mongodb/bin:$PATH 。/usr/local/monogdb/bin 为 MongoDB 的 bin 目录的绝对路径。</p>
<figure data-type="image" tabindex="23"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235631.png" alt="" loading="lazy"></figure>
<p>重新加载/etc/profile 文件</p>
<figure data-type="image" tabindex="24"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235643.png" alt="" loading="lazy"></figure>
<p>测试结果</p>
<figure data-type="image" tabindex="25"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708235656.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h4 id="432-关闭mongodb">4.3.2 关闭MongoDB</h4>
<ol>
<li>
<p>使用 Ctrl+C 关闭<br>
如果我们的启动方式是前置启动，那么直接使用快捷键Ctrl+C 就可以关闭 MongoDB。这种关闭方式会等待当前进行中的的操作完成，所以依然是安全的关闭方式。</p>
</li>
<li>
<p>使用 kill 命令关闭<br>
我们可以通过 Linux 的 kill 命令结束 MongoDB 进程，然后删除 data/db 目录中的mongod.lock 文件，否则下次无法启动。但是此方法不建议使用，因为会造成数据损坏现象。</p>
</li>
<li>
<p>使用 MongoDB 的函数关闭<br>
在 MongoDB 中提供了两个关闭数据库的函数：<br>
db.shutdownServer()<br>
db.runCommand(“shutdown”)<br>
如上两个方法都需要在 admin 库中执行，并且都是安全的关闭方式。</p>
</li>
<li>
<p>使用 mongod 命令关闭 MongoDB<br>
mongod --shutdown --dbpath&lt;数据库路径&gt;</p>
<p>./mongod --shutdown --dbpath /usr/local/mongodb/data/db/</p>
<figure data-type="image" tabindex="26"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709000025.png" alt="" loading="lazy"></figure>
<p>mongod 命令的 shutdown 选项能安全的关闭 MongoDB 服务</p>
</li>
</ol>
<h2 id="5-mongodb-的用户与权限管理">5、MongoDB 的用户与权限管理</h2>
<p>Mongodb 作为时下最为热门的数据库，那么其安全验证也是必不可少的，否则一个没有验证的数据库暴露出去，任何人可随意操作，这将是非常危险的。我们可以通过创建用户的方式来降低风险。</p>
<h3 id="51-mongodb-用户权限列表">5.1  Mongodb 用户权限列表</h3>
<table>
<thead>
<tr>
<th style="text-align:center">Read</th>
<th style="text-align:center">允许用户读取指定数据库</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">readWrite</td>
<td style="text-align:center">允许用户读写指定数据库</td>
</tr>
<tr>
<td style="text-align:center">dbAdmin</td>
<td style="text-align:center">允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profile</td>
</tr>
<tr>
<td style="text-align:center">userAdmin</td>
<td style="text-align:center">允许用户向system.users 集合写入，可以找指定数据库里创建、删除和管理用户</td>
</tr>
<tr>
<td style="text-align:center">clusterAdmin</td>
<td style="text-align:center">只在admin 数据库中可用，赋予用户所有分片和复制集相关函数的管理权限</td>
</tr>
<tr>
<td style="text-align:center">readAnyDatabase</td>
<td style="text-align:center">只在admin 数据库中可用，赋予用户所有数据库的读权限</td>
</tr>
<tr>
<td style="text-align:center">readWriteAnyDatabase</td>
<td style="text-align:center">只在admin 数据库中可用，赋予用户所有数据库的读写权限</td>
</tr>
<tr>
<td style="text-align:center">userAdminAnyDatabase</td>
<td style="text-align:center">只在admin 数据库中可用，赋予用户所有数据库的userAdmin 权限</td>
</tr>
<tr>
<td style="text-align:center">dbAdminAnyDatabase</td>
<td style="text-align:center">只在admin 数据库中可用，赋予用户所有数据库的dbAdmin 权限</td>
</tr>
<tr>
<td style="text-align:center">root</td>
<td style="text-align:center">只在admin 数据库中可用。超级账号，超级权限</td>
</tr>
</tbody>
</table>
<h3 id="52-mongodb-用户使用">5.2  MongoDB 用户使用</h3>
<h4 id="521-创建-db-管理用户">5.2.1 创建 DB 管理用户</h4>
<p>mongodb 有一个用户管理机制，简单描述为，有一个管理用户组，这个组的用户是专门为管理普通用户而设的，暂且称之为管理员。<br>
管理员通常没有数据库的读写权限，只有操作用户的权限, 因此我们只需要赋予管理员userAdminAnyDatabase 角色即可。<br>
另外管理员账户必须在 admin 数据库下创建。</p>
<ol>
<li>
<p>切换到 Admin 库</p>
<p>管理员需要在admin 数据库下创建，所以我们需要切换到admin 数据库。</p>
<figure data-type="image" tabindex="27"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709000410.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>查看admin 中的用户</p>
<p>我们可以通过db.system.users.find()函数来查看admin 库中的所有用户信息。</p>
<figure data-type="image" tabindex="28"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709000437.png" alt="" loading="lazy"></figure>
<p>目前在admin 库中没有用户，所以查无结果。</p>
</li>
<li>
<p>db.createUser 函数<br>
在 MongoDB 中可以使用 db.createUser({用户信息})函数创建用户。</p>
<p>db.createUser({<br>
user: &quot;<name>&quot;,<br>
pwd: &quot;<cleartext password>&quot;,<br>
customData: { <any information> },<br>
roles: [<br>
{ role: &quot;<role>&quot;, db: &quot;<database>&quot; } | &quot;<role>&quot;,<br>
...<br>
]<br>
});</p>
<p>1）user:新建用户名。<br>
2）pwd:新建用户密码。<br>
3）customData:存放一些用户相关的自定义数据，该属性也可忽略。<br>
4）roles:数组类型，配置用户的权限。</p>
</li>
<li>
<p>创建管理员用户<br>
我们现在需要在admin 库中创建一个名为admin 的管理员用户，密码为admin。 db.createUser({user:'admin',pwd:'admin,roles:[{role:'userAdminAnyDatabase',db:'admin'}]})</p>
<p>创建成功后会看到如下提示：</p>
<figure data-type="image" tabindex="29"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709000650.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>重启 MongoDB</p>
<p>在管理员账户创建完成后，我们需要重新启动 MongoDB，并开启验证。<br>
重新启动函数:db.shutdownServer()。</p>
<figure data-type="image" tabindex="30"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709000714.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>使用权限方式启动 MongoDB<br>
在默认的情况下MongoDB 是不开启用户认证的。如果我们添加用户，那么需要开启用户认证机制。通过修改 mongodb.conf 配置文件，在文件中添加auth=true 即可。</p>
<figure data-type="image" tabindex="31"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709000730.png" alt="" loading="lazy"></figure>
<p>修改完成后启动MongoDB。</p>
</li>
<li>
<p>用户认证<br>
创建管理员后，需要认证方可使用该用户，否则会提示需要认证。</p>
<figure data-type="image" tabindex="32"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709001157.png" alt="" loading="lazy"></figure>
<p>认证函数：db.auth(‘用户名’,’密码’)</p>
<figure data-type="image" tabindex="33"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709001217.png" alt="" loading="lazy"></figure>
<p>如果结果返回1，则表示认证成功，返回0 则表示认证失败。<br>
登录成功后可查询用户</p>
<figure data-type="image" tabindex="34"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709001248.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h4 id="522-创建普通用户">5.2.2 创建普通用户</h4>
<p>普通用户由管理员创建。通常需要指定操作某个数据库。</p>
<ol>
<li>
<p>需求<br>
我们创建一个test 数据库，给这个数据库添加一个用户，用户名为test,密码为 123。并授予该用户对test 数据库进行读写操作的权限。</p>
</li>
<li>
<p>使用管理员用户登录<br>
普通用户需要由管理员创建并授权。所以，我们首先做的就是用管理员账户登录数据库。</p>
</li>
<li>
<p>创建test 数据库<br>
use 命令切换数据库时如果该库不存在，那么则会创建该数据库。 （要让改用户操作哪个数据库，就切换到哪个数据库）</p>
</li>
<li>
<p>创建普通用户</p>
<p>db.createUser({user:&quot;test&quot;,pwd:&quot;123&quot;,roles:[{role:&quot;readWrite&quot;,db:&quot;test&quot;}]})</p>
</li>
<li>
<p>切换到test 数据库<br>
由于我们是在test 数据库中创建的test 用户，所以需要先切换到 test 库。</p>
</li>
<li>
<p>登录普通用户<br>
如果我们不登录会发现无法对该数据库进行插入操作。因为缺少用户认证。</p>
<figure data-type="image" tabindex="35"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709020628.png" alt="" loading="lazy"></figure>
<p>通过认证函数对用户进行登录认证。</p>
<p>db.auth(&quot;test&quot;,&quot;123&quot;)</p>
<p>认证成功后操作通过该用户操作 test库。该用户对 test库具备读写操作。</p>
</li>
</ol>
<h4 id="523-更新用户角色">5.2.3 更新用户角色</h4>
<p>​		如果我们需要对已存在的用户的角色做修改，那么我们可以使用 db.updateUser()函数来更新用户角色。注意，该函数需要当前用户具有userAdminAnyDatabase 或者更高的权限。</p>
<ol>
<li>
<p>更新角色语法格式</p>
<p>db.updateUser(&quot;用户名&quot;, {&quot;roles&quot;:[{&quot;role&quot;:&quot;角色名称&quot;},{&quot;更新项 2&quot;:&quot;更新内容&quot;}]})</p>
</li>
<li>
<p>需求<br>
目前 admin 管理员用户只具备 userAdminAnyDatabase 用户管理角色，我们为该用户添加一个dbAdminAnyDatabase 数据库管理角色。</p>
</li>
<li>
<p>更新角色<br>
db.updateUser(&quot;admin,{roles : [{&quot;role&quot; : &quot;userAdminAnyDatabase&quot;,&quot;db&quot; : &quot;admin&quot;},{&quot;role&quot; : &quot;dbAdminAnyDatabase&quot;,&quot;db&quot; : &quot;admin&quot;}]})</p>
<p>如果没有提示任何信息则表示更新成功。退出当前客户端重新连接即可生效。</p>
</li>
<li>
<p>查看用户信息</p>
<p>通过 show users 命令查看到 bjsxt 用户的角色已经发生改变。</p>
</li>
</ol>
<h4 id="524-更新用户密码">5.2.4 更新用户密码</h4>
<p>更新用户密码有两种方式：<br>
1）使用db.updateUser()函数更新密码。<br>
2）使用db.changeUserPassword()函数更新密码</p>
<ol>
<li>
<p>更新密码方式一<br>
使用 db.upateUser()函数将xxx用户的密码修改为 xxx</p>
<p>db.updateUser(&quot;用户名&quot;,{&quot;pwd&quot;:&quot;新密码&quot;})</p>
<p>如果未提示任何信息则表示更新成功。退出当前客户端重新连接认证即可。</p>
</li>
<li>
<p>更新密码方式二<br>
使用 db.changeUserPassword()函数将xxx用户的密码修改为 xxx。</p>
<p>db.changeUserPassword(&quot;用户名&quot;,&quot;新密码&quot;)</p>
<p>如果未提示任何信息则表示更新成功。退出当前客户端重新连接认证即可。</p>
</li>
</ol>
<h4 id="525-删除用户">5.2.5 删除用户</h4>
<p>通过 db.dropUser()函数可删除指定用户。删除成功后会返回true。在删除用户时需要切换到创建用户时所指定的数据库中才可以删除。注意：需要使用具有userAdminAnyDatabse角色管理员用户才可以删除其他用户。</p>
<ol>
<li>
<p>需求<br>
我们使用函数将test 用户删除。</p>
</li>
<li>
<p>切换数据库<br>
test 用户在test 数据库中，所以需要先切换到 sxt 数据库。</p>
</li>
<li>
<p>通过函数删除用户</p>
<figure data-type="image" tabindex="36"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709021400.png" alt="" loading="lazy"></figure>
<p>函数返回了true，表示删除成功。</p>
</li>
</ol>
<h2 id="6-mongodb-的数据库操作">6、MongoDB 的数据库操作</h2>
<h3 id="61-创建数据库">6.1 创建数据库</h3>
<p>在 MongoDB 中创建数据库的命令使用的是 use 命令。该命令有两层含义：<br>
1）切换到指定数据库。<br>
2）如果切换的数据库不存在，则创建该数据库。<br>
我们使用use 命令创建一个名为 test01 的数据库。</p>
<h3 id="62-查看所有数据库">6.2 查看所有数据库</h3>
<p>我们可以通过show dbs 命令查看当前MongoDB 中的所有数据库。<br>
如果开启了用户认证，则需要先登录方可查看到结果，否则不显示任何信息。如果使用的是具备数据库管理员角色的用户，那么则可以看到 MongoDB 中的所有数据库，如果使用的普通用户登录的那么只能查询到该用户所拥有的数据库。</p>
<p>用户未登录查询数据库。</p>
<figure data-type="image" tabindex="37"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709021637.png" alt="" loading="lazy"></figure>
<p>在查询结果中并未包含我们刚刚创建的 test01数据库。因为，在show dbs 命令中不显示未含有任何信息的数据的库。</p>
<p>使用具有数据库管理员角色的用户登录查询数据库。</p>
<p>使用普通用户登录查询数据库。<br>
我们在test数据库中创建一个只具备读写权限的普通用户。</p>
<p>使用普通用户登录并查询数据库。</p>
<h3 id="63-删除数据库">6.3 删除数据库</h3>
<p>在 MongoDB 中使用 db.dropDatabase()函数来删除数据库。在删除数据库之前，需要使用具备dbAdminAnyDatabase 角色的管理员用户登录，然后切换到需要删除的数据库，执行db.dropDatabase()函数即可。删除成功后会返回一个{ &quot;ok&quot; : 1 }的 JSON 字符串。</p>
<p>我们现在将刚刚创建的test01 删除。</p>
<h2 id="7-mongodb-的集合操作">7、MongoDB 的集合操作</h2>
<p>MongoDB 中的集合是一组文档的集，相当于关系型数据库中的表。</p>
<h3 id="71-创建集合">7.1 创建集合</h3>
<p>MongoDB 使用db.createCollection()函数来创建集合。<br>
语法格式：db.createCollection(name, options)。<br>
name: 要创建的集合名称。<br>
options: 可选参数, 指定有关内存大小及索引的选项。</p>
<p>options 可以是如下参数。</p>
<table>
<thead>
<tr>
<th style="text-align:center">字段</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">capped</td>
<td style="text-align:center">布尔</td>
<td style="text-align:center">（可选）如果为 true，则创建固定集合。固定集合是指有着固定大小的集合，当达到最大值时，它会自动覆盖最早的文档。 <br/><strong>当该值为 true 时，必须指定 size 参数</strong>。</td>
</tr>
<tr>
<td style="text-align:center">autoindexid</td>
<td style="text-align:center">布尔</td>
<td style="text-align:center">可选）如为 true，自动在 _id 字段创建索引。默认为 false。</td>
</tr>
<tr>
<td style="text-align:center">size</td>
<td style="text-align:center">数值</td>
<td style="text-align:center">可选）为固定集合指定一个最大值（以字节计）。 <strong>如果 capped 为 true，也需要指定该字段。</strong></td>
</tr>
<tr>
<td style="text-align:center">max</td>
<td style="text-align:center">数值</td>
<td style="text-align:center">（可选）指定固定集合中包含文档的最大数量。</td>
</tr>
</tbody>
</table>
<p>在插入文档时，MongoDB 首先检查固定集合的 size 字段，然后检查 max 字段。</p>
<h4 id="711-使用默认集合">7.1.1 使用默认集合</h4>
<p>在 MongoDB 中，我们也可以不用创建集合，当我们插入一些数据时，会自动创建集合，并且会使用数据库的名字作为集合的名称。<br>
创建一个新数据库，名为develop</p>
<figure data-type="image" tabindex="38"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709022302.png" alt="" loading="lazy"></figure>
<p>如果开启认证，需要为新数据库创建访问用户。新建用户名为 itsxt，密码为 itsxtpwd</p>
<figure data-type="image" tabindex="39"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709022320.png" alt="" loading="lazy"></figure>
<p>使用 itsxt 用户登录 develop 库</p>
<figure data-type="image" tabindex="40"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709022337.png" alt="" loading="lazy"></figure>
<p>向 develop 库中插入一条数据</p>
<p>db.develop.insert({&quot;name&quot;,&quot;cy&quot;})</p>
<p>查询集合</p>
<figure data-type="image" tabindex="41"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709022409.png" alt="" loading="lazy"></figure>
<h4 id="712-创建不带参数的集合">7.1.2 创建不带参数的集合</h4>
<p>我们也可以根据自己的情况创建集合。在 develop 数据库中创建一个名为 dev 的集合，该集合创建时不指定任何参数。如果开启认证，则需要使用具有数据库管理员权限的用户来创建集合。</p>
<figure data-type="image" tabindex="42"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709022442.png" alt="" loading="lazy"></figure>
<h4 id="713-创建带参数的集合">7.1.3 创建带参数的集合</h4>
<p>在 develop 数据库中创建一个名为 dev2 的固定集合，整个集合空间大小为 2000000kb，文档最大个数为1000。</p>
<figure data-type="image" tabindex="43"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709022641.png" alt="" loading="lazy"></figure>
<h3 id="72-查看集合">7.2 查看集合</h3>
<p>如果要查看已有集合，可以使用 show collections 或 show tables 命令。</p>
<ol>
<li>show collections</li>
</ol>
<figure data-type="image" tabindex="44"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709093118.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>show tables</li>
</ol>
<figure data-type="image" tabindex="45"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709093132.png" alt="" loading="lazy"></figure>
<h3 id="73-删除集合">7.3 删除集合</h3>
<p>​		如果我们要删除集合，需要先切换到需要删除集合所在的数据库，使用 drop()函数删除集合即可。<br>
​		删除集合的语法格式为:db.集合名称.drop()。</p>
<p>​		删除 dev2 集合</p>
<p>​	<img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709093212.png" alt="" loading="lazy"></p>
<h2 id="8-mongodb-的文档操作">8、 MongoDB 的文档操作</h2>
<p>​		在 MongoDB 中文档是指多个键及其关联的值有序地放置在一起就是文档，其实指的就是数据，也是我们平时操作最多的部分。<br>
​		MongoDB 中的文档的数据结构和 JSON 基本一样。所有存储在集合中的数据都是 BSON 格式。<br>
​		BSON 是一种类似 JSON 的二进制形式的存储格式，是 Binary JSON 的简称。</p>
<h3 id="81-插入文档">8.1  插入文档</h3>
<h4 id="811-插入单个文档">8.1.1  插入单个文档</h4>
<ol>
<li>
<p>insert 函数</p>
<p>语法格式为：db.COLLECTION_NAME.insert(document)。</p>
<p>向 dev 集合中插入单个文档。<br>
db.dev.insert({title:' baidu',description:' 百度',url:'www.baidu.com',tags:['java',' 大数据','python']} )</p>
<p>查看文档</p>
<p>db.dev.find()</p>
</li>
<li>
<p>save 函数<br>
向 dev 集合中插入单个文档。</p>
<p>db.dev.save({title:' baidu',description:' 百度',url:'www.baidu.com',tags:['java',' 大数据','python']} )</p>
<p>查看文档</p>
<p>db.dev.find()</p>
</li>
<li>
<p>insertOne 函数</p>
<p>在 MongoDB3.2 以后的版本中，提供了 insertOne()函数用于插入文档。<br>
向 dev 集合中插入单个文档。</p>
<p>db.dev.insertOne({title:' baidu',description:' 百度',url:'www.baidu.com',tags:['java',' 大数据','python']} )</p>
<p>查看文档</p>
<p>db.dev.find()</p>
</li>
</ol>
<h4 id="812-插入多个文档">8.1.2  插入多个文档</h4>
<p>向集合中批量插入多个文档时，需要使用数组来存放文档。<br>
语法格式：db.COLLECTION_NAME.insert([{},{},{}.....])。</p>
<ol>
<li>
<p>insert 或者save 函数</p>
<p>db.dev.insert([{title:'java',tags:['JavaSE','JavaEE','JavaME']},{title:'ORM',tags:['Mybatis','Hibernate']},{title:'Spring',tags:['SpringMVC','SpringBoot','SpringCloud']}] )</p>
<figure data-type="image" tabindex="46"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709095534.png" alt="" loading="lazy"></figure>
<p>查看文档</p>
<p>db.dev.find()</p>
<figure data-type="image" tabindex="47"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709095637.png" alt="" loading="lazy"></figure>
<p>save函数同理</p>
</li>
<li>
<p>insertMany 函数</p>
<p>在 MongoDB3.2 以后的版本中，提供了 insertMany 函数用于插入文档。<br>
语法格式：db.COLLECTION_NAME.insertMany([{},{},{},.....])。</p>
<p>向 dev 集合中批量插入多个文档<br>
db.dev.insertMany([{title:'Web',tags:['JSP','Servlet']},{title:'RPC',tags:['RMI','Dubbo']},{title:'DataBase',tags:['Oracle','MySQL']}] )</p>
<figure data-type="image" tabindex="48"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709095754.png" alt="" loading="lazy"></figure>
<p>查看文档</p>
<figure data-type="image" tabindex="49"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709095832.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h4 id="813-通过变量插入文档">8.1.3 通过变量插入文档</h4>
<p>Mongo Shell 工具允许我们定义变量。所有的变量类型为 var 类型。也可忽略变量类型。变量中赋值符号后侧需要使用小括号来表示变量中的值。我们可以将变量作为任意插入文档的函数的参数。<br>
语法格式：变量名=({变量值})</p>
<ol>
<li>
<p>通过变量插入单个文档<br>
定义变量<br>
document=({title:'SpringCloud',tags:['Spring Cloud Netflix','Spring Cloud Security','Spring Cloud Consul']})</p>
<figure data-type="image" tabindex="50"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709100123.png" alt="" loading="lazy"></figure>
<p>插入文档</p>
<figure data-type="image" tabindex="51"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709100243.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>通过变量插入多个文档</p>
<p>我们也可以在变量中定义多个文档。<br>
语法结构：变量名=([{},{},{},....])</p>
<figure data-type="image" tabindex="52"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709100333.png" alt="" loading="lazy"></figure>
<p>插入文档</p>
<p>我们现在将多个文档放入到了一个变量中，所以在插入数据时，可直接使用插入单个文档的函数。</p>
<figure data-type="image" tabindex="53"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709103042.png" alt="" loading="lazy"></figure>
<p>查询文档</p>
<figure data-type="image" tabindex="54"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709103054.png" alt="" loading="lazy"></figure>
</li>
</ol>
<h3 id="82-更新文档">8.2 更新文档</h3>
<p>MongoDB 通过update 函数或者save 函数来更新集合中的文档。</p>
<h4 id="821-update-函数">8.2.1  update 函数</h4>
<p>update() 函数用于更新已存在的文档。<br>
语法格式：db.COLLECTION_NAME.update({查询条件},{更新内容},{更新参数(可选)})<br>
将 Spring Data 修改为 SpringData</p>
<p>注：update函数在更新时，取决于所给的更新内容，更新内容是什么样的，就会把文档对象更新成什么样，如果在更新内容中没有包含的内容，则会把这些内容替换掉</p>
<p>没更新前：</p>
<figure data-type="image" tabindex="55"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709103850.png" alt="" loading="lazy"></figure>
<p>更新后：</p>
<figure data-type="image" tabindex="56"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709103256.png" alt="" loading="lazy"></figure>
<h4 id="822-更新操作符">8.2.2 更新操作符</h4>
<ol>
<li>$set 操作符</li>
</ol>
<p>$set 操作符：用来指定一个键并更新键值，若键不存在并创建。<br>
语法格式：db.COLLECTION_NAME.update({查询条件},{更新操作符:{更新内容}})<br>
将 Spring Security 修改为 SpringSecurity。</p>
<figure data-type="image" tabindex="57"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709141029.png" alt="" loading="lazy"></figure>
<p>修改后的结果</p>
<figure data-type="image" tabindex="58"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709141042.png" alt="" loading="lazy"></figure>
<p>使用$set 在title 为 SpringData 的文档中添加一个属性为 num 值为1。</p>
<figure data-type="image" tabindex="59"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709141109.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="60"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709141128.png" alt="" loading="lazy"></figure>
<p>批量更新<br>
在更新文档时，可以使用multi 参数实现批量更新。<br>
添加测试数据</p>
<figure data-type="image" tabindex="61"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709141142.png" alt="" loading="lazy"></figure>
<p>将 title 为dev 的文档的 size 更新为500</p>
<figure data-type="image" tabindex="62"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709141218.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="63"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200709141229.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>$inc 操作符</li>
</ol>
<p>$inc 操作符：可以对文档的某个值为数字型（只能为满足要求的数字）的键进行增减的操作。<br>
将 title 为SpringData 的文档中的num 值递增 1。</p>
<figure data-type="image" tabindex="64"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131417.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="65"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131436.png" alt="" loading="lazy"></figure>
<ol start="3">
<li>$unset 操作符</li>
</ol>
<p>$unset 操作符：主要是用来删除键。<br>
删除 title 为 SpringData 的文档中的num 键。</p>
<figure data-type="image" tabindex="66"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131528.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="67"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131539.png" alt="" loading="lazy"></figure>
<ol start="4">
<li>
<p>$push 操作符</p>
<p>$push 操作符：向文档的某个数组类型的键添加一个数组元素，不过滤重复的数据。添加时键存在，要求键值类型必须是数组；键不存在，则创建数组类型的键。<br>
向 title 为SpringData 的文档中添加一个数组键为tags 值为[“Spirng Data Redis”]</p>
<figure data-type="image" tabindex="68"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131603.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="69"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131615.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>$pop 操作符</p>
<p>$pop 操作符：删除数据元素。<br>
1 表示从数组的尾部删除<br>
删除 title 为 Spring 的文档中tags 数组中的Spring Cloud</p>
<figure data-type="image" tabindex="70"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131637.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="71"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131653.png" alt="" loading="lazy"></figure>
<p>-1 表示从数组的头部删除元素<br>
删除 title 为 Spring 的文档中tags 数组中的SpringMVC</p>
<figure data-type="image" tabindex="72"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131705.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="73"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713131715.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>$pull 操作符</p>
<p>$pull 操作符：从数组中删除满足条件的元素<br>
删除 title 为 Spring 的文档中tags 数组中的SpringBoot</p>
<figure data-type="image" tabindex="74"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713132639.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="75"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713132651.png" alt="" loading="lazy"></figure>
</li>
<li>
<p>$pullAll 操作符</p>
</li>
</ol>
<p>$pullAll 操作符：从数组中删除满足条件的多个元素<br>
删除 title 为 java 的文档中tags 数组中的JavaSE、JavaEE</p>
<figure data-type="image" tabindex="76"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713132729.png" alt="" loading="lazy"></figure>
<p>注：键名tags可以加双引号也可以不加</p>
<p>查看结果</p>
<figure data-type="image" tabindex="77"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713132748.png" alt="" loading="lazy"></figure>
<ol start="8">
<li>$rename</li>
</ol>
<p>$rename 操作符：对键进行重新命名。<br>
将 title 为Java 的文档中的tags 键修改为tag。</p>
<figure data-type="image" tabindex="78"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713132813.png" alt="" loading="lazy"></figure>
<p>注：键名tags可以加双引号也可以不加</p>
<p>查看结果</p>
<figure data-type="image" tabindex="79"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713132823.png" alt="" loading="lazy"></figure>
<h4 id="823-使用save函数更新文档">8.2.3 使用save()函数更新文档</h4>
<p>save() 方法根据ObjectId，通过传入的文档来替换已有文档。<br>
语法格式：save({文档})<br>
更新 title 为 SpringData 的文档，将SpringData 修改为 Spring Data，并去掉 tags</p>
<figure data-type="image" tabindex="80"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713132947.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="81"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713132955.png" alt="" loading="lazy"></figure>
<h3 id="83-删除文档">8.3  删除文档</h3>
<h4 id="831-remove函数">8.3.1 remove()函数</h4>
<p>使用 remove()函数可删除集合中的指定文档。<br>
语法格式：remove({指定删除条件},删除参数(可选参数))<br>
删除 title 为 Spring data 的文档，可使用该文档的ObjectId 作为删除条件</p>
<figure data-type="image" tabindex="82"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133029.png" alt="" loading="lazy"></figure>
<p>如果使用的条件在集合中可以匹配多条数据，那么 remove()函数会删除所有满足条件的数据。我们可以在 remove 函数中给定 justOne，表示只删除第一条，在 remove 函数中给定参数1 即可。<br>
向 dev 集合中插入三条拥有相同 title 的测试数据</p>
<figure data-type="image" tabindex="83"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133058.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="84"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133108.png" alt="" loading="lazy"></figure>
<p>只删除第一条数据</p>
<figure data-type="image" tabindex="85"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133122.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="86"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133132.png" alt="" loading="lazy"></figure>
<p>注意：remove() 方法 并不会真正释放空间。需要继续执行 db.repairDatabase() 来回收磁盘空间。</p>
<figure data-type="image" tabindex="87"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133143.png" alt="" loading="lazy"></figure>
<h4 id="832-deleteone函数">8.3.2 deleteOne()函数</h4>
<p>deleteOne()函数是官方推荐删除文档的方法。该方法只删除满足条件的第一条文档。</p>
<figure data-type="image" tabindex="88"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133521.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="89"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133529.png" alt="" loading="lazy"></figure>
<h4 id="833-deletemany函数">8.3.3 deleteMany()函数</h4>
<p>deleteMany 函数是官方推荐的删除方法。该方法删除满足条件的所有数据。<br>
再次插入两条测试数据</p>
<figure data-type="image" tabindex="90"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133550.png" alt="" loading="lazy"></figure>
<p>查看结果</p>
<figure data-type="image" tabindex="91"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133557.png" alt="" loading="lazy"></figure>
<p>删除所有title 为 dev 的文档</p>
<figure data-type="image" tabindex="92"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133609.png" alt="" loading="lazy"></figure>
<h4 id="834-删除集合中的所有文档">8.3.4 删除集合中的所有文档</h4>
<p>使用 remove 函数删除集合中的所有文档<br>
语法格式：remove({})</p>
<figure data-type="image" tabindex="93"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133635.png" alt="" loading="lazy"></figure>
<p>使用 deleteMany 函数删除所有文档<br>
语法格式：deleteMany({})</p>
<figure data-type="image" tabindex="94"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133646.png" alt="" loading="lazy"></figure>
<h3 id="84-查询文档">8.4 查询文档</h3>
<h4 id="841-find函数">8.4.1 find()函数</h4>
<p>在 MongoDB 中可以使用 find()函数查询文档。<br>
语法格式为：find({查询条件(可选)},{指定投影的键(可选)})<br>
如果未给定参数则表示查询所有数据。<br>
pretty()函数可以使用格式化的方式来显示所有文档。</p>
<p>查询 dev 集合中的所有数据并格式化显示。</p>
<p>db.dev.find().pretty()</p>
<p>查询 title 为DataBase 的文档并格式化显示。</p>
<figure data-type="image" tabindex="95"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133828.png" alt="" loading="lazy"></figure>
<h4 id="842-findone函数">8.4.2 findOne()函数</h4>
<p>indOne()函数只返回满足条件的第一条数据。如果未做投影操作该方法则自带格式化功能。</p>
<p>语法格式：findOne({查询条件(可选)},{投影操作(可选)})</p>
<p>db.dev.findOne()</p>
<p>插入三条测试数据</p>
<figure data-type="image" tabindex="96"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133916.png" alt="" loading="lazy"></figure>
<p>使用 findOne 查询文档，条件为 title 的值为 dev 的文档。</p>
<figure data-type="image" tabindex="97"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133922.png" alt="" loading="lazy"></figure>
<h4 id="843-模糊查询">8.4.3 模糊查询</h4>
<p>在 MongoDB 中可以通过//与^ $实现模糊查询，注意使用模糊查询时查询条件不能放到双引号或单引号中。<br>
查询文档中title 的值含有a 的内容。</p>
<figure data-type="image" tabindex="98"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713133944.png" alt="" loading="lazy"></figure>
<p>使用^表示起始位置。</p>
<p>查询文档中title 的值以S 开头的内容。</p>
<figure data-type="image" tabindex="99"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713134138.png" alt="" loading="lazy"></figure>
<p>使用$表示结尾位置。<br>
查询文档中title 的值以结尾的内容。</p>
<figure data-type="image" tabindex="100"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713134147.png" alt="" loading="lazy"></figure>
<h4 id="844-投影操作">8.4.4 投影操作</h4>
<h5 id="8441-find函数投影操作">8.4.4.1  find()函数投影操作</h5>
<p>在 find 函数中我们可以指定投影键。<br>
语法格式为：find({查询条件},{投影键名:1(显示该列)|0(不显示该列),投影键名:1|0,......})</p>
<figure data-type="image" tabindex="101"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713134640.png" alt="" loading="lazy"></figure>
<p>_id 列默认为显示列。如果不显示_id 可在投影中通过 0 过滤。</p>
<figure data-type="image" tabindex="102"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713134855.png" alt="" loading="lazy"></figure>
<h5 id="8442-findone-函数投影操作">8.4.4.2 findOne 函数投影操作</h5>
<p>在 findOne 函数中我们可以指定投影列。<br>
语法格式为：findOne({查询条件},{投影键名:1(显示该列)|0(不显示该列)})</p>
<figure data-type="image" tabindex="103"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713134921.png" alt="" loading="lazy"></figure>
<h3 id="85-条件操作符">8.5  条件操作符</h3>
<h4 id="851-gt">8.5.1 $gt</h4>
<p>(&gt;) 大于操作符<br>
我们可以使用$gt 操作做大于的条件判断。该操作符可以数字或日期进行判断。<br>
添加测试数据。</p>
<figure data-type="image" tabindex="104"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135029.png" alt="" loading="lazy"></figure>
<p>查询 size 大于300 的文档。</p>
<figure data-type="image" tabindex="105"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135039.png" alt="" loading="lazy"></figure>
<h4 id="852-lt">8.5.2  $lt</h4>
<p>(&lt;) 小于操作符<br>
我们可以使用$lt 操作做小于的条件判断。该操作符可以数字或日期进行判断。<br>
查询 size 小于300 的文档。</p>
<figure data-type="image" tabindex="106"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135059.png" alt="" loading="lazy"></figure>
<h4 id="853-gte">8.5.3 $gte</h4>
<p>(&gt;=)大于或等于操作符<br>
我们可以使用$gte 操作做大于或等于的条件判断。该操作符可以数字或日期进行判断。<br>
查询 size 大于或等于 300 的文档。</p>
<figure data-type="image" tabindex="107"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135224.png" alt="" loading="lazy"></figure>
<h4 id="854-lte">8.5.4 $lte</h4>
<p>(&lt;=)小于或等于操作符<br>
我们可以使用$lte 操作做小于或等于的条件判断。该操作符可以数字或日期进行判断。<br>
查询 size 小于或等于 300 的文档。</p>
<figure data-type="image" tabindex="108"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135248.png" alt="" loading="lazy"></figure>
<h4 id="855-eq">8.5.5 $eq</h4>
<p>(==)等于操作符<br>
我们可以使用$eq 操作做相等的条件判断。<br>
查询 size 等于300 的文档。</p>
<figure data-type="image" tabindex="109"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135308.png" alt="" loading="lazy"></figure>
<h4 id="856-ne">8.5.6 $ne</h4>
<p>(!=)不等操作符<br>
我们可以使用$ne 操作做不等的条件判断。<br>
查询 size 不等于300 的文档。</p>
<figure data-type="image" tabindex="110"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135332.png" alt="" loading="lazy"></figure>
<h4 id="857-and">8.5.7  $and</h4>
<p>我们可以使用<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …。 
语法格式为：find({'>and 操作符来表示多条件间的并且关系。 
语法格式为：find({</span>and:[{条件一},{,条件二},.......]})<br>
插入测试数据</p>
<figure data-type="image" tabindex="111"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135358.png" alt="" loading="lazy"></figure>
<p>如果在查询中给定了多个查询条件，条件之间的关系默认为 and 关系。<br>
查询 size 大于100 并且小于300 的文档。</p>
<figure data-type="image" tabindex="112"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135408.png" alt="" loading="lazy"></figure>
<p>使用$and 指定多条件关系。<br>
查询 size 大于100 并且小于300 的文档。</p>
<figure data-type="image" tabindex="113"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135420.png" alt="" loading="lazy"></figure>
<h4 id="858-or">8.5.8  $or</h4>
<p>我们可以使用<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …。 
语法格式为：find({'>or 操作符来表示多条件间的或者关系。 
语法格式为：find({</span>or:[{条件一},{条件二},.....]})<br>
查询 title 的值为test2 或者size 大于 300 的文档。</p>
<figure data-type="image" tabindex="114"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135439.png" alt="" loading="lazy"></figure>
<h4 id="859-and-与or-联合使用">8.5.9 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><mi>n</mi><mi>d</mi><mi mathvariant="normal">与</mi></mrow><annotation encoding="application/x-tex">and 与</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mord cjk_fallback">与</span></span></span></span>or 联合使用</h4>
<p>查询 title 为 test5 并且 size 等于500，或者size 小于 400 的文档。</p>
<figure data-type="image" tabindex="115"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135507.png" alt="" loading="lazy"></figure>
<h4 id="8510-type-操作符">8.5.10 $type 操作符</h4>
<p>$type 操作符是基于 BSON 类型来检索集合中匹配的数据类型，并返回结果。<br>
插入测试数据</p>
<figure data-type="image" tabindex="116"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135530.png" alt="" loading="lazy"></figure>
<p>查询 title 的值为number 类型。</p>
<figure data-type="image" tabindex="117"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135539.png" alt="" loading="lazy"></figure>
<h3 id="86-limit-函数与-skip-函数">8.6 Limit 函数与 Skip 函数</h3>
<h4 id="861-limit-函数">8.6.1 Limit 函数</h4>
<p>如果需要在MongoDB 中读取指定数量的数据记录，可以使用MongoDB 的 Limit 函数，limit()函数接受一个数字参数，该参数指定从 MongoDB 中读取的记录条数。<br>
语法格式：db.COLLECTION_NAME.find().limit(NUMBER)</p>
<figure data-type="image" tabindex="118"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713135729.png" alt="" loading="lazy"></figure>
<h4 id="862-skip-函数">8.6.2 Skip 函数</h4>
<p>我们除了可以使用 limit()函数来读取指定数量的数据外，还可以使用 skip()函数来跳过指定数量的数据，skip 函数同样接受一个数字参数作为跳过的记录条数。<br>
语法格式：db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER)</p>
<p>我们可以使用 skip 函数与 limit 函数实现 MongoDB 的分页查询，但是官方并不推荐这样做，因为会扫描全部文档然后在返回结果，效率过低。</p>
<h3 id="87-mongodb-排序">8.7  MongoDB 排序</h3>
<p>在 MongoDB 中使用 sort() 函数对查询到的文档进行排序，sort() 函数可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而 -1 是用于降序排列。<br>
语法格式：db.COLLECTION_NAME.find().sort({排序键:1})</p>
<h4 id="871-升序排序">8.7.1 升序排序</h4>
<p>查询 size 的值为number 类型的文档，显示title，size 的内容，并对size 做升序排序。</p>
<figure data-type="image" tabindex="119"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713140440.png" alt="" loading="lazy"></figure>
<h4 id="872-降序排序">8.7.2 降序排序</h4>
<p>查询 size 的值为number 类型的文档，显示title，size 的内容，并对size 做降序排序。</p>
<figure data-type="image" tabindex="120"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713140440.png" alt="" loading="lazy"></figure>
<h4 id="873-对字符串排序">8.7.3 对字符串排序</h4>
<p>对字符串排序的方式采用的是大小写分离排序。</p>
<figure data-type="image" tabindex="121"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713140612.png" alt="" loading="lazy"></figure>
<h3 id="88-mongodb-索引">8.8  MongoDB 索引</h3>
<p>索引通常能够极大的提高查询的效率，如果没有索引，MongoDB 在读取数据时必须扫描集合中的每个文件并选取那些符合查询条件的记录。这种扫描全集合的查询效率是非常低的，特别在处理大量的数据时，查询可以要花费几十秒甚至几分钟，这对系统的性能是非常致命的。索引是特殊的数据结构，索引存储在一个易于遍历读取的数据集合中，索引是对数据库表中一列或多列的值进行排序的一种结构</p>
<h4 id="881-创建索引">8.8.1 创建索引</h4>
<p>在 MongoDB 中会自动为文档中的_Id(文档的主键)键创建索引，与关系型数据的主键索引类似。<br>
我们可以使用createIndex()函数来为其他的键创建索引。在创建索引时需要指定排序规则。1 按照升序规则创建索引，-1 按照降序规则创建索引。<br>
在创建索引时，需要使用具有 dbAdmin 或者 dbAdminAnyDatabase 角色的用户。<br>
语法格式：db.COLLECTION_NAME.createIndex({创建索引的键:排序规则,......},{创建索引的参数(可选参数)})</p>
<p>参数说明</p>
<figure data-type="image" tabindex="122"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713140800.png" alt="" loading="lazy"></figure>
<p>为 dev 集合中的title 键创建索引，并让创建工作在后台运行。</p>
<figure data-type="image" tabindex="123"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713140811.png" alt="" loading="lazy"></figure>
<h4 id="882-查看索引">8.8.2 查看索引</h4>
<h5 id="8821-查看集合索引">8.8.2.1  查看集合索引</h5>
<p>我们可以通过getIndexes()或者getIndexSpecs()函数查看集合中的所有索引信息。<br>
语法格式：db.COLLECTION_NAME.getIndexse()<br>
语法格式：db.COLLECTION_NAME.getIndexSpecs()<br>
使用 getIndexes()函数查看当前 dev 集合中的索引</p>
<figure data-type="image" tabindex="124"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713140925.png" alt="" loading="lazy"></figure>
<p>使用 getIndexSpecs()函数查看当前dev 集合中的索引</p>
<figure data-type="image" tabindex="125"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713140958.png" alt="" loading="lazy"></figure>
<h5 id="8822-查看索引键">8.8.2.2 查看索引键</h5>
<p>我们可以通过使用 getIndexKeys()函数查看集合的索引键。<br>
语法格式：db.COLLECTION_NAME.getIndexKeys();<br>
查看 dev 集合中的索引键</p>
<figure data-type="image" tabindex="126"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713141018.png" alt="" loading="lazy"></figure>
<h5 id="8823-查看索引大小">8.8.2.3 查看索引大小</h5>
<p>我们可以通过totalIndexSize()函数来查看当前集合中索引的大小，单位为字节。<br>
语法格式：db.COLLECTION_NAME.totalIndexSize(<a href="%E5%8F%AF%E9%80%89%E5%8F%82%E6%95%B0">detail</a>)<br>
参数解释：detail 可选参数，传入除 0 或 false 外的任意数据，那么会显示该集合中每个索引的大小及集合中索引的总大小。如果传入 0 或 false 则只显示该集合中所有索引的总大小。默认值为false。</p>
<p>查看 dev 集合中所有索引的总大小。</p>
<figure data-type="image" tabindex="127"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713141048.png" alt="" loading="lazy"></figure>
<p>查看 dev 集合中的每个索引的大小以及总大小</p>
<figure data-type="image" tabindex="128"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713141652.png" alt="" loading="lazy"></figure>
<h4 id="883-修改索引">8.8.3 修改索引</h4>
<p>MongoDB 没有单独的修改索引函数，如果要修改某个索引，需要先删除旧的索引，再创建新的索引。</p>
<h4 id="884-删除索引">8.8.4 删除索引</h4>
<h5 id="8841-删除集合中的指定索引">8.8.4.1  删除集合中的指定索引</h5>
<p>我们可以通过dropIndex()函数来删除指定索引。<br>
语法格式：db.COLLECTION_NAME.dropIndex(&quot;索引名称&quot;)。</p>
<p>删除 title 键的索引</p>
<figure data-type="image" tabindex="129"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142208.png" alt="" loading="lazy"></figure>
<h5 id="8842-删除集合中的全部索引">8.8.4.2 删除集合中的全部索引</h5>
<p>我们可以使用dropIndexes()函数删除集合中的全部索引，_id 键的索引除外。<br>
语法格式：db.COLLECTION_NAME.dropIndexes()</p>
<figure data-type="image" tabindex="130"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142227.png" alt="" loading="lazy"></figure>
<h4 id="885-重建索引">8.8.5 重建索引</h4>
<p>我可以使用reIndex()函数重建索引。重建索引可以减少索引存储空间，减少索引碎片，优化索引查询效率。一般在数据大量变化后，会使用重建索引来提升索引性能。重建索引是删除原索引重新创建的过程，不建议反复使用。<br>
语法格式：db.COLLECTION_NAME.reIndex()</p>
<figure data-type="image" tabindex="131"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142255.png" alt="" loading="lazy"></figure>
<h4 id="886-mongodb-中的索引类型">8.8.6 MongoDB 中的索引类型</h4>
<p>在 MongoDB 中支持多种类型的索引，包括单字段索引、复合索引、多 key 索引、文本索引等，每种类型的索引有不同的使用场合。</p>
<h5 id="8861-单字段索引single-field-index">8.8.6.1 单字段索引（Single Field Index）</h5>
<p>所谓单字段索引是指在索引中只包含了一个键。查询时，可加速对该字段的各种查询请求，是最常见的索引形式。MongoDB 默认创建的_Id 索引也是这种类型。我们可以使用createIndexes({索引键：排序规则})函数来创建单字段索引。</p>
<p>语法格式：db.COLLECTION_NAME.createIndexes({索引键名:排序规则})<br>
为 dev 集合中的title 键创建单字段索引</p>
<figure data-type="image" tabindex="132"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142349.png" alt="" loading="lazy"></figure>
<h5 id="8862-交叉索引">8.8.6.2 交叉索引</h5>
<p>所谓交叉索引就是为一个集合的多个字段分别建立索引，在查询的时候通过多个字段作为查询条件，这种情况称为交叉索引。<br>
在查询文档时，在查询条件中包含一个交叉索引键或者在一次查询中使用多个交叉索引键作为查询条件都会触发交叉索引。<br>
为 dev 集合中的size 键创建交叉索引。</p>
<figure data-type="image" tabindex="133"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142439.png" alt="" loading="lazy"></figure>
<h5 id="8863-复合索引compound-index">8.8.6.3 复合索引（Compound Index）</h5>
<p>复合索引是Single Field Index 的升级版本，它针对多个字段联合创建索引，先按第一个字段排序，第一个字段相同的文档按第二个字段排序，依次类推。<br>
语法格式：db.COLLECTION_NAME.createIndex({索引键名:排序规则, 索引键名:排序规则,......});<br>
复合索引能满足的查询场景比单字段索引更丰富，不光能满足多个字段组合起来的查询，也能满足所以能匹配符合索引前缀的查询。</p>
<p>删除 dev 中的交叉索引。</p>
<figure data-type="image" tabindex="134"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142531.png" alt="" loading="lazy"></figure>
<p>创建 title 与 size 的符合索引</p>
<figure data-type="image" tabindex="135"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142553.png" alt="" loading="lazy"></figure>
<p>查看索引</p>
<figure data-type="image" tabindex="136"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142601.png" alt="" loading="lazy"></figure>
<h5 id="8864-多-key-索引-multikey-index">8.8.6.4 多 key 索引 （Multikey Index）</h5>
<p>当索引的字段为数组时，创建出的索引称为多 key 索引，多 key 索引会为数组的每个元素建立一条索引。<br>
语法格式：db.COLLECTION_NAME.createIndex({数组键名:排序规则});</p>
<p>为 dev 集合中tags 键创建多Key 索引</p>
<figure data-type="image" tabindex="137"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142627.png" alt="" loading="lazy"></figure>
<p>查看索引</p>
<figure data-type="image" tabindex="138"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142644.png" alt="" loading="lazy"></figure>
<h4 id="887-索引额外属性">8.8.7 索引额外属性</h4>
<p>MongoDB 除了支持多种不同类型的索引，还能对索引定制一些特殊的属性。</p>
<h5 id="8871-唯一索引-unique-index">8.8.7.1 唯一索引 (unique index)</h5>
<p>唯一索引会保证索引对应的键不会出现相同的值，比如_id 索引就是唯一索引<br>
语法格式：db.COLLECTION_NAME.createIndex({索引键名:排序规则},{unique:true})<br>
如果唯一索引所在字段有重复数据写入时，抛出异常。</p>
<p>删除 dev 集合中的索引。为 dev 集合中的title 键建立唯一索引</p>
<figure data-type="image" tabindex="139"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142725.png" alt="" loading="lazy"></figure>
<p>插入 title 相同的值测试唯一索引</p>
<figure data-type="image" tabindex="140"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142734.png" alt="" loading="lazy"></figure>
<h5 id="8872-部分索引-partial-index">8.8.7.2 部分索引 (partial index):</h5>
<p>部分索引是只针对符合某个特定条件的文档建立索引，3.2 版本才支持该特性。<br>
MongoDB 部分索引只为那些在一个集合中，满足指定的筛选条件的文档创建索引。由于部分索引是一个集合文档的一个子集，因此部分索引具有较低的存储需求，并降低了索引创建和维护的性能成本。部分索引通过指定过滤条件来创建，可以为 MongoDB 支持的所有索引类型使用部分索引。<br>
简单点说：部分索引就是带有过滤条件的索引，即索引只存在与某些文档之上<br>
语 法 格 式 ： db.COLLECTION_NAME.createIndex({ 索 引 键 名 : 排 序 规<br>
则},{partialFilterExpression:{键名:{匹配条件:条件值}}})</p>
<p>为 dev 集合中的size 键创建部分索引。条件为大于300</p>
<figure data-type="image" tabindex="141"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142812.png" alt="" loading="lazy"></figure>
<p>查看索引</p>
<figure data-type="image" tabindex="142"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142822.png" alt="" loading="lazy"></figure>
<p>注意：部分索引只为集合中那些满足指定的筛选条件的文档创建索引。如果你指定的partialFilterExpression 和唯一约束、那么唯一性约束只适用于满足筛选条件的文档。具有唯一约束的部分索引不会阻止不符合唯一约束且不符合过滤条件的文档的插入。</p>
<h5 id="8873-稀疏索引sparse-index">8.8.7.3 稀疏索引(sparse index)</h5>
<p>稀疏索引仅包含具有索引字段的文档的条目，即使索引字段包含空值也是如此。索引会跳过缺少索引字段的任何文档。索引是“稀疏的”，因为它不包含集合的所有文档。相反，非稀疏索引包含集合中的所有文档，为那些不包含索引字段的文档存储空值。<br>
语法格式：db.COLLECTION_NAME.createIndex({索引键名:排序规则},{sparse:true})</p>
<p>为 dev 集合中的tag 键创建稀疏索引</p>
<figure data-type="image" tabindex="143"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713142859.png" alt="" loading="lazy"></figure>
<p>查看索引</p>
<figure data-type="image" tabindex="144"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713143051.png" alt="" loading="lazy"></figure>
<p>注意：从MongoDB 3.2 开始，MongoDB 提供了创建部分索引的选项 。部分索引提供了稀疏索引功能的超集。如果您使用的是 MongoDB 3.2 或更高版本，则部分索引应优先于稀疏索引。</p>
<h4 id="888-覆盖索引查询">8.8.8 覆盖索引查询</h4>
<p>官方的MongoDB 的文档中说明，覆盖查询是以下的查询：</p>
<ol>
<li>
<p>所有的查询字段是索引的一部分</p>
</li>
<li>
<p>所有的查询返回字段在同一个索引中</p>
</li>
</ol>
<p>由于所有出现在查询中的字段是索引的一部分， MongoDB 无需在整个数据文档中检<br>
索匹配查询条件和返回使用相同索引的查询结果。<br>
因为索引存在于RAM 中，从索引中获取数据比通过扫描文档读取数据要快得多。<br>
如有如下索引：<br>
db.stu.createIndex({title:1,:size:1})<br>
那么执行如下查询时，该索引会覆盖查询：<br>
db.stu.find({title:&quot;dev&quot;},{size:1,_id:0})<br>
也就是说，对于上述查询，MongoDB 的不会去数据库文件中查找。相反，它会从索引中提取数据，这是非常快速的数据查询。<br>
由于我们的索引中不包括 _id 字段，_id 在查询中会默认返回，我们可以在 MongoDB的查询结果集中排除它。</p>
<h4 id="889-查询计划">8.8.9 查询计划</h4>
<p>在 MongoDB 中通过 explain()函数启动执行计划，我们可以使用查询计划分析索引的使用情况，可通过查看详细的查询计划来决定如何优化。<br>
语法结构：db.COLLECTION_NAME.find().explain()<br>
删除 dev 集合中的所有索引。通过查询计划查看查询size 键的值大于200 的查询结果</p>
<figure data-type="image" tabindex="145"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713143244.png" alt="" loading="lazy"></figure>
<p>为 size 键创建单字段索引。再次查看查询结果。<br>
创建索引</p>
<figure data-type="image" tabindex="146"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713143257.png" alt="" loading="lazy"></figure>
<p>查看执行结果</p>
<figure data-type="image" tabindex="147"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713143315.png" alt="" loading="lazy"></figure>
<h4 id="8810-使用索引注意事项">8.8.10 使用索引注意事项</h4>
<p>既然索引可以加快查询速度，那么是不是只要是查询语句，就创建索引呢？答案是否定的。因为索引虽然加快了查询速度，但索引也是有代价的：索引文件本身要消耗存储空间，同时索引会加重插入、删除和修改记录时的负担，另外，数据库在运行时也要消耗资源维护索引，因此索引并不是越多越好。<br>
那么什么情况不建议创建索引呢？例如一两千条甚至只有几百条记录的表，没必要建索引，让查询做全集合扫描就好了。至于多少条记录才算多？我个人建议以2000 作为分界线，记录数不超过 2000 可以考虑不建索引，超过 2000 条可以酌情考虑创建索引。</p>
<ol>
<li>
<p><strong>建立合适的索引</strong><br>
为每一个常用查询结构建立合适的索引。<br>
复合索引是创建的索引由多个字段组成，例如：<br>
db.test.createIndex({&quot;username&quot;:1, &quot;age&quot;:-1})<br>
交叉索引是每个字段单独建立索引，但是在查询的时候组合查找，例如：<br>
db.test.createIndex({&quot;username&quot;:1})<br>
db.test.createIndex({&quot;age&quot;:-1})<br>
db.test.find({&quot;username&quot;:&quot;kaka&quot;, &quot;age&quot;: 30})<br>
交叉索引的查询效率较低，在使用时，当查询使用到多个字段的时候，尽量使用复合索引，而不是交叉索引。</p>
</li>
<li>
<p><strong>复合索引的字段排列顺序</strong><br>
当我们的组合索引内容包含匹配条件以及范围条件的时候，比如包含用户名(匹配条件)以及年龄(范围条件)，那么匹配条件应该放在范围条件之前<br>
比如需要查询：<br>
db.test.find({&quot;username&quot;:&quot;kaka&quot;, &quot;age&quot;: {$gt: 30}})<br>
那么复合索引应该这样创建：<br>
db.test.ensureIndex({&quot;username&quot;:1, &quot;age&quot;:-1})</p>
</li>
<li>
<p>**查询时尽可能仅查询出索引字段 **<br>
有时候仅需要查询少部分的字段内容，而且这部分内容刚好都建立了索引，那么尽可能只查询出这些索引内容，需要用到的字段显式声明（_id 字段需要显式忽略！）。因为这些数据需要把原始数据文档从磁盘读入内存，造成一定的损耗。<br>
比如说我们的表有三个字段：<br>
name, age, mobile<br>
索引是这样建立的：<br>
db.stu.createIndex({&quot;name&quot;:1,&quot;age&quot;:-1})<br>
我们仅需要查到某个用户的年龄(age)，那可以这样写：<br>
db.stu.find({&quot;name&quot;:&quot;kaka&quot;}, {&quot;_id&quot;:0, &quot;age&quot;:1})<br>
注意到上面的语句，我们除了”age”:1 外，还加了”_id”:0，因为默认情况下，_id都是会被一并查询出来的，当不需要_id 的时候记得直接忽略，避免不必要的磁盘操作。</p>
</li>
<li>
<p><strong>对现有的数据大表建立索引的时候，采用后台运行方式</strong></p>
<p>在对数据集合建立索引的过程中，数据库会停止该集合的所有读写操作，因此如果建立索引的数据量大，建立过程慢的情况下，建议采用后台运行的方式，避免影响正常业务流程。<br>
db.stu.ensureIndex({&quot;name&quot;:1,&quot;age&quot;:-1},{&quot;background&quot;:true})</p>
</li>
</ol>
<h4 id="8811-索引限制">8.8.11 索引限制</h4>
<ol>
<li>
<p><strong>额外开销</strong><br>
每个索引占据一定的存储空间，在进行插入，更新和删除操作时也需要对索引进行操作。<br>
所以，如果你很少对集合进行读取操作，建议不使用索引。</p>
</li>
<li>
<p><strong>内存使用</strong><br>
由于索引是存储在内存(RAM)中,你应该确保该索引的大小不超过内存的限制。<br>
如果索引的大小大于内存的限制，MongoDB 会删除一些索引，这将导致性能下降。</p>
</li>
<li>
<p><strong>查询限制</strong><br>
索引不能被以下的查询使用：<br>
正则表达式（最左匹配除外）及非操作符，如 $nin, $not, 等。<br>
算术运算符，如 $mod, 等。<br>
所以，检测你的语句是否使用索引是一个好的习惯，可以用 explain 来查看。</p>
</li>
<li>
<p><strong>最大范围</strong><br>
集合中索引不能超过 64 个<br>
索引名的长度不能超过 128 个字符<br>
一个复合索引最多可以有31 个字段</p>
</li>
</ol>
<h4 id="8812-正则查询">8.8.12 正则查询</h4>
<p>MongoDB 中查询条件也可以使用正则表达式作为匹配约束。<br>
语法格式：db.COLLECTION_NAME.find({字段名:正则表达式}); 或<br>
db.COLLECTION_NAME.find({字段名:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>e</mi><mi>g</mi><mi>e</mi><mi>x</mi><mo>:</mo><mi mathvariant="normal">正</mi><mi mathvariant="normal">则</mi><mi mathvariant="normal">表</mi><mi mathvariant="normal">达</mi><mi mathvariant="normal">式</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">regex:正则表达式,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.3em;vertical-align:-0.19444em;"></span><span class="mord cjk_fallback">正</span><span class="mord cjk_fallback">则</span><span class="mord cjk_fallback">表</span><span class="mord cjk_fallback">达</span><span class="mord cjk_fallback">式</span><span class="mpunct">,</span></span></span></span>options:正则选项}});</p>
<p>正则表达式格式：/xxx/<br>
正则选项：<br>
i - 不区分大小写以匹配大小写的情况。<br>
m - 多行查找，如果内容里面不存在换行符号（例如 \n）或者条件上没有（start/end），该选项没有任何效果<br>
x - 设置x 选项后，正则表达式中的非转义的空白字符将被忽略。需要<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>e</mi><mi>g</mi><mi>e</mi><mi>x</mi><mi mathvariant="normal">与</mi></mrow><annotation encoding="application/x-tex">regex 与</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord cjk_fallback">与</span></span></span></span>options 语法<br>
s - 允许点字符（即.）匹配包括换行符在内的所有字符。需要<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>e</mi><mi>g</mi><mi>e</mi><mi>x</mi><mi mathvariant="normal">与</mi></mrow><annotation encoding="application/x-tex">regex 与</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mord cjk_fallback">与</span></span></span></span>options 语法<br>
i，m，x，s 可以组合使用。</p>
<p>查询 dev 集合中 title 字段以'S'开头的数据<br>
db.dev.find({title:/^S/})</p>
<figure data-type="image" tabindex="148"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713143941.png" alt="" loading="lazy"></figure>
<p>db.dev.find({title:{$regex:/^S/}})</p>
<figure data-type="image" tabindex="149"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144005.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中 title 字段以'g'结尾的数据<br>
db.stu.find({title:/g$/})</p>
<figure data-type="image" tabindex="150"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144019.png" alt="" loading="lazy"></figure>
<p>db.stu.find({title:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>e</mi><mi>g</mi><mi>e</mi><mi>x</mi><mo>:</mo><mi mathvariant="normal">/</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">regex:/g</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">/</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span></span></span></span>/}});</p>
<figure data-type="image" tabindex="151"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144030.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中dev 字段中包含'ing'的数据<br>
db.stu.find({title:/ing/});</p>
<figure data-type="image" tabindex="152"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144121.png" alt="" loading="lazy"></figure>
<p>db.stu.find({title:{$regex:/ing/}});</p>
<figure data-type="image" tabindex="153"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144133.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中 title 字段以'L'开头的数据，且忽略大小写<br>
db.dev.find({title:/^S/i});</p>
<figure data-type="image" tabindex="154"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144143.png" alt="" loading="lazy"></figure>
<p>db.dev.find({title:{$regex:/^S/i}});</p>
<figure data-type="image" tabindex="155"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144152.png" alt="" loading="lazy"></figure>
<p>db.dev.find({title:{$regex:/^S/, $options:&quot;i&quot;}});</p>
<figure data-type="image" tabindex="156"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144203.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中 title 字段已'S'开头、'g'结尾的数据<br>
db.dev.find({title:/^S.*g$/});</p>
<figure data-type="image" tabindex="157"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144212.png" alt="" loading="lazy"></figure>
<p>db.dev.find({title:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi><mi>e</mi><mi>g</mi><mi>e</mi><mi>x</mi><mo>:</mo><msup><mi mathvariant="normal">/</mi><mi>z</mi></msup><mi mathvariant="normal">.</mi><mo>∗</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">regex:/^z.*n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.04398em;">z</span></span></span></span></span></span></span></span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">n</span></span></span></span>/}});</p>
<figure data-type="image" tabindex="158"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713144658.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中 title 字段以'S'或't'开头的数据<br>
db.dev.find({title:{$in:[/^S/, /^t/]}});</p>
<figure data-type="image" tabindex="159"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713145555.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中 title 字段不以'S'开头的数据<br>
db.dev.find({title:{$not:/^S/}});</p>
<p>查询 dev 集合中 title 字段不以'S'或't'开头的数据<br>
db.stu.find({title:{$nin:[/^S/, /^t/]}});</p>
<h3 id="89-mongodb-聚合查询">8.9 MongoDB 聚合查询</h3>
<p>在 MongoDB 中我们可以通过 aggregate()函数来完成一些聚合查询，aggregate()函数主要用于处理诸如统计,平均值,求和等，并返回计算后的数据结果。<br>
语法格式：<br>
db.COLLECTION_NAME.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: group:{_id:&quot;'>group:{_id:&quot;</span>分组键名&quot;,&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …....,别名:{聚合运算:&quot;'>分组键名&quot;,.....,别名:{聚合运算:&quot;</span>运算列&quot;}}},{条件筛选:{键名:{运算条件:运算值}}}])<br>
常见的mongo 的聚合操作和 mysql 的查询做类比</p>
<figure data-type="image" tabindex="160"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713145720.png" alt="" loading="lazy"></figure>
<h4 id="891-求和-sum">8.9.1 求和 - $sum</h4>
<p>查询 dev 集合中一共有多少个文档。</p>
<p>相当于sql 语句：SELECT count(*) AS count FROM dev<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …id:null,count:{'>group:{_id:null,count:{</span>sum:1}}}])</p>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi mathvariant="normal">：</mi><mi mathvariant="normal">分</mi><mi mathvariant="normal">组</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">代</mi><mi mathvariant="normal">表</mi><mi mathvariant="normal">聚</mi><mi mathvariant="normal">合</mi><mi mathvariant="normal">的</mi><mi mathvariant="normal">分</mi><mi mathvariant="normal">组</mi><mi mathvariant="normal">条</mi><msub><mi mathvariant="normal">件</mi><mi>i</mi></msub><mi>d</mi><mi mathvariant="normal">：</mi><mi mathvariant="normal">分</mi><mi mathvariant="normal">组</mi><mi mathvariant="normal">的</mi><mi mathvariant="normal">字</mi><mi mathvariant="normal">段</mi><mi mathvariant="normal">。</mi><mi mathvariant="normal">相</mi><mi mathvariant="normal">当</mi><mi mathvariant="normal">于</mi><mi>S</mi><mi>Q</mi><mi>L</mi><mi mathvariant="normal">分</mi><mi mathvariant="normal">组</mi><mi mathvariant="normal">语</mi><mi mathvariant="normal">法</mi><mi>g</mi><mi>r</mi><mi>o</mi><mi>u</mi><mi>p</mi><mi>b</mi><mi>y</mi><mi>c</mi><mi>o</mi><mi>l</mi><mi>u</mi><mi>m</mi><msub><mi>n</mi><mi>n</mi></msub><mi>a</mi><mi>m</mi><mi>e</mi><mi mathvariant="normal">中</mi><mi mathvariant="normal">的</mi><mi>c</mi><mi>o</mi><mi>l</mi><mi>u</mi><mi>m</mi><msub><mi>n</mi><mi>n</mi></msub><mi>a</mi><mi>m</mi><mi>e</mi><mi mathvariant="normal">部</mi><mi mathvariant="normal">分</mi><mi mathvariant="normal">。</mi><mi mathvariant="normal">如</mi><mi mathvariant="normal">果</mi><mi mathvariant="normal">根</mi><mi mathvariant="normal">据</mi><mi mathvariant="normal">某</mi><mi mathvariant="normal">字</mi><mi mathvariant="normal">段</mi><mi mathvariant="normal">的</mi><mi mathvariant="normal">值</mi><mi mathvariant="normal">分</mi><mi mathvariant="normal">组</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">则</mi><mi mathvariant="normal">定</mi><mi mathvariant="normal">义</mi><msub><mi mathvariant="normal">为</mi><mi>i</mi></msub><mi>d</mi><msup><mo>:</mo><mo mathvariant="normal">′</mo></msup></mrow><annotation encoding="application/x-tex">group：分组，代表聚合的分组条件 
_id：分组的字段。相当于SQL 分组语法group by column_name 中的 column_name 部分。
如果根据某字段的值分组，则定义为_id:&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.946332em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord mathdefault">p</span><span class="mord cjk_fallback">：</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">组</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">代</span><span class="mord cjk_fallback">表</span><span class="mord cjk_fallback">聚</span><span class="mord cjk_fallback">合</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">组</span><span class="mord cjk_fallback">条</span><span class="mord"><span class="mord cjk_fallback">件</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord cjk_fallback">：</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">组</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">字</span><span class="mord cjk_fallback">段</span><span class="mord cjk_fallback">。</span><span class="mord cjk_fallback">相</span><span class="mord cjk_fallback">当</span><span class="mord cjk_fallback">于</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">Q</span><span class="mord mathdefault">L</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">组</span><span class="mord cjk_fallback">语</span><span class="mord cjk_fallback">法</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord mathdefault">p</span><span class="mord mathdefault">b</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">a</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord cjk_fallback">中</span><span class="mord cjk_fallback">的</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">a</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord cjk_fallback">部</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">。</span><span class="mord cjk_fallback">如</span><span class="mord cjk_fallback">果</span><span class="mord cjk_fallback">根</span><span class="mord cjk_fallback">据</span><span class="mord cjk_fallback">某</span><span class="mord cjk_fallback">字</span><span class="mord cjk_fallback">段</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">值</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">组</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">则</span><span class="mord cjk_fallback">定</span><span class="mord cjk_fallback">义</span><span class="mord"><span class="mord cjk_fallback">为</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel"><span class="mrel">:</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span>字段名'。所以此案例中的 null 代表一个固定的字面值'null'。<br>
count：返回结果字段名。可以自定义，类似SQL 中的字段别名。<br>
$sum：求和表达式。相当于 SQL 中的 sum()。<br>
1：累加值。</p>
<figure data-type="image" tabindex="161"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713145816.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中的所有 size 键中的值的总和。<br>
相当于sql 语句：SELECT sum(size) AS totalSize FROM dev<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …ull,totalSize:{'>group:{_id:null,totalSize:{</span>sum:&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 6: size&quot;}̲}}]) 
&quot;'>size&quot;}}}]) 
&quot;</span>size&quot;：代表文档中的 szie 字段的值。</p>
<figure data-type="image" tabindex="162"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713145837.png" alt="" loading="lazy"></figure>
<p>对每一个title 进行分组并计算每组中的 size 的总和<br>
相当于sql 语句：SELECT title AS _id , sum(size) AS totalSize FROM dev GROUP BY title db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: group:{_id:&quot;'>group:{_id:&quot;</span>title&quot;,totalSize:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>u</mi><mi>m</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">sum:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>size&quot;}}}])</p>
<figure data-type="image" tabindex="163"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713145912.png" alt="" loading="lazy"></figure>
<h4 id="892-条件筛选-match">8.9.2 条件筛选 - $match</h4>
<p>查询 dev 集合有多少文档的 size 大于200。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: match:{size:{'>match:{size:{</span>gt:200}}},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …ull,totalSize:{'>group:{_id:null,totalSize:{</span>sum:1}}}])<br>
相当于SQL 语句：SELECT count(*) FROM dev WHERE size &gt; 200<br>
$match：匹配条件，相当于 SQL 中的 where 子句，代表聚合之前进行条件筛选。</p>
<figure data-type="image" tabindex="164"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713145938.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合，根据 title 分组计算出每组的 size 的总和，并过滤掉总和小于等于 200的文档。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: group:{_id:&quot;'>group:{_id:&quot;</span>title&quot;,totalSize:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>u</mi><mi>m</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">sum:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>size&quot;}}},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …ch:{totalSize:{'>match:{totalSize:{</span>gt:200}}}])<br>
相当于 SQL 语句：SELECT sum(size) AS totalSize FROM dev GROUP BY title HAVING totalSize &gt; 200</p>
<figure data-type="image" tabindex="165"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200713150011.png" alt="" loading="lazy"></figure>
<h4 id="893-最大值-max">8.9.3 最大值 - $max</h4>
<p>查询 dev 集合中 size 最大的文档。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …:null,maxSize:{'>group:{_id:null,maxSize:{</span>max:&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 6: size&quot;}̲}}]) 
'>size&quot;}}}]) 
</span>max:&quot;$size&quot;：计算 size 键中的最大值。<br>
相当于SQL 语句：SELECT max(size) FROM dev</p>
<figure data-type="image" tabindex="166"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715021541.png" alt="" loading="lazy"></figure>
<h4 id="894-最小值-min">8.9.4 最小值 - $min</h4>
<p>查询 dev 集合中 size 最小的文档。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …:null,minSize:{'>group:{_id:null,minSize:{</span>min:&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 6: size&quot;}̲}}]) 
'>size&quot;}}}]) 
</span>min:&quot;$size&quot;：计算 size 键中的最小值。<br>
相当于SQL 语句：SELECT min(size) FROM dev</p>
<figure data-type="image" tabindex="167"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715021605.png" alt="" loading="lazy"></figure>
<h4 id="895-平均值-avg">8.9.5  平均值 - $avg</h4>
<p>查询 dev 集合中 size 的平均值<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …:null,sizeAvg:{'>group:{_id:null,sizeAvg:{</span>avg:&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 6: size&quot;}̲}}]) 
'>size&quot;}}}]) 
</span>avg:&quot;$size&quot;：计算 size 键的平均值。<br>
相当于SQL 语句：SELECT avg(size) FROM dev</p>
<figure data-type="image" tabindex="168"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715021626.png" alt="" loading="lazy"></figure>
<h4 id="896-统计结果返回数组-push">8.9.6 统计结果返回数组 - $push</h4>
<p>查询 dev 集合，按照 size 分组并返回他们的title，如果size 相同则使用数组返回他们的title。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: group:{_id:&quot;'>group:{_id:&quot;</span>size&quot;,title:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>u</mi><mi>s</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">push:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault">u</span><span class="mord mathdefault">s</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>title&quot;}}}])<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>u</mi><mi>s</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">push:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault">u</span><span class="mord mathdefault">s</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>title&quot;：如果 size 相同则使用数组返回他们不同的title</p>
<h4 id="897-数组字段拆分-unwind">8.9.7 数组字段拆分 - $unwind</h4>
<p>查询 dev 集合，将数组中的内容拆分显示。<br>
db.dev.aggregate([{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi><mi>n</mi><mi>w</mi><mi>i</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">unwind:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>tags&quot;}])<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi><mi>n</mi><mi>w</mi><mi>i</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">unwind:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>tags&quot;：对数组中的元素进行拆分显示。</p>
<h4 id="898-管道操作">8.9.8 管道操作</h4>
<p>什么是管道操作：<br>
管道在Unix 和Linux 中一般用于将当前命令的输出结果作为下一个命令的参数。<br>
MongoDB 的聚合管道将 MongoDB 文档在一个管道处理完毕后将结果传递给下一个管道处理。管道操作是可以重复的。<br>
管道操作符是按照书写的顺序依次执行的，每个操作符都会接受一连串的文档，对这些文档做一些类型转换，最后将转换后的文档作为结果传递给下一个操作符（对于最后一个管道操作符，是将结果返回给客户端），称为流式工作方式。<br>
管道操作符：<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi mathvariant="normal">、</mi></mrow><annotation encoding="application/x-tex">match、</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">c</span><span class="mord mathdefault">h</span><span class="mord cjk_fallback">、</span></span></span></span>group、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>o</mi><mi>r</mi><mi>t</mi><mi mathvariant="normal">、</mi></mrow><annotation encoding="application/x-tex">sort、</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">t</span><span class="mord cjk_fallback">、</span></span></span></span>limit、<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>k</mi><mi>i</mi><mi>p</mi><mi mathvariant="normal">、</mi></mrow><annotation encoding="application/x-tex">skip、</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mord mathdefault">i</span><span class="mord mathdefault">p</span><span class="mord cjk_fallback">、</span></span></span></span>unwind<br>
管道操作符，只能用于计算当前聚合管道的文档，不能处理其它的文档。</p>
<h5 id="8981-project-聚合投影约束">8.9.8.1 $project-聚合投影约束</h5>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>r</mi><mi>o</mi><mi>j</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi mathvariant="normal">操</mi><mi mathvariant="normal">作</mi><mi mathvariant="normal">符</mi><mi mathvariant="normal">：</mi><mi mathvariant="normal">我</mi><mi mathvariant="normal">们</mi><mi mathvariant="normal">可</mi><mi mathvariant="normal">以</mi><mi mathvariant="normal">使</mi><mi mathvariant="normal">用</mi></mrow><annotation encoding="application/x-tex">project 操作符：我们可以使用</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord cjk_fallback">操</span><span class="mord cjk_fallback">作</span><span class="mord cjk_fallback">符</span><span class="mord cjk_fallback">：</span><span class="mord cjk_fallback">我</span><span class="mord cjk_fallback">们</span><span class="mord cjk_fallback">可</span><span class="mord cjk_fallback">以</span><span class="mord cjk_fallback">使</span><span class="mord cjk_fallback">用</span></span></span></span>project 操作符做聚合投影操作。<br>
查询 dev 集合，将数组中的内容拆分显示，并只显示 title 键与 tags 键的值。<br>
db.dev.aggregate([{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi><mi>n</mi><mi>w</mi><mi>i</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">unwind:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>tags&quot;},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …t:{_id:0,tags:&quot;'>project:{_id:0,tags:&quot;</span>tags&quot;,title:&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 7: title&quot;}̲}]) 
tags:&quot;'>title&quot;}}]) 
tags:&quot;</span>tags&quot;:显示tags 的值，字段名为tags。<br>
title:&quot;$title&quot;:显示title 的值，字段名为title。</p>
<p>查询 dev 集合，将数组中的内容拆分显示。要求只显示 title 键与 tags 键的值并将 title键修改为Title。<br>
db.dev.aggregate([{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi><mi>n</mi><mi>w</mi><mi>i</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">unwind:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>tags&quot;},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …t:{_id:0,tags:&quot;'>project:{_id:0,tags:&quot;</span>tags&quot;,Title:&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 7: title&quot;}̲}]) 
Title:&quot;'>title&quot;}}]) 
Title:&quot;</span>title&quot;:显示 title 的值，字段名为Title。</p>
<h5 id="8982-project-字符串处理">8.9.8.2  $project-字符串处理</h5>
<p>在<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …ev.aggregate([{'>project 中我们可以通过 MongoDB 的字符串操作符对投影的内容做字符串处理。 
查询 dev 集合，将数组中的内容拆分显示。将 title 中的值换为小写并命名为New_Title，将tags 的值转换为大写并命名为 New_Tags。 
db.dev.aggregate([{</span>unwind:&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 6: tags&quot;}̲,{'>tags&quot;},{</span>project:{_id:0,New_Title:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>o</mi><mi>L</mi><mi>o</mi><mi>w</mi><mi>e</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">toLower:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>title&quot;},New_tags:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>o</mi><mi>U</mi><mi>p</mi><mi>p</mi><mi>e</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">toUpper:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault">p</span><span class="mord mathdefault">p</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>tags&quot;}}}])<br>
New_Title:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>o</mi><mi>L</mi><mi>o</mi><mi>w</mi><mi>e</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">toLower:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>title&quot;}:将 title 的值转换为小写，显示字段名为New_Title。<br>
New_tags:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>o</mi><mi>U</mi><mi>p</mi><mi>p</mi><mi>e</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">toUpper:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10903em;">U</span><span class="mord mathdefault">p</span><span class="mord mathdefault">p</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>tags&quot;}:将 tags 的值转换为大写，显示字段名为New_Tags。</p>
<p>查询 dev 集合，将数组中的内容拆分显示。将 title 字段和 tags 字段的值拼接为一个完整字符串并在Title_Tags 字段中显示。<br>
db.dev.aggregate([{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi><mi>n</mi><mi>w</mi><mi>i</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">unwind:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>tags&quot;},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …:0,Title_Tags:{'>project:{_id:0,Title_Tags:{</span>concat:[&quot;<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>t</mi><mi>i</mi><mi>t</mi><mi>l</mi><mi>e</mi><mi mathvariant="normal">&quot;</mi><mo separator="true">,</mo><mi mathvariant="normal">&quot;</mi><mo>−</mo><mi mathvariant="normal">&quot;</mi><mo separator="true">,</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">title&quot;,&quot;-&quot;,&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">e</span><span class="mord">&quot;</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">&quot;</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord">&quot;</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">&quot;</span></span></span></span>tags&quot;]}}}])<br>
Title_Tags:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo>:</mo><mo>[</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">concat:[&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">&quot;</span></span></span></span>title&quot;,&quot;-&quot;,&quot;$tags&quot;]}:将字段 title 与字符串'-'和字段 tags 的值拼接为新的字符串，并显示字段名为Title_Tags</p>
<p>查询 dev 集合，将数组中的内容拆分显示。只显示 title 字段的前 3 个字符，并命名为Title_Prefix<br>
db.dev.aggregate([{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi><mi>n</mi><mi>w</mi><mi>i</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">unwind:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">u</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>tags&quot;},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …,Title_Prefix:{'>project:{_id:0,Title_Prefix:{</span>substr:[&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 12: title&quot;,0,3]}̲}}]) 
Title_Pre…'>title&quot;,0,3]}}}]) 
Title_Prefix:{</span>substr:[&quot;$title&quot;,0,3]}:将title 的值从0 开始截取截3 位，并命名为Title_Prefix</p>
<figure data-type="image" tabindex="169"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022052.png" alt="" loading="lazy"></figure>
<p>我们可以看到对于汉字部分并未截取三位，原因是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>u</mi><mi>b</mi><mi>s</mi><mi>t</mi><mi>r</mi><mi mathvariant="normal">只</mi><mi mathvariant="normal">能</mi><mi mathvariant="normal">匹</mi><mi mathvariant="normal">配</mi><mi>A</mi><mi>S</mi><mi>C</mi><mi>I</mi><mi>I</mi><mi mathvariant="normal">的</mi><mi mathvariant="normal">数</mi><mi mathvariant="normal">据</mi><mi mathvariant="normal">，</mi><mi mathvariant="normal">对</mi><mi mathvariant="normal">于</mi><mi mathvariant="normal">中</mi><mi mathvariant="normal">文</mi><mi mathvariant="normal">要</mi><mi mathvariant="normal">使</mi><mi mathvariant="normal">用</mi></mrow><annotation encoding="application/x-tex">substr 只能匹配 ASCII 的数据，对于中文要使用</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">u</span><span class="mord mathdefault">b</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord cjk_fallback">只</span><span class="mord cjk_fallback">能</span><span class="mord cjk_fallback">匹</span><span class="mord cjk_fallback">配</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord mathdefault" style="margin-right:0.07847em;">I</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">据</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">对</span><span class="mord cjk_fallback">于</span><span class="mord cjk_fallback">中</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">要</span><span class="mord cjk_fallback">使</span><span class="mord cjk_fallback">用</span></span></span></span>substrCP</p>
<h5 id="8983-project-算术运算">8.9.8.3 $project-算术运算</h5>
<p>在<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …ev.aggregate([{'>project 中我们可以通过 MongoDB 的算数作符对投影的内容做运算处理。 
查询 dev 集合中数据，显示 title 和 size 字段，为 size 字段数据做加 1 操作，显示字段命名为New_Size。 
db.dev.aggregate([{</span>project:{_id:0,title:1,New_Size:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><mi>d</mi><mi>d</mi><mo>:</mo><mo>[</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">add:[&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault">d</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">&quot;</span></span></span></span>size&quot;,1]}}}])<br>
New_Size:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>a</mi><mi>d</mi><mi>d</mi><mo>:</mo><mo>[</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">add:[&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault">d</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">&quot;</span></span></span></span>size&quot;,1]}:在查询结果中，对size 的值做加1 处理，并命名为New_Size。</p>
<figure data-type="image" tabindex="170"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022255.png" alt="" loading="lazy"></figure>
<p>排除那些没有size 键的文档。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: match:{size:{'>match:{size:{</span>ne:null}}},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …le:1,New_Size:{'>project:{_id:0,title:1,New_Size:{</span>add:[&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 9: size&quot;,1]}̲}}]) 
'>size&quot;,1]}}}]) 
</span>match:{size:{$ne:null}:排除那些没有 size 的文档。</p>
<figure data-type="image" tabindex="171"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022309.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中数据，显示 title 和 size 字段，为 size 字段数据做减 1 操作，显示字段命名为New_Size。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: match:{size:{'>match:{size:{</span>ne:null}}},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …le:1,New_Size:{'>project:{_id:0,title:1,New_Size:{</span>subtract:[&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 9: size&quot;,1]}̲}}]) 
New_Size:…'>size&quot;,1]}}}]) 
New_Size:{</span>subtract:[&quot;$size&quot;,1]}:在查询结果中，对 size 的值做减 1 处理，并命名为New_Size。</p>
<figure data-type="image" tabindex="172"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022324.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中数据，显示 title 和 size 字段，为 size 字段数据做乘 2 操作，显示字段命名为New_Size。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: match:{size:{'>match:{size:{</span>ne:null}}},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …le:1,New_Size:{'>project:{_id:0,title:1,New_Size:{</span>multiply:[&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 9: size&quot;,2]}̲}}]) 
New_Size:…'>size&quot;,2]}}}]) 
New_Size:{</span>multiply:[&quot;$size&quot;,2]}:在查询结果中，对 size 的值做乘 2 处理，并命名为New_Size.</p>
<figure data-type="image" tabindex="173"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022347.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中数据，显示 title 和 size 字段，为 size 字段数据做除 2 操作，显示字段命名为New_Size。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: match:{size:{'>match:{size:{</span>ne:null}}},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …le:1,New_Size:{'>project:{_id:0,title:1,New_Size:{</span>divide:[&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 9: size&quot;,2]}̲}}]) 
New_Size:…'>size&quot;,2]}}}]) 
New_Size:{</span>divide:[&quot;$size&quot;,2]}:在查询结果中，对 size 的值做除 2 处理，并命名为New_Size.</p>
<figure data-type="image" tabindex="174"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022402.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中数据，显示 title 和 size 字段，为 size 字段数据做模 2 操作，显示字段命名为New_Size。<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: match:{size:{'>match:{size:{</span>ne:null}}},{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …le:1,New_Size:{'>project:{_id:0,title:1,New_Size:{</span>mod:[&quot;<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 9: size&quot;,2]}̲}}]) 
New_Size:…'>size&quot;,2]}}}]) 
New_Size:{</span>mod:[&quot;$size&quot;,2]}:在查询结果中，对size 的值做模2处理，并命名为New_Size.</p>
<figure data-type="image" tabindex="175"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022421.png" alt="" loading="lazy"></figure>
<h5 id="8984-project-日期操作">8.9.8.4 $project-日期操作</h5>
<ol>
<li>MongoDB 中的日期处理</li>
</ol>
<p>插入当前时间db.dev.insert({date:new Date()})<br>
MongoDB 中的时间会比系统当前时间少 8 个小时。因为他的时间是 UTC 的时间，而中国的时区是东八区，比UTC 快8 个小时，所以会比当前时间少8 个小时。</p>
<figure data-type="image" tabindex="176"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022507.png" alt="" loading="lazy"></figure>
<p>插入指定日期<br>
方式一：<br>
db.dev.insert({time:new Date(&quot;2018-05-01T14:20:23Z&quot;)})<br>
new Date(&quot;2018-05-01T14:20:23Z&quot;):创建时间对象，日期格式为 yyyy-MM-ddThh:mm:ss</p>
<figure data-type="image" tabindex="177"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022528.png" alt="" loading="lazy"></figure>
<p>方式二：<br>
db.dev.insert({time:ISODate(&quot;2019-06-01T16:30:00Z&quot;)})<br>
ISODate(&quot;2019-06-01T16:30:00Z&quot;):</p>
<p>注：这种方式对日期格式要求较低</p>
<figure data-type="image" tabindex="178"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022557.png" alt="" loading="lazy"></figure>
<p>查询时间<br>
db.dev.find({time:{$eq:new Date(&quot;2018-05-01T14:20:23&quot;)}})</p>
<figure data-type="image" tabindex="179"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022612.png" alt="" loading="lazy"></figure>
<p>或者<br>
db.dev.find({time:{$gt:new Date(&quot;2018-04-01&quot;)}})</p>
<figure data-type="image" tabindex="180"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022630.png" alt="" loading="lazy"></figure>
<p>或者</p>
<figure data-type="image" tabindex="181"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022640.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>$project-日期处理</li>
</ol>
<p>向 dev 集合中插入一个文档，该文档包含 name:”admin” birth:”1990-05-01T13:30:00Z”</p>
<figure data-type="image" tabindex="182"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022706.png" alt="" loading="lazy"></figure>
<p>查询 dev 集合中数据，显示 birth 字段的各部分数据，包括：年、月、日等信息。</p>
<p>显示年月日<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 21: …:{name:&quot;admin&quot;}}̲,{'>match:{name:&quot;admin&quot;}},{</span>project:{ 年 份 :{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">year:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 月份:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">month:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},日:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>M</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfMonth:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}}}])<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">year:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}年份<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">month:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}月份<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>M</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfMonth:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}日期</p>
<figure data-type="image" tabindex="183"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022727.png" alt="" loading="lazy"></figure>
<p>显示小时、分钟、秒、毫秒<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 21: …:{name:&quot;admin&quot;}}̲,{'>match:{name:&quot;admin&quot;}},{</span>project:{ 年 份 :{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">year:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 月份:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">month:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 日:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>M</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfMonth:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 时:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mi>o</mi><mi>u</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">hour:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 分:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi>u</mi><mi>t</mi><mi>e</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">minute:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},秒:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">second:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},毫秒:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>l</mi><mi>l</mi><mi>i</mi><mi>s</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">millisecond:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}}}])<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mi>o</mi><mi>u</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">hour:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}:小时<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi>u</mi><mi>t</mi><mi>e</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">minute:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}:分钟<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">second:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}:秒<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>l</mi><mi>l</mi><mi>i</mi><mi>s</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">millisecond:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}:毫秒</p>
<figure data-type="image" tabindex="184"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022746.png" alt="" loading="lazy"></figure>
<p>显示星期、全年的第几周、全年中的第几天<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 21: …:{name:&quot;admin&quot;}}̲,{'>match:{name:&quot;admin&quot;}},{</span>project:{ 年 份 :{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">year:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 月份:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">month:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 日:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>M</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfMonth:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 时:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mi>o</mi><mi>u</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">hour:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 分:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi>u</mi><mi>t</mi><mi>e</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">minute:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},秒:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">second:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},毫秒:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>l</mi><mi>l</mi><mi>i</mi><mi>s</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">millisecond:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},星期:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>W</mi><mi>e</mi><mi>e</mi><mi>k</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfWeek:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mord mathdefault">e</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},全年的第几周:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mi>e</mi><mi>e</mi><mi>k</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">week:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">e</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},全年中的第几天:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>Y</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfYear:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}}}])<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>W</mi><mi>e</mi><mi>e</mi><mi>k</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfWeek:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mord mathdefault">e</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}:星期日为1，星期六为7。<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mi>e</mi><mi>e</mi><mi>k</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">week:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">e</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}:全年的周计数从 0 开始。<br>
{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>Y</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfYear:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}:全年中的第几天。</p>
<figure data-type="image" tabindex="185"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022815.png" alt="" loading="lazy"></figure>
<p>显示自定义日期格式<br>
db.dev.aggregate([{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;}&#039; at position 21: …:{name:&quot;admin&quot;}}̲,{'>match:{name:&quot;admin&quot;}},{</span>project:{ 年 份 :{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">year:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 月份:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">month:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 日:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>M</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>h</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfMonth:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.10903em;">M</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 时:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>h</mi><mi>o</mi><mi>u</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">hour:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">h</span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 分:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>n</mi><mi>u</mi><mi>t</mi><mi>e</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">minute:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault">u</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},秒:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">second:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},毫秒:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>i</mi><mi>l</mi><mi>l</mi><mi>i</mi><mi>s</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>n</mi><mi>d</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">millisecond:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">m</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},星期:{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>W</mi><mi>e</mi><mi>e</mi><mi>k</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfWeek:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="mord mathdefault">e</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;},全年的第几周 :{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mi>e</mi><mi>e</mi><mi>k</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">week:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02691em;">w</span><span class="mord mathdefault">e</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 全 年 中 的 第 几 天 :{<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>a</mi><mi>y</mi><mi>O</mi><mi>f</mi><mi>Y</mi><mi>e</mi><mi>a</mi><mi>r</mi><mo>:</mo><mi mathvariant="normal">&quot;</mi></mrow><annotation encoding="application/x-tex">dayOfYear:&quot;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">d</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord mathdefault" style="margin-right:0.02778em;">O</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span><span class="mord mathdefault">e</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord">&quot;</span></span></span></span>birth&quot;}, 自 定 义 日 期 格式:{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …H:%M:%S&quot;,date:&quot;'>dateToString:{format:&quot;%Y 年%m 月%d 日 H:%M:%S&quot;,date:&quot;</span>birth&quot;}}}}])<br>
{<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;}&#039;, got &#039;EOF&#039; at end of input: …H:%M:%S&quot;,date:&quot;'>dateToString:{format:&quot;%Y 年%m 月%d 日 %H:%M:%S&quot;,date:&quot;</span>birth&quot;}:自定义日期格式<br>
具体格式如下：</p>
<figure data-type="image" tabindex="186"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022856.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="187"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715022903.png" alt="" loading="lazy"></figure>
<h2 id="9-java-访问-mongodb">9、 Java 访问 MongoDB</h2>
<h3 id="91-连接-mongodb-数据库">9.1 连接 MongoDB 数据库</h3>
<h4 id="911-创建工程">9.1.1 创建工程</h4>
<p>在POM 文件中添加 MongoDB 驱动坐标</p>
<pre><code class="language-xml">&lt;!-- https://mvnrepository.com/artifact/org.mongodb/mongo-java-driver --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mongodb&lt;/groupId&gt;
            &lt;artifactId&gt;mongo-java-driver&lt;/artifactId&gt;
            &lt;version&gt;3.8.2&lt;/version&gt;
        &lt;/dependency&gt;
</code></pre>
<h4 id="912-创建mongodb-连接">9.1.2 创建MongoDB 连接</h4>
<p>封装 MongoDBUtil</p>
<pre><code class="language-java">public class MongoDBUtil {
    private static MongoClient mongoClient = null;

    static {
        if (mongoClient == null) {
            mongoClient=new MongoClient(&quot;124.70.181.124&quot;,27017);
        }
    }

    //获取数据库
    public static MongoDatabase getDatabase(String dbName){
       return mongoClient.getDatabase(dbName);
    }

    //获取集合
    public static MongoCollection getCollection(String dbName,String collName){
        return mongoClient.getDatabase(dbName).getCollection(collName);
    }
}
</code></pre>
<h4 id="913-创建mongodb-的认证连接">9.1.3 创建MongoDB 的认证连接</h4>
<p>封装 MongoDBAuthUtil</p>
<pre><code class="language-java">/**
 * 创建MongoDB拦截-使用用户认证
 */
public class MongoDBAuthUtil {
    ////创建连接对象
    private static MongoClient mongoClient = null;

    static {
        if (mongoClient==null){
            /**
             *创建一个封装用户认证信息
             * createCredential(userName,database,password)
             */
            MongoCredential credential = MongoCredential.createCredential(&quot;root&quot;, &quot;admin&quot;, &quot;root&quot;.toCharArray());
            //封装MongoDB的地址与端口
            ServerAddress serverAddress = new ServerAddress(&quot;124.70.181.124&quot;,27017);
            mongoClient=new MongoClient(serverAddress, Arrays.asList(credential));
        }
    }

    //获取数据库
    public static MongoDatabase getDatabase(String dbName){
        return mongoClient.getDatabase(dbName);
    }

    //获取集合
    public static MongoCollection getCollection(String dbName,String collName){
        return mongoClient.getDatabase(dbName).getCollection(collName);
    }
}
</code></pre>
<h4 id="914-创建mongodb-的池连">9.1.4 创建MongoDB 的池连</h4>
<p>封装 MongoDBPoolUtil</p>
<pre><code class="language-java">/**
 * 使用池连的方式
 */
public class MongoDBPoolUtil {
    private static MongoClient mongoClient = null;

    static {
        if (mongoClient == null) {
            //连接池参数
            MongoClientOptions.Builder builder=new MongoClientOptions.Builder();
            builder.connectionsPerHost(10);//每个地址最大连接数
            builder.connectTimeout(5000);//设置连接超时时间
            builder.socketTimeout(5000);//设置读写操作超时时间
            ServerAddress serverAddress = new ServerAddress(&quot;124.70.181.124&quot;, 27017);
            mongoClient=new MongoClient(serverAddress,builder.build());
        }
    }

    //获取数据库
    public static MongoDatabase getDatabase(String dbName){
        return mongoClient.getDatabase(dbName);
    }

    //获取集合
    public static MongoCollection getCollection(String dbName, String collName){
        return mongoClient.getDatabase(dbName).getCollection(collName);
    }
}
</code></pre>
<h4 id="915-创建mongodb-的认证池连">9.1.5 创建MongoDB 的认证池连</h4>
<p>封装 MongoDBAuthPoolUtil</p>
<pre><code class="language-java">/**
 *支持用户认证的池连
 */
public class MongoDBPoolAuthUtil {
    private static MongoClient mongoClient = null;

    static {
        if (mongoClient == null) {
            //连接池参数
            MongoClientOptions.Builder builder=new MongoClientOptions.Builder();
            builder.connectionsPerHost(10);//每个地址最大连接数
            builder.connectTimeout(5000);//设置连接超时时间
            builder.socketTimeout(5000);//设置读写操作超时时间

            MongoCredential mongoCredential = MongoCredential.createCredential(&quot;root&quot;, &quot;admin&quot;, &quot;root&quot;.toCharArray());

            ServerAddress serverAddress = new ServerAddress(&quot;124.70.181.124&quot;, 27017);
            mongoClient=new MongoClient(serverAddress,mongoCredential,builder.build());
        }
    }

    //获取数据库
    public static MongoDatabase getDatabase(String dbName){
        return mongoClient.getDatabase(dbName);
    }

    //获取集合
    public static MongoCollection getCollection(String dbName, String collName){
        return mongoClient.getDatabase(dbName).getCollection(collName);
    }
}

</code></pre>
<h3 id="92-操作集合">9.2  操作集合</h3>
<h4 id="921-创建集合">9.2.1 创建集合</h4>
<pre><code class="language-java">/**
 *支持用户认证的池连
 */
public class MongoDBPoolAuthUtil {
    private static MongoClient mongoClient = null;

    static {
        if (mongoClient == null) {
            //连接池参数
            MongoClientOptions.Builder builder=new MongoClientOptions.Builder();
            builder.connectionsPerHost(10);//每个地址最大连接数
            builder.connectTimeout(5000);//设置连接超时时间
            builder.socketTimeout(5000);//设置读写操作超时时间

            MongoCredential mongoCredential = MongoCredential.createCredential(&quot;root&quot;, &quot;admin&quot;, &quot;root&quot;.toCharArray());

            ServerAddress serverAddress = new ServerAddress(&quot;124.70.181.124&quot;, 27017);
            mongoClient=new MongoClient(serverAddress,mongoCredential,builder.build());
        }
    }

    //获取数据库
    public static MongoDatabase getDatabase(String dbName){
        return mongoClient.getDatabase(dbName);
    }

    //获取集合
    public static MongoCollection getCollection(String dbName, String collName){
        return mongoClient.getDatabase(dbName).getCollection(collName);
    }

    //创建集合
    public static void createCollection(String dbName,String collName){
        mongoClient.getDatabase(dbName).createCollection(collName);
    }
}

</code></pre>
<h4 id="922-获取集合">9.2.2 获取集合</h4>
<pre><code class="language-java">//获取集合
public static MongoCollection getCollection(String dbName, String collName){
    return mongoClient.getDatabase(dbName).getCollection(collName);
}
</code></pre>
<h4 id="923-删除集合">9.2.3 删除集合</h4>
<pre><code class="language-java">/**
 *支持用户认证的池连
 */
public class MongoDBPoolAuthUtil {
    private static MongoClient mongoClient = null;

    static {
        if (mongoClient == null) {
            //连接池参数
            MongoClientOptions.Builder builder=new MongoClientOptions.Builder();
            builder.connectionsPerHost(10);//每个地址最大连接数
            builder.connectTimeout(5000);//设置连接超时时间
            builder.socketTimeout(5000);//设置读写操作超时时间

            MongoCredential mongoCredential = MongoCredential.createCredential(&quot;root&quot;, &quot;admin&quot;, &quot;root&quot;.toCharArray());

            ServerAddress serverAddress = new ServerAddress(&quot;124.70.181.124&quot;, 27017);
            mongoClient=new MongoClient(serverAddress,mongoCredential,builder.build());
        }
    }

    //获取数据库
    public static MongoDatabase getDatabase(String dbName){
        return mongoClient.getDatabase(dbName);
    }

    //获取集合
    public static MongoCollection getCollection(String dbName, String collName){
        return mongoClient.getDatabase(dbName).getCollection(collName);
    }

    //创建集合
    public static void createCollection(String dbName,String collName){
        mongoClient.getDatabase(dbName).createCollection(collName);
    }

    //删除集合
    public static void dropCollection(MongoCollection coll){
        coll.drop();
    }
}
</code></pre>
<h3 id="93-操作文档">9.3  操作文档</h3>
<h4 id="931-添加文档">9.3.1 添加文档</h4>
<pre><code class="language-java">/**
 * 插入文档
 */
public class InsertDocument {
    public static void main(String[] args) {
        InsertDocument insertDocument = new InsertDocument();
        //insertDocument.insertSingleDocument();
        insertDocument.insertManyDocument();
    }

    /**
     * 插入单个文档
     */
    public void insertSingleDocument() {
        //获取集合
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);

        Document doc = new Document();
        doc.append(&quot;name&quot;, &quot;张三&quot;).append(&quot;sex&quot;, &quot;男&quot;).append(&quot;userdesc&quot;, &quot;Very Good&quot;).append(&quot;userlike&quot;, Arrays.asList(new String[]{&quot;Music&quot;, &quot;Sport&quot;}));
        collection.insertOne(doc);
    }

    /**
     * 插入多个文档
     */
    public void insertManyDocument() {
        //获取集合
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);
        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; 5; i++) {
            Document doc = new Document();
            doc.append(&quot;name&quot;,&quot;zhangsan&quot;+i);
            doc.append(&quot;sex&quot;,&quot;男&quot;+i);
            doc.append(&quot;userdesc&quot;,&quot;OK&quot;+i);
            doc.append(&quot;userlike&quot;,Arrays.asList(new String[]{&quot;Music&quot;,&quot;Sport&quot;}));
            list.add(doc);
        }
        collection.insertMany(list);
    }
}

</code></pre>
<figure data-type="image" tabindex="188"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200715025104.png" alt="" loading="lazy"></figure>
<h4 id="932-更新文档">9.3.2 更新文档</h4>
<pre><code class="language-java">/**
 * 更新文档
 */
public class UpdateDocument {
    public static void main(String[] args) {
        UpdateDocument updateDocument = new UpdateDocument();
        //updateDocument.updateSingleDocumentOneKey();
        //updateDocument.updateSingleDocumentManyKey();
        //updateDocument.updateManyDocumentOneKey();
        //updateDocument.updateManyDocumentOneKey();
        updateDocument.updateDocumentArray();
    }

    /**
     *更新单个文档单个键
     */
    public void updateSingleDocumentOneKey(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);
        //更新文档
        //Filters封装了条件的一个工具类{$set:{userage:28}}
        //一个{}对应java中的一个document
        collection.updateOne(Filters.eq(&quot;name&quot;,&quot;张三&quot;),new Document(&quot;$set&quot;,new Document(&quot;sex&quot;,&quot;女&quot;)));
    }

    /**
     * 更新单个文档多个键
     */
    public void updateSingleDocumentManyKey(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);

        collection.updateOne(Filters.eq(&quot;name&quot;,&quot;zhangsan0&quot;),new Document(&quot;$set&quot;,new Document(&quot;sex&quot;,&quot;女&quot;).append(&quot;userdesc&quot;,&quot;very good&quot;)));
    }

    /**
     *更新多个文档单个键
     */
    public void updateManyDocumentOneKey(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);

        collection.updateMany(Filters.ne(&quot;name&quot;,null),new Document(&quot;$set&quot;,new Document(&quot;userdesc&quot;,&quot;very good&quot;)));
    }

    /**
     *更新多个文档多个键
     */
    public void updateManyDocumentManyKey(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);

        collection.updateMany(Filters.ne(&quot;name&quot;,null),new Document(&quot;$set&quot;,new Document(&quot;userdesc&quot;,&quot;very good&quot;).append(&quot;sex&quot;,&quot;女&quot;)));
    }

    /**
     * 更新文档中的数组
     * {$push:{}}
     */
    public void updateDocumentArray(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        collection.updateOne(Filters.eq(&quot;name&quot;,&quot;李四&quot;),new Document(&quot;$push&quot;,new Document(&quot;userlike&quot;,&quot;Art&quot;)));
    }
}
</code></pre>
<h4 id="933-查询文档">9.3.3 查询文档</h4>
<pre><code class="language-java">/**
 * 查询文档
 */
public class SelectDocument {
    public static void main(String[] args){
        SelectDocument docu= new SelectDocument();
        //docu.selectDocumentAll();
        //docu.selectDocumentById();
        //docu.selectDocumentConditionByGt();
        //docu.selectDocumentConditionByType();
        // docu.selectDocumentConditionByIn();
        // docu.selectDocumentConditionByNin();
        // docu.selectDocumentConditionByRegex();
        //docu.selectDocumentConditionUseAnd();
        //docu.selectDocumentConditionUseOr();
        //docu.selectDocumentConditionAndOr();
        docu.selectDocumentSorting();
    }

    /**
     * 查询全部文档
     */
    public void selectDocumentAll(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        //返回的是一个文档的迭代器
        FindIterable&lt;Document&gt; iterable = collection.find();
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }

    /**
     * 根据_id查询文档
     */
    public void selectDocumentById(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable&lt;Document&gt; iterable = collection.find(Filters.eq(&quot;_id&quot;,new ObjectId(&quot;5d398cd64b022206d87d168e&quot;)));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }


    /**
     * 根据年龄查询文档，条件是年龄大于19
     */
    public void selectDocumentConditionByGt(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable iterable = collection.find(Filters.gt(&quot;userage&quot;,19));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }

    /**
     * 根据年龄查询文档，添加是年龄的值是整数类型(number)
     */
    public void selectDocumentConditionByType(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable iterable = collection.find(Filters.type(&quot;userage&quot;,&quot;number&quot;));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }
    /**
     * 查询用户的名字为 zhangsan1,zhangsan2
     */
    public void selectDocumentConditionByIn(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable iterable = collection.find(Filters.in(&quot;username&quot;,&quot;zhangsan1&quot;,&quot;zhangsan2&quot;));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }

    /**
     * 查询用户的名字不是 zhangsan1,zhangsan2
     */
    public void selectDocumentConditionByNin(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable iterable = collection.find(Filters.nin(&quot;username&quot;,&quot;zhangsan1&quot;,&quot;zhangsan2&quot;));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }

    /**
     * 查询用户的名字是z开头2结尾的。
     */
    public void selectDocumentConditionByRegex(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable iterable = collection.find(Filters.regex(&quot;username&quot;, Pattern.compile(&quot;^z.*2$&quot;)));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }

    /**
     * 查询用户username是zhangsan1并且年龄为20岁的用户
     */
    public void selectDocumentConditionUseAnd(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable iterable = collection.find(Filters.and(Filters.eq(&quot;username&quot;,&quot;zhangsan1&quot;),Filters.eq(&quot;userage&quot;,21),Filters.eq(&quot;userdesc&quot;,&quot;Very Good&quot;)));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }

    /**
     * 查询用户要求username是list，或者userage是20 或者 userdesc是Very Good
     */
    public void selectDocumentConditionUseOr(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable iterable = collection.find(Filters.or(Filters.eq(&quot;username&quot;,&quot;lisi&quot;),Filters.eq(&quot;userage&quot;,20),Filters.eq(&quot;userdesc&quot;,&quot;Very Good&quot;)));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }
    /**
     * 查询文档中username为lisi并且年龄为20岁，或者userdesc为Very Good
     */
    public void selectDocumentConditionAndOr(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable iterable = collection.find(Filters.or(Filters.and(Filters.eq(&quot;username&quot;,&quot;lisi&quot;),Filters.eq(&quot;userage&quot;,20)),Filters.eq(&quot;userdesc&quot;,&quot;Very Good&quot;)));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }
    /**
     * 查询文档中username是z开头的，根据username对结果做降序排序。1升序排序， -1降序排序规则  $sort:{username,-1}
     */
    public void selectDocumentSorting(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        FindIterable iterable = collection.find(Filters.regex(&quot;username&quot;,Pattern.compile(&quot;^z&quot;))).sort(new Document(&quot;username&quot;,-1));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;));
        }
    }
}

</code></pre>
<h4 id="934-日期操作">9.3.4 日期操作</h4>
<p>创建日期处理工具类</p>
<pre><code class="language-java">public class DateUtil {

    /**
     * Date To String
     */
    public static String dateToString(String pattern, Date date){
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat(pattern);
       return  simpleDateFormat.format(date);
    }

    /**
     * String To Date
     */
    public static Date stringToDate(String pattern, String date){
        SimpleDateFormat simpleDateFormat = new SimpleDateFormat(pattern);
        Date d = null;
        try{
            d = simpleDateFormat.parse(date);
        }catch(Exception e){
            e.printStackTrace();
        }
        return d;
    }
}
</code></pre>
<p>日期操作</p>
<pre><code class="language-java">/**
 * 日期操作
 */
public class DateOperation {
    public static void main(String[] args){
        DateOperation operation = new DateOperation();
        //operation.insertDocumentSystemDate();
        //operation.insertDocumentCustoDate();
        //operation.selectDocumentDateUseEq();
        operation.selectDocumentDateUseGt();
    }

    /**
     * 插入系统当前日期
     */
    public void insertDocumentSystemDate(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        Document docu = new Document();
        docu.put(&quot;username&quot;,&quot;wangwu&quot;);
        docu.put(&quot;userage&quot;,22);
        docu.put(&quot;userdesc&quot;,&quot;Very Good&quot;);
        docu.put(&quot;userlike&quot;, Arrays.asList(new String[]{&quot;Music&quot;,&quot;Art&quot;}));
        docu.put(&quot;userbirth&quot;,new Date());
        collection.insertOne(docu);
    }

    /**
     * 插入指定日期
     */
    public void insertDocumentCustoDate(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        Date date= DateUtil.stringToDate(&quot;yyyy-MM-dd HH:mm:ss&quot;,&quot;2019-05-01 13:32:13&quot;);
        Document docu = new Document();
        docu.put(&quot;username&quot;,&quot;zhaoliu&quot;);
        docu.put(&quot;userage&quot;,24);
        docu.put(&quot;userdesc&quot;,&quot;Very Good&quot;);
        docu.put(&quot;userlike&quot;, Arrays.asList(new String[]{&quot;Music&quot;,&quot;Art&quot;}));
        docu.put(&quot;userbirth&quot;,date);
        collection.insertOne(docu);
    }

    /**
     * 查询日期：查询用的生日为2019-05-01 13:32:13的用户信息
     */
    public void selectDocumentDateUseEq(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        Date date = DateUtil.stringToDate(&quot;yyyy-MM-dd HH:mm:ss&quot;,&quot;2019-05-01 13:32:13&quot;);
        FindIterable iterable = collection.find(Filters.eq(&quot;userbirth&quot;,date));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            String temp = DateUtil.dateToString(&quot;yyyy-MM-dd HH:mm:ss&quot;,(Date) docu.get(&quot;userbirth&quot;));
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;)+&quot;\t&quot;+temp);
        }
    }

    /**
     * 查询日期：查询用的生日大于2019-01-01 00:00:00的用户信息
     */
    public void selectDocumentDateUseGt(){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        Date date = DateUtil.stringToDate(&quot;yyyy-MM-dd HH:mm:ss&quot;,&quot;2019-01-01 00:00:00&quot;);
        FindIterable iterable = collection.find(Filters.gt(&quot;userbirth&quot;,date));
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            String temp = DateUtil.dateToString(&quot;yyyy-MM-dd HH:mm:ss&quot;,(Date) docu.get(&quot;userbirth&quot;));
            System.out.println(docu.get(&quot;username&quot;)+&quot;\t&quot;+docu.get(&quot;userage&quot;)+&quot;\t&quot;+docu.get(&quot;userdesc&quot;)+&quot;\t&quot;+docu.get(&quot;userlike&quot;)+&quot;\t&quot;+temp);
        }
    }

}

</code></pre>
<h4 id="935-聚合操作">9.3.5 聚合操作</h4>
<pre><code class="language-java">/**
 * 聚合操作
 */
public class AggergateOper {

    public static void main(String[] args) {
        AggergateOper oper = new AggergateOper();
        //oper.selectDocumentAggregateCount();
        //oper.selectDocumentAggregateSum();
        //oper.selectDocumentAggregateGroupBySum();
        // oper.selectDocumentAggregateGroupByWhere();
        oper.selectDocumentAggregateGroupByHaving();
    }

    /**
     * 需求：查询集合中的文档数量
     * Mongo Shell:db.dev.aggregate([{$group:{_id:null,count:{$sum:1}}}])
     */
    public void selectDocumentAggregateCount() {
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);

        Document sum = new Document();
        sum.put(&quot;$sum&quot;, 1);

        Document count = new Document();
        count.put(&quot;_id&quot;, null);
        count.put(&quot;count&quot;, sum);

        Document group = new Document();
        group.put(&quot;$group&quot;, count);

        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        list.add(group);

        AggregateIterable iterable = collection.aggregate(list);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while (cursor.hasNext()) {
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;count&quot;));
        }
    }

    /**
     * 需求：查询集合中所有size键中的值的总和
     * Mongo Shell:db.dev.aggregate([{$group:{_id:null,totalSize:{$sum:&quot;$size&quot;}}}])
     */
    public void selectDocumentAggregateSum() {
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);
        Document sum = new Document();
        sum.put(&quot;$sum&quot;, &quot;$size&quot;);

        Document totalSize = new Document();
        totalSize.put(&quot;_id&quot;, null);
        totalSize.put(&quot;totalSize&quot;, sum);

        Document group = new Document();
        group.put(&quot;$group&quot;, totalSize);

        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        list.add(group);

        AggregateIterable iterable = collection.aggregate(list);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while (cursor.hasNext()) {
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;totalSize&quot;));
        }

    }

    /**
     * 需求：对title进行分组，计算每组中的size的总和
     * Mongo Shell:db.dev.aggregate([{$group:{_id:&quot;$title&quot;,totalSize:{$sum:&quot;$size&quot;}}}])
     */
    public void selectDocumentAggregateGroupBySum() {
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);
        Document sum = new Document();
        sum.put(&quot;$sum&quot;, &quot;$size&quot;);

        Document totalSize = new Document();
        totalSize.put(&quot;_id&quot;, &quot;$title&quot;);
        totalSize.put(&quot;totalSize&quot;, sum);

        Document group = new Document();
        group.put(&quot;$group&quot;, totalSize);

        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        list.add(group);

        AggregateIterable iterable = collection.aggregate(list);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while (cursor.hasNext()) {
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;totalSize&quot;));
        }
    }

    /**
     * 需求：查询dev集合有多少文档的size大于200。
     * Mongo Shell：
     * db.dev.aggregate([{$match:{size:{$gt:200}}},{$group:{_id:null,totalSize:{$sum:1}}}])
     */
    public void selectDocumentAggregateGroupByWhere() {
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);
        Document gt = new Document();
        gt.put(&quot;$gt&quot;, 200);

        Document size = new Document();
        size.put(&quot;size&quot;, gt);

        Document match = new Document();
        match.put(&quot;$match&quot;, size);


        Document sum = new Document();
        sum.put(&quot;$sum&quot;, 1);

        Document totalSize = new Document();
        totalSize.put(&quot;_id&quot;, null);
        totalSize.put(&quot;totalSize&quot;, sum);

        Document group = new Document();
        group.put(&quot;$group&quot;, totalSize);

        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        list.add(match);
        list.add(group);

        AggregateIterable iterable = collection.aggregate(list);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while (cursor.hasNext()) {
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;totalSize&quot;));
        }
    }

    /**
     * 需求：查询dev集合，根据title分组计算出每组的size的总和，并过滤掉总和小于200的文档。
     * Mongo Shell：
     * db.dev.aggregate([{$group:{_id:&quot;$title&quot;,totalSize:{$sum:&quot;$size&quot;}}},{$match:{totalSize:{$gt:200}}}])
     */
    public void selectDocumentAggregateGroupByHaving() {
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);
        Document sum = new Document();
        sum.put(&quot;$sum&quot;, &quot;$size&quot;);

        Document totalSize = new Document();
        totalSize.put(&quot;_id&quot;, &quot;$title&quot;);
        totalSize.put(&quot;totalSize&quot;, sum);

        Document group = new Document();
        group.put(&quot;$group&quot;, totalSize);

        //{$match:{totalSize:{$gt:200}}}
        Document gt = new Document();
        gt.put(&quot;$gt&quot;, 200);

        Document mtotalSize = new Document();
        mtotalSize.put(&quot;totalSize&quot;, gt);

        Document match = new Document();
        match.put(&quot;$match&quot;, mtotalSize);

        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        list.add(group);
        list.add(match);
        AggregateIterable iterable = collection.aggregate(list);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while (cursor.hasNext()) {
            Document docu = cursor.next();
            System.out.println(docu.get(&quot;totalSize&quot;));
        }
    }

    /**
     * 需求：查询 dev 集合，将数组中的内容拆分显示，并只显示 title 键与tags键的值。
     * Mongo Shell：
     * db.dev.aggregate([{$unwind:&quot;$tags&quot;},{$project:{_id:0,tags:&quot;$tags&quot;,title:&quot;$title&quot;}}])
     */
    public void selectDocumentProject() {
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);
        Document unwind = new Document();
        unwind.put(&quot;$unwind&quot;, &quot;$tags&quot;);

        Document pro = new Document();
        pro.put(&quot;_id&quot;, 0);
        pro.put(&quot;tags&quot;, &quot;$tags&quot;);
        pro.put(&quot;title&quot;, &quot;$title&quot;);

        Document project = new Document();
        project.put(&quot;$project&quot;, pro);

        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        list.add(unwind);
        list.add(project);
        AggregateIterable iterable =
                collection.aggregate(list);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while (cursor.hasNext()) {
            System.out.println(cursor.next());
        }
    }

    /**
     * 需求：查询 dev 集合，将数组中的内容拆分显示。将 title字段和 tags字段的值拼接为一个完整字符串并在 Title_Tags 字段中显示。
     * Mongo Shell：
     * db.dev.aggregate([{$unwind:&quot;$tags&quot;},{$project:{_id:0,Title_Tags:{$concat:[&quot;$title&quot;,&quot;-&quot;,&quot;$tags&quot;]}}}])
     */
    public void selectDocumentProjectConcat() {
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);
        Document unwind = new Document();
        unwind.put(&quot;$unwind&quot;, &quot;$tags&quot;);

        Document concat = new Document();
        concat.put(&quot;$concat&quot;, Arrays.asList(new String[]{&quot;$title&quot;, &quot;-&quot;, &quot;$tags&quot;}));

        Document title = new Document();
        title.put(&quot;_id&quot;, 0);
        title.put(&quot;Title_Tags&quot;, concat);

        Document project = new Document();
        project.put(&quot;$project&quot;, title);

        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        list.add(unwind);
        list.add(project);
        AggregateIterable iterable = collection.aggregate(list);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while (cursor.hasNext()) {
            System.out.println(cursor.next());
        }
    }

    /**
     * 需求：查询 dev 集合中数据，显示 title 和size字段，为 size 字段数据做加1操作，显示字段命名为 New_Size。排除那些没有size键的文档。
     * Mongo Shell：
     * db.dev.aggregate([{$match:{size:{$ne:null}}},{$project:{_id:0,title:1,New_Size:{$add:[&quot;$size&quot;,1]}}}])
     */
    public void selectDocumentProjectAdd() {
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;dev&quot;);

        Document ne = new Document();
        ne.put(&quot;$ne&quot;, null);

        Document size = new Document();
        size.put(&quot;size&quot;, ne);
        Document match = new Document();
        match.put(&quot;$match&quot;, size);

        //{$project:{_id:0,title:1,New_Size:{$add:[&quot;$size&quot;,1]}}}
        Document add = new Document();
        add.put(&quot;$add&quot;, Arrays.asList(new
                Object[]{&quot;$size&quot;, 1}));

        Document new_Size = new Document();
        new_Size.put(&quot;_id&quot;, 0);
        new_Size.put(&quot;title&quot;, 1);
        new_Size.put(&quot;New_Size&quot;, add);

        Document project = new Document();
        project.put(&quot;$project&quot;, new_Size);

        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        list.add(match);
        list.add(project);
        AggregateIterable iterable = collection.aggregate(list);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while (cursor.hasNext()) {
            System.out.println(cursor.next());
        }
    }

    /**
     * 需求：查询 devtest 集合查询那些有生日的用户，并按照 YYYY 年 mm月 dd日 HH:MM:SS 格式显示日期。
     * 注意：如果直接在 MongoDB 中做日期的格式化处理，那么是按照表示 UTC时间来处理的，会少 8 个小时。建议在程序中通过 java.util.Date 来做日期的转换。
     * Mongo Shell：
     * db.devtest.aggregate([{$match:{userbirth:{$ne:null}}},{$project:{自定义日期格式:{$dateToString:{format:&quot;%Y 年%m 月%d日 %H:%M:%S&quot;,date:&quot;$userbirth&quot;}}}}])
     */
    public void selectDocumentProjectDate() {
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;, &quot;devtest&quot;);

        Document ne = new Document();
        ne.put(&quot;$ne&quot;, null);

        Document birth = new Document();
        birth.put(&quot;userbirth&quot;, ne);

        Document match = new Document();
        match.put(&quot;$match&quot;, birth);

        //{$project:{自定义日期格式:{$dateToString:{format:&quot;%Y 年%m 月%d 日 %H:%M:%S&quot;,date:&quot;$userbirth&quot;}}}}
        Document format = new Document();
        format.put(&quot;format&quot;, &quot;%Y 年%m 月%d 日 %H:%M:%S&quot;);
        format.put(&quot;date&quot;, &quot;$userbirth&quot;);

        Document dateToString = new Document();
        dateToString.put(&quot;$dateToString&quot;, format);

        Document custoDate = new Document();
        custoDate.put(&quot;自定义日期格式&quot;, dateToString);

        Document project = new Document();
        project.put(&quot;$project&quot;, custoDate);
        
        List&lt;Document&gt; list = new ArrayList&lt;&gt;();
        list.add(match);
        list.add(project);
        AggregateIterable iterable = collection.aggregate(list);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while (cursor.hasNext()) {
            System.out.println(cursor.next());
        }
    }
}

</code></pre>
<h4 id="936-分页查询">9.3.6 分页查询</h4>
<pre><code class="language-java">/**
 * MongoDB分页查询
 */
public class SelectDocumentByPage {
    public static void main(String[] args){
        SelectDocumentByPage page = new SelectDocumentByPage();
        //page.selectDocumentByPageUseSkipAndLimit(1);
        page.selectDocumentByPageUseCondition(2,2,&quot;5d30753b4e3d27202fd768fa&quot;);
    }

    /**
     * 通过skip与limit方法实现分页
     */
    public void selectDocumentByPageUseSkipAndLimit(int pageIndex){
        int page = (pageIndex-1)*2;
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        Document condition = new Document(&quot;size&quot;,new Document(&quot;$ne&quot;,null));
        long countNum =  collection.countDocuments(condition);
        System.out.println(countNum);
        FindIterable iterable = collection.find(condition).skip(page).limit(2);
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu);
        }
    }

    /**
     * 通过条件判断实现分页,替代skip
     */
    public void selectDocumentByPageUseCondition(int pageIndex,int pageSize,String lastId){
        MongoCollection collection = MongoDBPoolAuthUtil.getCollection(&quot;develop&quot;,&quot;dev&quot;);
        Document condition = new Document(&quot;size&quot;,new Document(&quot;$ne&quot;,null));
        long countNum =  collection.countDocuments(condition);
        System.out.println(countNum);
        FindIterable iterable = null;
        if(pageIndex == 1){
          iterable = collection.find(condition).limit(pageSize);
        }else{
            if(lastId != null){
                condition.append(&quot;_id&quot;,new Document(&quot;$gt&quot;,new ObjectId(lastId)));
                iterable = collection.find(condition).limit(pageSize);
            }
        }
        MongoCursor&lt;Document&gt; cursor = iterable.iterator();
        while(cursor.hasNext()){
            Document docu = cursor.next();
            System.out.println(docu);
        }
    }
}

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis]]></title>
        <id>https://jonchan1013.github.io/post/redis/</id>
        <link href="https://jonchan1013.github.io/post/redis/">
        </link>
        <updated>2020-07-07T08:30:47.000Z</updated>
        <summary type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707163549.png" alt="" loading="lazy"></figure>
<h2 id="1-redis-介绍">1、Redis 介绍</h2>
<h3 id="11-redis-简介">1.1 Redis 简介</h3>
<p>​		<strong>Remote Dictionary Server(Redis)是一个开源的使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的 API。</strong><br>
​		它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map),列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。</p>
]]></summary>
        <content type="html"><![CDATA[<figure data-type="image" tabindex="1"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707163549.png" alt="" loading="lazy"></figure>
<h2 id="1-redis-介绍">1、Redis 介绍</h2>
<h3 id="11-redis-简介">1.1 Redis 简介</h3>
<p>​		<strong>Remote Dictionary Server(Redis)是一个开源的使用 ANSI C 语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的 API。</strong><br>
​		它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map),列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。</p>
<!-- more -->
<h3 id="12-redis-的特点">1.2 Redis 的特点</h3>
<ol>
<li>支持多种数据结构，如 string(字符串)、 list(双向链表)、dict(hash 表)、set(集合)、zset(排序 set)、hyperloglog(基数估算)</li>
<li>支持持久化操作，可以进行 aof 及 rdb 数据持久化到磁盘，从而进行数据备份或数据恢复等操作，较好的防止数据丢失的手段。</li>
<li>支持通过 Replication 进行数据复制，通过 master-slave 机制，可以实时进行数据的同步复制，支持多级复制和增量复制，master-slave 机制是 Redis 进行 HA 的重要手段。</li>
<li><strong>单进程</strong>请求，所有命令串行执行，并发情况下不需要考虑数据一致性问题。</li>
</ol>
<h2 id="2-安装-redis-单机版">2、安装 Redis 单机版</h2>
<p>第一步 需要在 linux 系统中安装 gcc<br>
命令：yum install -y gcc-c++<br>
第二步 需要将下载好的 redis 压缩包添加到 linux 服务器中<br>
版本：redis-3.0.0.tar.gz<br>
redis 的版本：<strong>副版本号奇数版本号是测试版，不建议在生产环境中使用。</strong><br>
<strong>偶数版本时稳定版建议在生产环境中使用。</strong><br>
<strong>3.0 版本更新比较大。集成了集群技术</strong></p>
<p>第三步 解压压缩包<br>
命令：tar -zxvf redis......</p>
<p>第四步 编译 redis<br>
命令：进入 redis 的解压完毕的根目录下 执行命令：make</p>
<p>第五步 安装 redis<br>
命 令 ： 进 入 redis 的 解 压 完 毕 的 根 目 录 下 ， 执 行 命 令 ： make install<br>
PREFIX=/usr/local/redis</p>
<p>第六步：启动 redis</p>
<p><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707170241.png" alt="" loading="lazy">1）前端启动<br>
在 bin 目录下执行命令： ./redis-server （ctrl+c）退出 redis</p>
<figure data-type="image" tabindex="2"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707170339.png" alt="" loading="lazy"></figure>
<p>2)修改拷贝过来的 redis.conf 配置文件<br>
命令：vim redis.conf<br>
将 daemonize no 改为 yes</p>
<figure data-type="image" tabindex="3"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707170910.png" alt="" loading="lazy"></figure>
<p>(3)启动 redis<br>
在 bin 目录下执行命令：./redis-server redis.conf</p>
<p>(4)查看 redis 启动是否成功<br>
输入命令：ps aux|grep redis</p>
<ol start="5">
<li>关闭 redis 的命令<br>
./redis-cli shutdown</li>
</ol>
<p>第七步：测试 redis<br>
在 bin 目录下启动 redis 自带的客户端 ./redis-cli<br>
常见 redis 命令：<br>
ping---&gt;pong</p>
<figure data-type="image" tabindex="4"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707171333.png" alt="" loading="lazy"></figure>
<h2 id="3-redis-数据类型">3、Redis 数据类型</h2>
<h3 id="31-string字符串">3.1 String(字符串)</h3>
<p>Redis 字符串是字节序列。Redis 字符串是二进制安全的，这意味着他们有一个已知的长度没有任何特殊字符终止，所以你可以存储任何东西，512 兆为上限</p>
<p>示例：<br>
redis 127.0.0.1:6379&gt; set name kevin<br>
OK<br>
redis 127.0.0.1:6379&gt; get name<br>
&quot;kevin&quot;</p>
<p>incr 让当前键值以 1 的数量递增，并返回递增后的值<br>
incrby 可以指定参数一次增加的数值，并返回递增后的值<br>
decr 让当前键值以 1 的数量递减 并返回递减后的值<br>
decrby 可以指定参数一次递减的数值，并返回递减后的值<br>
incrbyfloat 可以递增一个双精度浮点数<br>
append 作用是向键值的末尾追加 value。如果键不存在则将该键的值设置为 value。返<br>
回值是追加后字符串的总长度。<br>
mget/mset 作用与 get/set 相似，不过 mget/mset 可以同时获得/设置多个键的键值<br>
del 根据 key 来删除 value<br>
flushdb 清除当前库的所有数据</p>
<figure data-type="image" tabindex="5"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707172641.png" alt="" loading="lazy"></figure>
<h3 id="32-hashhash-表">3.2 Hash(hash 表)</h3>
<figure data-type="image" tabindex="6"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707173524.png" alt="" loading="lazy"></figure>
<p>Redis 的哈希是键值对的集合。 Redis 的哈希值是字符串字段和字符串值之间的映射，因此它们被用来表示对象<br>
示例：<br>
redis 127.0.0.1:6379&gt; hset key field value<br>
OK<br>
redis 127.0.0.1:6379&gt; hget key field<br>
value<br>
hset 存储一个哈希键值对的集合<br>
hset key field value</p>
<p>hget 获取一个哈希键的值<br>
hget key field</p>
<p>hmset 存储一个或多个哈希是键值对的集合<br>
hmset key field1 value1 ......fieldN keyN</p>
<p>hmget 获取多个指定的键的值<br>
hmget key field1 ... fieldN</p>
<figure data-type="image" tabindex="7"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707173657.png" alt="" loading="lazy"></figure>
<h3 id="33-list链表">3.3  List(链表)</h3>
<figure data-type="image" tabindex="8"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707220524.png" alt="" loading="lazy"></figure>
<p>Redis 的链表是简单的字符串列表，排序插入顺序。您可以添加元素到 Redis 的列表的<br>
头部或尾部<br>
示例：<br>
redis 127.0.0.1:6379&gt; lpush tutoriallist redis<br>
(integer) 1<br>
redis 127.0.0.1:6379&gt; lpush tutoriallist mongodb<br>
(integer) 2<br>
redis 127.0.0.1:6379&gt; lpush tutoriallist rabitmq<br>
(integer) 3<br>
redis 127.0.0.1:6379&gt; lrange tutoriallist 0 10</p>
<ol>
<li>&quot;rabitmq&quot;</li>
<li>&quot;mongodb&quot;</li>
<li>&quot;redis<br>
lpush key value 向链表左侧添加<br>
rpush key value 向链表右侧添加<br>
lpop key 从左边移出一个元素<br>
rpop key 从右边移出一个元素</li>
</ol>
<figure data-type="image" tabindex="9"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707222122.png" alt="" loading="lazy"></figure>
<p>llen key 返回链表中元素的个数 相当于关系型数据库中 select count(*)<br>
lrange key start end lrange 命令将返回索引从 start 到 stop 之间的所有元素。Redis 的列表起始索引为 0。<br>
lrange 也支持负索引 lrange nn -2 -1 如 -1 表示最右边第一个元素 -2 表示最右边第二个元素，依次类推。<br>
lindex key indexnumber 如果要将列表类型当做数组来用，lindex 命令是必不可少的。<br>
lindex 命令用来返回指定索引的元素，索引从 0 开始，如果是负数表示从右边开始计算的索引，最右边元素的索引是-1。<br>
Lset key indexnumber value 是另一个通过索引操作列表的命令，它会将索引为 index的元素赋值为 value。</p>
<figure data-type="image" tabindex="10"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707222706.png" alt="" loading="lazy"></figure>
<h3 id="34-set集合">3.4 Set(集合)</h3>
<figure data-type="image" tabindex="11"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707223508.png" alt="" loading="lazy"></figure>
<p>Redis 的集合是字符串的无序不重复集合。<br>
示例：<br>
redis 127.0.0.1:6379&gt; sadd tutoriallist redis<br>
(integer) 1<br>
redis 127.0.0.1:6379&gt; sadd tutoriallist mongodb<br>
(integer) 1<br>
redis 127.0.0.1:6379&gt; sadd tutoriallist rabitmq<br>
(integer) 1<br>
redis 127.0.0.1:6379&gt; sadd tutoriallist rabitmq<br>
(integer) 0<br>
redis 127.0.0.1:6379&gt; smembers tutoriallist</p>
<ol>
<li>&quot;rabitmq&quot;</li>
<li>&quot;mongodb&quot;</li>
<li>&quot;redis&quot;</li>
</ol>
<p>sadd key value 添加一个 string 元素到,key 对应的 set 集合中，成功返回 1,如果元素已经在集合中返回 0<br>
scard key 返回 set 的元素个数，如果 set 是空或者 key 不存在返回 0<br>
smembers key 返回 key 对应 set 的所有元素，结果是无序的<br>
sismember key value 判断 value 是否在 set 中，存在返回 1，0 表示不存在或者 key 不存在<br>
srem key value 从 key 对应 set 中移除给定元素，成功返回 1，如果 value 在集合中不存在或者 key 不存在返回 0</p>
<figure data-type="image" tabindex="12"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707223554.png" alt="" loading="lazy"></figure>
<h3 id="35-sortedset有序集合zset">3.5  SortedSet(有序集合)zset</h3>
<p>Redis 的有序集合类似于 Redis 的集合，字符串不重复的集合。<br>
示例：<br>
redis 127.0.0.1:6379&gt; zadd tutoriallist 0 redis<br>
(integer) 1<br>
redis 127.0.0.1:6379&gt; zadd tutoriallist 0 mongodb<br>
(integer) 1<br>
redis 127.0.0.1:6379&gt; zadd tutoriallist 0 rabitmq<br>
(integer) 1<br>
redis 127.0.0.1:6379&gt; zadd tutoriallist 0 rabitmq<br>
(integer) 0<br>
redis 127.0.0.1:6379&gt; ZRANGEBYSCORE tutoriallist 0 1000</p>
<ol>
<li>&quot;redis&quot;</li>
<li>&quot;mongodb&quot;</li>
<li>&quot;rabitmq&quot;</li>
</ol>
<p>zadd key score value 将一个或多个 value 及其 socre 加入到 set 中<br>
zrange key start end 0 和-1 表示从索引为 0 的元素到最后一个元素（同 LRANGE 命令相似）</p>
<p>zrange key 0 -1 withscores 也可以连同 score 一块输出，使用 WITHSCORES 参数<br>
zremrangebyscore key start end 可用于范围删除操作</p>
<figure data-type="image" tabindex="13"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200707224101.png" alt="" loading="lazy"></figure>
<h3 id="36-redis-中的其他命令">3.6 Redis 中的其他命令</h3>
<p>ping 测试 redis 是否链接 如果已链接返回 PONG<br>
echo value 测试 redis 是否链接 如果已链接返回 echo 命令后给定的值<br>
keys * 返回所有的 key 可以加*通配<br>
exists key 判断 string 类型一个 key 是否存在 如果存在返回 1 否则返回 0<br>
expire key time(s) 设置一个 key 的过期时间 单位秒。时间到达后会删除 key 及 value<br>
ttl key 查询已设置过期时间的 key 的剩余时间 如果返回-2 表示该键值对已经被删除<br>
persist 移除给定 key 的过期时间<br>
select dbindex 选择数据库(0-15)<br>
move key dbIndex 将当前数据库中的 key 转移到其他数据库中<br>
dbsize 返回当前数据库中的 key 的数目<br>
info 获取服务器的信息和统计<br>
flushdb 删除当前选择的数据库中的 key<br>
flushall 删除所有数据库中的所有 key<br>
quit 退出连接</p>
<h2 id="4-redis-的配置以及持久化方案">4、Redis 的配置以及持久化方案</h2>
<h3 id="41-redisconf-文件">4.1 redis.conf 文件</h3>
<pre><code class="language-properties">#redis.conf
# Redis configuration file example.
# ./redis-server /path/to/redis.conf
################################## INCLUDES
###################################
#这在你有标准配置模板但是每个 redis 服务器又需要个性设置的时候很有用。
# include /path/to/local.conf
# include /path/to/other.conf
################################ GENERAL #####################################
#是否在后台执行，yes：后台运行；no：不是后台运行（老版本默认）
daemonize yes
#3.2 里的参数，是否开启保护模式，默认开启。要是配置里没有指定 bind 和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。要是开启了密码 和 bind，可以开启。否 则最好关闭，设置为no。
protected-mode yes
#redis 的进程文件
pidfile /var/run/redis/redis-server.pid
#redis 监听的端口号。
port 6379
#此参数确定了 TCP 连接中已完成队列(完成三次握手之后)的长度， 当然此值必须不大于 Linux 系统定
义的/proc/sys/net/core/somaxconn 值，默认是 511，而 Linux 的默认参数值是 128。当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。该内核参数默认值一般是 128，对于负载很大的服务程序来说大大的不够。一般会将它修改为 2048 或者更大。在/etc/sysctl.conf 中添加:net.core.somaxconn = 2048，然后在终端中执行 sysctl -p。
tcp-backlog 511
#指定 redis 只接收来自于该 IP 地址的请求，如果不进行设置，那么将处理所有请求
#bind 127.0.0.1
#配置 unix socket 来让 redis 支持监听本地连接。
# unixsocket /var/run/redis/redis.sock
#配置 unix socket 使用文件的权限
# unixsocketperm 700
# 此参数为设置客户端空闲超过 timeout，服务端会断开连接，为 0 则服务端不会主动断开连接，不能小于 0。
timeout 0
#tcp keepalive 参数。如果设置不为 0，就使用配置 tcp 的 SO_KEEPALIVE 值，使用 keepalive 有两个好处:检测挂掉的对端。降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。在 Linux内核中，设置了 keepalive，redis 会定时给对端发送 ack。检测到对端关闭需要两倍的设置值。
tcp-keepalive 0
#指定了服务端日志的级别。级别包括：debug（很多信息，方便开发、测试），verbose（许多有用的信息，但是没有 debug 级别信息多），notice（适当的日志级别，适合生产环境），warn（只有非常重要的信息）
loglevel notice
#指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的 redis 标准输出是/dev/null。
logfile /var/log/redis/redis-server.log
#是否打开记录 syslog 功能
# syslog-enabled no
#syslog 的标识符。
# syslog-ident redis
#日志的来源、设备
# syslog-facility local0
#数据库的数量，默认使用的数据库是 DB 0。可以通过”SELECT “命令选择一个 db
databases 16
################################ SNAPSHOTTING ################################
# 快照配置
# 注释掉“save”这一行配置项就可以让保存数据库功能失效
# 设置 sedis 进行数据库镜像的频率。
# 900 秒（15 分钟）内至少 1 个 key 值改变（则进行数据库保存--持久化）
# 300 秒（5 分钟）内至少 10 个 key 值改变（则进行数据库保存--持久化）
# 60 秒（1 分钟）内至少 10000 个 key 值改变（则进行数据库保存--持久化）
save 900 1
save 300 10
save 60 10000
#当 RDB 持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过 info 中的 rdb_last_bgsave_status 了解 RDB 持久化是否有错误
stop-writes-on-bgsave-error yes
#使用压缩 rdb 文件，rdb 文件压缩使用 LZF 压缩算法，yes：压缩，但是需要一些 cpu 的消耗。no：不压缩，需要更多的磁盘空间
rdbcompression yes
#是否校验 rdb 文件。从 rdb 格式的第五个版本开始，在 rdb 文件的末尾会带上 CRC64 的校验和。这跟有利于文件的容错性，但是在保存 rdb 文件的时候，会有大概 10%的性能损耗，所以如果你追求高性能，可以关闭该配置。
rdbchecksum yes
#rdb 文件的名称
dbfilename dump.rdb
#数据目录，数据库的写入会在这个目录。rdb、aof 文件也会写在这个目录
dir /root/temp
################################# REPLICATION
#################################
#复制选项，slave 复制对应的 master。
# slaveof &lt;masterip&gt; &lt;masterport&gt;
#如果 master 设置了 requirepass，那么 slave 要连上 master，需要有 master 的密码才行。
masterauth 就是用来配置 master 的密码，这样可以在连上 master 后进行认证。
# masterauth &lt;master-password&gt;
#当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：1) 如果slave-serve-stale-data 设置为 yes(默认设置)，从库会继续响应客户端的请求。2) 如果slave-serve-stale-data 设置为 no，除去 INFO 和 SLAVOF 命令之外的任何请求都会返回一个错误”SYNC with master in progress”。
slave-serve-stale-data yes
#作为从服务器，默认情况下是只读的（yes），可以修改成 NO，用于写（不建议）。
slave-read-only yes
#是否使用 socket 方式复制数据。目前 redis 复制提供两种方式，disk 和 socket。如果新的 slave连上来或者重连的 slave 无法部分同步，就会执行全量同步，master 会生成 rdb 文件。有 2 种方式：disk 方式是 master 创建一个新的进程把 rdb 文件保存到磁盘，再把磁盘上的 rdb 文件传递给 slave。socket 是 master 创建一个新的进程，直接把 rdb 文件以 socket 的方式发给 slave。disk 方式的时候，当一个 rdb 保存的过程中，多个 slave 都能共享这个 rdb 文件。socket 的方式就的一个个 slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用 socket 方式。
repl-diskless-sync no
#diskless 复制的延迟时间，防止设置为 0。一旦复制开始，节点不会再接收新 slave 的复制请求直到下一个 rdb 传输。所以最好等待一段时间，等更多的 slave 连上来。
repl-diskless-sync-delay 5
#slave 根据指定的时间间隔向服务器发送 ping 请求。时间间隔可以通过repl_ping_slave_period来设置，默认 10 秒。
# repl-ping-slave-period 10
#复制连接超时时间。master 和 slave 都有超时时间的设置。master 检测到 slave 上次发送的时间超过 repl-timeout，即认为 slave 离线，清除该 slave 信息。slave 检测到上次和 master 交互的时间超过 repl-timeout，则认为 master 离线。需要注意的是 repl-timeout 需要设置一个比repl-ping-slave-period 更大的值，不然会经常检测到超时。
# repl-timeout 60
#是否禁止复制 tcp 链接的 tcp nodelay 参数，可传递 yes 或者 no。默认是 no，即使用 tcp nodelay。如果 master 设置了 yes 来禁止 tcp nodelay 设置，在把数据复制给 slave 的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择 yes。
repl-disable-tcp-nodelay no
#复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。这样在 slave 离线的时候，不需要完全复制 master 的数据，如果可以执行部分同步，只需要把缓冲区的部分数据复制给 slave，就能恢复正常复制状态。缓冲区的大小越大，slave 离线的时间可以更长，复制缓冲区只有在有 slave 连接的时候才分配内存。没有 slave 的一段时间，内存会被释放出来，默认 1m。
# repl-backlog-size 5mb
#master 没有 slave 一段时间会释放复制缓冲区的内存，repl-backlog-ttl 用来设置该时间长度。
单位为秒。
# repl-backlog-ttl 3600
#当 master 不可用，Sentinel 会根据 slave 的优先级选举一个 master。最低的优先级的 slave，当选 master。而配置成 0，永远不会被选举。
slave-priority 100
#redis 提供了可以让 master 停止写入的方式，如果配置了 min-slaves-to-write，健康的 slave的个数小于 N，mater 就禁止写入。master 最少得有多少个健康的 slave 存活才能执行写命令。这个配置虽然不能保证 N 个 slave 都一定能接收到 master 的写操作，但是能避免没有足够健康的 slave 的时候，master 不能写入来避免数据丢失。设置为 0 是关闭该功能。
# min-slaves-to-write 3
#延迟小于 min-slaves-max-lag 秒的 slave 才认为是健康的 slave。
# min-slaves-max-lag 10
# 设置 1 或另一个设置为 0 禁用这个特性。
# Setting one or the other to 0 disables the feature.
# By default min-slaves-to-write is set to 0 (feature disabled) and
# min-slaves-max-lag is set to 10.
################################## SECURITY
###################################
#requirepass 配置可以让用户使用 AUTH 命令来认证密码，才能使用其他命令。这让 redis 可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户也不需要认证。使用requirepass 的时候需要注意，因为 redis 太快了，每秒可以认证 15w 次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。
# requirepass foobared
#把危险的命令给修改成其他名称。比如 CONFIG 命令可以重命名为一个很难被猜到的命令，这样用户不能使用，而内部工具还能接着使用。
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#设置成一个空的值，可以禁止一个命令
# rename-command CONFIG &quot;&quot;
################################### LIMITS
####################################
# 设置能连上 redis 的最大客户端连接数量。默认是 10000 个客户端连接。由于 redis 不区分连接是客户端连接还是内部打开文件或者和 slave 连接等，所以 maxclients 最小建议设置到 32。如果超过了maxclients，redis 会给新的连接发送’max number of clients reached’，并关闭连接。
# maxclients 10000
#redis 配置的最大内存容量。当内存满了，需要配合 maxmemory-policy 策略进行处理。注意 slave的输出缓冲区是不计算在 maxmemory 内的。所以为了防止主机内存使用完，建议设置的 maxmemory 需要更小一些。
# maxmemory &lt;bytes&gt;
#内存容量超过 maxmemory 后的处理策略。
#volatile-lru：利用 LRU 算法移除设置过过期时间的 key。
#volatile-random：随机移除设置过过期时间的 key。
#volatile-ttl：移除即将过期的 key，根据最近过期时间来删除（辅以 TTL）
#allkeys-lru：利用 LRU 算法移除任何 key。
#allkeys-random：随机移除任何 key。
#noeviction：不移除任何 key，只是返回一个写错误。
#上面的这些驱逐策略，如果 redis 没有合适的 key 驱逐，对于写命令，还是会返回错误。redis 将不再接收写请求，只接收 get 请求。写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。
# maxmemory-policy noeviction
#lru 检测的样本数。使用 lru 或者 ttl 淘汰算法，从需要淘汰的列表中随机选择 sample 个 key，选出闲置时间最长的 key 移除。
# maxmemory-samples 5
############################## APPEND ONLY MODE ###############################
#默认 redis 使用的是 rdb 方式持久化，这种方式在许多应用中已经足够用了。但是 redis 如果中途宕机，会导致可能有几分钟的数据丢失，根据 save 来策略进行持久化，Append Only File 是另一种持久化方式，可以提供更好的持久化特性。Redis 会把每次写入的数据在接收后都写入 appendonly.aof文件，每次启动时 Redis 都会先把这个文件的数据读入内存里，先忽略 RDB 文件。
appendonly no
#aof 文件名
appendfilename &quot;appendonly.aof&quot;
#aof 持久化策略的配置
#no 表示不执行 fsync，由操作系统保证数据同步到磁盘，速度最快。
#always 表示每次写入都执行 fsync，以保证数据同步到磁盘。
#everysec 表示每秒执行一次 fsync，可能会导致丢失这 1s 数据。
appendfsync everysec
# 在 aof 重写或者写入 rdb 文件的时候，会执行大量 IO，此时对于everysec 和 always 的 aof 模式来说，执行 fsync 会造成阻塞过长时间，no-appendfsync-on-rewrite 字段设置为默认设置为 no。如果对延迟要求很高的应用，这个字段可以设置为 yes，否则还是设置为 no，这样对持久化特性来说这是更安全的选择。设置为 yes 表示 rewrite 期间对新写操作不 fsync,暂时存在内存中,等 rewrite 完成后再写入，默认为 no，建议 yes。Linux 的默认 fsync 策略是 30 秒。可能丢失 30 秒数据。
no-appendfsync-on-rewrite no
#aof 自动重写配置。当目前 aof 文件大小超过上一次重写的 aof 文件大小的百分之多少进行重写，即当aof 文件增长到一定大小的时候 Redis 能够调用 bgrewriteaof 对日志文件进行重写。当前 AOF 文件大小是上次日志重写得到 AOF 文件大小的二倍（设置为 100）时，自动启动新的日志重写过程。
auto-aof-rewrite-percentage 100
#设置允许重写的最小 aof 文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写
auto-aof-rewrite-min-size 64mb
#aof 文件可能在尾部是不完整的，当 redis 启动的时候，aof 文件的数据被载入内存。重启可能发生在redis 所在的主机操作系统宕机后，尤其在 ext4 文件系统没有加上 data=ordered 选项（redis 宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，可以选择让 redis 退出，或者导入尽可能多的数据。如果选择的是 yes，当截断的 aof 文件被导入的时候，会自动发布一个 log 给客户端然后 load。如果是 no，用户必须手动 redis-check-aof 修复 AOF 文件才可以。
aof-load-truncated yes
################################ LUA SCRIPTING ###############################
# 如果达到最大时间限制（毫秒），redis 会记个 log，然后返回 error。当一个脚本超过了最大时限。只有 SCRIPT KILL 和 SHUTDOWN NOSAVE 可以用。第一个可以杀没有调 write 命令的东西。要是已经调用了 write，只能用第二个命令杀。
lua-time-limit 5000
################################ REDIS CLUSTER ###############################
#集群开关，默认是不开启集群模式。
# cluster-enabled yes
#集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。这个文件并不需要手动配置，这个配置文件有 Redis 生成并更新，每个 Redis 集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突
# cluster-config-file nodes-6379.conf
#节点互连超时的阀值。集群节点超时毫秒数
# cluster-node-timeout 15000
#在进行故障转移的时候，全部 slave 都会请求申请为 master，但是有些 slave 可能与 master 断开连接一段时间了，导致数据过于陈旧，这样的 slave 不应该被提升为 master。该参数就是用来判断 slave节点与 master 断线的时间是否过长。判断方法是：
#比较 slave 断开连接的时间和(node-timeout * slave-validity-factor) +
repl-ping-slave-period
#如果节点超时时间为三十秒, 并且 slave-validity-factor 为 10,假设默认的repl-ping-slave-period 是 10 秒，即如果超过 310 秒 slave 将不会尝试进行故障转移
# cluster-slave-validity-factor 10
#master 的 slave 数量大于该值，slave 才能迁移到其他孤立 master 上，如这个参数若被设为 2，那么只有当一个主节点拥有 2 个可工作的从节点时，它的一个从节点会尝试迁移。
# cluster-migration-barrier 1
#默认情况下，集群全部的 slot 有节点负责，集群状态才为 ok，才能提供服务。设置为 no，可以在 slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的 master 一直在接受写请求，而造成很长时间数据不一致。
# cluster-require-full-coverage yes
################################## SLOW LOG
###################################
###slog log 是用来记录 redis 运行中执行比较慢的命令耗时。当命令的执行超过了指定时间，就记录在 slow log 中，slog log 保存在内存中，所以没有 IO 操作。
#执行时间比 slowlog-log-slower-than 大的请求记录到 slowlog 里面，单位是微秒，所以 1000000就是 1 秒。注意，负数时间会禁用慢查询日志，而 0 则会强制记录所有命令。
slowlog-log-slower-than 10000
#慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存。
slowlog-max-len 128
################################ LATENCY MONITOR
##############################
#延迟监控功能是用来监控 redis 中执行比较缓慢的一些操作，用 LATENCY 打印 redis 实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。0 的话，就是关闭监视。默认延迟监控功能是关闭的，如果你需要打开，也可以通过 CONFIG SET 命令动态设置。
latency-monitor-threshold 0
############################# EVENT NOTIFICATION
##############################
#键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。
#notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：
##K 键空间通知，所有通知以 __keyspace@__ 为前缀
##E 键事件通知，所有通知以 __keyevent@__ 为前缀
##g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知
##$ 字符串命令的通知
##l 列表命令的通知
##s 集合命令的通知
##h 哈希命令的通知
##z 有序集合命令的通知
##x 过期事件：每当有过期键被删除时发送
##e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送
##A 参数 g$lshzxe 的别名
#输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考 http://redis.io/topics/notifications
notify-keyspace-events &quot;&quot;
############################### ADVANCED CONFIG
###############################
#数据量小于等于 hash-max-ziplist-entries 的用 ziplist，大于 hash-max-ziplist-entries用 hash
hash-max-ziplist-entries 512 #value 大小小于等于 hash-max-ziplist-value 的用ziplist，大于 hash-max-ziplist-value 用 hash。
hash-max-ziplist-value 64
#数据量小于等于 list-max-ziplist-entries 用 ziplist，大于 list-max-ziplist-entries用 list。
list-max-ziplist-entries 512#value 大小小于等于 list-max-ziplist-value 的用ziplist，大于 list-max-ziplist-value 用 list。
list-max-ziplist-value 64
#数据量小于等于 set-max-intset-entries 用 iniset，大于 set-max-intset-entries 用 set。
set-max-intset-entries 512
#数据量小于等于 zset-max-ziplist-entries 用 ziplist，大于 zset-max-ziplist-entries用 zset。
zset-max-ziplist-entries 128#value 大小小于等于 zset-max-ziplist-value 用 ziplist，大于 zset-max-ziplist-value 用 zset。
zset-max-ziplist-value 64
#value 大小小于等于 hll-sparse-max-bytes 使用稀疏数据结构（sparse），大于hll-sparse-max-bytes 使用稠密的数据结构（dense）。一个比 16000 大的 value 是几乎没用的，建议的 value 大概为 3000。如果对 CPU 要求不高，对空间要求较高的，建议设置到 10000 左右。
hll-sparse-max-bytes 3000
#Redis 将在每 100 毫秒时使用 1 毫秒的 CPU 时间来对 redis 的 hash 表进行重新 hash，可以降低内存的使用。当你的使用场景中，有非常严格的实时性需要，不能够接受 Redis 时不时的对请求有 2 毫秒的延迟的话，把这项配置为 no。如果没有这么严格的实时性要求，可以设置为 yes，以便能够尽可能快的释放内存。
activerehashing yes
##对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。
#对于 normal client，第一个 0 表示取消 hard limit，第二个 0 和第三个 0 表示取消 soft limit，normal client 默认取消限制，因为如果没有寻问，他们是不会接收数据的。
client-output-buffer-limit normal 0 0 0#对于 slave client 和 MONITER client，如果client-output-buffer 一旦超过 256mb，又或者超过 64mb 持续 60 秒，那么服务器就会立即断开客户端连接。
client-output-buffer-limit slave 256mb 64mb 60#对于 pubsub client，如果client-output-buffer 一旦超过 32mb，又或者超过 8mb 持续 60 秒，那么服务器就会立即断开客户端连接。
client-output-buffer-limit pubsub 32mb 8mb 60
#redis 执行任务的频率为 1s 除以 hz。
hz 10
#在 aof 重写的时候，如果打开了 aof-rewrite-incremental-fsync 开关，系统会每 32MB 执行一次 fsync。这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值。
aof-rewrite-incremental-fsync yes
</code></pre>
<h3 id="42-redis-的数据持久化">4.2 Redis 的数据持久化</h3>
<h4 id="421-rdb-方式">4.2.1 RDB 方式</h4>
<p>对内存中数据库状态进行快照<br>
RDB 方式：将 Redis 在内存中的数据库状态保存到磁盘里面，RDB 文件是一个经过压缩的二进制文件，通过该文件可以还原生成 RDB 文件时的数据库状态（默认下，持久化到dump.rdb 文件，并且在 redis 重启后，自动读取其中文件，据悉，通常情况下一千万的字符串类型键，1GB 的快照文件，同步到内存中的 时间是 20-30 秒）<br>
RDB 的生成方式：<br>
1）执行命令手动生成<br>
有两个 Redis 命令可以用于生成 RDB 文件，一个是 SAVE，另一个是 BGSAVE SAVE命令会阻塞 Redis 服务器进程，直到 RDB 文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求，BGSAVE 命令会派生出一个子进程，然后由子进程负责创建RDB 文件，服务器进程（父进程）继续处理命令请求，创建 RDB 文件结束之前，客户端发送的 BGSAVE 和 SAVE 命令会被服务器拒绝<br>
2）通过配置自动生成<br>
可以设置服务器配置的 save 选项，让服务器每隔一段时间自动执行一次 <strong>BGSAVE</strong> 命令，可以通过 save 选项设置多个保存条件，但只要其中任意一个条件被满足，服务器就会执行 BGSAVE 命令<br>
例如：<br>
save 900 1<br>
save 300 10<br>
save 60 10000<br>
那么只要满足以下三个条件中的任意一个，BGSAVE 命令就会被执行<br>
服务器在 900 秒之内，对数据库进行了至少 1 次修改<br>
服务器在 300 秒之内，对数据库进行了至少 10 次修改<br>
服务器在 60 秒之内，对数据库进行了至少 10000 次修改</p>
<h4 id="422-aof-方式">4.2.2 AOF 方式</h4>
<p>AOF 持久化方式在 redis 中默认是关闭的，需要修改配置文件开启该方式。<br>
AOF：把每条命令都写入文件，类似 mysql 的 binlog 日志<br>
AOF 方式：是通过保存 Redis 服务器所执行的写命令来记录数据库状态的文件。<br>
AOF 文件刷新的方式，有三种：<br>
appendfsync always - 每提交一个修改命令都调用 fsync 刷新到 AOF 文件，非常非常慢，但也非常安全<br>
appendfsync everysec - 每秒钟都调用 fsync 刷新到 AOF 文件，很快，但可能会丢失一秒以内的数据<br>
appendfsync no - 依靠 OS 进行刷新，redis 不主动刷新 AOF，这样最快，但安全性就差<br>
默认并推荐每秒刷新，这样在速度和安全上都做到了兼顾</p>
<p>AOF 数据恢复方式<br>
服务器在启动时，通过载入和执行 AOF 文件中保存的命令来还原服务器关闭之前的数据库状态，具体过程：</p>
<ul>
<li>载入 AOF 文件</li>
<li>创建模拟客户端</li>
<li>从 AOF 文件中读取一条命令</li>
<li>使用模拟客户端执行命令</li>
<li>循环读取并执行命令，直到全部完成</li>
<li>如果同时启用了 RDB 和 AOF 方式，AOF 优先，启动时只加载 AOF 文件恢复数据</li>
</ul>
<h2 id="5-安装-redis-集群">5、安装 Redis 集群</h2>
<h3 id="51-redis-集群介绍">5.1 Redis 集群介绍</h3>
<p>​		Redis3.0 版本之后支持 Cluster。<strong>集群要求集群节点中必须要支持主备模式，也就说集中的主节点(Master)至少要有一个从节点(Slave)</strong><br>
​		每一个蓝色的圈都代表着一个 redis 集群中的主节点。它们任何两个节点之间都是相互连通的。客户端可以与任何一个节点相连接，然后就可以访问集群中的任何一个节点。对其进行存取和其他操作</p>
<h4 id="511-redis-cluster-架构图">5.1.1 Redis-Cluster 架构图</h4>
<figure data-type="image" tabindex="14"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708010154.png" alt="" loading="lazy"></figure>
<h4 id="512-redis-cluster-选举容错">5.1.2 Redis-Cluster 选举:容错</h4>
<p>​		Redis 之间通过互相的 ping-pong 判断是否节点可以连接上。如果有一半以上的节点去ping 一个节点的时候没有回应，集群就认为这个节点宕机了，然后去连接它的从节点。如果某个节点和所有从节点全部挂掉，我们集群就进入 fail 状态。还有就是如果有一半以上的主节点宕机，那么我们集群同样进入 fail 了状态。这就是我们的 redis 的投票机制，具体原理如下图所示：</p>
<figure data-type="image" tabindex="15"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708010227.png" alt="" loading="lazy"></figure>
<p>投票过程是集群中所有 master 参与,如果半数以上 master 节点与 master 节点通信超时(cluster-node-timeout),认为当前 master 节点挂掉.<br>
什么时候整个集群不可用(cluster_state:fail)?</p>
<ol>
<li>如果集群任意 master 挂掉,且当前 master 没有 slave。此时集群进入 fail 状态,也可以理解成集群的 slot 映射[0-16383]不完整时进入 fail 状态。</li>
<li>如果集群超过半数以上 master 挂掉，无论是否有 slave，集群进入 fail 状态.</li>
</ol>
<h4 id="513-redis-cluster-数据存储">5.1.3 Redis-Cluster 数据存储</h4>
<p>​		当我们的存取的 key 到达的时候，redis 会根据 crc16 的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。</p>
<figure data-type="image" tabindex="16"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708010312.png" alt="" loading="lazy"></figure>
<p>例如：在 Node1 执行 set name kevin</p>
<ol>
<li>使用 CRC16 算法对 key 进行计算，得到一个数字，然后对数字进行取余。<br>
CRC16 : name = 26384<br>
26384%16384 = 10000</li>
<li>查找到包含 10000 插槽的节点，比如是 node2，自动跳转到 node2</li>
<li>在 node2 上执行 set name kevin 命令完成数据的插入</li>
<li>如果在 node1 上执行 get name，先使用 CRC16 算法对 key 进行计算，在使用16384 取余，得到插槽的下标，然后跳到拥有该插槽的 node2 中执行 get name 命令，并返回结果。</li>
</ol>
<h3 id="52-安装集群">5.2 安装集群</h3>
<h4 id="521-需求">5.2.1 需求</h4>
<p>搭建一个 Redis 的最小集群，使用伪集群方式。<br>
Redis 中最小的集群三对主从。<br>
在 192.168.0.179 中安装 6 个 redis 实例。<br>
如果使用已经使用过的单机版创建集群时，需要删除 dump.rdb 与 apeendonly.aof 文件。<br>
6 个 redis 实例的端口分配：8001、8002、8003、8004、8005、8006</p>
<h4 id="522-集群步骤">5.2.2 集群步骤</h4>
<p>redis 集群时需要使用一个 ruby 的脚本来完成集群。</p>
<p>第一步 安装 ruby 环境<br>
命令： yum install ruby</p>
<p>第二步 安装 ruby 的包管理器<br>
命令：yum install rubygems</p>
<p>第三步 进入到 redis 的安装目录下的 src 目录下找到到 redis-trib.rb 这个文件 这是集群时需要的脚本</p>
<p>第四步 这个脚本的执行需要依赖于一些其他的 ruby 包 所以我们还要下载一个<br>
redis-3.0.0.gem<br>
将这个文件上传到 linux 服务器中</p>
<p>第五步 安装这个 ruby 包<br>
命令：gem install redis-3.0.0.gem</p>
<p>第六步 先启动 redis 的 6 个实例<br>
先在 local 目录下创建一个目录名称为：redis-cluster<br>
命令：mkdir redis-cluster</p>
<p>第七步 将安装好的 redis 下的 bin 目录拷贝到 redis-cluster 目录下 并起名为 redis01<br>
命令：进入到 redis 目录下执行：cp -r bin ../redis-cluster/redis01</p>
<p>第九步 修改 redis.conf 配置文件<br>
命令：vim redis.conf<br>
(1)修改端口：默认的为 6379 将六个 redis 实例的端口改成从 7001-7006 在配置文件<br>
的 port 属性中。<br>
(2)修改开启集群 在配置文件中搜索 cluster 找到后 将默认为注释的 cluster-enabled yes 去掉注释</p>
<p>第十步 将这个 redis01 拷贝 6 份到当前这个目录下<br>
命令：cp -r redis01/ redis02<br>
cp -r redis01/ redis03<br>
cp -r redis01/ redis04<br>
cp -r redis01/ redis05<br>
cp -r redis01/ redis06</p>
<p>第十一步 修改拷贝的这些 redis 的端口<br>
命令：<br>
[root@localhost redis-cluster]# vim redis02/redis.conf<br>
[root@localhost redis-cluster]# vim redis03/redis.conf<br>
[root@localhost redis-cluster]# vim redis04/redis.conf<br>
[root@localhost redis-cluster]# vim redis05/redis.conf<br>
[root@localhost redis-cluster]# vim redis06/redis.conf</p>
<figure data-type="image" tabindex="17"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708011226.png" alt="" loading="lazy"></figure>
<p>第十二步 把创建集群的 ruby 脚本复制到 redis-cluster 中<br>
命令：[root@localhost src]# cp *.rb /usr/local/redis-cluster/</p>
<p>第十二步 创建一个能够批量启动的脚本程序<br>
命令：vim startall.sh</p>
<p>第十三步 在脚本文件中添加命令<br>
命令：</p>
<p>cd redis01<br>
./redis-server redis.conf<br>
cd ..<br>
cd redis02<br>
./redis-server redis.conf<br>
cd ..<br>
cd redis03<br>
./redis-server redis.conf<br>
cd ..<br>
cd redis04<br>
./redis-server redis.conf<br>
cd ..<br>
cd redis05<br>
./redis-server redis.conf<br>
cd ..<br>
cd redis06<br>
./redis-server redis.conf<br>
cd ..</p>
<p>第十四步 将批量启动脚本设置为可执行权限<br>
命令:chmod +x startall.sh</p>
<p>第十五步 执行这个批量启动的脚本<br>
命令：[root@localhost redis-cluster]# ./startall.sh</p>
<p>第十六步 查看 redis 是否启动成功<br>
命令：ps aux|grep redis</p>
<figure data-type="image" tabindex="18"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708013049.png" alt="" loading="lazy"></figure>
<p>第十七步 创建集群<br>
命 令 ： ./redis-trib.rb create --replicas 1 192.168.0.179:8001 192.168.0.179:8002 192.168.0.179:8003 192.168.0.179:8004 192.168.0.179:8005 192.168.0.179:8006</p>
<figure data-type="image" tabindex="19"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708013922.png" alt="" loading="lazy"></figure>
<p>如果控制台输出如下信息表集群成功</p>
<figure data-type="image" tabindex="20"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708014103.png" alt="" loading="lazy"></figure>
<p>测试 Redis 集群<br>
测试 Redis 集群：可以连接集群中的任意一个节点进行测试 注意一定要有-c 参数，否则能连上，但是无法操作 redis 集群<br>
命令：[root@localhost redis-cluster]# ./redis01/redis-cli -h 192.168.0.179 -p 8001 -c</p>
<p>关闭 Redis 集群<br>
命令：./redis-cli -h 192.168.0.179 -p 8001 shutdown</p>
<p>也可以编写一个批量关闭的脚本<br>
命令：vim shutdown.sh<br>
redis01 /redis-cli -h 192.168.0.179 -p 8001 shutdown<br>
redis02 /redis-cli -h 192.168.0.179 -p 8002 shutdown<br>
redis03 /redis-cli -h 192.168.0.179 -p 8003 shutdown<br>
redis04 /redis-cli -h 192.168.0.179 -p 8004 shutdown<br>
redis05 /redis-cli -h 192.168.0.179 -p 8005 shutdown<br>
redis06 /redis-cli -h 192.168.0.179 -p 8006 shutdown</p>
<h2 id="6-使用-jedisapi-操作-redis">6、使用 JedisAPI 操作 Redis</h2>
<p>Jedis 集成了 redis 的一些命令操作，封装了对 redis 命令的 Java 客户端。</p>
<h3 id="61-使用-jedis-操作-redis-单机版">6.1 使用 Jedis 操作 Redis 单机版</h3>
<ol>
<li>创建工程</li>
<li>修改 POM 文件添加 Jedis 坐标</li>
</ol>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.cy&lt;/groupId&gt;
    &lt;artifactId&gt;JedisDemo&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;redis.clients&lt;/groupId&gt;
            &lt;artifactId&gt;jedis&lt;/artifactId&gt;
            &lt;version&gt;2.9.0&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
</code></pre>
<ol start="3">
<li>测试 Jedis 操作 Redis 单机版</li>
</ol>
<pre><code class="language-java">	/**
     * Jedis单机版测试
     */
    public static void testJedisSingle(){
        //创建一个Jedis对象
        Jedis jedis = new Jedis(&quot;124.70.181.124&quot;,6379);
        //调用Jedis的API完成对Redis的操作。在jedis中方法的命名与操作Redis的命令相同
        String result = jedis.set(&quot;key1&quot;, &quot;hello&quot;);
        System.out.println(result);
        String str = jedis.get(&quot;key1&quot;);
        System.out.println(str);
        System.out.println(&quot;--------------------------&quot;);
        Long rel = jedis.hset(&quot;user&quot;, &quot;username&quot;, &quot;cy&quot;);
        System.out.println(rel);
        String hrel = jedis.hget(&quot;user&quot;, &quot;username&quot;);
        System.out.println(hrel);
        jedis.close();

    }
</code></pre>
<ol start="4">
<li>测试使用连接池操作 Redis 单机版</li>
</ol>
<pre><code class="language-java">	/**
     * 使用连接池
     */
    public static void testJedisPool(){
        //创建连接池
        JedisPool pool = new JedisPool(&quot;124.70.181.124&quot;,6379);
        //取出实例
        Jedis jedis = pool.getResource();
        String s = jedis.hget(&quot;user&quot;, &quot;username&quot;);
        System.out.println(s);
        jedis.close();
    }

</code></pre>
<h3 id="62-使用-jedis-操作-redis-集群">6.2 使用 Jedis 操作 Redis 集群</h3>
<pre><code class="language-java"> 	/**
     * 集群测试
     */
    public static void testJedisCluster() throws IOException {
        //创建HostAndPort:集群中的的一个节点
        Set&lt;HostAndPort&gt; nodes=new HashSet&lt;&gt;();
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8001));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8002));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8003));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8004));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8005));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8006));
        // 创建操作集群的jedis对象
        JedisCluster jedisCluster = new JedisCluster(nodes);
        //在jedisCluster中方法的命名与操作Redis的命令相同
        jedisCluster.set(&quot;name&quot;,&quot;cy&quot;);
        String name = jedisCluster.get(&quot;name&quot;);
        System.out.println(name);
        jedisCluster.close();
    }
</code></pre>
<h2 id="7-spring-整合-jedis">7、Spring 整合 Jedis</h2>
<h3 id="71-整合单机版">7.1 整合单机版</h3>
<ol>
<li>创建工程</li>
<li>修改 POM 文件添加 Jedis 与 Spring 的坐标</li>
</ol>
<pre><code class="language-java">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;groupId&gt;com.bjsxt&lt;/groupId&gt;
  &lt;artifactId&gt;springJedisDemo&lt;/artifactId&gt;
  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
  
  &lt;dependencies&gt;
		&lt;dependency&gt;
			&lt;groupId&gt;redis.clients&lt;/groupId&gt;
			&lt;artifactId&gt;jedis&lt;/artifactId&gt;
			&lt;version&gt;2.9.0&lt;/version&gt;
		&lt;/dependency&gt;
		
		&lt;dependency&gt;
		        &lt;groupId&gt;org.springframework&lt;/groupId&gt;
				&lt;artifactId&gt;spring-context&lt;/artifactId&gt;
				&lt;version&gt;4.1.3.RELEASE&lt;/version&gt;
			&lt;/dependency&gt;
			&lt;dependency&gt;
				&lt;groupId&gt;org.springframework&lt;/groupId&gt;
				&lt;artifactId&gt;spring-beans&lt;/artifactId&gt;
				&lt;version&gt;4.1.3.RELEASE&lt;/version&gt;
			&lt;/dependency&gt;
	&lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>
<ol start="3">
<li>创建 JedisDao 接口与接口实现类</li>
</ol>
<p>JedisDao</p>
<pre><code class="language-java">public interface JedisDao {
	
	public String set(String key,String value);
	public String get(String key);
	public Long hset(String hkey,String key,String value);
	public String hget(String hkey,String key);
}

</code></pre>
<p>JedisDaoImplSingle</p>
<pre><code class="language-java">public class JedisDaoImplSingle implements JedisDao {
	
	@Autowired
	private JedisPool jedisPool;
	

	@Override
	public String set(String key, String value) {
		Jedis jedis = this.jedisPool.getResource();
		return jedis.set(key, value);
	}

	@Override
	public String get(String key) {
		Jedis jedis = this.jedisPool.getResource();
		return jedis.get(key);
	}

	@Override
	public Long hset(String hkey, String key, String value) {
		Jedis jedis = this.jedisPool.getResource();
		return jedis.hset(hkey, key, value);
	}

	@Override
	public String hget(String hkey, String key) {
		Jedis jedis = this.jedisPool.getResource();
		return jedis.hget(hkey, key);
	}
}

</code></pre>
<ol start="4">
<li>在 Spring 配置文件中整合 Jedis</li>
</ol>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
	xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot;
	xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
	xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;
	xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
        http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd
        http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;
	&lt;context:component-scan base-package=&quot;com.cy.jedisdao&quot;/&gt;
	&lt;!-- jedisPool的配置 --&gt;
	&lt;bean id=&quot;poolconfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt;
	        &lt;!-- 最大连接数 --&gt;
		&lt;property name=&quot;maxTotal&quot; value=&quot;30&quot; /&gt;
		&lt;!-- 最大空闲连接数 --&gt;
		&lt;property name=&quot;maxIdle&quot; value=&quot;10&quot; /&gt;
		&lt;!-- 每次释放连接的最大数目 --&gt;
		&lt;property name=&quot;numTestsPerEvictionRun&quot; value=&quot;1024&quot; /&gt;
		&lt;!-- 释放连接的扫描间隔（毫秒） --&gt;
		&lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;30000&quot; /&gt;
		&lt;!-- 连接最小空闲时间 --&gt;
		&lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;1800000&quot; /&gt;
		&lt;!-- 连接空闲多久后释放, 当空闲时间&gt;该值 且 空闲连接&gt;最大空闲连接数 时直接释放 --&gt;
		&lt;property name=&quot;softMinEvictableIdleTimeMillis&quot; value=&quot;10000&quot; /&gt;
		&lt;!-- 获取连接时的最大等待毫秒数,小于零:阻塞不确定的时间,默认-1 --&gt;
		&lt;property name=&quot;maxWaitMillis&quot; value=&quot;1500&quot; /&gt;
		&lt;!-- 在获取连接的时候检查有效性, 默认false --&gt;
		&lt;property name=&quot;testOnBorrow&quot; value=&quot;true&quot; /&gt;
		&lt;!-- 在空闲时检查有效性, 默认false --&gt;
		&lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt;
		&lt;!-- 连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认true --&gt;
		&lt;property name=&quot;blockWhenExhausted&quot; value=&quot;false&quot; /&gt;
	&lt;/bean&gt;
	&lt;!-- 配置JedidesPool --&gt;
	&lt;bean id=&quot;jedisPool&quot; class=&quot;redis.clients.jedis.JedisPool&quot;&gt;
		&lt;constructor-arg name=&quot;poolConfig&quot;&gt;
			&lt;ref bean=&quot;poolconfig&quot;/&gt;
		&lt;/constructor-arg&gt;
		&lt;constructor-arg name=&quot;host&quot;&gt;
			&lt;value&gt;124.70.181.124&lt;/value&gt;
		&lt;/constructor-arg&gt;
		&lt;constructor-arg name=&quot;port&quot;&gt;
			&lt;value&gt;6379&lt;/value&gt;
		&lt;/constructor-arg&gt;
	&lt;/bean&gt;
    	&lt;!-- JedisDaoImplSingle --&gt;
	&lt;bean id=&quot;jedisDaoImplSingle&quot; class=&quot;com.cy.jedisdao.impl.JedisDaoImplSingle&quot;&gt;&lt;/bean&gt; 
&lt;/beans&gt;
</code></pre>
<ol start="5">
<li>测试单机版</li>
</ol>
<p>public class Test {</p>
<pre><code class="language-java">public static void main(String[] args) {
	Test.testJedisSingle();
}

/**
 * 测试单机版Jedis
 */
public static void testJedisSingle(){
	ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;applicationContext-Jedis.xml&quot;);
	JedisDao jd = (JedisDao)ac.getBean(&quot;jedisDaoImplSingle&quot;);
	String str = jd.set(&quot;hello&quot;, &quot;Redis&quot;);
	System.out.println(str);
	String result = jd.get(&quot;hello&quot;);
	System.out.println(result);
}
}
</code></pre>
<h3 id="72-整合集群版">7.2 整合集群版</h3>
<ol>
<li>添加 JedisDao 实现类。基于 JedisCluster 的实现</li>
</ol>
<pre><code class="language-java">public class JedisDaoImplCluster implements JedisDao {

	@Autowired
	private JedisCluster jedisCluster;
	
	@Override
	public String set(String key, String value) {
		return this.jedisCluster.set(key, value);
	}

	@Override
	public String get(String key) {
		return this.jedisCluster.get(key);
	}

	@Override
	public Long hset(String hkey, String key, String value) {
		return this.jedisCluster.hset(hkey, key, value);
	}

	@Override
	public String hget(String hkey, String key) {
		return this.jedisCluster.hget(hkey, key);
	}

}
</code></pre>
<ol start="2">
<li>在 Spring 配置文件中整合 JedisCluster</li>
</ol>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
	xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot;
	xmlns:context=&quot;http://www.springframework.org/schema/context&quot;
	xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot;
	xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd
        http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd
        http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt;
	&lt;context:component-scan base-package=&quot;com.cy.jedisdao&quot;/&gt;
	&lt;!-- jedisPool的配置 --&gt;
	&lt;bean id=&quot;poolconfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt;
	        &lt;!-- 最大连接数 --&gt;
		&lt;property name=&quot;maxTotal&quot; value=&quot;30&quot; /&gt;
		&lt;!-- 最大空闲连接数 --&gt;
		&lt;property name=&quot;maxIdle&quot; value=&quot;10&quot; /&gt;
		&lt;!-- 每次释放连接的最大数目 --&gt;
		&lt;property name=&quot;numTestsPerEvictionRun&quot; value=&quot;1024&quot; /&gt;
		&lt;!-- 释放连接的扫描间隔（毫秒） --&gt;
		&lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;30000&quot; /&gt;
		&lt;!-- 连接最小空闲时间 --&gt;
		&lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;1800000&quot; /&gt;
		&lt;!-- 连接空闲多久后释放, 当空闲时间&gt;该值 且 空闲连接&gt;最大空闲连接数 时直接释放 --&gt;
		&lt;property name=&quot;softMinEvictableIdleTimeMillis&quot; value=&quot;10000&quot; /&gt;
		&lt;!-- 获取连接时的最大等待毫秒数,小于零:阻塞不确定的时间,默认-1 --&gt;
		&lt;property name=&quot;maxWaitMillis&quot; value=&quot;1500&quot; /&gt;
		&lt;!-- 在获取连接的时候检查有效性, 默认false --&gt;
		&lt;property name=&quot;testOnBorrow&quot; value=&quot;true&quot; /&gt;
		&lt;!-- 在空闲时检查有效性, 默认false --&gt;
		&lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt;
		&lt;!-- 连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认true --&gt;
		&lt;property name=&quot;blockWhenExhausted&quot; value=&quot;false&quot; /&gt;
	&lt;/bean&gt;
	&lt;!-- 配置JedidesPool --&gt;
	&lt;bean id=&quot;jedisPool&quot; class=&quot;redis.clients.jedis.JedisPool&quot;&gt;
		&lt;constructor-arg name=&quot;poolConfig&quot;&gt;
			&lt;ref bean=&quot;poolconfig&quot;/&gt;
		&lt;/constructor-arg&gt;
		&lt;constructor-arg name=&quot;host&quot;&gt;
			&lt;value&gt;124.70.181.124&lt;/value&gt;
		&lt;/constructor-arg&gt;
		&lt;constructor-arg name=&quot;port&quot;&gt;
			&lt;value&gt;6379&lt;/value&gt;
		&lt;/constructor-arg&gt;
	&lt;/bean&gt;
	&lt;!-- JedisDaoImplSingle --&gt;
	&lt;!-- &lt;bean id=&quot;jedisDaoImplSingle&quot; class=&quot;com.bjsxt.jedisdao.impl.JedisDaoImplSingle&quot;&gt;&lt;/bean&gt; --&gt;
	
	
	&lt;!-- JedislCluster --&gt;
     &lt;!-- 这里等同于做了
        创建HostAndPort:集群中的的一个节点
        Set&lt;HostAndPort&gt; nodes=new HashSet&lt;&gt;();
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8001));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8002));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8003));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8004));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8005));
        nodes.add(new HostAndPort(&quot;124.70.181.124&quot;,8006));
        创建操作集群的jedis对象
        JedisCluster jedisCluster = new JedisCluster(nodes);
        --&gt; 
	&lt;bean id=&quot;jedisCluster&quot; class=&quot;redis.clients.jedis.JedisCluster&quot;&gt;
		&lt;constructor-arg name=&quot;nodes&quot;&gt;
			&lt;set&gt;
				&lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;
					&lt;constructor-arg name=&quot;host&quot;&gt;
					 &lt;value&gt;124.70.181.124&lt;/value&gt;
					&lt;/constructor-arg&gt;
					&lt;constructor-arg name=&quot;port&quot;&gt;
					  &lt;value&gt;8001&lt;/value&gt;
					&lt;/constructor-arg&gt;
				&lt;/bean&gt;
				&lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;
					&lt;constructor-arg name=&quot;host&quot;&gt;
					 &lt;value&gt;124.70.181.124&lt;/value&gt;
					&lt;/constructor-arg&gt;
					&lt;constructor-arg name=&quot;port&quot;&gt;
					  &lt;value&gt;8002&lt;/value&gt;
					&lt;/constructor-arg&gt;
				&lt;/bean&gt;
				&lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;
					&lt;constructor-arg name=&quot;host&quot;&gt;
					 &lt;value&gt;124.70.181.124&lt;/value&gt;
					&lt;/constructor-arg&gt;
					&lt;constructor-arg name=&quot;port&quot;&gt;
					  &lt;value&gt;8003&lt;/value&gt;
					&lt;/constructor-arg&gt;
				&lt;/bean&gt;
				&lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;
					&lt;constructor-arg name=&quot;host&quot;&gt;
					 &lt;value&gt;124.70.181.124&lt;/value&gt;
					&lt;/constructor-arg&gt;
					&lt;constructor-arg name=&quot;port&quot;&gt;
					  &lt;value&gt;8004&lt;/value&gt;
					&lt;/constructor-arg&gt;
				&lt;/bean&gt;
				&lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;
					&lt;constructor-arg name=&quot;host&quot;&gt;
					 &lt;value&gt;124.70.181.124&lt;/value&gt;
					&lt;/constructor-arg&gt;
					&lt;constructor-arg name=&quot;port&quot;&gt;
					  &lt;value&gt;8005&lt;/value&gt;
					&lt;/constructor-arg&gt;
				&lt;/bean&gt;
				&lt;bean class=&quot;redis.clients.jedis.HostAndPort&quot;&gt;
					&lt;constructor-arg name=&quot;host&quot;&gt;
					 &lt;value&gt;124.70.181.124&lt;/value&gt;
					&lt;/constructor-arg&gt;
					&lt;constructor-arg name=&quot;port&quot;&gt;
					  &lt;value&gt;8006&lt;/value&gt;
					&lt;/constructor-arg&gt;
				&lt;/bean&gt;
			&lt;/set&gt;
		&lt;/constructor-arg&gt;
		&lt;constructor-arg name=&quot;poolConfig&quot;&gt;
			&lt;ref bean=&quot;poolconfig&quot;/&gt;
		&lt;/constructor-arg&gt;
	&lt;/bean&gt;
	
	&lt;!-- JedisDaoImplCluster --&gt;
	&lt;bean id=&quot;jedisDaoImplCluster&quot; class=&quot;com.cy.jedisdao.impl.JedisDaoImplCluster&quot;&gt;&lt;/bean&gt;
&lt;/beans&gt;
</code></pre>
<ol start="3">
<li>测试集群版</li>
</ol>
<pre><code class="language-java">public class Test {

	public static void main(String[] args) {
		//Test.testJedisSingle();
		Test.testJedisCluster();
	}

	/**
	 * 测试单机版Jedis
	 */
	public static void testJedisSingle(){
		ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;applicationContext-Jedis.xml&quot;);
		JedisDao jd = (JedisDao)ac.getBean(&quot;jedisDaoImplSingle&quot;);
		String str = jd.set(&quot;hello&quot;, &quot;Redis&quot;);
		System.out.println(str);
		String result = jd.get(&quot;hello&quot;);
		System.out.println(result);
	}
	
	/**
	 * 测试集群版Jedis
	 */
	public static void testJedisCluster(){
		ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;applicationContext-Jedis.xml&quot;);
		JedisDao jd = (JedisDao)ac.getBean(&quot;jedisDaoImplCluster&quot;);
		String str = jd.set(&quot;name&quot;, &quot;cy&quot;);
		System.out.println(str);
		String result = jd.get(&quot;name&quot;);
		System.out.println(result);
	}
}

</code></pre>
<h2 id="8-redis-desktop-manager-的使用">8、Redis Desktop Manager 的使用</h2>
<figure data-type="image" tabindex="21"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708143600.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="22"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708143629.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="23"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708143700.png" alt="" loading="lazy"></figure>
<h2 id="9-实战案例">9、实战案例</h2>
<ol>
<li>
<p>需求<br>
1）实现用户添加功能。<br>
2）实现用户查询功能，并使用 Redis 作为查询缓存。<br>
3）实现用户更新功能，同步缓存。</p>
</li>
<li>
<p>数据库的表结构</p>
</li>
</ol>
<pre><code class="language-mysql">CREATE TABLE `users` (
`userid` int(11) NOT NULL AUTO_INCREMENT,
`username` varchar(30) DEFAULT NULL,
`userage` int(11) DEFAULT NULL,
PRIMARY KEY (`userid`)
) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;
</code></pre>
<ol start="3">
<li>创建项目</li>
<li>修改 POM 文件</li>
</ol>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;

&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;com.cy&lt;/groupId&gt;
    &lt;artifactId&gt;usermanger&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;packaging&gt;war&lt;/packaging&gt;

    &lt;parent&gt;
        &lt;groupId&gt;com.cy&lt;/groupId&gt;
        &lt;artifactId&gt;redis-parent&lt;/artifactId&gt;
        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;/parent&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;redis.clients&lt;/groupId&gt;
            &lt;artifactId&gt;jedis&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- 单元测试 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- 日志处理 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- Mybatis --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- MySql --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- 连接池 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;druid&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- Spring --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-context&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-beans&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- JSP相关 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;jstl&lt;/groupId&gt;
            &lt;artifactId&gt;jstl&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;
            &lt;artifactId&gt;servlet-api&lt;/artifactId&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;
            &lt;artifactId&gt;jsp-api&lt;/artifactId&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;!-- Jackson Json处理工具包 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
            &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
            &lt;version&gt;${jackson.version}&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;resources&gt;
            &lt;resource&gt;
                &lt;directory&gt;src/main/java&lt;/directory&gt;
                &lt;includes&gt;
                    &lt;include&gt;**/*.xml&lt;/include&gt;
                &lt;/includes&gt;
            &lt;/resource&gt;
            &lt;resource&gt;
                &lt;directory&gt;src/main/resources&lt;/directory&gt;
                &lt;includes&gt;
                    &lt;include&gt;**/*.xml&lt;/include&gt;
                    &lt;include&gt;**/*.properties&lt;/include&gt;
                &lt;/includes&gt;
            &lt;/resource&gt;
        &lt;/resources&gt;
        &lt;!-- tomcat插件，由于子项目不一定每个都是web项目，所以该插件只是声明，并未开启 --&gt;
        &lt;plugins&gt;
            &lt;!-- 配置Tomcat插件 --&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt;
                &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;path&gt;/&lt;/path&gt;
                    &lt;port&gt;8080&lt;/port&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;

</code></pre>
<ol start="5">
<li>框架整合</li>
</ol>
<figure data-type="image" tabindex="24"><img src="https://gitee.com/chenyong1013/picCloud/raw/master/20200708164009.png" alt="" loading="lazy"></figure>
<ol start="6">
<li>
<p>添加用户</p>
</li>
<li>
<p>根据用户 ID 查询用户</p>
<ol>
<li>创建 findUser.jsp</li>
</ol>
<pre><code class="language-jsp">&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot;
    pageEncoding=&quot;UTF-8&quot;%&gt;
&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01 Transitional//EN&quot; &quot;http://www.w3.org/TR/html4/loose.dtd&quot;&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot;&gt;
&lt;title&gt;Insert title here&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
	&lt;form action=&quot;/user/findUserById&quot; method=&quot;post&quot;&gt;
		用户ID:&lt;input type=&quot;text&quot; name=&quot;userid&quot;/&gt;
		&lt;input type=&quot;submit&quot; value=&quot;OKOK&quot;/&gt;
	&lt;/form&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<ol start="2">
<li>UserMapper 与 UserMapper 映射配置文件</li>
</ol>
<p>UserMapper 接口</p>
<pre><code class="language-java">public interface UserMapper {

	public void insertUser(Users user);
	
	public List&lt;Users&gt; selectUserAll();
	
	Users findUserById(int userid);
	
	void updateUser(Users users);
}
</code></pre>
<p>映射配置文件</p>
<pre><code class="language-java">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;
&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot; &gt;
&lt;mapper namespace=&quot;com.bjsxt.mapper.UserMapper&quot; &gt;

  &lt;insert id=&quot;insertUser&quot; parameterType=&quot;com.bjsxt.pojo.Users&quot;&gt;
  		insert into users(username,userage) values(#{username},#{userage})
  &lt;/insert&gt;
  
  &lt;select id=&quot;selectUserAll&quot; resultType=&quot;com.bjsxt.pojo.Users&quot;&gt;
  		select * from users
  &lt;/select&gt;
  
  &lt;select id=&quot;findUserById&quot; resultType=&quot;com.bjsxt.pojo.Users&quot;&gt;
  		select * from users where userid = #{userid}
  &lt;/select&gt;
  
  &lt;select id=&quot;updateUser&quot; parameterType=&quot;com.bjsxt.pojo.Users&quot;&gt;
  		update users set username = #{username},userage = #{userage} where userid=#{userid}
  &lt;/select&gt;
&lt;/mapper&gt;
</code></pre>
<ol start="3">
<li>实现业务</li>
</ol>
<pre><code class="language-java">@Service
public class UserServiceImpl implements UserService {

	@Autowired
	private UserMapper userMapper;

	@Autowired
	private JedisDao jedisDao;

	@Value(&quot;${REDIS_USERS_PRIFX}&quot;)
	private String REDIS_USERS_PRIFX;

	@Override
	public void addUser(Users users) {
		this.userMapper.insertUser(users);
	}

	@Override
	public Users findUserById(int userid) {
        //先在redis中查询，如果没有再从数据库中查询并将查询结果放入redis中，并且返回user到controller
		try {
			// 查询缓存
			String json = this.jedisDao.get(this.REDIS_USERS_PRIFX + &quot;:&quot; + userid);
			// 在缓存中是否命中
			if (json != null &amp;&amp; json.length() &gt; 0) {
				System.out.println(&quot;.........................&quot;);
				Users user = JsonUtils.jsonToPojo(json, Users.class);
				return user;
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
		// 查询数据库
		Users user = this.userMapper.findUserById(userid);
		System.out.println(&quot;,,,,,,,,,,,,,,,,,,,,,,,,,,,,,&quot;);
		try {
			// 放入到redis中
			String res = JsonUtils.objectToJson(user);
			this.jedisDao.set(this.REDIS_USERS_PRIFX + &quot;:&quot; + userid, res);
			this.jedisDao.expire(this.REDIS_USERS_PRIFX + &quot;:&quot; + userid, 60);
		} catch (Exception e) {
			e.printStackTrace();
		}
		return user;
	}

	@Override
	public void updateUser(Users users) {
		this.userMapper.updateUser(users);
		try{
			//同步redis
			this.jedisDao.del(this.REDIS_USERS_PRIFX+&quot;:&quot;+users.getUserid());
		}catch(Exception e){
			e.printStackTrace();
		}
	}
}
</code></pre>
<ol start="4">
<li>controller</li>
</ol>
<pre><code class="language-java">@Controller
@RequestMapping(&quot;/user&quot;)
public class UserController {

	@Autowired
	private UserService userService;
	/**
	 * 添加用户
	 */
	@RequestMapping(&quot;/addUser&quot;)
	public String addUser(Users user){
		this.userService.addUser(user);
		return &quot;ok&quot;;
	}
	
	/**
	 * 根据用户ID查询用户
	 */
	@RequestMapping(&quot;/findUserById&quot;)
	public String showUser(Model model,int userid){
		Users users = this.userService.findUserById(userid);
		model.addAttribute(&quot;users&quot;, users);
		return &quot;showUser&quot;;
	}
	
	/**
	 * 更新用户
	 */
	@RequestMapping(&quot;/updateUser&quot;)
	public String updateUser(Users users){
		this.userService.updateUser(users);
		return &quot;ok&quot;;
	}
}
</code></pre>
</li>
</ol>
]]></content>
    </entry>
</feed>